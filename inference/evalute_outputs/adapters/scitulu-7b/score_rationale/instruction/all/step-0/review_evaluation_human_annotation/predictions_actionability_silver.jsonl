{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While it implies that the authors should conduct additional analysis, it does not specify what kind of analysis is needed or how to conduct it. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and outofcontext images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or outofcontext images. However, the comment lacks detailed evidence or references to support this claim, such as specific examples or studies that demonstrate the potential noise in artificially created datasets. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or outofcontext images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it suggested specific analyses or methods to evaluate the dataset\"s quality and noise level. Overall, the comment is 3 as it points out a relevant issue but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. The authors can infer that it relates to the theoretical analysis or results sections, but this inference is not direct. The comment is specific in identifying the lack of convergence properties and theory profs, but it is 1 as it does not explicitly mention which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is valuable as it highlights an area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending particular theoretical frameworks or methods to explore. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It implies that these options might be better alternatives to the ones chosen. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they should consider these alternatives but are not given clear instructions on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of operators and suggesting that the \"and\" operator or elementwise max might be better options. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. The reviewer suggests that these options might be better alternatives to the ones chosen. However, the comment lacks specific reasoning or evidence to support why these alternatives are better or how they relate to the current choices. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand and address the suggestion without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of operators in the paper, specifically asking why the authors did not consider the \"and\" operator or elementwise max. It suggests that these options might be better alternatives to the ones chosen, as they correspond to the ideas of union and intersection from the \"or\" operator and elementwise min. This feedback is 3 as it prompts the authors to reconsider their choices and potentially improve the clarity and effectiveness of their work. However, the comment could be more helpful if it provided specific examples or reasoning to support the suggestion, which would guide the authors in making more informed decisions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose of the reported duration and potentially include information about the time spent by the user waiting for the model to generate a response. While the action is implied, it is clear and concrete, as it guides the authors to provide a more detailed explanation or clarification in their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in Table 1 and requests a supporting explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests a supporting explanation. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification and does not present an argument or claim that needs justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights an area where the authors could provide more clarity and context for their readers. By asking for a clearer explanation, the comment prompts the authors to consider how their readers might interpret the reported duration and whether it includes time spent by the user waiting for the model to generate a response. This feedback is 3 as it identifies a potential gap in the paper that could be addressed to enhance its clarity and comprehensibility. However, it could be more helpful if it offered specific suggestions on how to provide the requested explanation or what additional context might be beneficial. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that the authors should correct the phrase \"on par or better\" to avoid a cognitive bias among NLP researchers. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The reviewer acknowledges that the experimental results are acceptable but recommends correcting the wording to avoid this bias. While the comment provides a clear and actionable suggestion for improving the clarity of the results, it could be more helpful if it offered specific alternative phrasing or examples of how to rephrase the sentence. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically asking how to interpret certain comparisons. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left to infer that they should clarify or explain these interpretations, but without guidance on how to do so, the comment lacks actionability. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the interpretation of results, particularly regarding the comparisons between Chinese MOSQ, NVSB, and GT Mel A, and the overlapping 95% CI for Baseline and NVSB in Chinese and English MOSV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and questions about the interpretation of results in Table 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results shown in Table 3, specifically regarding the comparisons between Chinese MOSQ, NVSB, and GT Mel A, and the overlapping 95% CI for Baseline and NVSB in Chinese and English MOSV. While the comment identifies areas of potential confusion, it does not provide any actionable feedback or suggestions for improvement. It lacks depth and does not guide the authors on how to address these issues or improve the clarity of their results. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are inconsistencies in the spacing between accuracy and standard deviation in Tables 2 and 3, which affects the presentation\"s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a formatting issue in Tables 2 and 3, specifically noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. However, the comment could be more helpful if it provided suggestions on how to standardize the spacing or offered guidance on how this formatting change might impact the overall readability and clarity of the tables. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the quality of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. It suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not specify which part of the paper discusses these ideas or how they are applied to videotext models. This lack of specificity makes it difficult for the authors to identify the exact sections that need attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks novelty, as adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim is not 5, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. While the comment highlights a potential issue with the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this lack of novelty or enhance the originality of their work. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a \"lot of space.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a \"lot of space.\" However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The authors can infer that it relates to the experimental results or the assumptions section, but this inference is not direct. The comment is specific in its critique of the dedication of space, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dedicating a whole section and experimental results for the assumptions is a \"lot of space,\" suggesting that it might be excessive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a \"lot of space.\" While it acknowledges the effort to expand on the assumptions, it points out that this might be excessive. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might streamline or prioritize the content. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed models\" and the \"MST baseline,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison between the proposed models and models that only consider different senses but not sememes. The comment suggests that the paper would be stronger with the inclusion of more baselines based on related work. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. The comment provides a logical reasoning by pointing out the potential comparison between the proposed models and existing models that only consider different senses. However, it lacks specific examples or references to support the claim that the MST baseline is an example of such a model. Additionally, it does not provide detailed guidance on how to incorporate more baselines or what specific aspects of the comparison should be addressed. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the comparison between the proposed models and models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including additional comparisons and references. By addressing this point, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided specific examples of related work or baselines that should be considered. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the selection of frame similarity factors and attributes similarity factors. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity as it does not provide details on what is unclear about the selection process or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential area of confusion regarding the selection of frame similarity factors and attributes similarity factors. However, it does not provide specific guidance or suggestions on how the authors might clarify this aspect of their work. Without actionable feedback or detailed explanations, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to discuss the results for the task of inferring knowledge on objects and includes specific suggestions for model (B) and terminology consistency in Tables 1 and 2. It also questions the omission of \"latent in verbs\" regarding objects. The comment provides clear and concrete actions for the authors to take, such as discussing the results for the task and using consistent terminology. The explicit nature of these instructions and the specific suggestions make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to discuss the results for the task of inferring knowledge on objects and includes suggestions for model (B) and terminology consistency in Tables 1 and 2. Additionally, it questions the omission of \"latent in verbs\" regarding objects. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point consists of factual statements and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). It also points out the inconsistency in terminology between the paper and Tables 1 and 2. Additionally, it questions the omission of \"latent in verbs\" regarding objects. These suggestions are clear and actionable, providing the authors with concrete steps to enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered additional guidance on how to present these results or why they are important. Overall, the feedback is 4 as it directs the authors toward significant improvements, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific sentence in line 212 that is not correct and suggests an alternative phrasing. It provides a clear and explicit action for the authors to revise the sentence to accurately reflect the process. The comment also references Figure 2, which presumably shows the correct process, giving the authors a concrete direction for improvement. The action is explicit and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, suggesting that it should be revised to accurately reflect the process. The comment provides a clear suggestion for improvement by pointing out the correct way to phrase the sentence, which is based on the observation from Figure 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not correct and suggests a correction. The reviewer provides a specific alternative phrasing, \"you do a bidirectional encoder that encodes the source sentence into a set of vectors,\" which is based on their observation from Figure 2. This provides a clear and specific justification for the claim, making it 5. The authors can easily understand and address the issue by following the suggested correction. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It provides a clear and actionable suggestion to revise the sentence to accurately reflect the process, suggesting that the authors should use the phrase \"bidirectional encoder\" instead. Additionally, the comment references Figure 2, which presumably shows the correct process, offering a concrete basis for the correction. This feedback is valuable as it helps the authors improve the accuracy and clarity of their description, ensuring that the paper\"s methodology is correctly presented. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it 5. The authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to fully substantiate the claim. The suggestion to compare with these works is logical, but the lack of detailed evidence or references makes the claim 3. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide enough guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the baseline models are weak and suggesting that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. This feedback is clear and actionable, as it provides specific guidance on how to improve the paper by including comparisons to relevant works. By addressing these suggestions, the authors can enhance the robustness and credibility of their findings. However, the comment could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is 4 as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to consider. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains, but this is not directly related to the issue of societal biases. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. It does not provide any examples or data to demonstrate the presence of societal biases or how they might impact the issue. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While it identifies a relevant area for consideration, it lacks specific guidance or suggestions on how the authors might address this issue or what steps to take to ensure the knowledge bases are free from societal biases. Additionally, the comment mentions a preference for attacking implicit offensive texts with reasoning chains but does not provide any context or explanation for this preference. Overall, the comment provides some insight but lacks actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, it does not provide specific guidance on which baselines should be included or how to justify the omission of others. The action is implicit and somewhat vague, as the authors are left to infer that they need to include more baselines but are not given detailed instructions on which ones to include or how to justify the omission. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. The comment provides a clear direction for improvement by asking the authors to justify the reason for not including these baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, the comment does not provide specific examples of these baselines or explain why they are considered strong. Without this additional context or justification, the claim is not 5, as it lacks detailed support or reasoning. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that Table 3 should include many strong baselines that are not currently compared. It specifically mentions a reference [1] that lists these baselines, providing a clear direction for improvement. However, the comment lacks specific guidance on which baselines should be included or how to justify their omission. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the reference to Supplementary Figure 6 in S3.1 and the model comparison and other details of the span vs. sentence investigation as examples of this reliance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the paper\"s independence. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their reliance on supplementary materials but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as S3.1 and the model comparison, allowing the authors to accurately identify the parts being addressed. It also specifies the issue of reliance on supplemental space, which is a clear concern for the paper\"s independence. However, the comment could be more specific in detailing what aspects of the paper\"s reliance on supplemental space are problematic and how they impact the paper\"s independence. Therefore, this comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which makes it not truly independent. The reviewer supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplementary materials. Additionally, the reviewer mentions the investigation of spans vs. sentences as another example of reliance on supplementary materials. This provides a clear and specific rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s independence, noting that it relies heavily on supplemental space to contain the paper. This is a critical observation, as it suggests that the paper may not stand on its own without additional materials. The comment specifically references specific sections, such as S3.1 and the model comparison, where the paper relies on supplementary materials. This feedback is valuable as it highlights a potential weakness in the paper\"s structure and content, prompting the authors to reconsider their approach to independence. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending ways to integrate the supplementary materials more seamlessly into the main text or proposing alternative approaches to enhance the paper\"s independence. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, considering that generic summarization systems often build knowledge graphs and generate summaries accordingly. The reviewer suggests that with the increase in node numbers, concept maps become harder to distinguish, making general summaries more readable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they should consider the necessity of treating concept map extraction as a separate task. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion that general summaries should be more readable due to the difficulty in distinguishing concept maps. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. The comment provides a logical reasoning by comparing it to generic summarization systems that build knowledge graphs and generate summaries accordingly. However, it lacks specific examples or references to support the claim that concept maps become harder to distinguish as the number of nodes increases. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. It suggests that general summaries should be more readable due to the difficulty in distinguishing concept maps. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their methodology. The feedback is 3 as it prompts the authors to consider the tradeoffs between treating concept map extraction as a separate task versus incorporating it into general summarization systems. However, it could be more helpful if it provided actionable steps or examples for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions imply a need for clarification or evidence to support the claim. However, the comment does not provide any supporting evidence or references to substantiate these claims. Therefore, the comment is considered 2, as it raises important questions but lacks the necessary evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by questioning the authors about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It raises important questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This feedback is clear and encourages the authors to provide more detailed descriptions and justifications for their methodology, which could significantly improve the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided examples of what such descriptions might entail. Overall, the comment is 4 as it guides the authors toward improving the clarity and robustness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that lines 102106 are misleading, as they refer to a \"such distribution\" that cannot be related to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and its relation to the discussion in the previous section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically mentioning that \"such distribution\" cannot refer to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the text, noting that lines 102106 are misleading due to the use of the phrase \"such distribution.\" It points out that this phrase cannot refer to the discussion in the previous section, which is a clear and actionable observation. However, the comment does not provide any suggestions or guidance on how the authors might clarify or correct this issue, leaving them without actionable feedback. While it highlights a potential problem, it lacks depth and does not offer detailed advice on how to resolve it. Therefore, the comment is 3, as it provides some insight but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it points out a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. While it identifies a potential improvement, it does not provide detailed instructions or examples to fully support the authors in making these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly requests examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without these details, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what kind of examples would be helpful. This limits the comment\"s usefulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding a statement to their paper. The comment is clear and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. Without explicit references, the authors cannot confidently determine the exact location of the suggestion in the paper. The comment is specific in suggesting what needs to be added, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help improve the transparency and reproducibility of the study. By including this information, the authors can provide more detailed insights into the variability of task completion across annotators, which could be valuable for understanding the robustness of their results. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the findings. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors should focus their efforts to improve clarity. Without explicit references to sections or specific analyses, the authors may struggle to identify the areas needing attention. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be clarified. This aligns with a score of 2.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and the specific hypothesis tested, as well as how the different pieces of the puzzle fit together. While the comment points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a key area for clarity, but it could be more beneficial with actionable advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of numerical results and expressing curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is valuable as it highlights an area where the paper could be strengthened by including numerical results, which would provide more concrete evidence and support for the claims made. However, the comment lacks specific guidance on how to implement this suggestion or what specific comparisons should be made. While it points out a critical area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. This provides a clear and explicit action for the authors to take, either by strengthening the formal basis of the connection or by rephrasing the language to enhance clarity. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table where the connection is discussed. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting how to address the issue. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not wellestablished and suggests that it should be formalized more or clarified in the language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or examples to substantiate the need for formalization or clarification. As a result, the claim is 3, as it points out a potential issue but lacks the necessary evidence or justification to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not wellestablished and lacks formal clarity. It provides a clear and actionable suggestion for the authors to either formalize the connection more or adjust the language to clarify it. This feedback is valuable as it points out a specific area that could be improved to enhance the paper\"s clarity and rigor. However, the comment could be more helpful if it included examples or specific suggestions on how to formalize the connection or clarify the language. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is 4, as it identifies a specific area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its request for empirical evidence, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be sufficient or how to present it effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with highdimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the scalability of the robust training scheme, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with highdimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. It points out that the accuracy might unfavorably scale unless the size of V scales exponentially with the dimension. This feedback is 3 as it highlights a potential limitation of the robust training scheme, which the authors should consider when designing their experiments or evaluating its applicability. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how it might be overcome. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or specific actions for the authors to take, such as recommending additional datasets or discussing the type of style shifts that occur during the fouryear period. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets and the duration of four years for studying style shifts. However, it does not specify which part of the paper this question pertains to, such as a specific section or dataset description. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the type of style shifts that occur during the fouryear period, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture all style shifts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture all style shifts and suggests that understanding the type of style shifts that occur during this period is crucial to appreciating what the model is capturing. This feedback is 3 as it prompts the authors to consider the adequacy of their dataset choice and the potential limitations of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns, such as recommending additional datasets or discussing the types of style shifts that might occur during the fouryear period. Overall, the comment provides a valuable insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant concern with the experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper should include comparisons with other models to provide a more comprehensive understanding of its results. The comment is clear and provides a concrete action for the authors to take, which is to include comparisons with other models. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models, and suggests including comparisons with SketchRNN. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with other models, specifically mentioning SketchRNN, and that this lack of comparisons contributes to the poor motivation problem. The comment provides a logical reasoning by suggesting that comparisons with other models would enhance the paper\"s comprehensiveness and credibility. However, it does not provide specific examples or references to support the claim that SketchRNN is a relevant comparison, nor does it explain why this comparison is necessary. While the claim is 3 due to the logical reasoning, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically the lack of comparisons with other models. It points out that the paper only includes selfcomparisons, which contributes to the poor motivation problem. The comment suggests that comparisons with SketchRNN could be beneficial. While the comment highlights an important area for improvement, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. This limits the comment\"s helpfulness, as it offers a direction for improvement but lacks detailed instructions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or a particular technique. Without explicit references to sections or techniques, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results or techniques are not obvious or require technical competency. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. This feedback highlights a potential weakness in the paper\"s presentation, as it may not be accessible to a broader audience. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed feedback or examples, the authors may struggle to understand and implement the necessary improvements. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While it identifies a potential area for clarification and differentiation, the comment lacks depth and does not provide specific guidance on how to implement this distinction or why it is important. The authors are left with a general suggestion but no detailed instructions or examples on how to incorporate this distinction into their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making that improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the discrepancy in data usage and the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the conclusion that the direct model is clearly better based on the difference in data usage between the direct and endtoend systems. However, it does not provide specific data or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed evidence or reasoning to substantiate the claim, making it 3. The authors would need to further explore the data usage and performance differences to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion drawn about the superiority of the direct model compared to the endtoend system. It points out that the difference between the two systems is only a few percentage points, which raises questions about the validity of the conclusion. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment suggests that this lack of detail hinders understanding. However, the comment does not provide specific examples or references to support the claim that GaRare\"s advantages over GaLore are unclear or that the algorithmic presentation is insufficient. While the claim is logical, the lack of detailed evidence or examples makes it 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft. The suggestion to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore is particularly valuable, as it can help the authors better justify their approach and enhance the paper\"s clarity. However, the comment could be more helpful if it offered specific examples or references to support the need for a more detailed algorithmic presentation. Overall, the feedback is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is 3 as it points out a potential gap in the literature review that could enhance the authors\" understanding and comparison of their work. However, the comment lacks specific suggestions on how to incorporate these references or what aspects of the similar work are relevant to the paper. While it highlights an area for improvement, it does not provide detailed guidance on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide more detailed explanations or analysis to support their claims. The comment is explicit in its request for clarification and actionable, as it clearly identifies areas where the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model\"s predictions and the limitations of Gaussian noise input. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA and suggests that the authors should provide more insights into how it works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into its mechanism. This claim is 3 as it provides a logical basis for the suggestion to explain WPA, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several areas where the authors could improve their work. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. The comment also questions whether any input serves as a white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the paper spends a lot of time showing WPA improves the test performance of the original model but fails to provide useful insights into how WPA works. This feedback is highly valuable as it identifies specific areas where the authors can enhance their draft, particularly by providing more detailed explanations or analysis to support their claims. By addressing these points, the authors can significantly improve the clarity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification, but it is concrete in that it specifies the need for more information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential similarity between the method part of the paper and a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. While the comment highlights an area of potential concern, it does not provide specific guidance on how the authors might address this issue or what aspects of the method need clarification. The feedback is 3 as it points out a potential issue but lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a critical issue regarding the absence of discussion on how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. While it identifies a specific area that needs attention, it does not provide explicit instructions or concrete steps on how the authors should address this issue. The comment implies that the authors should discuss these parameters in the experimental section, but it lacks detailed guidance on how to do so or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the specific parameters/thresholds being discussed, namely the minimum cluster size and conductance threshold. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on how these parameters are set and how sensitive the performance is to them. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss or mention how the important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper, specifically the absence of discussion on how important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a significant oversight that could impact the validity and reproducibility of the experimental results. The comment highlights a clear area for improvement, prompting the authors to include this discussion in the experimental section. However, it does not provide specific guidance on how to address this issue or what aspects of the parameter setting should be discussed. While it points out a critical gap, the comment could be more helpful with additional suggestions or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to studies that have demonstrated the inefficiency or difficulty of using reinforcement learning for static VQA tasks. Without such support, the claim remains 1, as it is based on a personal opinion without sufficient evidence or reasoning. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. While the comment identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern. It does not provide suggestions on how to mitigate the potential weakness or improve the approach. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this delay. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the dataset\"s availability, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the paper\"s contribution, specifically the availability of the promised dataset. It suggests that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. While this feedback identifies a critical aspect of the paper\"s contribution, it lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential impact of the delay. The comment could be more helpful if it provided suggestions on how to make the dataset more accessible or how to communicate the delay in its release to the readers. As it stands, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors claim to achieve stateoftheart results on challenging scene text recognition tasks, but the reviewer finds this claim unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. While the comment implies that the authors should conduct such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct comparisons experiments to validate their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It also mentions the need for comparisons experiments with existing detection methods. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or claims presented in the paper. The comment is specific in its critique of the authors\" claims and the need for comparisons experiments, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks are unconvincing. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed comparisons to substantiate the claim, making it 3. The authors would need to make a significant effort to understand and address the critique, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claims of achieving stateoftheart results on challenging scene text recognition tasks. The reviewer suggests that the performance is mainly due to the first step, which makes it reasonable to conduct comparisons experiments with existing detection methods. This feedback is 3 as it points out a potential weakness in the authors\" claims and suggests a direction for improvement. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis that demonstrates the performance difference. Without such supporting information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to provide an explanation or rationale for this observation, which is a clear and actionable suggestion. By addressing this issue, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it included specific suggestions on how to investigate or explain the performance difference. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified. The comment lacks specificity regarding the issue and does not provide guidance on how to address it. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the required implicit call to the Witness oracle being confusing. This feedback is 3 as it points out a potential source of confusion for readers, which could impact the clarity and accessibility of the paper. However, the comment lacks depth and does not provide suggestions on how to clarify or improve the explanation of this concept. Without additional guidance or examples, the authors may struggle to fully address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work has already demonstrated control over both facial expression and headpose. The comment suggests that the authors should consider incorporating headpose control into their method, similar to the previous work. However, the comment lacks specific references or detailed reasoning to support why this is a significant issue or how it could be addressed. While it highlights a potential gap in the methodology, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it cannot handle headpose while suggesting that a previous work has already demonstrated control over both facial expression and headpose. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to the previous work. This feedback is 3 as it points out a gap in the methodology and provides a specific example of a previous work that could serve as a reference or inspiration for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or incorporate the previous work\"s approach into the current method. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the impact of these spurious features. The authors are left to infer that they should investigate the impact of these features and consider ways to mitigate their influence, but the comment lacks concrete steps or suggestions for improvement. Therefore, the comment is 3, as it points out a potential issue but does not provide detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the spurious features, comparing them to backdoor triggers and referencing specific examples from Chen et al. (2017) and Gu et al. (2019). This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are known to have a significant impact on the trained model. The reviewer supports this claim by referencing specific examples from Chen et al. (2017) and Gu et al. (2019), providing a logical basis for the comparison. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Despite this, the comment is 4, as it offers a reasonable basis for the claim and provides references to support it. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to support its claim, highlighting the known impact of such triggers on the trained model. This feedback is valuable as it points out a potential weakness in the paper that could affect its robustness and generalizability. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as discussing ways to mitigate the impact of these spurious features or suggesting additional experiments to validate the model\"s robustness. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization component is emphasized several times but notes that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The comment lacks concrete actions or detailed suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this optimization component is discussed in, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which could be confusing and reduce the contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization component is emphasized several times but that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the emphasis on structural optimization and the direct use of an optimization algorithm from previous works. This observation highlights a potential confusion in the contribution of the paper, which could be clarified or addressed by the authors. However, the comment lacks specific suggestions or guidance on how to improve the clarity or originality of the contribution. While it points out a potential weakness, it does not provide actionable feedback for the authors to address it effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing a specific work ([A]). This direct suggestion provides a clear and concrete action for the authors to take, ensuring that they are aware of the relevant literature and can incorporate it into their introduction. The comment is 5 as it clearly specifies what needs to be added to the paper, making it easy for the authors to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the introduction by adding relevant references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is crucial to mention related work on modular networks for VQA, specifically referencing work [A]. This claim is 3 as it logically suggests that including this work would provide a more comprehensive overview of the related literature. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why this work is particularly relevant or how it relates to the current paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section of the paper, noting that it seems to imply that no one does modular architectures for VQA. It suggests that the authors should mention related work on modular networks for VQA, such as [A], to provide a more comprehensive overview of the literature. This feedback is clear and actionable, as it directs the authors to include relevant references that could enhance the introduction and contextualize their work. However, the comment could be more helpful if it explained why this reference is particularly important or how it relates to the paper\"s contributions. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. It lacks concrete suggestions on what specific comparisons or contrasts should be included or how to present them. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and contrasting methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of contrast with other methods in terms of computational efficiency and guarantees. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the basis of the claim. Without detailed comparisons or references, the claim is not fully substantiated, making it 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. This feedback highlights a gap in the paper that could be addressed by including comparisons with these methods. However, the comment does not provide specific suggestions on how to incorporate these comparisons or what aspects to focus on, leaving the authors with a general direction but without detailed guidance. Therefore, the comment is 3, as it points out an area for improvement but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance without reinforcement learning (RL) dropped lower than without dependency tree, and that the tables do not list the cases where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights a potential discrepancy in the results, which the authors can address to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or what specific changes should be made to the tables. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of comprehensive experimental evaluation on different datasets and model types. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, specifically the use of only the CIFAR10 dataset and the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. While the comment provides a logical reasoning for the need to consider additional datasets, it lacks specific examples or references to the works mentioned, which would strengthen the claim. Therefore, the comment is 3, as it provides a clear direction for improvement but requires more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which only consider the CIFAR10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experiments. By addressing this feedback, the authors can significantly improve the quality and impact of their paper. However, the comment could be more helpful if it provided additional details on how these works could be integrated or what specific aspects of the experiments should be expanded. Overall, the comment is 4 as it effectively directs the authors to a meaningful area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their draft. The comment implies that the authors should consider using another dataset, but it lacks concrete details on how to implement this suggestion or what specific aspects of the claim need to be revised. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is 3 as it identifies a potential weakness in the paper but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and questions the ecological validity of such a study. The reviewer also points out that previous work has considered multiple vulnerabilities or weaknesses simultaneously and suggests that the authors\" approach may not be appropriate. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and justify their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and suggesting that previous work has considered multiple vulnerabilities or weaknesses at once. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer acknowledges the data imbalance issue and questions the ecological validity of such a study. The comment references previous work that considered multiple vulnerabilities or weaknesses simultaneously, suggesting that the authors\" approach may not be appropriate. However, the comment lacks specific examples or references to support the claim that previous work considered multiple vulnerabilities. This makes the claim 3, as the authors would need to infer the relevance of the reference and the implications of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the vulnerability discovery methodology, questioning the authors\" approach of considering only a single vulnerability at a time. It acknowledges the data imbalance issue and raises concerns about the ecological validity of such a study. The reviewer also references previous work that considered multiple vulnerabilities or weaknesses simultaneously, suggesting that the authors\" approach may not be appropriate. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their methodology. While it highlights a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by providing more details, particularly on the definition of the resistance distance and explanations on Algorithm 1. While the comment implies that these details should be added, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details but may not be entirely sure which specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s content, specifically mentioning the \"many graph notions\" and the difficulty in understanding them. It also provides specific suggestions for improvement, such as the definition of the resistance distance and more explanations on Algorithm 1. However, the comment does not explicitly mention which sections or parts of the paper these issues are related to, making it weakly grounded. The suggestions are specific, but without clear grounding, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to understand due to the many graph notions and provides a general observation that the writing is generally good but could be improved with more details. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment acknowledges that the paper is generally wellwritten but points out that it can be challenging to understand due to the many graph notions. It suggests that the paper could be improved by providing more details, such as the definition of the resistance distance and explanations on Algorithm 1. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or what additional details should be included. The feedback is 3 as it points out potential areas for enhancement, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is 3 as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive critique that could guide the authors in improving their draft, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of this related work and its potential impact on the understanding of the stateoftheart. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the AAAI15 paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a relevant reference that could enhance their understanding and analysis. However, the comment could be more helpful if it provided specific insights or suggestions on how to integrate this reference into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and clarify the computation of optimal transport. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, particularly in relation to the Sinkhorn method. The comment provides clear guidance on what needs to be addressed, such as testing scalability on normal machines and clarifying the computation of optimal transport. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of the method and its computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights the need to clarify the computation of optimal transport, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to test scalability or how to address the computational issue. Overall, the comment is 4 as it provides actionable feedback on areas that need further exploration and clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are relevant to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model\"s specificity in relation to the infinite subdivisions and bounded parameters. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are relevant to the example model. The comment provides guidance on what should be clarified, such as the setting with infinite subdivisions and bounded parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should introduce specific aspects of their model that are relevant to the example model, such as clarifying the setting with infinite subdivisions and bounded parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are relevant to the example model. It highlights the need to clarify the setting with infinite subdivisions and bounded parameters, which are crucial for understanding the model\"s applicability. This guidance is clear and constructive, as it directs the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the transparency and accessibility of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it encourages the authors to expand their work beyond the current focus on image data and ViT, which could enhance the method\"s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is 4 as it prompts the authors to consider a broader scope for their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses tensor networks used to represent PMF of discrete variables but does not clarify how these results are useful to machine learning algorithms or how they can be analyzed. The reviewer suggests that the paper lacks significance due to this lack of clarity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information on the practical applications and significance of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper due to a lack of clarity on how these results are useful to machine learning algorithms or how they can be analyzed. However, it does not specify which part of the paper discusses these tensor networks, making it weakly grounded. The comment is specific in its critique of the paper\"s lack of clarity and significance, but without explicit references to sections or details, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity on how the tensor networks used to represent PMF of discrete variables are useful to machine learning algorithms or how they can be analyzed. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while tensor networks can be used to represent PMF of discrete variables, the paper lacks clarity on how these results are useful to machine learning algorithms or how they can be analyzed. This feedback highlights a critical gap in the paper\"s explanation and significance, which is crucial for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might improve the clarity or significance of their work. While it points out a significant weakness, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission\"s contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other fewshot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to fewshot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific in detailing what aspects of the evaluation are missing or how the authors could address this gap. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the observations presented do not evaluate the generalizability to fewshot learners beyond Prototypical Networks, which may limit the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the paper\"s contributions regarding understanding the properties of episodic training. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this gap. Providing examples of other fewshot learners or offering suggestions on how to evaluate the generalizability would enhance the helpfulness of the comment. As it stands, the comment is 3, as it directs the authors\" attention to a critical area for improvement but does not fully support them in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities of different instances and suggests that Equation 3 directly removes the modal subset of all instances. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the contribution of different modalities of different instances and the issue with Equation 3, which directly removes the modal subset of all instances. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with Equation 3 and suggesting how to deal with it, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities of different instances and suggests that Equation 3 directly removes the modal subset of all instances. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the contribution of different modalities of different instances and suggests that Equation 3 directly removes the modal subset of all instances. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The comment highlights a potential problem but lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and actionable, giving the authors a clear direction on what to improve in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. While the comment highlights an important area for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are given a clear direction to enhance their abstract, but the feedback could be more comprehensive with additional details or examples. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should address the confusion and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the use of sparse labels and the notation for target domain \u03c4. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is 3 as it provides a logical basis for the confusion and references the original work for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the use of unlabeled data in source domains during training. By pointing out these inconsistencies and questions, the comment provides clear and actionable feedback for the authors to improve the clarity and accuracy of their description. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how the description could be improved. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of epochwise analysis and how it could be applied to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a logical reasoning for the potential benefits of epochwise analysis, it lacks specific examples or references to support the claim. The suggestion is 3, as it provides a clear rationale but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It suggests that epochwise analysis, particularly in finite sum settings, could offer insights into the behavior of optimization algorithms. This analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after every full pass of data. Additionally, it proposes that this approach could aid in comparative analysis of deterministic and stochastic methods. The comment is specific and provides a clear direction for the authors to enhance their analysis and understanding of the algorithms. By offering a concrete suggestion for improving the paper, the comment is 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the contribution being incremental and the lack of citation of key baselines, as well as the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer supports this claim by referencing specific works, which provides a logical basis for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these algorithms would enhance the paper. Overall, the claim is 4 due to the reference to specific works, but it could be further substantiated with additional details or examples.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It also points out the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG, which are relevant to the paper\"s focus on RAG for EHR. The comment provides specific suggestions for improvement, such as introducing these algorithms and explaining their relevance to the paper. However, it could be more helpful if it offered guidance on how to effectively integrate these suggestions into the paper. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on execution. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, such as providing additional context or examples to clarify the distinction. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between the three classes of extreme speech, specifically questioning the classification of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. While the comment identifies a specific issue, it lacks detailed reasoning or references to support the claim that the distinction is unclear. The authors would need to provide additional context or examples to fully address the concern. Therefore, the comment is 3, as it provides a starting point for the authors to improve their draft but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the distinction between the three classes of extreme speech, particularly in the context of the sample data file provided. It questions the classification of a specific instance as exclusionary extreme speech and highlights the potential influence of local regulation on the classification. The comment is 4 as it prompts the authors to clarify the distinction and provide additional context or examples to support their classification. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how the distinction could be clarified. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests that the notation should be introduced beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the notation \"L_l\" and the need for mathematical correctness. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests that it should be introduced beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. The suggestion is 3 as it identifies a specific issue but does not provide a comprehensive rationale or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, specifically the use of \"L_l\" instead of \"L.\" It suggests that this change is necessary for mathematical correctness and provides a clear example of the notation issue. Additionally, it points out that the notation should be introduced beforehand to avoid confusion. This feedback is actionable and provides the authors with a clear direction for improving the clarity and correctness of their work. However, the comment could be more helpful if it offered suggestions on how to introduce the notation or provided examples of how it should be used. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Disentanglement\" and \"Broader Impacts and Limitations,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors should address this issue, but without further elaboration, the claim remains 3. The authors would need to make a significant effort to understand and address the issue, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to ensure a more comprehensive understanding of their work. This feedback is clear and actionable, as it directs the authors to provide more detailed information on a critical aspect of their methodology. However, it could be more helpful if it offered specific suggestions on how to present this information or what types of details should be included. Overall, the comment is 4 as it highlights an important area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is 3 as it provides some logical reasoning and specific examples to support the observation. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is 3 as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, it lacks specific suggestions or guidance on how to address the issue or improve the results. To be more helpful, the comment could provide suggestions on how to improve the design solutions or clarify the implications of Eq. 4. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of specific stateoftheart references in the face recognition experiment, particularly mentioning \"Baidu\"s work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\"s work\" and the reported results on the dataset containing 9K identities and 450K images. It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper being addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning \"Baidu\"s work\" and its reported results. The reviewer provides a specific reference to the work, which adds credibility to the claim. However, the comment could be strengthened by providing more detailed comparisons or analysis of the missing references, such as how they might impact the results or conclusions of the paper. Despite this, the claim is 4 due to the specific reference provided.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain stateoftheart references, such as \"Baidu\"s work\" and its reported results. It provides a clear and actionable suggestion by recommending the inclusion of these references, which could enhance the paper\"s credibility and comprehensiveness. Additionally, the comment highlights the similarity between the results reported in the paper and those from the Webface dataset, suggesting that the authors should compare their results with those from the reference work. This feedback is valuable as it directs the authors to a specific area for improvement and provides a clear path for enhancing the paper\"s contribution. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the generalization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to question answering, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the question answering process, particularly the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, specifically the use of template mapping to transform questions into masked statements, might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to studies or literature that demonstrate the limitations of this approach or how it affects generalization. As a result, the claim is 3, as it requires further elaboration and evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve their question answering process. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that comparing the performance of a model pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and finetune the model on realworld datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pretrained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of a model pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that finetuning the model on realworld datasets with different losses is necessary to showcase the model\"s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s comparison of model performance, suggesting that comparing a model pretrained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or what specific metrics to use. Overall, the comment is 4 as it effectively points out a weakness and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. The reference to Hewitt and Manning is provided, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the paper, noting that it is common in similar cases to average over subword representations. It provides a reference to Hewitt and Manning (2019, footnote 4) as an example of this practice. While the comment highlights a potential improvement, it lacks depth and does not offer specific suggestions or guidance on how to implement this change or why it might be beneficial. The feedback is 3 as it points out a potential area for improvement but does not fully support the authors in making that change. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\" method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\" method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the lack of discussion on crucial conditions for DICE and the need to ensure that these conditions are met. It explicitly mentions that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. However, the comment does not provide specific guidance on how to ensure DICE meets these conditions or what aspects of the discussion should be expanded. While the authors can infer that they need to address these issues, the lack of concrete steps or examples makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on crucial conditions for DICE and how to ensure these conditions are met. The comment provides specific examples of the conditions (ID and OOD range and the need for an identical mean) and suggests that these should be discussed in more detail. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are 3 as they are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims. Providing more detailed evidence or references could strengthen the verifiability of the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of discussion on crucial conditions for DICE and the need to ensure these conditions are met. It points out that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These observations are important for the authors to address, as they highlight areas where the paper could be strengthened. However, the comment does not provide detailed guidance on how to ensure DICE meets these conditions or what aspects of the discussion should be expanded. While it highlights important issues, the lack of actionable suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks full grounding as it does not specify the exact sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. While the comment identifies specific issues, it does not provide detailed reasoning or evidence to support these claims. The authors would need to infer the basis of these concerns and determine how to address them. Therefore, the comment is 3, as it provides some direction but lacks sufficient justification or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how similar studies have addressed these concerns. Overall, the comment is 4 as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that all sparsity patterns seem to perform equally well and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It also notes a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more insight into the results and clarify the presentation of \"bits.\" The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the uniqueness of the results and suggesting that the authors provide more insight into the sparsity patterns. The comment is specific because it clearly identifies what needs to be addressed, namely the lack of insight into the results and the discrepancy in the presentation of \"bits.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the uniqueness of the results and suggests that all sparsity patterns perform equally well. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or data to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that all sparsity patterns seem to perform equally well and questioning whether this is unique to the sparsity detection problem or applies to GNNs in general. It also points out a discrepancy in the presentation of \"bits\" in Section 4.3. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or provide more insight into the results. The feedback is 3 as it prompts the authors to consider the generalizability of their findings and the presentation of their work, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2 that \"this methodology requires significant additional assumptions.\" It suggests that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer also points out a mistake in the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific issues with the claim and the inequality, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The comment also points out a mistake in the inequality on line 310, providing specific guidance on how to correct it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is natural and not extreme. However, the comment lacks specific examples or references to support the claim that this assumption is common in machine learning settings. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme by implying that the methodology requires significant additional assumptions. The reviewer points out that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially adjust their methodology to better align with common practices. Additionally, the comment identifies a mistake in the inequality on line 310, which is a helpful detail for the authors to correct. However, the comment could be more helpful if it provided suggestions on how to address the issue or improve the clarity of the claim. Overall, the comment is 4 as it offers actionable feedback on the claim and the inequality, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how the comparison should be structured. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate why this comparison is necessary or how it would enhance the paper. As a result, the claim is 1, as it does not offer sufficient justification or evidence to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Section 6, suggesting that the authors could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is 3 as it points out a potential gap in the paper that could enhance its comprehensiveness and originality. However, the comment lacks specific guidance on how to structure this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in its suggestion to examine performance with different scenarios, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how it could be implemented. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This is a valuable observation that could lead to a meaningful experiment or analysis. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the performance to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue is discussed. The authors can infer that it relates to the model evaluation or training process, but this inference is not direct. The comment is specific in its question about the model\"s ability to predict quality labels, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or test their model under disturbances. The feedback is 3 as it prompts the authors to consider the robustness of their model, but it could be more beneficial with additional details or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or examples of how similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights an important area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the bounded noise assumption in the context of stochastic optimization literature and suggests that it is somewhat restrictive. It references specific works that have extended these noise conditions, providing references to A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to consider these references or incorporate the extended noise conditions into their work. While the references provide a clear direction for further exploration, the comment lacks explicit guidance on how to apply this information to improve the draft. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bounded noise assumption, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that this assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The comment provides specific references to relevant works, which further clarifies the need for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer supports this claim by referencing specific works, such as A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, which have explored sgd in the nonconvex world and provided theoretical insights. These references provide a solid foundation for the claim, making it 4. However, the comment could be strengthened by further elaborating on how these references relate to the bounded noise assumption or how they might impact the authors\" work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential limitation in the bounded noise assumption commonly used in stochastic optimization literature. It suggests that this assumption may be somewhat restrictive and points out that there have been efforts to extend these noise conditions. The comment provides specific references to relevant works, which can help the authors explore these extensions and potentially enhance their understanding of the topic. However, the comment could be more helpful if it offered suggestions on how to incorporate these references or how to address the limitations of the bounded noise assumption in the context of the paper. Overall, the comment provides valuable insights but could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. Without guidance on how to address this issue, the authors are left without a clear action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the paper\"s limited contribution due to the combination of existing techniques. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the comment does not provide detailed reasoning or evidence to support the claim that the contribution is incremental. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution could be considered incremental. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the contribution. The feedback lacks actionable advice or detailed critique, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance on what the authors should do to improve the draft, the comment lacks actionability. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the meaning of \"100 steps\" and whether it refers to 100 sampled strategies. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically asking whether it refers to 100 sampled strategies. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the clarity and understanding of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and notes that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model, which involve compositional generation through logical combination of concepts learned through data subsets, are similar to a prior VAE paper. This feedback is 3 as it highlights an area of potential interest and a similarity to prior work, which the authors could consider addressing. However, the comment lacks specific suggestions or guidance on how to address the similarity or improve the paper in this context. While it provides some insight, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the current domain. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and highdimensional observations. The claim is 3 as it provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the results can be applied to other domains. The comment provides a specific recommendation to conduct experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is actionable and offers a clear path for the authors to improve their draft by expanding the evaluation to a more diverse set of domains. However, the comment could be more helpful if it included examples of how the Atari benchmark could be used or why it is particularly relevant for the method under consideration. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model\"s functionality, which could be interesting. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, leaving the authors with a general direction but without detailed instructions. Therefore, the comment is 3, as it points out a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of scalability in the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the scalability issue but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and questions the scalability issue, suggesting that there might be a need for tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the practicality and applicability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to consider. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of adapting f_R and f_P over time, specifically mentioning the incorporation of domain knowledge into their structure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the impractical amount of data required for a less informed f_R/f_P. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that f_R and f_P can be adapted over time but that the experiments performed here incorporate a great deal of domain knowledge into their structure. The comment suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the claim or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what steps they could take to improve their work. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should conduct these experiments or what specific aspects to focus on. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these aspects are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that obtaining labeled data for imitation learning is necessary and that there are no experiments on the difficulties in obtaining such data or how performance changes with data size. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data for imitation learning and the impact of data size on performance. It highlights the need for experiments to address these issues, which is a crucial aspect of the methodology. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on. While it points out an important area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it directs the authors to a critical area for enhancement but does not fully support them in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization may not lead to robust generalization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between necessary conditions and generalization bounds, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of overparameterization and its implications on generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. It mentions that the constructions of ReLU networks for robust memorization may not lead to robust generalization, but does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the theoretical or experimental sections, but the comment lacks full grounding as it does not explicitly mention these sections. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between overparameterization and generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific examples or detailed reasoning to support the claim that the constructions of ReLU networks for robust memorization would not lead to robust generalization. Without such evidence or references, the claim remains 3, as it provides a logical basis but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the connection between overparameterization and generalization bounds. It suggests that the necessary conditions may have stronger implications if they are connected to generalization bounds, and points out that the constructions of ReLU networks for robust memorization may not lead to robust generalization. While the comment acknowledges that the authors acknowledge this in the conclusion, it highlights a serious concern that the authors should address. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it raises an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action to take, it lacks specific guidance on how to integrate this information into the paper or what aspects of the current method should be compared. The authors are given a clear direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work on untrained NNs and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current method is interesting because it shows strong OOD generalization, but it also mentions that untrained NNs have been used for inverse problems in imaging. The reviewer suggests that the current method should be placed in context and potentially compared with other methods in this class. While the comment provides a logical observation about the current method\"s context, it lacks specific references or examples to fully substantiate the claim about the recent work on untrained NNs. This makes the claim 3, as the authors would need to follow up on the suggestion to provide more detailed evidence or references to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion by pointing out that the current method\"s OOD generalization is interesting, but it also highlights that untrained NNs have been used for inverse problems in imaging. The reviewer suggests that the current method should be placed in context by mentioning the recent work on untrained NNs and potentially comparing it with other methods in this class. This feedback is actionable and offers a clear direction for the authors to enhance the paper by integrating this context and comparison into their work. By doing so, the authors can strengthen the novelty and relevance of their method. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. The references provided are relevant but do not directly address the comment\"s suggestion. Therefore, the comment is weakly grounded because it does not specify where the additional experiments should be conducted, and it is not specific in detailing what aspects need to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The reviewer provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples of how the suggested experiments would improve the paper. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on which aspects of the paper would benefit from these additional experiments or how they should be conducted. The references provided are relevant but do not offer detailed instructions or suggestions for the authors to follow. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding why the mechanism preserves the label distribution. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the mechanism is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear why this mechanism preserves the label distribution. This feedback is 3 as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to other models or studies that could be considered, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their work by including more diverse models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant information. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant information. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that performance degrades. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant information. This is a clear and actionable request for the authors to provide an explanation or analysis of this phenomenon. By addressing this question, the authors can improve the clarity and robustness of their results. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of similar cases where performance degradation was observed. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their explanations. By addressing these issues, the authors can enhance the readability and accessibility of their paper, which is valuable guidance for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment also implies that the current introduction may be confusing or difficult to understand, which further guides the authors on what aspects need improvement. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation and the need for a revised introduction to make the paper easier to follow. This provides clear guidance on what aspects of the paper need improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the lack of clarity in the motivation. It suggests that the introduction should be revised to make the paper easier to follow, which is a crucial point for the authors to address. However, the comment does not provide specific guidance on how to revise the introduction or what aspects of the motivation are unclear. While it highlights an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but lacks depth and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the features or positions are problematic or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they need to consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the limited scope of the experiments, specifically mentioning that the paper only conducts experiments on a \"very limited number of molecules\" and provides indistribution testing for these samples. It also suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitation of the method due to the need for individual training. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique and potentially make additional efforts to understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s scope, noting that it only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the paper\"s experimental design, which could impact the generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments to include more molecules. While it highlights an area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the red line in the figure and asks for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern. The comment lacks depth and actionable advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The authors can infer that it relates to the sections on presentation and formatting, but this inference is not direct. The comment is specific in detailing what needs to be improved, such as the figures and tables, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim 2, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It highlights specific areas for improvement, such as presentation and formatting, particularly in figures and tables. While the comment provides some insight into the areas needing attention, it lacks detailed guidance or specific suggestions on how to improve the writing and formatting. The authors are left with a general understanding of the issues but without actionable steps to address them. Therefore, the comment is 3, as it points out areas for improvement but does not provide comprehensive guidance for the authors to make significant improvements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. While the comment implies that the authors should clarify the novelty of their contribution, it does not provide specific guidance on how to do so or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical results of prior work that show samplewise multiple descent in linear regression, which provides a clear reference point for the authors to address. It also specifies the main contribution of the paper, which is the result that optimal regularization can remove double descent in certain anisotropic settings. The comment suggests that if this is not the case, the paper should better highlight the novelty of their result in relation to prior results. However, it does not provide specific guidance on how to achieve this or what aspects of the paper should be emphasized. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent in certain anisotropic settings, which is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper but suggests that the claims seem correct. This provides a logical basis for the claim but lacks specific references or detailed evidence to fully substantiate it. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence or references to fully support it.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, noting that the main result about removing double descent in certain anisotropic settings is based on prior work that theoretically shows samplewise multiple descent in linear regression. The reviewer suggests that the paper should better highlight the novelty of its result in relation to prior results, as the theoretical basis is already established. While the comment provides a clear direction for improvement, it lacks specific guidance on how to effectively highlight the novelty or what aspects of the paper should be emphasized. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed suggestions for enhancing the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could provide valuable insights into the model\"s performance. While the comment identifies areas for clarification and potential enhancement, it does not offer specific guidance or suggestions on how to address these issues. The authors are prompted to consider these points, but the feedback lacks depth and actionable advice. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks actionable details, such as recommending additional analyses or discussions that could be included to enhance the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these subtasks are discussed in or where the discussions are lacking. Without explicit references to sections or specific subtasks, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of discussions are needed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for bAbi and suggests that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples of how the subtasks are simplistic or how they could be improved with additional discussions. Without such support, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the 10 subtasks being considered simplistic for bAbi, suggesting that they could solve all the subtasks with their final model. However, it lacks specificity and does not provide actionable guidance on how the authors could address this issue or what kind of discussions are needed. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential weakness but does not provide sufficient direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\"s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\"s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is 3 as it points out a potential misclassification, but it does not offer actionable advice or detailed critique to help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps the authors should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation, and suggests that it might make sense to learn AccNet in this context. While it identifies a potential area for improvement, the comment lacks specific guidance or suggestions on how to address this issue or what specific benefits such an inclusion might bring. The feedback is 3 as it points out a potential area for enhancement, but it could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the proposed metric, noting that it is only tested on a single dataset. However, it does not specify which dataset or which part of the paper discusses this metric, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the testing of the metric, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this limitation or how it affects the validity of the metric. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the paper, noting that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing the implications of this limitation. While it points out a potential weakness, the feedback does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional competitors. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the evaluation of base DA methods with/without the proposed architecture, and suggests including competitors like AutoDial and AdaBN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by comparing base DA methods with and without the proposed TransferNorm (TN) architecture to similar competitors like AutoDial and AdaBN. This claim is 3 as it logically suggests that including these competitors would enhance the evaluation. However, the comment lacks specific examples or references to support why these competitors are relevant or how they would impact the evaluation. Providing more detailed reasoning or examples would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm (TN) architecture, as well as with similar competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons that could strengthen their results. By addressing this suggestion, the authors can improve the robustness and comprehensiveness of their evaluation, which is valuable guidance for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out that some abbreviations are not defined and that the superscript notation in Equation 6 is not defined until later, which hinders understanding. The comment provides examples of similar works that have defined these terms, offering clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It provides examples of similar works that have defined these terms, which helps to substantiate the claim that these elements are unclear. However, the comment could be strengthened by providing more detailed explanations or references to the specific sections where these issues occur, which would enhance the verifiability. As it stands, the comment is 4, as it provides some evidence but lacks detailed justification or examples. Therefore, the score is 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how the authors can improve the clarity and accessibility of their paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it suggested ways to address these issues, such as providing definitions or examples of how these terms are defined in the context of the paper. Overall, the comment is 4 as it identifies important areas for improvement and offers concrete suggestions for addressing them."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes or improvements could be made to the evaluation or baselines. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"evaluation\" and \"baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. The reviewer suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider using more recent baselines or compare their method with other 3D CNN approaches, such as X3D, SlowFast, etc. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be compared with more recent 3D CNN approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider more recent baselines or compare their method with other 3D CNN approaches. While the comment raises a valid concern, it lacks specific examples or references to support the claim that the current baselines are outdated or inadequate. The suggestion to compare with other approaches is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be compared with more recent 3D CNN approaches. This feedback is 3 as it points out a specific area for improvement and encourages the authors to consider alternative approaches. However, the comment lacks detailed guidance or examples on how to conduct these comparisons or what specific aspects to focus on. While it provides a direction for improvement, it could be more actionable and comprehensive to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors could improve it. The comment lacks actionable guidance or suggestions for enhancing the analysis, leaving the authors without clear direction on how to address the critique. As a result, the feedback is not helpful, as it does not provide the authors with a path to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the result only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. While the comment identifies a potential issue with the assumption and suggests a comparison, it lacks specific examples or references to support the claim that previous algorithms do not require this assumption. This makes the claim 3, as the authors would need to further explore the literature to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical result of the paper, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. This is a critical observation that highlights a potential weakness in the paper\"s theoretical foundation. Additionally, the comment suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing works that demonstrate the applicability of the algorithm to nonGaussian data. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not specify how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, as it lacks detailed guidance on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with the original approach, but it lacks detailed guidance on how to implement this comparison or what aspects to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s contribution. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, such as which specific aspects of the original approach should be compared or how to interpret the results. While it provides a general direction for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful if it offered specific suggestions on which additional baselines or comparisons to include, or how to present the results effectively. While it provides a valuable direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue or improve the clarity of their work. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. Therefore, the comment is 5, as it provides a direct and specific action for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the paper, as it highlights a gap in the description of the dataset creation process. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this detail is important or how it affects the quality of the dataset. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a specific area where the paper could be improved by including additional data or analysis. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific metrics or analyses would be most relevant. While it points out a potential gap in the paper, it does not offer detailed suggestions for improvement, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\"s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it provided additional guidance on how to present and describe the algorithm, such as by suggesting specific sections or elements to focus on. Overall, the comment is 4 as it identifies a clear area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential addition. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, as it mentions the possibility of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it does not fully support the authors in making that enhancement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation or if it is an open (hard) problem. The comment provides a clear and actionable suggestion for improving the paper by acknowledging the issue and offering a potential solution. This feedback is valuable as it guides the authors in enhancing the clarity and completeness of their work. However, it could be more helpful if it included specific references or examples of existing work that addresses this issue. Overall, the comment is 4 as it provides a constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and the impact of the number of images on model performance. It also suggests that the first appearance of BYOL in the abstract should be explained. However, it does not specify which part of the paper these questions are related to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for an explanation of BYOL and the impact of image number on performance, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that more training images might negatively affect performance. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. The comment also requests an explanation of BYOL in the abstract, but it lacks specific reasoning or data to support the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. This feedback is 3 as it prompts the authors to consider the effect of image number on model performance and to clarify the introduction of BYOL. However, the comment lacks specific guidance or suggestions on how to conduct the analysis or what aspects of the BYOL explanation should be clarified. While it points out areas for improvement, it does not provide detailed instructions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the effectiveness of the method, particularly regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors provide stronger arguments or intuitions to explain why the method works, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the understanding of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of why the method works, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial to enhance the understanding of the method. While the comment highlights an important area for improvement, it lacks specific guidance on how to address this issue or what kind of arguments or intuitions would be most effective. The feedback is 3 as it points out a critical area for clarification, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the binary classification are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to alternative metrics or methods that could be used instead. As a result, the claim is not 5, making it difficult for the authors to understand and address the concern. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. While it identifies a potential weakness in the methodology, it lacks specific suggestions or guidance on how the authors might address this concern or what alternative metrics could be used. The comment highlights an important area for consideration, but without actionable advice or detailed feedback, it does not provide significant value to the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for improvement by specifying the metrics to compare and the conditions under which SynTextBench should be used. The action is implicit but concrete, as the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely comparing the SynTextBench metric to other metrics proposed in the literature and clarifying under what conditions SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and mentions specific metrics like MMLU and Big Bench. It also claims that some of the metrics in the literature do not satisfy the proposed desiderata, but it does not provide specific examples or detailed reasoning to support this claim. The comment suggests comparing the SynTextBench metric to other metrics proposed in the literature, but it lacks specific examples or detailed guidance on how to conduct this comparison. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending a comparison between the SynTextBench metric and other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. This feedback is valuable as it guides the authors in demonstrating the utility and applicability of their metric in the broader context of existing evaluation methods. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any guidance on how to improve the clarity or accessibility of the content. Without actionable suggestions or examples, the authors are left without a clear understanding of what changes to make to enhance the readability of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This is a relevant observation that could prompt the authors to reconsider their results and provide a more comprehensive analysis. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This is an important point that could impact the validity and generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what potential implications it might have on the study. While it points out a potential weakness, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a relevant area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs\" ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks instances with more than 7 variables, which raises concerns about LLMs\" ability to model problems with large instance sizes. However, the comment does not provide specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the limited number of instances with more than 7 variables, which raises concerns about LLMs\" ability to model problems with large instance sizes. This feedback is clear and actionable, as it suggests that the authors should expand their dataset to include more instances with larger variable counts. However, the comment could be more helpful if it provided specific guidance on how to generate these instances or what constraints and variables should be considered. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, which can enhance the robustness and generalizability of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment could be more helpful if it offered examples of how these alternative approaches have been applied in similar contexts or provided guidance on how to implement them effectively. While the suggestion is actionable, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion and a summary of the article\"s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the article\"s contributions, providing full grounding as it clearly identifies the parts of the paper being addressed. It is specific because it clearly specifies what needs to be added, namely a conclusion and a summary of the paper\"s contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the article\"s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for enhancing the paper\"s conclusion, the comment offers valuable insight that can help the authors improve the clarity and impact of their work. However, the comment could be more helpful if it provided additional guidance on what elements should be included in the conclusion or how to effectively summarize the paper\"s contributions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or modifications to the experiment, making it difficult for the authors to know how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the synthetic experiment in a nonseparable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model, given the nonlinear expression ability of neural networks. This is a valid point that could lead to a deeper understanding of the experiment and its implications. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the experiment. While it identifies a potential problem, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detail, but it is concrete in that it specifies what needs to be elaborated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support the claim that elaboration is necessary. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the importance of elaborating on why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the experimental setup, but this inference is not direct. The comment is specific in suggesting the need for multiple train/test splits, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the paper. The suggestion is based on a general understanding of standard practices in the field, but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup of the paper, suggesting that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. This feedback is 3 as it points out a common practice in the field and encourages the authors to enhance their experimental design. However, the comment lacks specific guidance on how to implement this suggestion or what specific benefits it might bring to the paper. While it highlights an area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer\"s understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section for essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about the neural network memorizing critical points is inaccurate, as it does not memorize exact points as in TopoNet [24]. The reviewer provides a logical reasoning by referencing TopoNet, which suggests that the neural network does not memorize exact points. However, the comment lacks specific examples or references to the exact inaccuracies in the original statement, making it 3. The suggestion to tone down the statement is somewhat supported by the reference to TopoNet, but more detailed evidence or examples would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the manuscript. It identifies a misleading statement about the neural network memorizing critical points, suggesting that the authors should tone down this claim. This is a clear and important correction that can improve the accuracy of the paper. Additionally, the comment points out that the method section is wordy and could be compressed, offering a concrete suggestion for simplification. Finally, it highlights grammatical errors, providing specific examples like \"l.\" This detailed feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes might be necessary to clarify the statement. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they could impact the paper\"s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant point for the authors to consider. It also seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy, which could provide valuable insights into the robustness and performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for further exploration, it does not provide actionable feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it points out potential areas for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, namely, to include these citations to enhance the context of their work. The explicit nature of the suggestion and the provided examples make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly details what needs to be addressed by including these citations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it directly references existing literature that could be relevant to the context of the paper. The suggestion is 5, as it offers a clear path for the authors to enhance their work by including these citations.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include these citations to enhance the context and relevance of their work. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the action is implicit, it is clear that the authors need to include such comparisons in their analysis. The comment provides a specific direction for improvement, but it lacks concrete details on which methods to compare with or how to conduct the comparison. Therefore, the action is 3, as the authors know they need to make a comparison but may not be entirely sure of the specifics.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular comparison, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the understanding and evaluation of the proposed method. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. This limits the authors\" ability to fully understand and address the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison with Megatron and clarify their claims about parameter efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the overrating of the comparison and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\" claim of parameter efficiency, which is relevant to the experimental setup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the overrating of the comparison with Megatron and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overrated. However, the comment could be strengthened by providing specific examples or references to these other models, which would further substantiate the claim. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between COCOLM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it challenges the authors to reconsider the significance of their comparison and potentially adjust their conclusions accordingly. Additionally, the comment raises a question about the authors\" claim of parameter efficiency, prompting them to clarify their experimental setup and the potential impact of changing BPE vocabulary on performance. While the comment provides actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or what specific aspects of the comparison or parameter efficiency should be further explored. Overall, the comment is 4 as it directs the authors to consider important aspects of their work that could be improved."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. It suggests that the authors should compare their work with a chainofthought prompting approach, which is a specific and concrete suggestion for improvement. This feedback provides clear guidance on what the authors need to do to enhance their comparisons and make their work more robust. The explicit nature of the suggestion and the concrete example of a potential baseline make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chainofthought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors should compare their work with a chainofthought prompting approach. While the comment identifies a potential issue with the baselines, it does not provide specific examples or detailed reasoning to support why the current baselines are insufficient. The suggestion to compare with a chainofthought prompting approach is a logical one, but the comment lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that despite mentioning various model criticism techniques in Section 2, the authors limit their comparisons to simple naive baselines. The comment suggests that the authors should compare their work with a chainofthought prompting approach, which is a more meaningful baseline. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the robustness and credibility of the paper. By addressing this point, the authors can significantly strengthen their comparisons and demonstrate the effectiveness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the approach when labels are not available. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalizability of this approach when labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to improve the generalizability of the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential problem, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It explicitly states that there needs to be an indepth exploration of the reasons for the experimental results. This provides a clear and concrete action for the authors to take, which is to conduct a more thorough analysis of the experimental results and consider proposing new metrics. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests an indepth exploration of the reasons for the experimental results, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to understand the basis of the critique without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by proposing new metrics or conducting a more thorough analysis of the existing ones. However, the comment could be more helpful if it offered examples of how to conduct such an exploration or provided guidance on what specific aspects to focus on. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to resolve this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided examples of how the notation could be clarified or revised. Overall, the comment is 4 as it directs the authors to a specific area needing attention and offers a clear suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the weak recovery problem studied is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their argument. The suggestion for more citation is implied but not directly stated, leaving the authors with a vague understanding of what needs to be done. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unclear connection between human cognition and the problem at hand. The comment suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated, and it questions the relevance of human cognition. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to understand and address the reviewer\"s point, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the relevance of connecting human cognition to the problem at hand, given that the authors acknowledge that the problem is reductionist and lacks mechanisms like bargaining and negotiation. The reviewer suggests that the interaction between cognitively basic adaptation mechanisms and the structure of the CPR might have a greater impact on selforganization than previously appreciated. This feedback is 3 as it prompts the authors to reconsider the relevance of human cognition in their analysis and potentially explore alternative perspectives. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or what additional evidence or analysis might be needed. Overall, the comment offers a valuable insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, namely the need for a comparison to baselines, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed explanations or clarifications, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on how the embeddings are combined and fed into the CSCM. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarifications are needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or clarifications in these areas. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects should be clarified. Overall, the comment is 4 as it effectively highlights a critical area for improvement in the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing what needs to be done to improve the robustness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be more robust. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a more comprehensive evaluation approach, the comment offers a concrete way to enhance the quality and reliability of the paper. However, it could be more helpful if it provided additional guidance on how to implement this change or what specific aspects of the evaluation should be considered. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement by merging the two bullets. The comment provides a clear and concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a potential improvement by combining the two bullets, but without explicit references to the sections, the authors may struggle to identify the exact parts being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction could be combined together. This is a specific and actionable suggestion that could streamline the introduction and improve the clarity of the paper\"s contributions. However, the comment lacks further explanation or justification for why this combination would be beneficial, such as how it would enhance the overall structure or content of the introduction. While the suggestion is clear, it could be more helpful if it included additional context or reasoning to guide the authors in implementing the change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm\"s improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to support their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s focus on a specific problem and appreciates its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the algorithm\"s performance is discussed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\"s improvement. This makes the claim 3, as the authors would need to make a concerted effort to address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific suggestions or examples on how to address the issue of robustness. The feedback is 3 as it points out a crucial area for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of overcorrelation, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is 3 due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment provides some insight into the paper\"s limitations, it does not offer specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it identifies a critical area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the action to take, it lacks concrete details on how to implement this suggestion. It does not provide specific guidance on what aspects of the pretraining method should be discussed or how to integrate it into the main paper. The authors are left with a clear action to take but without detailed instructions on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed discussion on the unsupervised pretraining method in the main paper. The comment suggests focusing more on the pretraining method and provides a rationale for why it is important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as specific data points or comparisons with other methods. The comment suggests that the unsupervised pretraining is more important than other modules presented in the paper, but it lacks detailed justification or examples to fully substantiate this claim. Therefore, the comment is 3, as it provides a logical suggestion but requires more detailed evidence or reasoning to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to integrate the discussion of the unsupervised pretraining into the main paper or what aspects of the pretraining method should be emphasized. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement and offers a clear actionable suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. It lacks concrete steps or recommendations for the authors to follow, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies a potential issue but does not offer specific actions for the authors to take.", "grounding_specificity_rationale": "The comment raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. The reviewer suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the accuracy of the model. The reasoning is somewhat logical, but without detailed evidence or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is valuable as it highlights a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to incorporate gender detection models into the pipeline. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested solution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more information or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition for the proof and inquires about the impact of different distributions on determining $f^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. The comment does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. These questions are relevant and could guide the authors in improving the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the feedback is 3 as it identifies areas for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might clarify or justify the notation choices, leaving them without a clear path forward. As a result, the action is vague and lacks specificity, making it highly 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, expecting them to be analogous but noting a discrepancy. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), expecting them to be analogous but noting a discrepancy. However, the comment does not provide any reasoning, explanation, or evidence to support why the notation should be analogous or why the discrepancy exists. Without additional context or justification, the claim is not verifiable, as it lacks the necessary information to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the notation used in equations (7) and (10), expecting them to be analogous but noting a discrepancy. This feedback highlights a potential issue in the clarity or consistency of the paper, prompting the authors to investigate and address the notation choices. However, the comment does not provide specific suggestions or guidance on how to resolve this issue or improve the clarity of the equations. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it provides a logical reasoning by stating that the authors should provide empirical evidence to demonstrate its effectiveness. However, the comment lacks specific examples or references to support the claim that the model captures diffusion phenomena in realworld scenarios. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the proposed model to realworld diffusion processes. It acknowledges the elegance of the solutions presented but suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to address the applicability issue by providing empirical evidence. However, the comment could be more helpful if it offered suggestions on how to conduct such experiments or what specific aspects of the diffusion process should be examined. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more novelty or depth in their methodology section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific references or detailed reasoning to support the claim that the ENCODE part is already proposed. The suggestion about the decomposition part is somewhat vague, as it does not provide a clear explanation of what the authors should do to address this issue. Therefore, the claim is 3, as it requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which involves factoring M_v into factor D and slicing Phi_v. While the comment highlights a potential weakness in the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific information should be included in the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or clarified regarding the domain of the inputs. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what additional information might be needed. Without actionable feedback or detailed advice, the authors are left with a vague understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity regarding what aspects of the performance comparison should be considered or how it should be conducted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not offer guidance on how to conduct this comparison or what aspects to focus on. Without detailed instructions or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a general direction but lack detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation, specifically mentioning that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion for an illustrative figure provides some specificity, making the comment weakly grounded but specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding visual aids. However, the comment could be more helpful if it offered specific examples of what types of figures or illustrations would be beneficial. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states that x and y are dependent given W. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to resolve the conflict. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the definition of Z\u00e2\u0080\u0099 and possibly revise the equation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z' and the independence of x and y given W. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. The reviewer provides a logical explanation by taking Z' to be the empty set, which leads to a contradiction with Eq. (7). This reasoning is 3 as it highlights a potential issue but lacks detailed justification or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. By taking Z' to be the empty set, the reviewer demonstrates a logical contradiction that could be addressed. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue or improve their draft. While it points out a potential problem, it lacks actionable advice or detailed feedback to help the authors fully address the issue. Therefore, the comment is 3, as it highlights a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. This provides clear guidance on how to improve the figure. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of the subscripts in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks the necessary evidence or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the visual presentation of the data, specifically the subscripts in Figure 3. It acknowledges the comprehensive nature of the data but points out that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a concrete suggestion for improving the visual presentation of the data. However, the comment could be more helpful if it offered specific suggestions on how to enhance the subscripts, such as font size, color, or layout. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is considered a grounding comment as it clearly identifies the issue with the spacing. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific adjustments or improvements to the spacing. The action is implicit and vague, leaving the authors without clear direction on how to improve the paper in this regard. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the reduced whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper violates the 9page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s acceptability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s formatting, noting that the reduced whitespace throughout the document results in cramped equations and captions too close to the figures. This is a clear and actionable observation that could impact the paper\"s readability and adherence to the 9page limit. However, the comment does not provide suggestions on how to address this issue or improve the spacing, such as recommending adjustments to the spacing between elements or providing examples of better spacing practices. While it highlights a significant problem, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should clarify this concept in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer definition or explanation of the concept. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the concept of \"local interactions,\" specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of \"local interactions,\" specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it identifies a potential area of confusion in the paper that could be clarified for readers. However, the comment lacks specific guidance or suggestions on how the authors might clarify this concept, such as providing examples or additional context. While it points out a potential issue, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the paper\"s claims regarding the Molecule generation experiment, specifically noting that the proposed constrained method actually yields lower validity and diversity. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to improve the results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results in the Molecule generation experiment are not as expected, specifically that the proposed constrained method actually yields lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper\"s claims regarding the Molecule generation experiment, specifically noting that the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\"s conclusions and credibility. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out a potential problem, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are instructed to provide a comment on the update process. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the update process of the archetype positions after initialisation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update process of the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it directs the authors to provide a comment on the update process. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how the update process might be explained. Overall, the comment is 4 as it points out a critical area for clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It also specifies what is missing, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes several claims about the missing information in the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These claims are 3 as they are based on logical reasoning and common knowledge about empirical studies. However, the comment could be strengthened by providing specific references or examples to support the claims or by offering more detailed explanations of the missing information. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper should perform crossdataset experiments to test the generalization of the work. While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for crossdataset experiments and determine how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of methods that exploit relationships between action units, noting that these relationships can differ across datasets. The comment suggests that the paper lacks crossdataset experiments to test the generalization of the work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that methods that exploit relationships between action units can suffer from differences in relationships across datasets, as seen in Figure 1. The reviewer suggests that crossdataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim 3, as the authors would need to infer the significance of the differences in Figure 1 and understand the implications of performing crossdataset experiments. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a potential issue with the generalization of such work, as demonstrated by the differences in cooccurrences of action units in Figure 1. The comment suggests that crossdataset experiments are necessary to test the generalization of the work. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct these experiments or what aspects of the relationships should be examined. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so or provide specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about the environment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is 1, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. This feedback is 3 as it identifies a specific area where the paper could be improved by providing additional context or background information. However, the comment lacks depth and does not offer specific suggestions on what aspects of the environment should be described or how this information could enhance the paper. While it points out a potential area for improvement, it does not provide actionable guidance or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described or compared. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level (though sparsity by landmark) and the complexity of the parsing model, which is described as a highorder factor graph with four types of factors. The reviewer suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment provides some logical reasoning by pointing out the timeconsuming nature of the training process, it lacks specific examples or references to existing work that could substantiate the claim. This makes the claim 3, as it provides a general idea but requires more detailed evidence or references to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described or compared. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should explore other domain adaptation methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other methods but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections, figures, or specific techniques. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of old and simple methods, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. The reviewer suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. The claim is 3 as it provides a specific example of an older method being used and suggests a potential improvement. However, it lacks detailed evidence or references to support the claim that more recent methods are indeed more effective. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on which domain adaptation methods to consider or how to implement them. The feedback is 3 as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the authors are left without a clear path for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects performance in a scenario where the game has repetitive background sounds. The reviewer also points out that the authors note that their method underperforms in this scenario, implying that the ablation could help remedy this issue. While the comment explicitly states the action of conducting an ablation, it does not provide specific guidance on how to implement this ablation or what specific aspects to focus on. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects performance in a scenario where the game has repetitive background sounds. This provides a clear direction for the authors to consider conducting an ablation. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the weighting method is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in suggesting an ablation and providing a rationale for its importance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation on the weighting method of the crossentropy loss, specifically mentioning that it could help remedy performance issues in a scenario with repetitive background sounds. This claim is 3 as it is based on a logical reasoning that the weighting method might have an impact on performance in such a scenario. However, the comment lacks specific examples or references to support the claim, such as data or experiments that demonstrate the effectiveness of the weighting method in this context. This makes the claim 3, as it provides a reasonable basis but requires more detailed evidence to fully substantiate it.", "helpfulness_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects performance in a scenario where the game has repetitive background sounds. This is a clear and actionable suggestion that could help the authors improve their draft by exploring the impact of the weighting method on performance. The comment also references the authors\" previous work, noting that the method underperforms in this scenario, providing a rationale for why the ablation is important. However, the comment could be more helpful if it offered specific guidance on how to conduct the ablation or what aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is 3, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. While the comment provides a clear understanding of the issue, it lacks specific suggestions or guidance on how the authors might address this weakness. The feedback is 3 as it identifies a significant problem but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This feedback is clear and provides a specific action for the authors to take, which is to provide examples to support their argument. The comment is concrete in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for solid examples to support the argument. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more explanation and justification for their claims. It points out that the removal of certain assumptions like bounded variance and bounded gradients is an important contribution, but it does not provide examples or detailed reasoning to support this claim. While the comment highlights a potential gap in the paper, it lacks specific guidance on how the authors might address this issue. Therefore, the comment is 3 as it directs the authors to a specific area needing improvement but does not fully support them in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the implementation of ImageNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training and references two external works, which provides some level of detail. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The comment suggests that labeled data might provide effective information for consistency training, referencing two external works to support the claim. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references provide some context, the comment could be strengthened by explaining how the labeled data might be beneficial or by discussing the specific aspects of the referenced works that support the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data might provide effective information for consistency training, which could be a valuable addition to the current approach. The comment references two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could be used to support the claim. However, the comment lacks depth and does not provide specific guidance or suggestions on how to implement this idea or integrate it into the current work. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the method\"s superiority. The suggestions for reorganization and the inclusion of specific experimental content are detailed, providing clear guidance for the authors to make improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and includes specific experimental suggestions that should be included in the main text. This feedback is valuable as it guides the authors on how to improve the presentation and clarity of their experimental results, which is crucial for the paper\"s credibility and impact. However, the comment could be more helpful if it included examples of how the experimental content could be reorganized or if it provided more detailed guidance on the specific experimental suggestions. Overall, the comment is 4 as it offers clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the shorter training time or consider publishing the code. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the shorter training time for Gerrymandering compared to Independent, and suggests that the code should be published if the main advantage is its computation time. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also mentions that in Experiment 2, ERM and plugin have similar performance to Kearns et al. and that the main advantage is the computation time. The comment suggests that publishing the code could be beneficial if the main advantage is the computation time. However, the comment lacks specific examples or references to support the claim about the training time or the advantage of the code. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might not be reasonable. It also points out that in Experiment 2, ERM and plugin have similar performance to Kearns et al. and that the main advantage is the computation time. The comment suggests that publishing the code could be beneficial if the main advantage is the computation time. While the comment identifies a potential issue with the experimental setup and suggests a potential improvement, it lacks specific guidance or actionable steps for the authors to address the issue or improve their work. The feedback is 3 as it highlights a potential area for improvement but does not provide detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on line 113. While the comment provides explicit actions for the authors to take, such as describing alternate formulations and clarifying the additional information captured by CD, it does not specify how to implement these actions or provide detailed guidance on how to address the questions raised. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on the additional information captured by Confidence Diversity (CD) on top of Predictive Uncertainty. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on the additional information captured by Confidence Diversity (CD) on top of Predictive Uncertainty. The reviewer acknowledges difficulty in understanding the extra information captured by CD and questions the entropy measure. However, the comment does not provide specific examples or references to support the claim that entropy is not a good measure or that CD captures additional information. This lack of detailed justification or evidence makes the claim 3, as the authors may find it challenging to fully understand and address the critique without additional guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarify the additional information captured by CD on top of Predictive Uncertainty. It also questions the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on line 113. This feedback is specific and provides the authors with a clear direction for improving their draft by addressing the identified issues. However, the comment could be more helpful if it offered suggestions on how to present the alternate formulations or provided examples of other measures that could be used. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. The reviewer points out that this is a problem, especially considering the other factors mentioned in Section 4.1 that contribute to the human baseline\"s weakness. Additionally, the comment notes that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. While the comment identifies a clear issue, it does not provide explicit guidance on how the authors should address this problem or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the duration of the human baseline and possibly revise the abstract statement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, the comment points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the limited duration of the human recordings. The reviewer supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, which is a significant difference compared to the model baseline. Additionally, the comment highlights that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that demonstrate the impact of limited human data on baseline performance. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. The comment also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited duration of the human baseline. This feedback is valuable as it highlights a potential weakness in the study that the authors should address to ensure the robustness and credibility of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or improve the human baseline. Overall, the comment is 3 as it identifies a critical issue and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue of the assumption being too strong, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and costeffectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and vague, as the authors are left to infer that they should consider using these methods as a baseline. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is 3 as it points out a potential gap in the paper\"s evaluation, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. To be more helpful, the comment could offer guidance on how to effectively use these methods as baselines or provide examples of how they could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should clarify this ambiguity or what specific actions they should take to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the use of \"efficient proxy\" or \"efficient proxies\" in their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the term and suggests that it might refer to a family of efficient proxies rather than a particular proxy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the term \"efficient proxy\" or \"efficient proxies\" in the paper, suggesting that the use of \"is\" might imply a particular proxy but that there is no such proxy called \"Efficient Proxy.\" This provides a logical reasoning for the claim, but it lacks specific examples or references to support the argument fully. The authors might need to clarify the use of these terms in their work, but the comment does not provide detailed guidance on how to do so. Therefore, the claim is 3, as it highlights a potential issue but lacks comprehensive evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the use of \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of efficient proxies. This feedback is 3 as it points out a potential source of confusion in the paper, which the authors can address to clarify their terminology. However, the comment could be more helpful if it provided suggestions on how to clarify this ambiguity or offered examples of how the authors might use the term more effectively. Overall, the comment is 3 as it highlights an area for improvement but lacks detailed guidance for the authors to fully address the issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model\"s complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of narrow focus and its potential impact on the broader impact of the work, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\"s impact. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential limitation of the work, noting that its focus on a narrow task (climate change QA) in a specific language (Arabic) could limit its broader impact. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or broaden the scope of their work. The comment lacks actionable feedback or detailed advice on how to enhance the paper\"s impact, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the action is explicit, it is somewhat vague as it does not specify which part of the main paper should include the mention of computational cost or how to present the runtime examples. However, the authors can infer that they need to add this information to the main paper and provide examples, making the comment 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper should include this information or where the computational cost is discussed in the appendix. The authors can infer that it relates to the main paper, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of computational cost information and providing an example, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim about the computational cost. The recommendation for runtime examples is 3, as it provides a clear direction for improvement but could be strengthened with more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which is currently discussed in the appendix, to help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and accessibility of their work. By addressing these points, the authors can significantly improve the clarity and appeal of their paper, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role. While the comment identifies a potential issue with interpretation, it lacks specific examples or references to support the claim that the spatial arrangement of the sensors is relevant. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should clarify this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and understanding of their results. By addressing this issue, the authors can enhance the transparency and interpretability of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. This makes the claim 3, as it requires further elaboration to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is 3 as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to improve the clarity or what specific aspects need to be clarified. The authors are left to infer that they need to clarify the modelled curves, but without concrete instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of not being immediately obvious what is being modelled, which is a clear and actionable concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction is unclear about what is being modelled, specifically mentioning \"modelling curves\" and presumably tumour growth. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of \"modelling curves\" does not immediately clarify the context, which is presumably tumour growth. This feedback is 3 as it highlights an area where the introduction could be improved to enhance the reader\"s understanding of the paper\"s focus. However, the comment does not provide specific suggestions or guidance on how to clarify this aspect, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks clarity regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This suggestion is based on logical reasoning and a clear understanding of the paper\"s content, making it 4. However, the comment could be strengthened by providing more detailed examples or references to similar studies, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, specifically regarding the optimization strategies and their corresponding results. It suggests that the paper should provide more explanation to make these contributions clearer. The reviewer provides a concrete example by asking what would happen by minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is actionable and constructive, as it guides the authors on how to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to present this information effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly specifies what the authors need to do to improve their draft. The comment provides a clear and concrete direction for the authors to add a definition, making it 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including a definition. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can ensure that readers understand the concept and its importance in the context of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the definition or examples of how it has been used in the proofs. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the performance of their algorithm. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the selfcontainment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the selfcontainment or what specific aspects of the supplementary material should be included. The action is explicit but somewhat vague, as the authors need to determine which parts of the supplementary material are most critical for selfcontainment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the selfcontainment of the paper and the need for the authors to release the source code of their experiments for reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. The reviewer also requests the authors to release the source code of their experiments. While the comment identifies a potential issue with the selfcontainment of the paper, it lacks specific examples or detailed reasoning to support why the supplementary material is necessary or how the source code release would enhance reproducibility. The claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the selfcontainment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it provides specific guidance on how to improve the selfcontainment and reproducibility of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the supplementary material or what specific aspects of the source code should be released. Overall, the comment is 4 as it directs the authors to address a critical aspect of their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithms need clarification. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is explicit and concrete, as it specifies the need for clarification and provides a clear direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the rationale behind the choice of algorithms and the potential influence of the attention model paper. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify their methodology and provide a more transparent explanation of their decisions. This feedback is clear and constructive, as it directly addresses a potential area of confusion or misunderstanding in the paper. However, it could be more helpful if it included examples or references to similar works that might have influenced the choice of algorithms. Overall, the comment is 4 as it guides the authors toward improving the clarity and transparency of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure where this analysis is discussed. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a direction for further exploration. However, the comment lacks specific guidance or suggestions on how to address this issue or what kind of theoretical support is needed. While it points out an important area for improvement, it could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network\"s training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network\"s training process, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of detail regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of detail in the paper regarding how the network fits the residual instead of directly learning the inputoutput mapping. This is a relevant point that could impact the clarity and understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights an area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details on the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific suggestions on how to do so or what specific aspects to focus on, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the initial calibration steps should be examined. The comment is 3 as it points out a potential area for improvement, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that these tasks are affected by the emission distributions. This makes the claim 3, as the authors would need to make a logical deduction to understand the implications of the emission distributions on inference tasks. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their model for inference tasks. However, the comment could be more helpful if it provided specific suggestions on how to address this gap or examples of how the emission distributions affect inference tasks. Overall, the comment is 4 as it directs the authors to a critical area needing further exploration and explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the reasons behind the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the underlying reasons for the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a more thorough analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the paper\"s analysis. However, the comment lacks depth and does not provide specific guidance on how to conduct the additional analysis or what aspects of the batch and greedy algorithms should be compared. While it points out a potential gap in the analysis, it does not offer detailed suggestions for enhancing the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to external works that may be relevant to understanding the process. While the comment identifies areas of confusion, it does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to clarify the calculations or the explanation of ELLA. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process and explanation of \u03bb and ELLA. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s impact on sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s impact on sample efficiency in a COMBO environment. The reviewer provides references to external works, which could help substantiate the claim that these issues are relevant and significant. However, the comment lacks detailed reasoning or specific examples from the references to fully support the claim. While the references provide some context, the comment itself does not contain a clear argument or evidence to fully verify the claim. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It raises questions about how \u03bb is calculated and the explanation of ELLA\"s impact on sample efficiency in a COMBO environment. The reviewer provides references to relevant external works, which could be helpful for the authors to understand and address the issue. However, the comment lacks specific guidance or suggestions on how the authors might clarify or improve their explanation. While it points out areas of confusion, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue. The comment lacks explicit instructions or concrete details on what the authors should do to clarify or expand on this aspect of their work. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding this method, making it underspecific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the specific method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the explanation. The comment lacks depth and actionable feedback, leaving the authors with only a vague idea of what needs to be clarified. Therefore, the comment is 2, as it points out a potential weakness but does not offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of lower bound double qlearning, particularly in the context of convergence and overestimation of true maximum values. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, based on observations from Figure 2 and specific environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. The reviewer provides some evidence by mentioning the slight performance decrease in MsPacman and the convergence of algorithms in other environments. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While it provides some support, the lack of detailed evidence or references makes the claim 3, as the authors would need to further explore the data or arguments to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of lower bound double qlearning, specifically questioning its performance in certain environments and its tendency to overestimate true maximum values. It provides specific examples from Figure 2 and other environments, which helps the authors understand the basis of the critique. However, the comment could be more helpful if it offered suggestions on how to address these concerns or improve the algorithm. While it highlights a relevant area for improvement, the lack of actionable guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the novelty is lacking or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\"s contribution, which could be addressed by providing more novel or innovative approaches to model interpretation. However, the comment does not offer specific suggestions or guidance on how the authors might enhance the novelty or address this limitation. While it points out an area for improvement, the lack of actionable advice makes it 3, as it provides insight but not a clear path for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete steps or detailed advice on how to clarify or improve the explanation in the paper. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential inconsistency in the results or expectations, prompting the authors to clarify or address this issue in their paper. However, the comment lacks specific guidance or suggestions on how to resolve this discrepancy or improve the explanation in the paper. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for further exploration but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or references to the earlier works that the authors have overlooked, making it 3. The authors would need to infer which systems are being referred to and potentially conduct additional research to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020. While the authors have explained their reasons for not doing so, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison with existing work. By addressing this point, the authors can strengthen the validity and relevance of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the authors could provide more detail or elaboration. It points out that the Hoeffding\"s bound and its implications for stochastic algorithms are not fully explained, suggesting that elaboration on this topic would be beneficial. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work that could enhance its clarity and depth. However, the comment could be more helpful if it provided specific suggestions on how to elaborate on the topic or what aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions on how to implement this suggestion or what specific details should be included. The action is clear but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could enhance the paper by providing additional context and comparison to existing methods. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\"s overall contribution. While it points out a potential area for improvement, it could be more helpful if it included more detailed reasoning or examples of how this addition would enhance the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to explain why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the prompt was chosen in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a gap in the experimental design. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It highlights the need for careful consideration of these terms to avoid confusion and ensure clarity in the paper. However, the comment does not provide detailed guidance on how to address this issue or suggest alternative terms that could be used. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks detailed explanation or analysis of why the assumptions are unclear or how they impact the paper\"s significance. The reference to the external work is helpful but does not fully substantiate the claim. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification or detailed reasoning.", "helpfulness_rationale": "The review comment questions the novelty and significance of the paper, suggesting that the use of PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper\"s novelty and significance, it lacks specific guidance on how the authors might address these concerns or what aspects of the assumptions need clarification. The reference to the external work is helpful, but the comment could be more actionable by providing more detailed feedback or suggestions for improvement. Overall, the comment is 3 as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It asks a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the fewshot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, referencing external sources. However, it does not provide specific details or comparisons to support this claim, such as which models are considered stateoftheart or how the performance of the models in question compares to those mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the fewshot RC models considered are not stateoftheart models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is 3 as it prompts the authors to consider the relevance and impact of their model selection. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as suggesting alternative models or methods for comparison. Overall, the comment offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, specifically that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific suggestions on what kind of results or observations would be beneficial, leaving the authors with a general direction but not detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to consider these questions, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the choice of 20 distribution sets is problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is 3 as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these issues. While it highlights an important area for consideration, the lack of detailed guidance limits its utility. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper by aligning it with current research practices. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are carried out on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more relevant to current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that these older models are indeed obsolete. The authors might need to conduct additional research to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement. It points out that the perplexity experiments are conducted on obsolete language models, specifically ngram HMM and RNN, which are not commonly used in current NLP trends. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more relevant and uptodate. This feedback is valuable as it guides the authors to align their work with current research practices, making it more impactful and relevant. However, the comment could be more helpful if it provided specific examples or references to recent studies that use transformerbased models for perplexity experiments. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify this issue or what specific steps they should take to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper this discussion is located in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu, as it is the proportion of missing observations, which is not clear how it can be estimated. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. This is a factual observation about the content of the paper, but it does not present an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, which makes it unclear how it can be estimated. This is a relevant point that could help the authors clarify their discussion or provide additional context to improve the understanding of their work. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue. While it points out a potential area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggested approach. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, with a detailed explanation of how to implement this approach. This includes randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. The comment is specific in detailing what needs to be addressed and how to implement the suggested approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This claim is 3 as it logically suggests that the mean error and variance might increase as the quality of initialization decreases. However, the comment lacks detailed justification or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which is a clear and concrete approach. The comment also provides a detailed explanation of how to implement this approach, including randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. This feedback is 5 as it offers a clear path for the authors to improve their draft by addressing a critical aspect of their work. By following this suggestion, the authors can enhance the robustness and generalizability of their results. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and robustness measures, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of highprobability bounds using ensemble methods, as performed in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the robustness and reliability of their results. By addressing these suggestions, the authors can significantly improve the quality and credibility of their work. However, the comment could be more helpful if it provided examples or references to ensemble methods or robustness measures that have been successfully used in similar contexts. Overall, the comment is 4 as it offers valuable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specific areas for improvement, it lacks full grounding as it does not explicitly mention where these aspects should be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides some insight into areas that could be improved, it lacks specific guidance on how to address these issues or what specific metrics should be considered. The feedback is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it is merely an application of a similar methodology to a new task. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific aspects of the paper need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper, specifically questioning whether it is merely an application of a similar methodology to a new task. However, it does not specify which part of the paper this concern relates to, such as the methodology or the application to the new task. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the concern effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the novelty of the paper, suggesting that it may be incremental and similar to a previous work. However, it does not provide specific examples or references to the work mentioned, making it difficult for the authors to understand the exact basis of the claim. Without detailed comparisons or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether it is merely an application of a similar methodology to a new task. While it identifies a potential issue with the paper\"s originality, it does not provide specific guidance or suggestions on how the authors might address this concern or differentiate their work from existing literature. The comment lacks actionable feedback or detailed analysis, leaving the authors without clear direction on how to improve the novelty of their work. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer constructive advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a discrepancy in the reported ablation studies, specifically regarding the performance of the complete loss function compared to those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the reported ablation studies, specifically regarding the performance of the complete loss function compared to those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are invalid. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the reported ablation studies, specifically regarding the performance of the complete loss function compared to those with missing terms on the CUB and SOP datasets. It questions the validity of these results and points out that the complete loss function performed worse than expected. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable advice or detailed feedback, the authors are left with a vague understanding of the problem and no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the statement in question, which is \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions.\" However, the comment lacks further explanation or justification for why this statement is unclear or how it could be clarified. Without additional context or examples, the claim is 3, as it provides a specific issue but does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggests that it should be revised to be more highlevel. It also points out that technical details are not necessary for the abstract. This feedback is clear and actionable, as it provides the authors with a specific area to focus on for improving the clarity and accessibility of their abstract. However, the comment could be more helpful if it offered suggestions on how to simplify the statement or provided examples of how to achieve a more highlevel abstract. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to incorporate them into the paper. While the suggestion is clear, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks. However, the comment does not specify which part of the paper should include these results or how they should be integrated. While the authors might have an idea of where to include these results, the lack of explicit guidance makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. The comment provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks, suggesting that people care more about OOD performance. However, the comment lacks specific examples or references to support the claim that expected test loss is not as relevant for languagerelated tasks. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It provides a rationale for why expected test loss might not be as meaningful for languagerelated tasks, suggesting that people care more about OOD performance. This feedback is 3 as it identifies a potential area for improvement and provides a logical basis for the suggestion. However, the comment could be more helpful if it offered specific guidance on how to incorporate these results or what aspects of OOD performance should be prioritized. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the importance of considering how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. The reviewer suggests that the paper defines and creates a fewshot situation but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"fewshot.\" This makes the claim 3, as the authors would need to further develop the reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the motivation of the work, specifically in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their work. However, the comment could be more helpful if it provided specific suggestions on how to effectively use \"fewshot\" or how to ensure generalizability. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in detailing the issue with the use of GP but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors might need to explore the literature further to understand the specific aspects of the critique. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of how to enhance the novelty or innovation of the work. As a result, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\" experience, as evidenced by the training of 1500dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the statement regarding the need for smaller architectures in LM compared to GAN models, questioning the claim and suggesting that the baseline models are not properly regularized. The comment further asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which suggests that the baseline models are not properly regularized. This provides a logical and 3 argument against the claim, as it challenges the authors\" assertion with a specific example. However, the comment could be strengthened by providing more detailed evidence or references to support the counterexample. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific statement in the supplemental section D.4 that the reviewer finds questionable, suggesting that the claim about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\" experience. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant area for clarification or discussion. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. Therefore, the comment is 3, as it points out a specific area for clarification but does not provide comprehensive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that some ablations are difficult to locate in the following contents, suggesting that the writing could be improved in this part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following contents, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or how to address them. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. It suggests that the writing could be improved in this part. While the comment highlights a potential problem, it lacks specific guidance or suggestions on how to improve the clarity of the writing or where the ablations should be better integrated. This limits the comment\"s usefulness, as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not address the issue of the differential privacy application being \"halfbaked.\" The lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the differential privacy application, suggesting that it is currently \"halfbaked.\" It encourages the authors to think through it more clearly and integrate the online algorithm and robustness into the main paper. This feedback is 3 as it points out a specific area for improvement, but it lacks detailed guidance or suggestions on how to address the issue. The authors are given a general direction but may need to infer more specific steps to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current methodology is insufficient or why robotic manipulation would be more appropriate. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance on how to implement this change or what aspects of the methodology need to be adjusted. The authors are given a direction to consider, but the comment could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of Geffect values or recommending specific analyses to be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. It points out that studying Geffects of each learning objective in isolation raises questions about the validity of these comparisons. This feedback is 3 as it highlights an area where the authors may need to address potential issues in their analysis. However, the comment lacks specific suggestions or guidance on how to address this concern, such as recommending additional analyses or discussing potential solutions. While it provides some insight, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the results, specifically the advantage of UNIFORM over other procedures, which is not consistent across the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. Additionally, the comment praises the clarity and welldesigned experiments, providing a clear direction for improvement. However, the comment does not specify which tables or sections need clarification, making it 3. The authors are given a general idea of what needs to be addressed, but the lack of specific guidance on how to implement the suggested clarification makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"tables\" and the \"1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the advantage of UNIFORM over other procedures, noting that the tables show that UNIFORM does not always offer a clear advantage. Additionally, it asks for clarification on why the method is not as effective in the 1shot setting and praises the clarity and welldesigned experiments. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables, and questions whether the authors have a theory to explain this. The comment also praises the clarity and welldesigned experiments, providing a 3 basis for the claim about the advantage of UNIFORM. However, the comment lacks specific examples or references to the tables or experiments that support the claim, making it 3. The authors would need to further investigate the tables and experiments to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results, specifically the advantage of UNIFORM over other procedures, which is not consistent across the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting and provides a clear direction for improvement. Additionally, the comment praises the clarity and welldesigned experiments, which is a positive aspect of the paper. However, the comment could be more helpful by providing specific examples or references to the tables or sections where the discrepancy is observed. Despite this, the feedback is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, and if there is any existing linguistic theory that could explain it. It also recommends adding this information to make the paper stronger. While the comment implies that the authors should explore this topic, it does not provide specific guidance on how to integrate this information into the paper or what specific linguistic theories to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This provides clear guidance on what the authors need to consider and explore in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and rigor. However, the comment could be more helpful if it provided specific suggestions on how to integrate this information or what linguistic theories to consider. Overall, the feedback is valuable in guiding the authors to strengthen their paper, but it could be more comprehensive with additional details. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It explicitly suggests that the authors should spend more time discussing these aspects, such as the biggest takeaways from the found architecture. This feedback provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the issue by pointing out that the authors did not spend much time discussing these aspects, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. The reviewer suggests that the authors did not spend enough time discussing these aspects, such as the biggest takeaways from the found architecture. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these aspects and the potential benefits of discussing them, which may not be immediately clear without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of discussion on the potential benefits of using AutoML approaches beyond raw performance. It suggests that the authors should spend more time discussing these aspects, such as the extraction of hints for future network architecture design. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper by addressing a critical aspect of the AutoML approach. However, the comment could be more helpful if it offered specific examples or insights into what might be the biggest takeaways from the found architecture. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and where it should be resolved. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of T_a(t) in Section 3.1 but only being defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the use of T_a(t) in Section 3.1 but only being defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this issue, the comment provides the authors with a specific area to focus on for revision, ensuring that the paper is more coherent and easier to follow. Therefore, the comment is 5 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for testing on more complex games, but it is somewhat vague in detailing how to implement this additional testing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on more complex games, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of input size for value and policy functions. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. This feedback is 3 as it points out a potential gap in the experimental setup and provides a direction for improvement. However, it could be more helpful if it offered specific examples of complex games or detailed guidance on how to implement the additional testing. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this contribution or where the authors should provide additional evidence or arguments. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its suggestion for improvement but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. It acknowledges that this is a significant contribution but points out the need for more substantial evidence or arguments to establish it as such. This feedback is 3 as it highlights an area where the authors could strengthen their paper by providing additional evidence or arguments to support their claim. However, the comment lacks specific suggestions on how to present this evidence or what kind of arguments would be most effective. Therefore, it provides some guidance but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\"s theoretical foundation and provide additional insights to readers. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative measures to evaluate the VCEs. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs. The comment provides a clear direction for improvement by suggesting the inclusion of quantitative measures, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of quantitative measures to evaluate the generated VCEs. It highlights that the evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics should be used. While it points out a gap in the paper, it lacks actionable suggestions that would help the authors address the issue effectively. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, indicating that the performance differences are not significant. However, the comment does not specify which part of the paper discusses these claims or the baselines, making it weakly grounded. The comment is specific in its critique of the performance improvements and the error range, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. The reviewer questions the significance of these performance differences, suggesting that the error range is high. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It questions the significance of these performance differences, suggesting that the error range is high, indicating that the performance differences between some methods are not very significant. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or improve the performance of their method. The feedback is 3 as it points out a potential weakness, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what exactly is missing or how to improve the evaluation set. As a result, the authors are left without clear direction on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding the evaluation set, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation compared to the previous method, and that the selection of representative images is unclear. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how to address these issues, nor does it offer guidance on how to improve the diversity and representation of the evaluation set. While it highlights a significant area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it points out a critical issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), providing a clear direction for the authors to consider the context and implications of this term in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), which is cited in the paper. This question prompts the authors to consider the context and implications of the term in their work, potentially leading to a deeper understanding and clarification of their ideas. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the paper. While it points out a relevant reference, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which additional datasets should be considered or how to implement this expansion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the experiments are limited or how the authors might expand their experiments to include more datasets. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. This feedback highlights an area where the authors could potentially expand their experiments to include more diverse datasets, which could enhance the generalizability and robustness of their results. However, the comment lacks specific suggestions on which datasets to consider or how to implement this expansion. While it identifies a potential weakness, it does not provide actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information of scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the originality of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from [10]. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The authors are left to infer that they need to consider this aspect, but without concrete steps or examples, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a sparsity constraint in the number of factors used by subsequent tasks, which is a critical aspect of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to increased computation with more tasks. The comment provides a logical reasoning by explaining the potential consequences of this lack of constraint, but it does not provide specific examples or references to substantiate the claim. The authors might find it challenging to understand the exact impact of this issue without additional context or evidence. Therefore, the claim is 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This observation highlights a potential limitation of the model, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate a sparsity constraint. While it points out a relevant concern, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to conduct these experiments or what aspects of the evaluation would be enhanced by including them. The comment could be more helpful if it provided suggestions on how to design and implement these experiments, or how they would impact the evaluation results. As it stands, the comment offers a general direction for improvement but does not fully support the authors in making those changes. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 9597 and 308310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it claims consistency between training and inference due to the smoothness of neural models but lacks adequate explanations. It suggests that the authors should provide more detailed explanations on this topic. While the comment highlights an area for improvement, it does not offer specific guidance or examples on how to enhance the explanation. This limits its helpfulness, as the authors are given a direction but not detailed steps to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide additional information or experiments to fully substantiate the claim, but the comment provides a clear direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model improves with larger word embedding and LSTM parameters, which is a relevant and important point for the authors to address. The comment provides a clear direction for the authors to provide evidence or experiments to support their claim, which could significantly impact the paper\"s credibility and impact. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the authors\" approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the comment identifies an issue and provides a suggestion for improvement, it does not offer specific guidance on how to implement this suggestion or what specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"LN model\" and \"GLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization, suggesting that the authors should try to reproduce the main features of previous models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to support the claim that the GLM by Pillow et al. did not crop the image. Without these details, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image but used L1 regularization for the filters and a lowrank approximation to the spatial filter. The comment suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the feedback highlights an important issue, it lacks specific guidance on how to address it or what specific features should be reproduced. The authors are left with a general direction but no detailed steps to follow, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include failure cases and related discussions. While it implies that the authors should include these elements, it does not provide specific guidance on how to implement this suggestion or what aspects of the failure cases should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include failure cases and related discussions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including failure cases and related discussions, but it does not specify which part of the paper should include these elements. The authors cannot confidently determine which sections or parts of the paper are being addressed, making the comment weakly grounded. However, the suggestion is specific in terms of what needs to be added, providing clear guidance on what the authors should consider. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including failure cases and related discussions would be beneficial. While it provides a general direction for improvement, it lacks specificity and does not offer guidance on how to implement this suggestion or what aspects of the failure cases should be discussed. The comment is 3 as it identifies a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to improve their draft by conducting an ablation study. By addressing this point, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added and how it could enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a specific example of a brief statement made in the paper. The reviewer suggests that the paper should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This claim is 3 as it provides a specific example of an issue with the discussion of computational complexity, but it lacks detailed reasoning or references to support the importance of this addition. The authors might find it challenging to fully understand the significance of the suggestion without further explanation or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the paper lacks explicit bounds and potentially elaboration on empirical runtimes, which are crucial for understanding the practical implications of the work. The comment provides a clear and actionable suggestion for the authors to enhance their discussion by explicitly adding these details. This feedback is valuable as it guides the authors to improve the clarity and depth of their analysis, making it more comprehensive and informative for readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. The comment provides clear and concrete actions for the authors to correct the typographical errors and offers a specific question for further clarification. The action is explicit and the authors know exactly what to do to address the errors and the question. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 108\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the typographical errors, such as the incorrect \"f\" in \"we fixed the form of\" and the extra period in a sentence, and it poses a question about the baseline MCL with deep learning. The comment provides clear guidance on what needs to be corrected and offers a specific question for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific typographical errors in the manuscript, which are important to correct for clarity and professionalism. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding their methodology. However, the comment could be more helpful if it provided suggestions on how to address the issue of early learning cutoff or how to ensure that each network has converged to reasonable results. Overall, the comment is actionable and provides valuable insights, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions or concrete steps on how to conduct the study or what specific aspects to focus on. The action is clear but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous topdown and bottomup pose estimation methods in terms of inference speed. This claim is 3 as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by suggesting that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including a study of inference time and benchmarking their method against others. However, the comment could be more helpful if it offered suggestions on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding the role of batch normalization in standardizing variance and centering activation. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes variance and centers activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by detailing how these limitations impact the results or what specific aspects of batch normalization should be discussed. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes variance and centers activation. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some lowvariance units, while batch normalization standardizes the variance and centers the activation. This feedback is clear and actionable, as it explicitly instructs the authors to discuss these limitations explicitly in their paper. However, the comment could be more helpful if it provided specific examples or suggestions on how to address these limitations or what aspects of batch normalization should be discussed. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their discussion on this topic."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\"s clarity by adding more details about the contribution. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this additional description should be added to, nor does it provide any guidance on what specific aspects of the contribution should be highlighted. Without explicit references to sections or specific elements of the paper, the authors may struggle to identify where to make these additions. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or evidence, the claim is not verifiable, as it lacks the necessary support to help the authors understand and address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the contribution should be highlighted or how the additional description should be structured. Without detailed suggestions or examples, the authors may struggle to understand how to effectively enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is 5 as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layerwise attention mechanism to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layerwise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is 3, as it provides a solid foundation for improvement but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which can help clarify the contributions of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which can improve the organization and accessibility of the paper. Finally, it points out that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of supervised baselines and the scale of the datasets used in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the inclusion of supervised baselines would be informative and provide insight into the performance of selfsupervised methods compared to a fully supervised pretrained network. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, where full annotation is assumed to be available. The reviewer supports this claim by reasoning that even if full annotation is not available, having an informative baseline would be beneficial to understand the performance of selfsupervised methods compared to a fully supervised pretrained network. This logical reasoning and the suggestion for inclusion of supervised baselines provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of supervised baselines in similar contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of selfsupervised methods. It logically reasons that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment further suggests that even if full annotation is not available, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. By addressing this issue, the authors can significantly improve the robustness and comprehensiveness of their evaluation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. While the comment implies that the authors should evaluate their method on different domains and include BEAR in the baselines, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its questions about the method\"s effectiveness and the inclusion of BEAR in the baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment lacks specific examples or references to support these claims or questions. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics to assess its empirical efficacy. This feedback is valuable as it prompts the authors to broaden the scope of their evaluation, which could enhance the robustness and generalizability of their findings. Additionally, the comment questions the absence of BEAR from baselines and suggests that the method may not have much benefit without this comparison. While the comment does not provide specific guidance on how to conduct these evaluations, it offers actionable insights that can help the authors improve their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. While the action is explicit, it lacks concrete details on how to present this justification or what specific aspects should be addressed. The authors are given a clear direction to provide theoretical justification, but without specific guidance on how to do so, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for theoretical justification but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and explain their impact. However, the comment lacks specific guidance on how to present this justification or what aspects of the results should be emphasized. While it identifies a potential area for improvement, it does not provide detailed instructions or examples on how to achieve it. Therefore, the comment is 3, as it points out a need for theoretical justification but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on what details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be added to, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment identifies areas for improvement, it lacks specific guidance or examples on what details should be included or how they should be presented. The authors are given a general direction but are not provided with actionable steps to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect inconsistencies in responses due to the variety of individuals being discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method\"s detection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific example of a prompt like \"introduce a sports celebrity to me,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, namely that it might struggle to detect hallucinations in openended responses due to the variety of individuals being discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The comment provides a logical reasoning by suggesting that the variety of individuals discussed in the responses could make it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be improved with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This feedback highlights a specific challenge that the method might face in detecting inconsistencies in responses due to the variety of individuals being discussed. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method\"s detection capabilities. The feedback is 3 as it directs the authors\" attention to a specific area for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors know that they need to verify the conclusion, but the comment could be more explicit in suggesting specific experiments or methods to conduct these tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for verification on MNIST and CNN, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verification is necessary to clarify the theoretical findings. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which is a clear and actionable suggestion. This feedback is valuable as it points out a potential gap in the paper and provides a concrete direction for the authors to address it. However, the comment could be more helpful if it explained why verification on these datasets is important or how it would impact the overall conclusion. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It suggests that the lack of reporting cosine similarities for such large weight decay strengths and the ending of plots at a weight decay strength where cosine similarities are still close to optimal is convenient. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The authors are left to infer that they should report cosine similarities for larger weight decay strengths or adjust the plotting range to show the full range of cosine similarities. While the comment highlights an area for improvement, it lacks concrete instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of reporting cosine similarities for large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by pointing out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to lead to large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It points out that the lack of reporting cosine similarities for such large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper that the authors can address by reporting cosine similarities for larger weight decay strengths or adjusting the plotting range to show the full range of cosine similarities. By providing this guidance, the comment offers valuable insights for improving the draft. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment suggests that this must be fixed for publication, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious issue and implies that it should be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant problem. While the claim is logical and somewhat supported by the mention of unsupervised random forests, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This is a critical issue that could lead to incorrect conclusions by casual readers. The reviewer suggests that this omission must be fixed before publication, providing a clear and actionable piece of feedback. However, the comment could be more helpful if it offered suggestions on how to effectively communicate this information in the paper or provided examples of how similar omissions have been addressed in other works. Despite this, the comment is 4 as it highlights a significant oversight and directs the authors to make a necessary correction."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to compare the computational complexity of their proposed method with other methods. This request is clear and provides a specific action for the authors to take, which is to conduct a comparison. However, it does not specify which methods to compare with or how to conduct the comparison, leaving some room for interpretation. The action is explicit but somewhat vague in terms of execution, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the proposed method requires more computation than other methods and requests a comparison of computational complexity. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to address the request effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison of computational complexity, which is an important aspect of evaluating the practicality of their approach. However, the comment lacks specific guidance on how to conduct this comparison or which methods to compare with. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. However, it does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 5 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about the differences between methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is 4 as it provides a logical reasoning and a specific example to support the claim. However, it could be strengthened by referencing external works or studies that demonstrate the importance of significance testing in similar contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is clear and actionable, as it directs the authors to conduct significance testing to support their claims. By addressing this issue, the authors can significantly improve the rigor and credibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it points out a critical area where the authors need to provide more detailed information to strengthen their work. However, the comment could be more helpful if it offered specific suggestions on what kind of evidence or analysis would be beneficial or how it could be presented. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more details about the two baselines presented in Figure 5 and the suggestion to extend CATER to other languages. This provides clear guidance on what the authors need to improve, making the comment 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the two baselines presented in Figure 5 are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages. The comment provides a logical reasoning for the need to clarify the baselines and extend CATER, but it lacks specific examples or references to support the claim about the difficulty of comprehending Figure 5. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the two baselines presented in the figure are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and comprehensiveness of the figure and its baselines. However, it could be more helpful if it offered suggestions on how to present the additional details or what specific aspects of the baselines should be highlighted. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"main contribution of the proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper lacks clarity in distinguishing itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the claim is based on logical reasoning, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically noting that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their literature review. However, it could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the benefits of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to strengthen their work. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which would further diversify the evaluation and provide more comprehensive results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it 1.", "grounding_specificity_rationale": "The comment addresses the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its request for the inclusion of the 1shot setting, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\"s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it 3. The authors would need to infer the importance of addressing this issue themselves, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the absence of the 1shot setting in the experiment part of the paper, noting that related works like RALE have included this setting. This observation highlights a potential gap in the paper\"s experimental evaluation, which could impact the authors\" conclusions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to fully explore the 1shot setting. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. The authors can infer that it relates to the discussion of LLMs, but this inference is not direct. The comment is specific in suggesting the need for more discussions, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically regarding the limitations and challenges of LLMs. However, the comment lacks specific guidance or suggestions on what aspects of these discussions should be included or how to structure them. While it points out a gap in the paper, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This implies that the authors should make a conscious effort to emphasize these aspects in their draft. However, the comment does not provide specific guidance on how to highlight these observations or what aspects should be emphasized. While the action is implied, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, which implies that the authors should highlight these aspects in the paper. However, it does not specify which observations or conclusions are being referred to, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what aspects of the observations and conclusions should be highlighted or how they should be presented. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not clearly highlighted or discussed. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these aspects would be beneficial for understanding the tradeoffs of annotation effort and corresponding training performance. While the comment provides a clear direction for improvement, it lacks specific guidance on how to highlight these observations or what aspects should be emphasized. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed suggestions on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct ablation experiments to validate the model performance, given that several modifications mentioned in Section 3.4 have been used. This feedback is explicit in its request for additional experiments, providing a clear action for the authors to take. However, it does not specify which modifications should be tested or how to conduct the ablation experiments, leaving some details to be inferred. While the action is clear, the lack of concrete guidance on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that ablation experiments should be conducted to validate the model performance, given that several modifications mentioned in Section 3.4 have been used. This claim is 3 as it logically suggests that such experiments would provide additional insight into the model\"s performance. However, the comment lacks specific examples or references to the modifications mentioned in Section 3.4, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct ablation experiments to validate the model performance, given that several modifications mentioned in Section 3.4 have been used. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s validation and analysis. However, the comment could be more helpful if it specified which modifications should be tested or how to conduct the ablation experiments. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references in the paper), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the KDE requiring more data when the classifier space is beyond binary and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the KDE requiring more data when the classifier space is beyond binary, which is relevant to the paper\"s methodology. It raises a question about whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment highlights an area for potential improvement, it lacks specific guidance or suggestions on how to address this issue or what specific datasets should be considered. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as specific sections or experiments where these issues are discussed. The authors may infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to address. The first question asks how the capacity of the SR model affects the FID, which could provide insight into the relationship between model capacity and performance. The second question about unexpected artifacts due to the proposed method being pipelined could help the authors identify potential issues or limitations in their methodology. However, the comment lacks specific guidance or suggestions on how to investigate or address these questions, leaving the authors with a general direction but without detailed steps to follow. While it points out areas for further exploration, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and provide a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the blank Appendix A and the unclear purpose of Proposition B.1, suggesting that it might be illustrating a wellknown concept in machine learning. The comment also points out the missing \"proof\" for this proposition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the purpose is unclear or that the \"proof\" is missing. This makes the claim 3, as the authors would need to further investigate and clarify the purpose and proof themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out the missing \"proof\" for this proposition. This feedback is clear and actionable, as it directs the authors to clarify the purpose and provide evidence for their claims. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar concepts have been presented in other works. Overall, the comment is 4 as it highlights important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should expand on the possible vulnerability of the approximations, particularly regarding the assumption of attacks being in the feasible set only in those lines. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the concern about the vulnerability of the approximations. As a result, the claim is 3, as it requires further elaboration to be fully understood and actionable by the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107110. It points out that while approximations are necessary, the paper does not adequately address the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. The comment suggests that the authors should expand on this issue to reassure readers that it is not a real concern. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to address it. However, it could be more helpful if it included suggestions on how to present this information or what additional details should be included. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, particularly on \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It also recommends providing more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details about the evaluation procedures is specific, but without clear grounding, the authors may struggle to identify where to address these issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. The comment suggests that more careful analysis is needed, particularly for these \"old\" benchmarks. However, the comment lacks specific examples or references to support the claim that the model\"s performance on these benchmarks is problematic. Without detailed evidence or reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It suggests that more careful analysis is needed, particularly for these benchmarks. Additionally, it recommends providing more details about the evaluation procedures, which could help the authors improve the transparency and robustness of their results. While the comment highlights important areas for consideration, it lacks specific suggestions or guidance on how to conduct the additional analysis or what details to include in the evaluation procedures. This limits the comment\"s helpfulness, as it provides a general direction but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of collaborative games, but without grounding, it is difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be beneficial in exploring the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it provides a specific direction for the authors to consider when designing their experiments. However, the comment could be more helpful if it offered examples of collaborative games or provided guidance on how to incorporate them into the existing experimental setup. Overall, the comment is 4 as it points out a meaningful area for improvement and provides a clear suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the rationale, but it could be more beneficial with additional details or examples on how to improve the clarity of the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of comparisons with existing fairness algorithms. The comment provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would significantly enhance the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that integrating benchmark comparisons against stateoftheart fairness algorithms would significantly enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This claim is 3 as it logically suggests that comparisons with existing fairness algorithms would strengthen the paper, but it lacks specific examples or references to existing work that could be used for comparison. The authors would need to infer the specific fairness algorithms to include and how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against stateoftheart fairness algorithms, which would significantly enhance the paper by offering tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is 5 as it guides the authors on how to strengthen their experimental section and improve the overall quality of their work. By addressing this suggestion, the authors can significantly enhance the credibility and impact of their paper. Therefore, the comment is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. However, the comment does not offer explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the TransformerM model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, as evidenced by TransformerM\"s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from QM9 in downstream experiments, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. As it stands, the claim is 4 due to the example provided, but it could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This feedback is 3 as it points out a specific area of concern and highlights a potential contradiction in the paper. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their description of the neural network model. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" statement on lines 8082 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer questions why the metric was considered useful in one place but not another, or what the authors meant by their statement. This feedback implies that the authors should clarify their reasoning or explanation for using the metric in both contexts. However, it does not provide explicit instructions on how to address this issue, leaving the authors to infer the action. The comment is 3 as it identifies a potential inconsistency but lacks concrete guidance on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (A&B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" reasoning for using the center correlation metric in figure 4 A&B, despite claiming it is not insightful for discriminating model defenses. This provides clear guidance on what needs to be addressed, namely the inconsistency in the authors\" reasoning or the clarification of their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement about the center correlation not being insightful for discriminating model defenses, as it is used in figure 4 A&B. The reviewer is seeking clarification on why the metric is considered useful in one context but not another, or what the authors meant by their statement. This is a request for clarification rather than a subjective claim or opinion, making it a factual observation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" reasoning regarding the center correlation metric. It points out that the authors claim it is not insightful for discriminating model defenses but then use it in figure 4 A&B. This feedback is valuable as it prompts the authors to clarify their reasoning or explanation for using the metric in both contexts. By addressing this inconsistency, the authors can improve the coherence and credibility of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or explained why it might be relevant in figure 4 A&B. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network\"s outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it may be too strong to accurately represent the empirical phenomenon presented. The comment provides a clear rationale for why the term might not be appropriate and suggests an alternative approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it may be too strong. The reviewer provides a logical reasoning by explaining that the term implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. This reasoning is based on the observation that the outputs match in a few test functions, suggesting that the phenomenon is not as idealized as the term implies. However, the comment lacks specific examples or references to support the claim that the term is inaccurate. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong, as it implies a complete vanishing of the total variation between the test and train distributions, which might not be the case. The reviewer provides a logical reasoning by explaining that the outputs might not match in all test functions, suggesting that the phenomenon is not as idealized as the term implies. However, the comment could be more helpful if it offered suggestions for alternative terms or phrasing that would better capture the empirical phenomenon. While it highlights a potential weakness, the feedback lacks actionable guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment explicitly states the preferred terminology, it does not provide detailed guidance on how to implement this change or why it is beneficial. The authors are left to infer that changing the terminology would improve clarity, but the comment lacks concrete steps or examples to fully guide the authors in making this change. Therefore, the comment is 3, as it provides an explicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and the specific terminology being discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology \"above/below 45 degree,\" suggesting that \"above/below diagonal\" would be easier to interpret. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning by comparing the two terms, explaining that \"above/below diagonal\" is more intuitive because it refers to a visual aspect, while \"above/below 45 degree\" is more ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more intuitive. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by recommending the use of \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot. However, the comment could be more helpful if it provided additional context or examples to explain why \"above/below diagonal\" is more intuitive or why \"above/below 45 degree\" is less clear. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, making it a valuable contribution to the authors\" draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing and suggesting that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it 3. The authors would need to infer the intended meaning and potentially revise the phrasing to align with the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it points out a potential area for clarification and improvement in the draft. However, it lacks specific suggestions or guidance on how to clarify the phrasing or what changes to make to enhance the clarity. While it highlights an issue, the comment could be more actionable with additional details or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the relationship between their work and prior taskoptimized approaches. The comment is 3 as it identifies a gap in understanding but lacks concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and nonlinear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically mentions that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. It points out that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which raises concerns about the contribution of the work. The comment highlights a critical gap in understanding the relationship between the model and prior approaches, suggesting that the authors need to provide a clearer explanation of their work. While the comment identifies a crucial area for improvement, it could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment is 3 as it points out a significant weakness but lacks detailed guidance on how to resolve it."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the tradeoff and possibly explore ways to mitigate it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. The comment further raises a question about the information encoded in the ancestral graph compared to the DAGs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant consideration for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the paper, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. While the comment implies that the authors should include such results, it does not provide explicit instructions or concrete steps on how to achieve this. The authors are left to infer that they should include these results, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or which specific results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention the sections or elements being addressed. Additionally, while it suggests a specific area for improvement, it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what should be included in the theoretical discussions. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for these results and determine how to incorporate them into their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems should include sample complexitytype results related to not returning NSF. The reviewer provides a clear and actionable suggestion by highlighting the need for results that would help determine the sufficient amount of training data points required to avoid returning NSF. This feedback is valuable as it guides the authors to enhance their theoretical discussions and provide more comprehensive analysis. However, the comment could be more helpful if it included examples or references to similar studies or methods that have successfully addressed this issue. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for the authors to consider. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the discussion section of the paper. It suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to enhance their discussion section with relevant and actionable information. However, the comment could be more helpful if it included additional context or references to support the empirical motivation. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It also mentions that ATSS literature has shown that regression methods do not significantly influence results. The reviewer suggests that the method that directly regresses [w, h] to the center point is sufficient, and questions the motivation for using RepPoints if there is no clear difference between the two methods. The comment explicitly asks the authors to clarify this issue, providing a clear action for the authors to take. However, it does not specify how the clarification should be provided, such as through additional explanations or examples. Despite this, the comment is 4 as it provides a clear direction for the authors to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet, and suggests that the motivation for using RepPoints may not be solid. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer references ATSS literature to support their claim that regression methods do not significantly influence results. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the lack of difference between the methods. While it provides some evidence, the justification is not as robust as it could be, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions and motivations in the paper, specifically regarding the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It references ATSS literature to support the claim that regression methods do not significantly influence results. The comment also questions the motivation for using RepPoints if there is no clear difference between it and other methods. This feedback is valuable as it prompts the authors to clarify and strengthen their definitions and motivations, which could significantly impact the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how the authors might clarify their definitions. Overall, the comment is 4 as it identifies critical areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments lack something to hang on to. However, it does not provide specific guidance on how to improve the clarity or intuition of the paper. The authors are left to infer that they need to make their work more accessible and provide a clearer structure, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention. Additionally, the comment does not provide specific guidance on how to improve the clarity or intuition of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what this \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further undermines the paper\"s clarity and impact. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or intuition of the paper. While it highlights a critical area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. It explicitly asks for KID/FID metrics of the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what the authors need to do to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"student and refinement networks\" and the \"teacher network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It prompts the authors to provide KID/FID metrics for the teacher network, which is a clear and actionable request. This feedback is 3 as it points out a potential area for improvement and provides a specific direction for the authors to follow. However, it could be more helpful if it included additional context or explanation about why this comparison is important or how it might impact the overall evaluation of the work. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that having a scaling variable before the attention weight might help. However, the comment lacks specific reasoning or evidence to support why this change would be beneficial or how it would affect the results. Without detailed explanation or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that having a scaling variable before the attention weight might help. This feedback is 3 as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this change or why it might be beneficial. To be more helpful, the comment could offer suggestions on how to test or evaluate the impact of this change. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s accuracy or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the LLM, particularly when faced with ambiguities in human language. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of goal misspecification and its consequences, such as failures on the ALFRED benchmark. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM, noting that failures on the ALFRED benchmark often occurred due to goal misspecification. It highlights that the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This feedback is valuable as it points out a critical area for improvement in the LLM\"s performance. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific techniques or approaches to improve goal misspecification. Despite this, the comment still offers a clear direction for the authors to improve their draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct this investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ModelSpecific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks modelspecific insights and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The comment provides a specific example of GPT4o and InternVL2 and suggests presenting differences in false positive rates (FPR) for a better comparison. This claim is 3 as it logically suggests a way to enhance the paper\"s analysis, but it lacks detailed evidence or references to support the assertion that these specific models behave differently. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for modelspecific insights, specifically recommending a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. The comment also suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to focus on modelspecific aspects that could enhance the paper\"s conclusions and provide more nuanced insights. However, the comment could be more helpful if it included specific guidance on how to conduct this investigation or what aspects of the models should be analyzed. Overall, the comment is 4 as it offers a clear path for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to improve the draft. The comment provides a concrete suggestion for enhancing the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure, allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. The comment is also specific because it clearly specifies what needs to be added to the paper, namely, the supplementation of the result comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Despite this, the feedback is 4 as it points out a specific area for improvement, making it rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation requiring additional computational costs, which is crucial for understanding the need for runtime comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which requires additional computational costs. The comment provides a logical reasoning by stating that direct runtime comparisons are necessary to demonstrate the efficiency of the proposed approach. However, it lacks specific examples or references to existing methods or studies that could support the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of such comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include direct runtime comparisons to strengthen their claims. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that focusing on which clusters are \"best\" rather than the differences in representation between them is an odd choice given the motivation of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unaligned with the paper\"s goals. Without specific examples or detailed explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus, suggesting that the authors should prioritize the differences in representation between clusters rather than which clusters are considered \"best.\" This feedback is 3 as it identifies an area where the paper may not align with its stated motivation. However, the comment lacks specific guidance on how to address this issue or what aspects of the representation differences should be emphasized. While it highlights a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Elementlevel Graph Pretraining\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that case studies are necessary for convincing the reader. While it provides a logical argument, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pretraining for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for considering these factors as separate evaluations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of why these factors might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential weakness in the paper, the feedback does not provide actionable steps for improvement, making it 3. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are given clear instructions on what to fix, but the lack of concrete suggestions on how to implement these changes limits the comment\"s actionability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional context or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and layout of the paper, identifying issues such as small font sizes, improper placement of figures and tables, and formatting errors. This level of detail allows the authors to understand exactly what needs to be addressed to improve the clarity and professionalism of their draft. By addressing these issues, the authors can enhance the readability and comprehensibility of their paper, which is valuable guidance for improving the draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or address these concerns. The authors are left to infer that they need to consider practicality and safety, but without concrete steps or examples on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as the intervention section or the results section. The authors can infer that it relates to the intervention or querying aspects, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why these considerations are necessary or how they would impact the paper\"s findings. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that while the types of interventions included are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. This feedback is valuable as it highlights a critical aspect that the authors may have overlooked, prompting them to consider the practical implications of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to assess and address these concerns. Overall, the comment is 3 as it directs the authors\" attention to an important consideration, but it lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim 3, as it provides a reasonable argument but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is actionable as it provides a clear direction for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. By doing so, the authors can better understand the impact of their method and provide stronger evidence to support their claims. However, the comment could be more helpful if it included specific suggestions on which baseline techniques to use or how to structure the evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the manual disentangling process and suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The comment suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. However, the comment lacks specific examples or references to support the claim that manual disentangling is not necessary or beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline and suggesting that the paper could be more interesting if it demonstrated everything being learned without manual intervention. This feedback is 3 as it prompts the authors to reconsider their methodology and potentially explore more automated approaches. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used to achieve this goal. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific actions they should take to clarify the behavior. The comment lacks guidance on whether the authors should provide additional analysis, simulations, or explanations to address this concern. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method\"s behavior is not clear without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method need clarification. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding by referencing specific elements of the paper. However, it does not specify which part of the paper these elements are discussed in, making it weakly grounded. The comment is specific in pointing out the issue of vagueness in the presentation of existing methods, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or detailed feedback, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment does not explicitly instruct the authors to perform a computational complexity analysis or provide guidance on how to address the power demand concern, it implies that the authors should consider these aspects. The action is implicit but concrete, as it points to specific areas that need attention. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is not 5, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates on the potential power demand if the Woodbury flow were to be used on a mobile device. While the comment identifies a relevant concern about computational complexity and power demand, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider these aspects, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied and somewhat vague, as the authors can infer that they need to develop a distributed version but are not given concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the scalability issue but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the method, suggesting that it may not be suitable for realworld datasets due to the large amount of data typically contained in them. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a scalable solution or discussing potential modifications to the method. While it points out a potential weakness, it does not provide actionable steps for the authors to improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the authors should provide more specific examples or references to support their claims. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the authors should focus on illustrating generalization capabilities through examples later in the paper. While the comment provides some guidance on what needs to be improved, it does not offer explicit instructions on how to implement these changes. The actions are implicit and somewhat vague, as the authors need to infer the specific changes required to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L1618,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by pointing out that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggesting that the reinforcement learning/agent analogy is out of place. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the discussion on certain RNNs working well for certain natural language reasoning tasks is vague and suggests that the authors should provide more specific examples or references to support their claims. The reviewer also critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the authors should focus on illustrating generalization capabilities through examples later in the paper. While the comment identifies potential issues, it lacks specific examples or references to support the claims, making it 3. The authors would need to make a significant effort to understand and address the critique, as the reasoning is not fully articulated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and specificity of the discussion on certain RNNs working well for certain natural language reasoning tasks. It suggests that the discussion is vague and recommends providing more specific examples or references to support the claims. Additionally, it critiques the use of the reinforcement learning/agent analogy, suggesting that it is out of place and that the authors should focus on illustrating generalization capabilities through examples later in the paper. While the comment identifies areas for improvement, it could be more helpful by providing specific examples or references to support the suggestions. Overall, the comment is 3 as it guides the authors toward improving the clarity and specificity of their discussion, but it lacks detailed guidance on how to implement these improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in terms of StableDiffusion and the need for further discussion, as well as the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in StableDiffusion, but it lacks specific examples or references to support the claim. The absence of detailed evidence or examples makes it 3, as the authors would need to infer the significance of the observation and the need for further discussion or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion. It also points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors to areas needing further exploration and justification, but it could be more actionable with specific suggestions or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples rather than sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is a clear and specific concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also highlights the cost of quantization in terms of both N (number of data) and M (dimension), and notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. The reviewer suggests that the quantization is a bottleneck for this method, making it lose its purpose. The claim is supported by logical reasoning and references to the paper, providing a clear rationale for the critique. However, the comment could be strengthened by including specific examples or references to quantization methods that are known to be scalable. Overall, the claim is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It highlights the cost of quantization in terms of both the number of data (N) and the dimension (M), and notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. The reviewer suggests that the quantization is a bottleneck for this method, making it lose its purpose. While the comment provides a clear understanding of the problem, it lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of their method. The feedback is 3 as it points out a significant weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim 3, as the authors would need to infer the specific methods and issues to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or methods to address. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out that the time complexity and efficiency of the computation are not clearly analyzed. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the time complexity and efficiency of the computation are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution rather than the form of the attack. While the feedback provides clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 3 as it highlights important areas for improvement, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a statement in the paper that claims every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinitedimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue and provides a direction for improvement, it does not offer concrete guidance on how to clarify this limitation or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinitedimensional RKHSs with neural networks. This provides clear guidance on how to improve the clarity of the paper in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinitedimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinitedimensional, making it impossible for a neural network with finite width to represent it. This logical reasoning supports the claim that the statement is not entirely accurate. However, the comment could be strengthened by providing specific references or examples to substantiate the claim further. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinitedimensional, making it impossible for a neural network with finite width to represent them. The reviewer suggests that this limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a potential misconception in the paper and offers a concrete way to clarify the issue. However, the comment could be more helpful if it provided additional guidance on how to present this limitation or suggested specific examples or references to support the clarification. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding during the generation phase. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training may limit the benefits of inference. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This feedback is 3 as it prompts the authors to consider the limitations of their approach and how it might impact the inference phase. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their method. To be more helpful, the comment could provide examples or additional context to help the authors understand and address the concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support the claim about the fit of GPI with behavioral data or the suitability of the approach for pattern separation tasks. The suggestion for discussion is somewhat vague, as it does not provide detailed guidance on what aspects of the discussion should be included. Therefore, the comment is 3, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several pertinent questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or what specific measures could be taken to demonstrate the fit of GPI with behavioral data. The feedback is 3 as it points out areas for further exploration and discussion, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly infer and implement. However, the comment does not provide specific guidance on how to conduct the comparison or what aspects to focus on, leaving some room for interpretation. Therefore, the action is explicit but somewhat vague in terms of execution. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting a comparison but lacks grounding as it does not explicitly mention a particular section or aspect of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. It does not offer detailed feedback or actionable advice, leaving the authors with a general suggestion that requires further exploration and interpretation. Therefore, the comment is 3 as it identifies an area for potential improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also asks if experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential issue in the paper that the authors may need to address. However, the comment lacks specific guidance or suggestions on how to resolve this issue or what experiments should be conducted to clarify the debate. While it highlights an area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing results is unfair due to the different training settings used by the proposed method compared to the other methods. The reviewer suggests that reproducing the results using the same setting as the other methods would be more fair. This claim is 3 as it logically points out a potential issue with the comparison, but it lacks specific examples or references to support the argument. The authors would need to infer the specific training settings used by the other methods and determine how to reproduce their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. This observation highlights a potential bias in the comparison, as the results may not be directly comparable due to the different training settings. The comment suggests that reproducing the results using the same setting as the other methods would be more fair, as most recent methods have their code released. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the fairness and validity of their comparison. By addressing this issue, the authors can enhance the credibility and reliability of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving plot size, color contrast, and label clarity. The comment is 5 as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are more effective in communicating their results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and \"plots are terrible,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the plots, such as their small size, color difficulty, and poorly labeled axis. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the plots are terrible, with specific issues such as small size, color difficulty, and poorly labeled axis. The reviewer also mentions that the labels are visually similar, which contributes to the overall clarity issue. While the comment provides specific examples of problems with the plots, it lacks detailed reasoning or references to support why these issues are problematic or how they impact the clarity of the results. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies issues such as the small size of the plots, difficulty in distinguishing colors, poorly labeled axis, and visually similar labels. This feedback is clear and constructive, offering the authors a clear path to improve the clarity and effectiveness of their presentation. By addressing these points, the authors can significantly enhance the clarity and impact of their work, making the comment highly valuable for improving the draft. Therefore, it deserves a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide the requested information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a question about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information. However, it does not provide any supporting evidence, reasoning, or references to justify why these types of information are relevant or how they might affect the feedback network. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment poses a series of questions about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information and the performance with just natural language feedback. This is a thoughtful and insightful question that prompts the authors to consider the effectiveness of their approach in different scenarios. However, the comment does not provide specific guidance or suggestions on how to address these questions or what specific analyses should be conducted. While it highlights an area for further exploration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting which experiments should be included or how to present the standard deviations. The action is implicit and somewhat vague, as the authors can infer that they need to include standard deviations but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to present the standard deviations or which experiments should be included to enhance the submission. While it highlights an important area for improvement, the feedback is somewhat limited in its guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the addition of parameters in LinearTop and NLTop, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether there is still a performance boost if a better Unary baseline is used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references external work ([14]) to support the claim that a different neural network might be better, but it does not provide specific details or evidence to substantiate the claim. The reasoning is somewhat logical, but the lack of detailed justification or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It references external work to support the claim that a different neural network might be better, providing some context for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for further exploration, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit suggestions for improving the structure of the paper and highlights specific sections that require multiple readings. It suggests reorganizing the structure from introduction to method to experiments, which is a clear and concrete action for the authors to take. Additionally, it points out the importance of the IEM in Fig. 3 and recommends focusing on it, providing a specific area for improvement. The comment also suggests improving the visualization of Fig. 7 and Fig., which are specific tasks that the authors can address. Overall, the comment is 5 as it provides clear and detailed guidance on how to improve the structure and presentation of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the introduction, method, and experiments, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear suggestions for improvement, such as reorganizing the structure and focusing on the IEM in Fig. 3. The comment also suggests improving the visualization of Fig. 7 and Fig., providing detailed guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests improvements to the structure, specifically recommending a change from introduction to method to experiments. The reviewer also highlights the importance of the IEM in Fig. 3 and suggests focusing on it. Additionally, the comment suggests improving the visualization of Fig. 7 and Fig. The claim is 3 as it provides logical reasoning for the suggested changes, such as the need for a clearer structure and the importance of the IEM. However, it lacks specific examples or references to support the claim about the IEM or the visualization of Fig. 7 and Fig. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reorganizing the sections from introduction to method to experiments. It also highlights the importance of the IEM in Fig. 3, which is the main figure in the paper, and recommends focusing on it. Additionally, the comment suggests improving the visualization of Fig. 7 and Fig., providing clear guidance for the authors to enhance the clarity and impact of their work. This feedback is detailed and constructive, empowering the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue or what additional testing might be needed. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important, as it could affect the results if the optimal learning rate for the baseline is outside the tested interval. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the need for information on the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. The reviewer suggests that if the optimal learning rate for the baseline is outside the tested interval, it could affect the results. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the importance of this information and the potential impact on the results, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by requesting information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. This is important as it could affect the results if the optimal learning rate for the baseline is outside the tested interval. The comment is clear and actionable, providing the authors with a direct and specific request for additional data or analysis. However, it could be more helpful if it offered suggestions on how to address this issue or what additional testing might be needed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make localitybiased models more effective. However, it does not provide specific guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks explicit instructions or concrete details on what the authors should do to improve their draft. As a result, the authors are left without a clear understanding of what actions to take to address the reviewer\"s concerns. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make localitybiased models more effective. However, it does not specify which part of the paper this concern is based on, such as a particular section or experiment where the transformer is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the transformer without locality bias, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make localitybiased models more effective. The reviewer provides a logical reasoning based on the nature of transformers and the speed of information propagation, but it lacks specific examples or references to support the claim. The comment is 3 as it provides a plausible argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might make localitybiased models more effective. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern or explain their choice. Without detailed feedback or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but lacks concrete details on what specific experiments or analyses should be conducted. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a concrete direction for improvement. However, the comment could be more helpful if it offered specific suggestions on which experiments or analyses would be most beneficial. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper presents an effective engineering method for ReC but notes that the proposed framework incorporates combinatorial and heuristic aspects. It specifically points out the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information about the heuristic components, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, such as the sophisticated filtering template. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. The reviewer suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for clarification, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components, which is a valuable point for improving the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify these aspects or what aspects of the heuristic components should be emphasized. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a doubt about the proposed method\"s ability to be trained without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific steps they could take to clarify or improve their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the method\"s ability to be trained without camera information and the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the proposed method\"s ability to be trained without camera information, specifically mentioning the \"knowledge of CAD model correspondences\" (Line 223). However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that this knowledge is necessary for training. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the proposed method\"s ability to be trained without camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for performing ray marching and determining the ray\"s origin. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim is not 5, as it lacks the necessary support to substantiate the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be improved by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional datasets and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a logical assumption, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified and improved, such as the tasks and experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task are unclear and that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without specific references or detailed explanations, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the generic argument task and the random argument task, as well as the cumbersomeness of the dataset transformation and experimental setup. It highlights that these aspects are not wellexplained, making it difficult for the authors to understand and address the issues. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or simplify the experimental setup. While it points out areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion on the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what kind of theoretical evidence would be appropriate. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification, which is crucial for strengthening the paper\"s contribution. However, the comment does not provide specific suggestions or examples of how the authors might address this issue or what kind of theoretical evidence would be appropriate. While it points out a significant weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. However, it does not provide detailed suggestions on how to resolve these issues, such as which specific papers are duplicates or how to ensure accurate publication information. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to verify and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to verify and correct the references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to identify and resolve duplicates or how to locate missing publication details. Overall, the comment is 4 as it highlights a critical aspect of the paper that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue with the clarity of the theoretical analysis, it does not provide specific examples or references to support the claim about the error bound or the need for comparison. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for the authors to improve the clarity and robustness of their theoretical analysis. By addressing this issue, the authors can enhance the rigor and credibility of their work. However, the comment could be more helpful if it offered specific guidance on how to analyze and compare the results, or provided examples of comparable methods to consider. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should use it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the method R3F should be applied to. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of R3F and how it might impact their results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune the multilingual model and mentions the method R3F. It suggests that the improvement of 0.8 in some lowresource language translations is insignificant in practical terms. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The suggestion to use R3F is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is used to maintain the generalization ability of the model. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is somewhat vague, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain the generalization ability of the model. While the comment provides some insight into the limitations of the current approach, it lacks specific guidance on how to address the issue or implement the suggested method. The reference to Aghajanyan et al. (2020) is helpful, but the comment could be more actionable with additional details or suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss their model\"s ability to work well for various image noise types, allowing the authors to accurately identify the relevant section. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specificity and does not offer a clear justification or explanation for the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments, which could affect the generalizability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional noise types could be considered. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and concrete action for the authors to take, as it provides a specific direction for improving the draft. The comment is specific in detailing what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and actionable suggestion that can significantly enhance the paper\"s research motivation and credibility. By visualizing the effect, the authors can provide a concrete demonstration of their claim, which is crucial for the paper\"s impact. However, the comment could be more helpful if it provided additional guidance on how to effectively visualize this effect or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific line in the paper (ln. 180182) and highlights a potential issue with the claim made in Corollary 10. It notes that the corollary only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors should clarify or rephrase their claim, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollary 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. The comment provides a logical reasoning by pointing out that the corollary does not directly address the minimization of the expected convex surrogate. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim made in Corollary 10, noting that it only shows that uncertainty sampling moves in descent directions of the expected 01 loss but does not necessarily imply that it is minimizing the expected convex surrogate. This is a clear and actionable point that the authors can address to improve the clarity and accuracy of their claims. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the claim to better support the authors\" argument. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics and evolution, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit, as the authors can infer that they need to consider ways to improve the dynamics and evolution of the model, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, which results in slow dynamics. Additionally, it notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, which results in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim about the dynamics and the evolution model\"s simplicity. This makes the claim 3, as the authors would need to further explore the dynamics and evolution model to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model does not allow for more frequent changes. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is valuable as it highlights a critical weakness in the model\"s dynamics and evolution, which the authors can address to improve the paper. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as proposing alternative models or methods for improving the dynamics and evolution. Overall, the comment is 4 as it identifies important areas for improvement, but it lacks detailed guidance on how to achieve those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method used for division (random or other considerations). It clearly instructs the authors to add these details, providing a direct and concrete action for improvement. The comment is specific about what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method used for division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and any considerations made. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division to train and test sets, including numbers and the method used for division. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the details about the division to train and test sets, including numbers and the method used for division. It clearly states that these details should be added to improve the clarity and transparency of the paper. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of how similar information has been handled in similar studies. Overall, the comment is 4 as it effectively points out a gap in the paper and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two claims: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. The first claim is based on the observation that text descriptions still require human labor, which is a factual observation. However, the second claim about scalability is less verifiable, as it lacks specific examples or references to support the assertion that longtext inputs restrict scalability. The comment could be strengthened by providing more detailed reasoning or evidence to substantiate the claim about scalability. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the scalability of their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out potential weaknesses but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods is not significant, as evidenced by the figure, and suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3. However, it does not provide specific details or data to support this claim, such as comparisons to other methods or baselines. The suggestion to use tables to present the key improvements is a logical suggestion, but without detailed evidence or examples, the claim remains 3. The authors would need to make a significant effort to verify the claim themselves, as the comment lacks the necessary evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods appears not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. However, the comment could be more helpful if it included specific examples of how the tables should be structured or what aspects should be highlighted. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be addressed. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence or results to substantiate their claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment implies that the authors should add these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fullysupervised baselines, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is still valuable as it directs the authors to a specific area for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the time complexity of the proposed algorithm, particularly the repeated calculation of hypervolume for promising region selection. The comment suggests that the time complexity could be a problem for problems with many objectives, such as >3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. The comment suggests that this could make LaMOO impractical for such problems. However, the comment lacks specific examples or references to support the claim that the time complexity is a significant issue. While it logically raises a concern, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. This is a relevant concern that could impact the practicality of the algorithm for certain types of problems. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or optimize the algorithm to reduce time complexity. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out an important area for consideration but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. The comment implies that the authors should consider running experiments on larger datasets, but it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider running experiments on larger datasets, but the comment lacks detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the dataset used in the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for results on larger datasets like ImageNet. This provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\"s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the issue of dataset size. The authors are left with a general idea of what could be improved but without actionable steps to achieve it. Therefore, the comment is 3, as it points out a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. The comment also suggests considering the landscape 10 years ago, but this does not contribute to the verifiability of the claims. Overall, the comment lacks sufficient evidence or detailed reasoning to support its claims, making them 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s depth and relevance. It also points out that the title is too generic and vague, suggesting that being more precise in the critique would be beneficial. Additionally, the reviewer questions the term \"brittle convergence properties\" and notes that DeepRL methods are widely adopted, suggesting that the authors should consider the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar works have tackled these topics. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. While the comment implies that the authors should provide empirical evidence to support this claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is based on logical reasoning, it lacks specific examples or references to support the claim that empirical justification is necessary. This makes the comment 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks empirical justification, which is the claim about the algorithm\"s unique contribution regarding the number of points and apriori knowledge needed. It suggests that providing empirical evidence would strengthen the paper\"s argument. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct the empirical analysis or what specific data or experiments should be included. This limits the comment\"s helpfulness, as it points out a potential weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a detailed discussion on the comparison with RMED. The comment is specific in identifying the issue and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion on the comparison with RMED. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to justify its novelty. This feedback is clear and actionable, as it directs the authors to include a detailed discussion on the comparison with RMED to enhance the novelty of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance or concrete suggestions on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a particular section or subsection where the discussion should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the previous work should be discussed or how it should be integrated into the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or how they should be integrated into the paper. Without specific references or examples, the claim lacks verifiability, as it does not provide a clear basis for the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s credibility and relevance. However, the comment lacks specific guidance on which previous works should be discussed or how they should be integrated into the paper. Without actionable suggestions or examples, the authors are left with a general direction but no clear path to follow. Therefore, the comment is 3, as it points out an important area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is 3 as it points out a potential gap in the paper\"s explanation, prompting the authors to provide a clearer explanation. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of how the distinction might be clarified. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address these limitations, such as suggesting specific experiments or analyses that could be conducted. While it points out an important area for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is wellstudied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\" dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in suggesting that the Kialo dataset could be used as an alternative, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. The reviewer claims that the Kialo dataset provides pairs of short claims and their counters and is cleaner than the dataset created by the authors. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides exactly what the authors need. While the suggestion to use the Kialo dataset is logical, the lack of detailed evidence or comparisons makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and suggests that the authors\" dataset can be considered extra data to learn from. While the comment identifies a potential source of data for the authors to consider, it lacks detailed guidance on how to incorporate this data or why it would be beneficial. The feedback is 3 as it points out a potential resource, but it could be more actionable and comprehensive to fully assist the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Transformer\" and \"crosslayer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring significant insight and that the selfcross attention improvement is limited. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of Transformer in the paper is not novel and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the selfcross attention improvement is limited (<1%), questioning its significance. However, the comment lacks specific examples or references to support the claim about the limited improvement. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critical analysis of the paper\"s use of Transformer, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement, suggesting that it is limited (<1%). This feedback is 3 as it identifies a potential weakness in the paper\"s novelty and contribution. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these concerns or improve the paper\"s impact. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks should be included in the experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim 3, as the authors would need to infer the importance of these tasks themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that they are limited to sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their experiments. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment raises a valid point, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their motivation. The authors are left to infer that they need to provide a clearer explanation or justification for their choice, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the motivation for analyzing only the last convolutional layer. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This is an important point that could impact the clarity and justification of the paper\"s analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation. While it identifies a potential weakness, it does not offer actionable steps or examples for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\"s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption (Assumption 4.1) that indicates $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to review and potentially revise the convergence proof to enhance its novelty and rigor. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation from previous theorems. The comment provides a clear rationale for why the proof is not substantial, which helps the authors understand the need for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This reasoning is based on logical deduction from the assumptions and the provided modifications, making the claim 4. However, the comment could be strengthened by referencing specific theorems or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which can be trivially adapted from previous theorems with straightforward modifications. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By suggesting that the convergence proof can be adapted from previous theorems, the reviewer offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided additional guidance on how to enhance the rigor and novelty of the proof. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a contradiction between two statements regarding the multienv model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to clarify the contradiction or what aspects of the statements are problematic. However, the authors can infer that they need to provide a clear explanation or resolution to the contradiction, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statements about the multienv model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of contradiction between the two statements regarding the model\"s performance and knowledge sharing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contradiction between two statements regarding the multienv model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of contradiction. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. This contradiction highlights a potential inconsistency in the paper that needs clarification. The comment is 3 as it prompts the authors to clarify this contradiction, which could be an important aspect of their work. However, it could be more helpful if it provided suggestions on how to address the contradiction or offered additional context to better understand the implications. Overall, the comment is 3 as it directs the authors to a critical area needing clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger motivation for the problem and consider dynamic datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis. The comment provides clear guidance on what needs to be addressed, namely the need to motivate the problem and consider dynamic datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it offer suggestions on how to address the issue. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of motivating the problem and consider dynamic datasets. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It points out that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. The comment highlights the need to motivate the problem and consider dynamic datasets to enhance the paper\"s relevance. While it provides a clear direction for improvement, it could be more helpful if it offered specific examples or suggestions on how to address this issue. Overall, the comment is 3 as it guides the authors toward a meaningful enhancement of their draft, but it could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models should be included in Tables 2 and 3. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to add these baselines or specify how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional relevant CoT baselines for incontext learning of large language models. This provides clear guidance on what the authors need to address to improve their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. The reviewer provides a specific observation that additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) are missing in Tables 2 and 3. This claim is 3 as it provides a logical reasoning for the need to include these baselines, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. The reviewer suggests that if this is not the case, additional relevant CoT baselines for incontext learning of large language models (such as text003 and ChatGPT) should be included in Tables 2 and 3. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the scope and comprehensiveness of their study. By addressing this point, the authors can ensure that their work is more comprehensive and relevant to the field. However, the comment could be more helpful if it included specific examples or references to relevant CoT baselines. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their study."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, stating that it is difficult to read anything on the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the readability and comprehension of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending adjustments to the figure size, font, or color scheme. Overall, the comment is 3 as it points out a clear issue but lacks detailed guidance on how to resolve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or improve their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the choice of `lambda`. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes two claims: first, that replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` is problematic, and second, that the use of an SGD learning rate of ~0.1 is unclear and lacks justification. The first claim is 3 as it points out a potential issue with the parameter choice, but it does not provide specific reasoning or examples to support the claim. The second claim is also 3, as it questions the justification behind the learning rate choice but lacks detailed explanation or references to support the claim. Overall, the comment is 3, as it highlights areas for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1 without a clear justification. It provides actionable feedback by suggesting that the authors should justify the use of `lambda` and clarify the rationale behind the learning rate choice. This feedback is clear and constructive, as it guides the authors on how to improve the clarity and justification of their work. However, the comment could be more helpful if it offered additional suggestions or examples of how to address these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a general direction for analysis and potential improvements, it does not offer specific guidance on how to conduct this analysis or what aspects to focus on. The authors are left to infer the details of how to implement these suggestions, making the action implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, nor does it provide detailed guidance on what aspects of the domain gap should be addressed. While the authors might have an idea of where to focus their analysis, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the domain gap or the value of the approach. Without such evidence or examples, the authors may find it challenging to understand and address the suggestions. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is valuable as it directs the authors to consider an important aspect of their work that could enhance its impact and relevance. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis or what aspects of the domain gap should be considered. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that at least one NCEbased method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper should include this comparison or which section would benefit from it. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding as it does not explicitly mention the sections. The suggestion is specific, as it clearly identifies the need for a comparison with NCEbased methods. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how NCEbased methods could enhance the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is 3 as it provides a clear direction for the authors to consider adding a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it would enhance the paper\"s contribution. While it identifies a potential area for improvement, the authors are left to determine the exact impact and relevance of including an NCEbased method. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new curriculum learning method for text graphs is not justified. It also points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is 3 as it highlights a potential gap in the paper\"s justification for the need of a new curriculum learning method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the research gap should be discussed. To be more helpful, the comment could provide examples of how existing methods might not be applicable or suggest ways to justify the need for a new method. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. This claim is 3 as it provides a logical reasoning for the suggestion, based on the common use of these models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This feedback is clear and constructive, as it offers a concrete way to improve the methodology and enhance the results. By following this advice, the authors can potentially improve the robustness and generalizability of their approach. However, the comment could be more helpful if it included additional context or examples to further explain the benefits of using these models. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in lines 196197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where more explanation is needed, specifically regarding the two quantities mentioned in lines 196197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights a potential gap in the explanation, it does not provide detailed guidance or suggestions on how to address this issue. The authors are given a clear direction to improve their draft, but the comment could be more helpful with additional context or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it identifies a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they would impact the framework\"s performance. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion or the importance of addressing these points. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is 3 as it identifies a potential area for further exploration and experimentation, which could enhance the robustness and generalizability of the framework. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific policy gradient approaches should be considered. While it points out a potential area for improvement, it could be more helpful with additional details or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. It explicitly asks for clarification on the \"relevant\" auxiliary model weights in definition 2.1. This feedback is clear and provides concrete guidance on what needs to be addressed to improve the clarity of the writing. The authors know exactly what needs to be done to enhance the clarity of their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the \"relevant\" auxiliary model weights in definition 2.1. This provides clear guidance on what needs to be improved in the writing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the writing in specific sections, such as definition 2.1. It provides examples of unclear or difficulttointerpret definitions, which is a logical observation. However, the comment does not offer specific examples or references to support the claim that the writing is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is 3, as it provides a basis for the critique but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, providing examples of unclear or difficulttointerpret definitions. This feedback is actionable and constructive, as it points out specific parts of the paper that need clarification. By addressing these issues, the authors can enhance the clarity and accessibility of their work, which is valuable for improving the overall quality of the draft. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the definitions or provided examples of clearer explanations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA [1] is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also suggests using ULiRA [1] as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for ULiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA [1] is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of ULiRA. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It raises a valid concern about the robustness of MIA testing for privacy guarantees, which is an important consideration for the paper\"s contributions. The comment suggests using ULiRA [1] as a more robust alternative, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it explained why MIA testing is not robust or how ULiRA might address these concerns. Overall, the comment provides valuable insight into a potential weakness and offers a constructive suggestion for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that the considerations should be applicable to kernel regression and that they could be presented in the language of kernel interpolation/smoothing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that these considerations should also be applicable to kernel interpolation/smoothing. However, the comment lacks any supporting evidence, reasoning, or references to justify why this is the case or how it would be beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that they should also be applicable to kernel interpolation/smoothing. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue. It does not offer actionable steps or examples of how the authors might present their considerations in the language of kernel interpolation/smoothing. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as concrete as it could be, as the authors are left to infer the exact details of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting that providing these settings would help the community by providing a single review of advances in this area. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This claim is 3 as it provides a logical reasoning for improvement, suggesting that such a comparison would enhance the paper\"s clarity and usefulness to the community. However, the comment lacks specific examples or references to prior work that have successfully implemented this approach, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and Searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and usefulness of their work. By including these settings, the authors could provide a single review of advances in the area, which would benefit the community. However, the comment could be more helpful if it included examples of how these settings were used in prior work or provided guidance on how to present them effectively. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the bias can happen, the general applicability of these situations is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or detailed advice on how to improve the clarity or applicability of these examples. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the general applicability of the examples presented. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shifts but does not clarify how general these situations are. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts. It points out that while the bias can happen, the general applicability of these situations is unclear. This feedback is 3 as it highlights a potential weakness in the clarity of the paper, but it lacks specific suggestions or guidance on how the authors might address this issue. The comment could be more helpful if it provided examples of how the authors might clarify the general applicability or examples of how these situations could be applied more broadly. Overall, the comment is 3 as it directs the authors\" attention to a specific area needing improvement, but it does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is specific in suggesting the addition of datasets, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the analysis. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides an example of interleaved imagetext tasks, such as question answering from images, as a potential area for improvement. While the comment implies that the authors should consider these tasks, it does not explicitly instruct them to do so or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these tasks but may not be entirely sure how to integrate them into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. However, the comment does not specify which part of the paper these tasks should be integrated into or how they would enhance the paper. While the authors might have an idea of where these tasks could fit, the comment lacks specificity in terms of grounding. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. However, the comment lacks specific examples or references to support the claim that these tasks would have been beneficial or how they would enhance the paper. Without detailed reasoning or evidence, the claim is 3, as it provides a general suggestion but lacks the necessary justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. This feedback is 3 as it points out a potential area for improvement by suggesting the inclusion of more diverse tasks. However, the comment lacks specific guidance on how to implement these tasks or what specific aspects of the dataset could be leveraged for these tasks. While it provides a general direction, the authors would need to make additional efforts to fully understand and address the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the section on 3D Gaussians generation, specifically mentioning the previous work by Luciddreamer. This request is clear and provides a direct action for the authors to take, which is to address the issue by either explaining the novelty or providing evidence of additional effort. The comment is specific and provides concrete guidance on what the authors need to do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation is merely a repetition of previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussians generation, specifically questioning whether there is any additional novel effort beyond the previous work by Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether their work builds upon existing efforts or introduces new contributions. However, the comment lacks specific guidance on how the authors might address this issue or what additional information they should provide to substantiate their claims. While it points out a potential weakness, it does not offer detailed suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is clear but lacks concrete details on how to execute the experiment, such as which specific features to select or how to evaluate the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a direction for further exploration, it could be more helpful with additional guidance or rationale. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern that the paper does not provide sufficient details for reproducibility, despite the inclusion of pseudocode in the supplementary material. It suggests that the paper is more focused on providing an intuitive understanding of the work rather than detailed technical information needed for reproduction. The reviewer explicitly states that more details are required, such as those about the RNN implementation, and provides a specific example of what is missing. This feedback is clear and concrete, giving the authors a direct action to take by including more detailed technical information in the paper or supplementary material. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, such as technical details about the RNN implementation and other aspects that are necessary for reproducibility. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide sufficient details for reproducibility, despite the inclusion of pseudocode in the supplementary material. The reviewer suggests that the paper is more focused on providing an intuitive understanding of the work rather than detailed technical information needed for reproduction. This claim is 3 as it highlights a potential issue with the paper\"s reproducibility, but it lacks specific examples or references to support the claim. The authors would need to make a significant effort to identify and address the missing details, which is not as straightforward as it could be. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not provide sufficient details for reproducibility despite including pseudocode in the supplementary material. It highlights that the paper is more focused on providing an intuitive understanding of the work rather than detailed technical information needed for reproduction. The reviewer provides specific examples of missing details, such as the number of units in the RNN implementation, which are crucial for reproducing the work. This feedback is clear and actionable, as it directs the authors to include more technical information to improve the reproducibility of their work. However, the comment could be more helpful if it suggested ways to address these missing details or provided examples of how similar works have addressed these issues. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED, specifically the potential biases introduced by basing eviction decisions solely on utility scores. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue of temporary high utility scores leading to premature evictions, but it lacks detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility scores for recent chunks. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is logical but could be strengthened with additional evidence or detailed explanation. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim 3, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, similar to how Theorem 1 is presented. This implies that the authors should consider simplifying the content of Theorem 2 to make it more accessible to a broader audience. However, the comment does not provide specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While the action is implied, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential simplification but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not provide any reasoning, examples, or references to support why this simplification is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. This feedback is 3 as it identifies a potential area for improvement in the clarity and accessibility of the paper. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors address it effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide explicit instructions on how to implement this suggestion or what specific aspects of the model should be tested at this resolution. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by testing the model at a larger resolution, but without explicit grounding, it is difficult for the authors to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion that could provide insights into how the model would perform with different image sizes. However, the comment lacks depth and does not explain why this change would be beneficial or how it might impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model should be tested at this resolution. While the suggestion is actionable, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the reviewer\"s concerns or improve the paper\"s analytical or empirical evidence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the central contribution of the paper, which is the use of ODEs to model weight evolution, and the issue of neural ODEs exhibiting inaccuracy while recomputing activations. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the reviewer\"s concern about the lack of convincing analytical or empirical evidence to support the claim about neural ODEs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the central contribution of the paper, which is the use of ODEs to model weight evolution, is based on a problem of neural ODEs exhibiting inaccuracy while recomputing activations. The reviewer questions the accuracy of this issue and points out that a previous paper first reported it. However, the comment lacks specific references to the previous paper or detailed evidence to support the claim. This makes the claim 3, as the authors would need to conduct further research to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s central contribution, which is the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. It points out that a previous paper first reported this issue, which raises a concern about the novelty and validity of the current paper\"s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or provide a more convincing analytical or empirical argument. While it highlights a potential problem, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While this is a specific and actionable suggestion, it lacks depth and context. The comment does not explain why this information is important or how it would enhance the paper. Providing more detailed reasoning or examples would help the authors understand the significance of this suggestion and how to implement it effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. However, the comment does not explicitly instruct the authors to conduct additional experiments or specify how to manage the compute issue. While the suggestion is clear, the lack of concrete guidance on execution makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets and acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. However, the comment does not specify which part of the paper should include these additional experiments or how the compute issue should be addressed. While the authors might infer that it relates to the experimental section, the comment lacks explicit grounding. It is specific about the need for additional experiments but does not provide detailed guidance on execution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the authors addressed concerns. However, the comment lacks specific reasoning or evidence to support the claim about maintaining probabilities or the compute issue. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model\"s performance. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue, particularly at large batch sizes. While the comment identifies a potential area for improvement, it does not offer specific guidance or suggestions on how to address the compute issue or manage the probabilities. The feedback is 3 as it points out a potential area for improvement but lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and it proposes a comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with previous approaches, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence or references to substantiate this claim. The suggestion to compare the method with previous approaches on fewshot classification in such datasets is logical but lacks specific examples or detailed reasoning to fully support the claim. Therefore, the comment is considered 2, as it provides a logical suggestion but lacks the necessary evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. This feedback provides a clear direction for the authors to consider, which could enhance the relevance and impact of their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to explore further."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how this explanation should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be provided. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the bounds need explanation or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, the comment lacks specificity and does not provide guidance on how to effectively explain the bounds or what aspects should be clarified. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any guidance on how the authors should revise or adjust their explanation. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is provided in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the explanation are considered unnecessary or how the authors might improve it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the explanation for the implementation of kernels with OpenAI\"s Triton is unnecessary due to wellknown engineering improvements. However, it does not provide any specific guidance or suggestions on how the authors might revise or improve their explanation. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3prong task with clockwise and counterclockwise rotations, and the 4prong task, which could provide sufficient information about the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the complexity of the tasks, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While it provides some evidence and examples, it could be strengthened by including more detailed explanations or references to support the argument. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or clarify their claims in the paper. While it identifies potential weaknesses and areas for improvement, it does not provide actionable steps or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights important areas for consideration but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to reconsider their analysis of neural networks and possibly expand it to include more complex models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This provides clear guidance on what needs to be addressed in the analysis of neural networks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks is less significant due to the existing NTK theorem, which trivially extends from linear models to wide fullyconnected neural networks. The reviewer supports this claim by referencing specific sections (3.2, 3.3) where this analysis is discussed. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the existing NTK theorem makes the analysis trivial or how the work bypasses the core problem of overparametrized neural networks. While the reference to specific sections provides some context, the comment could be strengthened with additional justification or examples. Therefore, the comment is 3, as it provides some support but lacks full clarity and depth.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it highlights a potential weakness in the analysis of neural networks, which the authors could address to enhance the rigor and depth of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the analysis need improvement. Overall, the comment offers some guidance but lacks detailed suggestions for improvement, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the paper regarding the use of terms like \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what specific changes should be made to clarify the terms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al., 2017). This provides full grounding as it clearly identifies the part of the paper being addressed. The comment also specifies the issue of confusion regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" and \"expensive to evaluate\" are confusing, as they appear in different parts of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or how they could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of terms like \"relatively inexpensive\" and \"expensive to evaluate\" in different parts of the document. This is a clear and actionable observation that could help the authors clarify their language and improve the coherence of their writing. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending a consistent terminology or rephrasing. Overall, the comment is 3 as it points out a specific area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparsereward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method\"s performance in sparsereward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparsereward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method\"s performance in sparsereward scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the method\"s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and subtaskspecific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires subtaskspecific rewards, which is similar to dense reward signals, and questions whether it can solve sparsereward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is a clear and actionable point that could help the authors clarify their methodology and ensure a fair comparison with other approaches. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional information should be included in the paper. Overall, the comment is 4 as it identifies a critical area for clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results on the official COOC leader board on the blind test set, which is a clear and direct action. It also suggests that the paper should compare to related work on the official test set and provides a link to the COOC leaderboard. Additionally, it suggests that the authors should consider comparing their results to other approaches that have been evaluated on the blind test set, which is a specific and actionable suggestion. The comment is 5 as it provides clear guidance on how to improve the paper by including these comparisons.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison of results to related work on the official COOC leader board on the blind test set. The comment provides a specific example of a related work that has been evaluated on the blind test set and suggests that the paper should follow suit. This level of detail provides clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared on the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a link to the COOC leaderboard and references other works that have been evaluated on the blind test set, such as [5,17]. This provides a clear and logical basis for the claim, as it suggests that the authors should follow established practices and benchmark their results against the bestperforming approaches. The reference to specific works and the leaderboard adds robustness to the claim, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on how the authors can improve their captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for evaluating the final results. The reviewer suggests that the paper should compare its results on the official COOC leader board on the blind test set, which is a widely recognized benchmark for captioning experiments. Additionally, the comment suggests that the authors should consider comparing their results to other approaches that have been evaluated on the blind test set, which could significantly enhance the paper\"s impact. This feedback is clear and provides a clear path for the authors to improve their draft, making it 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This is a request for clarification rather than a claim or opinion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and actionable, as it points out a potential confusion in the paper and provides a specific direction for improvement. By addressing this issue, the authors can enhance the clarity and coherence of their argument. However, the comment could be more helpful if it offered additional guidance on how to clarify these concepts or provided examples of how they might be clarified. Overall, the comment is 4 as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is 5 as it directly instructs the authors on how to enhance their experimental section to better support their claims.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\"s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the lack of a comparison with the image classification result of Mid Vision Feedback (MVF)\u2014and why this is important for proving the superiority of the schema searched by ELF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment highlights a gap in the experimental setup, noting that the current comparison only compares ELF (the author\"s method) with the baseline without MVF. This critique is 3 as it points out a specific issue with the experimental setup, but it could be strengthened by providing more detailed reasoning or examples of how the comparison with MVF could enhance the demonstration of the contribution points. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it suggests that the authors should include a comparison with the image classification result of MVF to demonstrate the superiority of their schema searched by ELF. By addressing this feedback, the authors can significantly enhance the experimental section of their paper, providing stronger evidence for their claims. Therefore, the comment is 5, as it offers a concrete and impactful suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples of specific activities or detailed suggestions on how to address this issue. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific section of the paper. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state and its relationship to elements or actions. The action is implicit and somewhat vague, as it lacks concrete steps on how to improve the clarity of the concept. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It suggests that more elaboration is needed to clarify this concept. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the concept of state is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and its relationship to \"elements\" or \"actions.\" It questions the equivalence of these terms and suggests that more elaboration is needed to clarify the concept. This feedback is 3 as it points out a potential area of confusion that the authors should address to improve the clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the concept or examples of how it might be misinterpreted. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. This feedback provides a clear and explicit action for the authors to take, which is to conduct a comparison using a Jaccard index. The suggestion is concrete, as it specifies the exact metric to use and the comparison to make, giving the authors a direct path to implement the suggested change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table. The authors can infer that it relates to the results or evaluation section, but this inference is not direct. The comment is specific in suggesting the use of a Jaccard index for comparison, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by the baseline methods, specifically mentioning the use of a Jaccard index. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific metric for evaluating the support of the solution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or why the Jaccard index is particularly relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed instructions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons to adaptive learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\"s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is 3, as it provides a direction for improvement but lacks actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination, suggesting that a simple yes response does not necessarily indicate comprehension of the object in the image. The reviewer provides a logical reasoning by explaining that the model may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support the claim that a simple yes/no response is insufficient. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative methods for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the FRM should be elaborated upon or how the innovation could be detailed. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation. However, it does not provide specific guidance or suggestions on how the authors might address this concern or what aspects of the FRM should be elaborated upon to demonstrate innovation. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer actionable steps or examples. As a result, the feedback is 3, as it points out a potential weakness but lacks depth and specificity in its guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how to present them, leaving the authors to infer the necessary actions. While the comment identifies an area for improvement, it lacks concrete guidance on how to address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or establish a connection between these concepts. While it highlights an area for improvement, the feedback lacks depth and actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment raises valid questions about the empirical results, it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is logical and relevant, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It points out that the simple greedy selection approach outperforms more principled acquisition functions and that deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment highlights a valuable area for exploration, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. The authors are given a clear direction but may need more detailed instructions to fully address the feedback. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific sources to consider. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out examples like Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. While the comment provides a clear action to take, it lacks specific guidance on how to address the issue, such as suggesting a particular section or paragraph where the contributions should be explained. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, such as Figure 1 and the deeprag algorithm, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the lack of clear explanation of the contributions in the Introduction and the placement of supporting material in the appendix. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that there is forward referencing where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned in the appendix but not in the main sections. The comment suggests that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions should be included in the main sections. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and organization of their paper. However, it could be more helpful if it provided suggestions on how to address the issue of forward referencing or how to better integrate the appendix material into the main sections. Overall, the comment is 4 as it identifies a significant weakness and offers concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how the authors should present them. The comment lacks concrete guidance on how to implement this suggestion, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is 1, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity because it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is 3 as it points out an area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail or clarity. Without these details, the claim is not fully substantiated, making it difficult for the authors to understand the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the related work section, specifically suggesting that the differences between the works mentioned are not described enough. This feedback is 3 as it points out a specific area where the paper could be strengthened, but it lacks depth and does not provide detailed guidance on how to address this issue. The authors are given a general direction to enhance the related work section, but the comment could be more helpful with additional suggestions or examples on how to improve the descriptions of the differences. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is concrete because it specifies the exact information that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for an explanation of what type of understanding is gained by looking at the PPP maps, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the authors\" explanation regarding the understanding gained from looking at PPP maps. It suggests that while the importance of reliable PPP metrics is mentioned, the article lacks explicit explanation or understanding of this concept. The comment is 3 as it logically points out a gap in the explanation but does not provide specific examples or references to support the claim. The authors may need to provide more detailed explanations to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the understanding gained from looking at PPP maps. It points out that while the authors mention the importance of reliable PPP metrics, they do not provide an explicit explanation or understanding of this concept. The comment is 3 as it highlights a specific area for improvement, namely the need for a more detailed explanation of the concept. However, it lacks depth and does not provide specific suggestions or examples on how the authors might address this issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of comparison affects the credibility. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which does not provide a clear schematic representation. It suggests that the figure should be redrawn to better connect the text and equations with the visual representation. This feedback is clear and provides concrete guidance on how to improve the draft by reworking the figure. Therefore, the comment is 5, as it gives the authors explicit instructions on what to do to enhance the clarity of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear schematic representation in Figure 2(b) and the difficulty in connecting the text with the figure and equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), which does not provide a clear schematic representation. The reviewer suggests that the figure should be redrawn to better connect the text and equations with the visual representation. This claim is 3 as it provides a specific example of the issue (Figure 2(b)) and suggests a potential solution (redrawing the figure). However, the comment lacks detailed reasoning or references to support why the current representation is insufficient or how it could be improved. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the forwardprediction model, particularly in Figure 2(b), which lacks a clear schematic representation. It suggests that the figure should be redrawn to better connect the text and equations with the visual representation. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by addressing the lack of clarity in the figure. However, the comment could be more helpful if it offered additional guidance on how to redraw the figure or what specific elements should be included to enhance the clarity. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" choice of baseline and suggests they should provide a stronger baseline to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline and consider the impact of rewardless actions on RBI. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RBI\" and \"Task 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that RBI only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone and questions the authors\" choice of baseline. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. The comment suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the significance of the issue and the potential impact on the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the model. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the authors\" choice of baseline and recommends providing a stronger baseline to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is 3, as it points out potential weaknesses but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiscale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is 4, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misleading aspect in the paper regarding the multiscale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or rephrase the statement to be more accurate. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is a vague direction, and the comment lacks specific guidance on how to address these issues. The authors are left with a general idea of what needs to be improved but without clear steps on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment also suggests a direction for the conclusion, but it does not provide specific guidance on how to address these issues or what specific aspects of the comparison with reinforcement learning should be discussed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and that there is no discussion of limitations. It also suggests that the paper could benefit from a comparison with reinforcement learning. While the comment identifies some areas for improvement, it lacks specific examples or references to support the claim about the baseline methods or the need for a discussion on limitations. The suggestion to compare with reinforcement learning is vague and does not provide detailed guidance on how to implement this comparison. Therefore, the comment is 3, as it provides some direction but lacks sufficient evidence or detailed reasoning to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It suggests a direction for the conclusion by proposing a discussion on the similarity and difference with reinforcement learning, as well as the generalizability of the results. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but may need to infer more detailed steps to take. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the definition of $e_l$ and consider the impact of $M$ on the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. However, the comment lacks specific examples or references to support the claim that the exponential dependence on $M$ is a weakness. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the definition of $e_l$ in Equation (3) and pointing out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that this dependence affects the constant factor of the required feature size. Additionally, the reviewer provides a specific observation about the performance in Figure 1, suggesting that the weakness of the proposed approaches may be demonstrated by this observation. This feedback is clear and actionable, as it guides the authors to clarify the definition of $e_l$ and address the issue of exponential dependence on $M$. However, the comment could be more helpful if it provided suggestions on how to improve the theoretical results or the experimental setup to mitigate this issue. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs and suggests that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. However, it does not specify which part of the paper discusses the longrange modeling ability or oversmoothing, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of oversmoothing but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that it could be due to oversmoothing. The reviewer supports this claim by referencing a paper that discusses oversmoothing in the context of very deep graph networks. However, the comment lacks specific examples or detailed explanations of how oversmoothing affects the modeling ability, making it 3. The authors would need to further explore the issue and understand the implications of oversmoothing to fully address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. It does not provide actionable steps or examples of how to mitigate oversmoothing, which would be beneficial for the authors to improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the problem formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are related to. Without explicit references to sections or examples, the authors cannot confidently determine where to focus their revisions. Additionally, the comment lacks specificity regarding what aspects of the problem formulation are unclear, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the authors may find it challenging to identify and resolve the problem. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear understanding of what needs to be addressed or how to enhance the clarity of their work. Therefore, the comment is not helpful, as it does not offer any constructive feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives. This provides a clear and concrete action for the authors to take, as it specifies the exact models to include in the experiments and the purpose of doing so. The suggestion is specific and direct, giving the authors a clear path to enhance their draft by including these additional experiments. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for experiments with different LLM families, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical reasoning for the need to conduct additional experiments, which could enhance the applicability and generalizability of the method across various LLM families. However, the comment lacks specific examples or references to support the claim, such as explaining why these particular models are relevant or how they would contribute to the study. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directs the authors to include specific experiments that could enhance the paper\"s contribution. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagination. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the connections or what specific changes should be made to align the process with the title or the authors\" expectations. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first part\" and \"FGE,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. However, the comment lacks specific suggestions on how to address this issue or improve the connections. Therefore, it is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, based on the author\"s interpretation of the first part and the title. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some basis but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not match the title or the author\"s imagination. It points out that the process could be computationally demanding, which is a relevant concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connections between the two parts. While it highlights a potential problem, it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it offers insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a known SOTA heuristicbased solver, to provide a better comparison with the learningbased solvers. This feedback is explicit and provides a clear action for the authors to take, as it specifies the need for including these results in the paper. The comment is concrete, as it directly instructs the authors on what to add to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front\" from Figure 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde to provide a better comparison with the learningbased solvers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, but it suggests that for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The reviewer provides a rationale by mentioning that the obtained Pareto front is not highly nonconvex, which affects the comparison. However, the comment lacks specific examples or references to support the claim about Concorde\"s performance. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers are better than the heuristicbased solvers but that for the single objective TSP, the SOTA heuristicsolver (e.g., Concorde) usually has the best performance. The comment suggests that the authors should include results for linear scalarization + Concorde to provide a better comparison. This feedback is clear and actionable, as it directs the authors to include additional results that could enhance the comprehensiveness and relevance of their experimental analysis. By addressing this suggestion, the authors can improve the clarity and depth of their experimental evaluation. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM, where loop closure is applied. This provides a clear and specific rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific methods or studies that demonstrate the similarities. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by incorporating a discussion of their method in relation to existing methods. However, the comment could be more helpful if it offered specific examples or references to these existing methods, which would guide the authors in their analysis and comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or improve their draft. The comment lacks actionable guidance or specific recommendations, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of grouping for quantization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of pertensor and perchannel grouping and suggests considering finer grouping instead. This provides clear guidance on what aspect of the quantization method is being questioned and what alternative might be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. This is a valid point that could lead to a more efficient or accurate quantization process. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or explore alternative methods. While it identifies a potential area for improvement, it does not offer actionable advice or detailed reasoning, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification for the authors to act on it.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and concrete suggestion for the authors to enhance their study. However, the comment could be more helpful if it provided additional context or examples of how this analysis could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice and whether it is justified. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it could be more helpful with additional context or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the used model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment notes that the vagueness of structural assumptions in the appendix makes it difficult to find the theoretical limitation. The reviewer also suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. The feedback is explicit and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fact that their theory does not seem to be applicable to the used model,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the vagueness of unspecified \"structural assumptions\" in the appendix, which makes it difficult to find the theoretical limitation. Additionally, the comment suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of structural assumptions in the appendix. The reviewer suggests that this makes it difficult to find the theoretical limitation. The comment also implies that the authors underestimate the current use of graph neural networks in industry and suggests that they should elaborate on the potential negative societal impact of graph neural networks in general. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Therefore, the claim is 3, as it provides a logical basis but could be strengthened with more detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. This is a critical oversight, as it affects the validity and applicability of the paper\"s claims. The reviewer suggests that the authors should address this limitation by explicitly mentioning it in the main text. Additionally, the comment points out the vagueness of structural assumptions in the appendix, which makes it difficult to find the theoretical limitation. This feedback is valuable as it highlights a critical gap in the paper that the authors need to address to strengthen their work. The suggestion to elaborate on the potential negative societal impact of graph neural networks in general is also insightful, as it could provide a more comprehensive understanding of the paper\"s implications. Overall, the comment is 5 as it identifies key areas for improvement and offers actionable guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilongreedy\" in the context of training, indicating that the authors need to provide more information about this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\" comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the importance of the framework in the context of weakly supervised learning. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspect of the framework is vital or how it contributes to the use of CLIP. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not provide any supporting evidence, reasoning, or references to justify why this part is crucial or how it distinguishes the paper from other related work. Without such information, the claim remains 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the discussion. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. However, it also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bitserial accelerators. It also mentions the use of bitparallel fixedpoint numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 2, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. This is a relevant observation that could impact the applicability and generalizability of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide specific guidance on how to address the issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis could be explained in depth, particularly regarding the information distortion and the quantization of MHSA. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and detailed explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the claims about information distortion and quantization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the information distortion and the quantization of MHSA. It highlights the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This feedback is 5 as it identifies specific areas where the authors need to provide more depth and clarity in their analysis. By pointing out the limitations of the proposed approach and referencing existing works, the comment offers actionable guidance for the authors to improve their draft. However, it could be further enhanced by suggesting specific ways to address the issues or providing additional references to support the claims. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons to STN and provide more detailed explanations of the Xtransformation. However, the comment lacks concrete steps or examples on how to implement these improvements, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"spatial transformer networks (STN)\" and the \"Xtransformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the absence of comparisons to STN, which are important aspects that need to be addressed. The comment provides specific guidance on what needs to be improved, such as the need for empirical or conceptual comparisons to STN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by pointing out that the proposed Xtransformation is similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, the comment notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment provides some logical reasoning and references to existing works, it could be strengthened by providing specific examples or references to these existing works. This would make the claim more 5, but the current information provides a solid basis for the authors to understand the issue and address it. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper, which is important for demonstrating the novelty of the work. The comment provides clear and actionable feedback by suggesting that the authors should include comparisons to STN and provide more detailed explanations of the Xtransformation. This feedback is valuable as it guides the authors on how to enhance the technical novelty and comparative analysis of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof link. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected (the labeling of \"Fig.7\" to \"Fig.12\") and suggests attaching each theorem and corollary to its corresponding proof link. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the labeling of \"Fig.7\" in Supp. Page 31, suggesting it should be changed to \"Fig.12.\" It also provides a suggestion to attach each theorem and corollary to its corresponding proof link to improve the reader\"s understanding. The comment is 4 as it provides a logical reasoning for the suggested changes, which would improve the clarity and organization of the paper. However, it lacks specific examples or references to support the claim about the importance of attaching theorems and corollaries to their proofs. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides several actionable suggestions to improve the clarity and organization of the paper. It points out a specific error in the labeling of \"Fig.7\" in Supp. Page 31, suggesting it should be changed to \"Fig.12.\" Additionally, it recommends attaching each theorem and corollary to its corresponding proof link to enhance the reader\"s understanding. This feedback is clear and offers concrete steps for the authors to improve the clarity and organization of their work. However, the comment could be more helpful if it provided additional context or examples on how these changes would impact the reader\"s experience. Overall, the comment is 4 as it offers actionable guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a specific suggestion for improvement by mentioning the appendix discussion on representation learning. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. The reviewer provides a logical reasoning by pointing out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. However, the comment lacks specific examples or references to the appendix or Section 4 to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the proposed invariant learning module by suggesting that it could be enhanced by considering representation learning, which is currently discussed in the appendix. It points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. This feedback is clear and actionable, as it provides a specific direction for the authors to consider incorporating representation learning into the feature selection process. By addressing this suggestion, the authors could significantly improve the robustness and generalizability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, specifically regarding the design of rewards. It highlights a gap in understanding that could impact the clarity and effectiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the reward design. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, offer guidance on how to address the weakness, or provide specific feedback on the execution effort or experimental design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, backed by good experimental design. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the novelty is limited, and the execution effort surpasses the novelty. The reviewer mentions that the weakness is a little nitpicking, but if there is no code release after the revision process, it becomes more significant. The comment provides a logical reasoning for the weakness but lacks specific examples or references to substantiate the claim. Therefore, the comment is 3, as it provides a rationale but requires more detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. It also points out that the novelty is limited, and the execution effort surpasses the novelty. However, the comment acknowledges that this weakness is a little nitpicking, especially considering that execution (replicability) beats idea (novelty). The reviewer suggests that if there is no code release after the revision process, the weakness stands. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the novelty of their approach. The feedback is 3 as it highlights a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on how to address it. The comment is concrete, as it specifies the need for runtime discussion and highlights a potential limitation for the application of Prithvi WxC. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" emulator, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitations for applications due to its large parameter count. This provides clear guidance on what aspect of the emulator needs attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This claim is 3 as it logically follows that runtime might be an important consideration for applications with large parameter counts. However, the comment lacks specific examples or references to support the claim, such as comparisons with other emulators or detailed analysis of the runtime impact. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count and computational cheapness. This is a clear and actionable suggestion that could help the authors address a potential limitation of their emulator in certain applications. However, the comment could be more helpful if it provided additional context or examples of how the runtime might impact the emulator\"s utility or performance. Overall, the comment is 4 as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as specific sections, figures, or claims. Without explicit references to these elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity regarding what aspects of the framing contribute to the overselling and how it affects the clarity of the contribution. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks concrete evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment points out that the paper oversells the method, which could lead to a less clear understanding of the contribution. However, it does not provide specific examples or guidance on how the framing could be improved to better convey the significance of the work. Without actionable suggestions or detailed feedback, the authors are left without a clear understanding of how to address this issue. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or references to support why these changes would improve understanding or why the current presentation is insufficient. The suggestion is based on logical reasoning but lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance clarity. While the comment provides actionable feedback, it could be more helpful if it offered specific examples or guidance on how to implement these improvements. Overall, the comment is 3 as it points out areas for improvement but lacks detailed guidance, making it 3 for the authors to make improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments to verify the framework\"s effectiveness and universality, but the comment lacks concrete details on how to implement this action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the FlippedQA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to verify the effectiveness and universality of the framework beyond LLMbased models. This provides clear guidance on what additional experiments or analysis are needed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FlippedQA framework is a general framework for various generative VideoQA models but is only applied to LLMbased models. The reviewer suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to test the framework on a broader range of models, it lacks specific examples or references to support the claim that these other models would be ideal for testing. This makes the claim 3, as it provides a clear direction but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, noting that the FlippedQA framework is only applied to LLMbased models. It suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and demonstrate the generalizability of their framework. By addressing this point, the authors can enhance the robustness and applicability of their work. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The authors are left without any concrete steps or examples to follow in order to enhance their draft. As a result, the comment lacks actionability, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to identify the exact areas that need improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, indicating that it was difficult to understand the main idea and theoretical analysis of the paper. However, it does not provide specific examples or guidance on how to improve the writing, such as suggesting clearer explanations or more accessible language. Without actionable feedback or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to ClopperPearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons to these methods. However, the comment lacks concrete instructions or examples on how to enhance the theoretical novelty or address the concerns effectively. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"existing methods\" that it builds upon, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the concerns about the lack of theoretical novelty and the need for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges a willingness to improve their score if the authors address these concerns. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of novelty. The references to ClopperPearson intervals and Gaussian elimination suggest that the reviewer is familiar with these methods, but this alone does not fully substantiate the claim. The comment could be strengthened by providing more detailed reasoning or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern about the proposed method, noting that it primarily builds upon existing methods and lacks significant theoretical novelty. It acknowledges the authors\" willingness to improve their score if the concerns are addressed. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues, such as suggesting ways to enhance the theoretical novelty or differentiate the method from existing approaches. While it points out a critical area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it highlights a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any specific reasoning or examples to support this claim. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 1217. It points out that the sentence is cumbersome and could be made clearer, providing a clear direction for improvement. However, the comment lacks depth and does not offer specific suggestions or examples on how to improve the clarity of the sentence. While it highlights an area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it provides a starting point for the authors but could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a tradeoff between head and tail categories but notes that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the tradeoffs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests exploring the tradeoff between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar tradeoffs have not been fully investigated for the baselines, specifically by changing hyperparameters in Decouple [Kang et al.]. This claim is 3 as it provides a specific example of the tradeoff between head and tail categories and suggests that further investigation is needed. However, the comment lacks detailed evidence or references to support the claim that the proposed approach is worse than Decouple [Kang et al.] or that similar tradeoffs have not been fully explored. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several pieces of constructive feedback that can help the authors improve their draft. First, it points out that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, which is a significant concern. It also highlights the tradeoff between head and tail categories shown in Table 5 and suggests that similar tradeoffs have not been fully explored for the baselines. The reviewer encourages the authors to continue this line of work for future submissions, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific guidance on how to investigate these tradeoffs or what specific hyperparameters to consider. Overall, the comment is 4 as it identifies areas for improvement and encourages further exploration, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the evaluation, specifically the reliance on only four OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for additional datasets, but it is somewhat vague in terms of how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited evaluation and the need for more scenarios like the LLaVA benchmark in ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. The comment provides a logical reasoning by pointing out the potential limitations of the current evaluation and the need for additional datasets to enhance its reliability. However, it lacks specific examples or references to the LLaVA benchmark or how it would improve the evaluation. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, specifically the reliance on only four OCR QA datasets. It suggests that more scenarios like the LLaVA benchmark should be included, particularly in ablation studies. This feedback is clear and actionable, as it points out a specific area where the evaluation could be strengthened by expanding the dataset selection. However, the comment could be more helpful if it provided additional context or examples of how the LLaVA benchmark could be integrated into the evaluation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the clarity of their visual reasoning tasks. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the visual reasoning tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. The comment also asks for proof that the current formulation is necessary. While the comment identifies potential issues with the paper\"s approach, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their visual reasoning tasks. The feedback is 3 as it points out areas for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of the evaluation and generation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors\" embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment lacks specific examples or references to support the claim that the evaluation is unrealistic. Therefore, the comment is 3, as it provides a logical basis for the critique but could benefit from more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. This feedback is 3 as it highlights areas where the evaluation could be improved, but it lacks specific suggestions or guidance on how to address these issues. The authors are given a direction to consider, but the comment could be more actionable with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete details on what is expected, the comment remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue that needs to be addressed. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment is specific about the need for visualization and comparison but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide specific examples or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of essential visualization of intermediate processes and comparisons. This is a clear and actionable point that the authors can address to enhance the clarity and comprehensiveness of their work. However, the comment does not provide specific guidance on what types of visualizations or comparisons are needed or how they could be effectively presented. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" is being used inappropriately. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or adjust their terminology. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This is a relevant point that could impact the interpretation and analysis of the data. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their terminology. While it points out a potential problem, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality. However, the comment does not provide specific guidance on how to achieve this improvement or what aspects of the output need to be addressed. The authors are left to infer that they need to improve the quality, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality and the need for improvement, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment lacks specific examples or references to recent GAN works that demonstrate the improvement in quality, making it 3. The authors would need to infer the specific examples or references themselves to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the limited novelty, low resolution output, and high hardware requirements. However, the comment does not provide specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it highlights an area for improvement, the lack of actionable feedback limits its usefulness for the authors. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas of concern but does not offer detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading due to the use of subpar hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. While the comment identifies potential issues with the methodology, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas of potential concern, but it could be more beneficial if it provided actionable advice or examples of how to improve the methodology. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset\"s size is problematic or how it affects the validity of the approach. Without specific guidance on how to address this issue, the authors may find it challenging to understand and implement the suggested improvements. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and how it affects the validity of the approach. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small, which may impact the validity of the approach. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in the number of images or providing additional data. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). While the comment implies that the authors should consider this approach, it does not provide explicit instructions or concrete steps on how to implement the study. The authors are left to infer that they should conduct the study, but without detailed guidance on how to structure it or what specific aspects to focus on. Therefore, the comment is 3, as it identifies an area for potential improvement but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the paper. Without such information, the claim remains 1, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) in the context of Named Entity Recognition (NER). This feedback is 3 as it identifies a potential area for improvement by suggesting a specific experiment that could enhance the understanding of the model\"s performance. However, the comment lacks detailed guidance on how to conduct the study, what specific aspects to focus on, or how to interpret the results. While it provides a direction for the authors to explore, it could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and that they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed, but the specific steps for improvement are not fully articulated. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds a level of detail and specificity to the claim. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that have successfully addressed similar issues. Overall, the claim is 4, as it is supported by specific examples and suggestions for improvement, but it could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed, and provides examples of what could be improved, such as explaining the colors in Fig. 2. The comment also notes that Fig. 1 and 2 did not contribute much to the reviewer\"s understanding, and that they had to read the text multiple times. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to enhance its clarity and accessibility. However, it could be more helpful if it provided additional guidance on how to improve the explanations or suggested specific changes to the mathematical derivations or figure captions. Overall, the comment is 4 as it directs the authors to key areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. It explicitly states that resolving this issue would influence the reviewer\"s rating. While the comment does not provide specific guidance on how to address this issue, it implies that the authors should investigate the robustness of their results to different hyperparameter settings. The action is implicit but concrete, as the authors can infer that they need to assess the sensitivity of their results and consider different hyperparameter choices. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"empirical results\" and the \"hyperparameter choices,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\"s effectiveness. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, noting that incorrect choices could undermine any improvements gained from the method. This claim is 3 as it highlights a potential issue with the robustness of the results, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer suggests that resolving this issue would influence their rating, indicating a need for more detailed analysis or evidence to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the robustness of the empirical results, specifically the sensitivity to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue would influence the reviewer\"s rating, providing a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it offered specific guidance on how to assess the sensitivity or how to make more robust choices for hyperparameters. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method\"s novelty, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty and contribution, as it highlights the need for a more detailed explanation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately addressed. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks sufficient evidence to be 5. Therefore, the comment is considered 2, as it provides some basis for the claim but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the proposed method is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method, implying that the current explanation is insufficient. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. Providing examples or detailed suggestions on how to differentiate the method from existing approaches would enhance the helpfulness of the comment. Therefore, the comment is 3, as it points out a potential weakness but does not offer actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the small size of the text in Table 1 and the missing gradient symbol in Algorithm 1. It also mentions specific references that should be included in the paper. While the comment identifies specific issues, it does not provide explicit instructions on how to address them, such as suggesting font size adjustments or suggesting where to include the references. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the text size in table 1 and the missing gradient symbol in Algorithm 1. Additionally, it provides specific references for the missing references, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about the paper, such as the size of the text in Table 1 and the missing gradient symbol in Algorithm 1. It also provides specific references to external works, which adds a level of verifiability. However, the comment does not contain subjective opinions, judgments, or suggestions that require justification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the small size of the text in Table 1 and the missing gradient symbol in Algorithm 1. It also provides specific references to relevant literature, which is helpful for the authors to address these issues. However, the comment could be more helpful if it offered suggestions on how to improve the readability of the text or how to incorporate the references effectively. Overall, the comment is 3 as it provides actionable feedback but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific calculations or examples to illustrate the practical limitations. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the scalability and practicality of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues or improve the discussion of computational aspects. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. While the comment implies that the authors should consider this baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between the residual blocks and suggests a potential baseline for comparison. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a potential baseline for comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison would be meaningful or beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet in the experiments, asking whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity and comparability of the results. The comment also suggests a potential baseline for comparison, which could enhance the understanding and interpretation of the experiments. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address the issue or explore the proposed baseline. While it identifies a potential area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation or what specific changes should be made to the architecture. As a result, the authors are left without a clear understanding of how to improve their draft in this area. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation of the crossencoder architecture, noting that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the motivation, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for the crossencoder architecture is poorly explained, specifically stating that it is not ignoring crossentity comparison but instead attends to all candidates at once. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the paper\"s motivation, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the motivation for their architecture. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unjustified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be convincing. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the methodology and encourages the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the design choice. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may struggle to effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without detailed feedback or constructive advice, the authors are left with only a general critique, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional adhoc postanalysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional adhoc postanalysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment\"s reliance on pseudo feature importance and the need for a more robust method to estimate true feature importance. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it guides the authors on how to improve the robustness and credibility of their experiment. By addressing these suggestions, the authors can enhance the reliability and trustworthiness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding SuppMat sections, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and uptodate. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to make a specific correction that can improve the clarity and accuracy of their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details on how to achieve this. As a result, the action is implicit and vague, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not specify which part of the paper this analysis should be applied to, nor does it provide details on what aspects should be included or how the analysis should be conducted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer a clear path for the authors to follow, making it difficult for them to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges the limitations of the paper\"s length but does not offer actionable steps for the authors to take. Without detailed suggestions or examples, the feedback lacks depth and specificity, making it 2. Therefore, the comment aligns with a score of 2, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and existing research, it does not specify which works should be cited or how to distinguish them. The action is explicit but lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need to cite related works and to distinguish approaches, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. The suggestion to link the RL work is more concrete, but the overall claim is 3 due to the lack of detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to expand their literature review and distinguish their work from related approaches in the field of metalearning. It highlights the importance of citing and discussing related works, particularly those that focus on RL for architecture search and optimizers, and their potential application to continual learning. This feedback is valuable as it guides the authors to strengthen their connection to existing research and enhance the clarity and originality of their work. However, the comment could be more helpful if it provided specific examples of related works or detailed guidance on how to distinguish the approaches. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of the suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or guidance on how to implement these suggestions. Additionally, it could be expanded to discuss the implications of this diversity on the results or the methodology. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not provide explicit instructions on how to do so or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is 3 as it identifies a potential area for improvement in the clarity and organization of the paper. However, the comment lacks specific guidance on how to achieve this clarity or what aspects of the supplementary experiments should be highlighted. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement reported in Table 6 and Table 7 does not support the claim that experimental results prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\" claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it points out a potential problem but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implied and somewhat vague, as the authors can infer that they need to explore different designs but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment does provide some specificity by suggesting different designs, such as experiments or analysis with different sampling intervals and sample sizes, but it lacks detailed guidance on how to implement these suggestions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, is vague and lacks specific guidance on how to implement these changes. Without concrete evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It provides a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out a potential area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific aspects of the analysis should be expanded. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or tables where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the lack of standard deviations. While it highlights a potential problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the feature extractor. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable point, as it prompts the authors to clarify an important detail in their methodology. By addressing this question, the authors can improve the clarity and transparency of their work, which is beneficial for both the reviewer and the readers. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that computation/algorithm/implementation details should be provided, which implies that the authors should include these details in their paper. However, it does not specify which details are missing or how they should be presented, leaving the authors with a general suggestion to include more technical information. While the action is implied, it is not concrete, as it lacks specific guidance on what details are needed or how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that computation/algorithm/implementation details should be provided, but it does not specify which part of the paper these details should be included in. The authors cannot confidently determine which sections or parts of the paper are being addressed, making the comment weakly grounded. However, it is specific in suggesting what additional information is needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The comment suggests that computation/algorithm/implementation details should be provided, but it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that computation/algorithm/implementation details should be provided, which could enhance the clarity and comprehensiveness of the paper. However, it lacks specificity and does not provide guidance on which details are most important or how they should be presented. Without detailed suggestions or examples, the authors may struggle to determine which aspects to focus on or how to effectively include these details. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the choice of p < 0.4 in Algorithm 1, which is a clear and actionable request for clarification. By asking for an explanation or justification of this choice, the reviewer prompts the authors to provide additional information that could enhance the transparency and understanding of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what aspects of the choice might be particularly important for readers to understand. Overall, the comment is 3 as it directs the authors to provide additional clarification but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides some reasoning by referencing external works, which could help the authors understand the importance of these comparisons. However, the comment lacks specific examples or detailed explanations of how these comparisons would enhance the analysis. This makes the claim 3, as it provides a direction for improvement but requires more detailed guidance for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects to focus on. This limits the comment\"s helpfulness, as it points out an important area for improvement but does not offer detailed suggestions on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any guidance or suggestions for the authors to address this question or improve their draft. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance is being questioned or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions for improvement. It lacks depth and actionable feedback, leaving the authors without a clear understanding of how to address the issue or enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCDRescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, suggesting that RLCD may not be able to scale to larger language models. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCDRescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis to substantiate the computational gains claimed in the paper. It specifies the types of measurements that would be helpful, such as GPU hours, memory usage, or training time. This provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and concrete, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for specific measurements or comparisons to substantiate the computational benefits claimed in the paper. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational gains claimed in the paper. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim that these measurements are necessary. The reasoning is 3, as it highlights a potential area for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of quantitative analysis to substantiate the computational gains claimed in the paper. It suggests that specific measurements, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This feedback is clear and actionable, as it directs the authors to include quantitative analysis to support their claims. By addressing this point, the authors can significantly enhance the credibility and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors need to infer that they should consider this aspect in their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider the time aspect, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the efficiency of the method, suggesting that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods. This feedback is 3 as it points out a potential weakness in the evaluation of the method, which could impact its practical applicability. However, the comment lacks depth and does not provide specific suggestions on how the authors might address this issue or what aspects of the evaluation should be revised. To be more helpful, the comment could offer guidance on how to incorporate the time consideration into the evaluation or suggest alternative methods for assessing efficiency. As it stands, the feedback provides some insight but could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It raises a concern about early training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training process and the potential impact on the agent\"s behavior, but without clear grounding, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific evidence or references to support the claim. The comment is 3 as it provides a reasonable basis for the critique but could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thoughtprovoking observation that could prompt the authors to consider how their results might be impacted by the agent\"s behavior during learning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their results. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a relevant concern but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to identify the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the perceived marginality or what changes could be made to enhance the contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential weakness in the contribution, it lacks specific suggestions or guidance on how the authors could address this issue or enhance their contribution. The feedback is 3 as it points out a potential limitation, but it does not provide actionable advice or detailed feedback for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivations for PBSD and its contribution to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivations for PBSD beyond improving the discriminative representation on tail classes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This claim is 3 as it highlights a potential inconsistency in the paper\"s focus, but it lacks specific examples or references to support the argument. The authors would need to further explore and clarify the motivations for PBSD to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This feedback is 3 as it points out a potential inconsistency in the paper\"s focus, which could be clarified to enhance the coherence and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as by providing additional context or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of the distribution. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or where the limitation is discussed, making it weakly grounded. The suggestion to consider a selfsupervised approach is specific, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. However, the comment lacks specific examples or references to support the claim that a selfsupervised approach would be more effective. The reasoning is based on a logical assumption, but without detailed evidence or comparisons, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their method. However, the comment could be more helpful if it included examples or detailed reasoning on why a selfsupervised approach might be more effective. Overall, the comment is 4 as it guides the authors toward a potential improvement in their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these additional experiments to fully demonstrate the scalability of their method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability on more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The claim is 3 as it logically argues that demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim that these tasks are indeed more challenging or how LFF could be applied to them. Providing such examples or references would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in these more complex tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is 3 as it highlights an area where the paper may be outdated and suggests that the authors consider more recent works. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as suggesting alternative baselines or explaining why MULT is still relevant. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and explicit action for the authors to take, specifying the exact steps needed to improve the clarity and fairness of the comparisons. The comment is 5 as it offers concrete guidance on how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"comparison against other models,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, namely the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. The comment provides a detailed suggestion for improvement by recommending that the authors compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is 3 as it provides a logical reasoning for the need to clarify the comparison and suggests a method for doing so. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and fairness of the experimental comparison in the paper. It points out that the value of the used ranks for all models is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is clear and actionable, providing the authors with a specific and detailed suggestion for improving the clarity and fairness of their comparisons. By addressing this issue, the authors can significantly enhance the transparency and robustness of their experimental results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the normalization module between the two versions and suggests that the figures are valuable for understanding the system but need standardization. It also points out a confusion in Fig. 4 regarding the chosen symbols overlapping. However, the comment does not provide explicit guidance on how to standardize the figures or address the discrepancy in the normalization module. The action is implicit and somewhat vague, as the authors need to infer that they should standardize the figures and address the discrepancy. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the normalization module, which is different in the two versions, and points out the confusion in Fig. 4 regarding the chosen symbols overlapping. Additionally, the comment provides specific suggestions for standardizing the figures and clarifying the text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the normalization module seems different in the two versions but is described as the same in the text. It also suggests that figures are valuable for understanding the system but need standardization. The reviewer provides a specific example of confusion in Fig. 4 regarding the chosen symbols overlapping. However, the comment lacks detailed reasoning or references to support the claim about the normalization module or the confusion in Fig. 4. While the suggestion for standardizing figures is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the normalization module between the two versions of the paper, which is a significant issue that needs to be addressed. It also points out that the figures are valuable for understanding the system but need standardization. Additionally, the comment highlights a specific confusion in Fig. 4 regarding the chosen symbols overlapping. While the comment provides some actionable feedback, it could be more helpful if it offered suggestions on how to standardize the figures or addressed the discrepancy in the normalization module. Overall, the comment is 3 as it provides valuable insights but lacks depth and specific guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It highlights that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer questions whether the algorithm requires extra computation cost for space partitioning. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this discrepancy or what additional details should be included in the theoretical part. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations of the algorithm and its computational requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation that only parts of subdivision splines are useful for decision boundaries. It points out that the theoretical part lacks details on how the proposed algorithm removes these splines, and it raises a concern about the extra computation cost for space partitioning. The comment is 3 as it highlights a potential gap in the paper\"s explanation and seeks clarification on the algorithm\"s computational requirements. However, it does not provide specific examples or references to support the claim or the need for additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that the authors claim that only parts of subdivision splines are useful for decision boundaries, but the theoretical part lacks details on how the proposed algorithm removes these splines. The reviewer also questions whether the algorithm requires extra computation cost for space partitioning. This feedback is 3 as it highlights a potential gap in the paper\"s explanation and suggests that the authors should provide more detailed information on the algorithm. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what additional details should be included. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300WLP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the use of the 300WLP dataset in their experiments and address the potential bias. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to clarify the dataset usage, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental methodology and the use of the 300WLP dataset. It specifies the issue by pointing out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. The comment also raises a question about whether 300WLP is used in all experiments or just some, and whether this could provide an unfair advantage to the proposed method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset. The reviewer points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. This observation is based on a logical inference and is not a subjective claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. This inconsistency raises questions about the fairness of the results and whether the proposed method has an unfair advantage. The comment highlights a critical area for clarification and potential bias, prompting the authors to address this issue in their experimental methodology. However, the comment could be more helpful if it provided specific suggestions on how to clarify the dataset usage or how to mitigate potential bias. Overall, the comment is 4 as it identifies a critical area for improvement but lacks detailed guidance on how to address it fully."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the algorithm, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the training dynamics observed. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and specifically mentions that the authors found inverse scaling over compute, but does not provide further details on what this means or how it affects the paper. It implies that the authors should provide an explanation for this observation, but without explicit references to specific sections or elements of the paper, the authors may struggle to identify where this analysis should be included. Therefore, the comment is weakly grounded because it does not specify which part of the paper should be analyzed, but it is specific in its request for an explanation. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and implies that the authors should provide an explanation for the observed training dynamics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that there is no indepth analysis of the training dynamics observed. It suggests that the authors should provide an explanation for the inverse scaling over compute, which would enhance the paper\"s solidity. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct the analysis or what aspects to focus on. This limits the comment\"s helpfulness, as it points out a critical issue but does not offer detailed suggestions for addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline\"s underperformance. While the comment implies that the authors should include more comprehensive analyses, it does not specify exactly what aspects need to be addressed or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed analyses but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough and questioning the extent to which the performance improvement can be attributed to the authors\" claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the majority of the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It suggests that the authors\" method underperforms the baseline in some instances, which raises questions about the extent to which the performance improvement can be attributed to the authors\" claim. The comment provides some logical reasoning by pointing out the lack of comprehensive analyses, but it lacks specific examples or references to support the claim about the method\"s underperformance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the underperformance of the authors\" method compared to the baseline, which raises questions about the extent to which the performance improvement can be attributed to the authors\" claim. This feedback is valuable as it points out a critical area for improvement in the paper, specifically the need for more detailed analyses and explanations of the method and its performance. However, the comment could be more helpful if it provided specific suggestions on how to address these issues, such as which aspects of the method or results should be further explored or explained. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is related to, such as specific sections or examples where the focus on multitask models is discussed. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on multitask models limits its applicability, which is a valid point. However, it does not provide any specific suggestions or guidance on how the authors might broaden the scope of their work or address this limitation. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section\" and \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The reviewer also poses a question about the Assumption 2 and the rate of QSGD in the stochastic regime. This claim is 4 as it provides specific references and examples to support the argument. However, the comment could be strengthened by providing more detailed analysis or comparisons between the mentioned papers and the current work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the literature review, noting that it ignores several relevant papers. It provides specific examples of papers that could be relevant to the current work, such as VRMARINA and DASHAMVR, which are mentioned in [1] and [2], respectively. The comment also raises a question about the Assumption 2 and the rate of QSGD in the stochastic regime, suggesting that these papers could be relevant to the analysis. This feedback is clear and actionable, as it directs the authors to consider these papers for further analysis and potential integration into their work. However, it could be more helpful if it provided more detailed guidance on how to incorporate these papers or why they are relevant. Overall, the comment is 4, as it effectively points out a gap in the literature review and offers a specific direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies potential areas for enhancement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. The reviewer suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of including this information and the potential benefits of doing so, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this optimization or how to present the results. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should focus on making their results more practical and actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more takeaway points for practitioners. It mentions a specific takeaway point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but this inference is not direct. The comment is specific in its suggestion for practical takeaways but lacks grounding as it does not explicitly mention which part of the paper it addresses. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not have immediate practical implications, which is 3. The reviewer acknowledges the novelty of the work and suggests that more practical takeaways for practitioners would be beneficial. However, the comment lacks specific examples or references to support the claim that the theoretical results are not immediately applicable. The suggestion to query a cluster proportionally to the square root of its size is mentioned but not fully developed, leaving the authors to infer the significance of this finding. Overall, the comment provides some basis for the claim but lacks detailed evidence or examples to fully substantiate it, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the theoretical results do not have immediate practical implications. It acknowledges the novelty of the work and suggests that more practical takeaways for practitioners would be beneficial. The comment provides a specific takeaway point, namely querying a cluster proportionally to the square root of its size, but notes that it is unclear if this is a novel finding in the paper. While the comment highlights an area for improvement, it lacks detailed guidance or suggestions on how to address the issue. The authors are left to infer that they should focus on making their results more practical and actionable, but without specific steps or examples, the feedback is 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide additional information or clarification regarding the purpose of separators. However, the comment lacks concrete details on what specific information is needed or how to present it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or examples to justify why the separators are necessary or what additional information they might offer. Without such justification, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This feedback is 3 as it identifies a potential gap in the paper that could be clarified or expanded upon. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or claims that require evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thoughtprovoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling should be questioned. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The comment implies that it is not necessary for each initialization to reach the global minimum, as long as at least one does. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific changes should be made to improve the experimental setup. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their experimental approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler approach, which is to run vanilla Adam on the final network with 40 random initial points. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the experimental setup and suggesting a simpler alternative. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests that a simpler approach could be to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. The claim is 3 as it provides a logical reasoning for why the current approach might not be optimal, but it lacks specific examples or references to support the claim. The authors would need to further explore the implications and potential consequences of the suggested alternative approach to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests a simpler alternative, which is to run vanilla Adam on the final network with 40 random initial points, which would likely result in finding the global minimum. This feedback is 3 as it points out a potential issue with the experimental setup and provides a suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to implement the suggested alternative or why it might be more effective. Overall, the comment provides some insight but lacks depth and actionable details, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should clarify what Omega is mentioned in L178 and provide more explicit information about the OMD family of algorithms. Additionally, it asks for clarification on the link function and the theorem in [32] that is being referred to for the regret guarantee. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the guidance is not as concrete as it could be. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as what Omega is and the link function used. The comment also asks for more explicit information about the OMD family of algorithms and the theorem in [32] that is being referred to for the regret guarantee. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting more explicit explanations. It asks for clarification on what Omega is mentioned in L178 and suggests that the authors be more explicit about the OMD family of algorithms. Additionally, it inquires about the link function and the theorem in [32] that is being referred to for the regret guarantee. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how to address these issues or provided additional context to guide the authors in their revisions. Overall, the comment is 4 as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer the actions needed to improve their draft, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthesized results for UCF101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes a claim about the synthesized results for UCF101, suggesting that the issue is inconsistent motion, changing color, or object disappearing over time. The reviewer suggests that using longer video sequences could address these issues. However, the comment lacks specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The reviewer suggests that using longer video sequences could address these issues. While the comment highlights areas for improvement, it lacks detailed guidance or specific suggestions on how to implement these changes. This limits the comment\"s helpfulness, as it provides some direction but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps for how to address it. The authors are left to infer that they should consider this experiment, but the comment lacks specific guidance on how to implement it or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely whether the study of 32bit logits helps against a more powerful adversary. This provides clear guidance on what the authors should consider in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical inference to understand the basis of the suggestion, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and its potential impact on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit should improve robustness against a more powerful adversary. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might explore this idea or what specific experiments could be conducted. The feedback is 3 as it points out a potential area for enhancement, but it lacks depth and actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is 5 because it clearly identifies what needs to be clarified and provides a concrete example to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL, and provides a reference to Foester et al. (NIPS 2016) to guide the authors in understanding this difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) to support this claim. However, the comment lacks detailed explanation or analysis of why the meta solvers are considered centralized controllers, making it 3. The reference to Foester et al. provides some support, but the authors would need to further explore the context and implications of the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion for the authors to consider. This feedback is 4 as it guides the authors to clarify a key aspect of their work, which could enhance the understanding and clarity of their methodology. However, it could be more helpful if it provided additional context or examples to further support the authors in their clarification efforts. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is 3, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\"s credibility and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as discussing the implications of this discrepancy or suggesting ways to improve the paper\"s timeliness. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of M_T, noting that it is defined over the probabilities of atomic events and that the notation is not clear. It suggests that the authors consider providing examples to clarify this concept. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to present these examples or what specific aspects of the notation should be clarified. This limits the comment\"s helpfulness, as it points out an issue but does not fully support the authors in addressing it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific experiments or results. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve this refinement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the experimental results or what specific aspects of the method need to be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide any specific reasoning or evidence to support this claim. The mention of \"IRM\" suggests that the reviewer believes the performance is similar to a known method, but this alone is not enough to substantiate the claim. The lack of detailed justification or references makes the claim 1, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the cause of this similarity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the experimental results. Without actionable feedback or detailed analysis, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment identifies a potential area of confusion or misunderstanding in the paper, it does not provide specific guidance or suggestions on how to address this issue. The authors are left with a vague understanding of what needs to be clarified, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it points out a potential area for improvement but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"nonsequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the terminology used, which could impact the clarity and understanding of the paper. While the comment identifies a specific area of concern, it does not provide any suggestions or guidance on how the authors might clarify or address this issue. The feedback is 3 as it points out a potential problem, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which seems incorrect due to a separate node with 0 neighbors. The reviewer asks how to explain this exception. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this question or clarify the exception. The action is implicit and somewhat vague, as the authors can infer that they need to provide a response but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for clarification on how to explain an exception involving a separate node with 0 neighbors. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the correctness of Theorem 1 and an observation about an exception involving a separate node with 0 neighbors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1, specifically questioning the upper bound in the context of a separate node with 0 neighbors. This is a relevant point that could lead to a clarification or correction in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or explain the exception. While it identifies a potential problem, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to enhance the novelty of their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and comparing the paper to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The comment provides a specific comparison with the papers, noting that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous works. This comparison provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific sections of the papers that support the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). It provides a specific comparison with the papers, highlighting the similarities in the idea, coattention mechanism, and architecture. This feedback is 3 as it points out an area where the paper could be improved by differentiating itself from existing work. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPTgenerated rumors are easier to detect than natural rumors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors could provide further analysis or solutions regarding the handling of rumors generated by GPT. It questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect, suggesting that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor. The comment highlights a gap in the analysis and provides a clear direction for the authors to consider. However, it could be more helpful if it offered suggestions on how the authors might address this issue or what specific analyses could be conducted to clarify the rationale. Overall, the comment is 4 as it points out a critical area for improvement and provides a direction for the authors to explore, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. However, it does not specify the exact font size that should be used or provide guidance on how to adjust the font size. While the action is explicit, the lack of concrete details on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6, which does not contain any subjective claims, opinions, or suggestions. It is a descriptive statement that requires no verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. While this feedback is clear and actionable, it does not provide any guidance on how the authors might address this issue, such as suggesting a specific font size or offering suggestions for improvement. The comment is 3 as it points out a minor issue but lacks depth and does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes they should make to ensure fair comparisons. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important consideration for the authors, as it could impact the interpretation and comparison of results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of the comparison. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, Navon et al. (2020), which explores learning the Pareto Front with Hypernetworks. This reference provides a basis for the claim, suggesting that the authors should consider alternative relationships. However, the comment could be strengthened by providing more detailed reasoning or examples of how the alternative relationships might be explored. Overall, the claim is 4, as it is supported by a reference but could be further developed with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, Navon et al. (2020), which could provide a starting point for the authors to consider alternative relationships. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or examples of alternative relationships to explore. Overall, the comment is 4 as it guides the authors toward a potentially valuable area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, suggesting that the examples chosen do not convincingly demonstrate the need for interprocess communication and recommending a focus on problems where the loss function does not decompose as the sum of sample losses. The comment provides a clear direction for improvement by suggesting a focus on Hogwild and other ERMbased distributed algorithms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the examples chosen in the paper do not convincingly demonstrate the need for interprocess communication, particularly in the second paragraph where samplingbased Bayesian methods are mentioned. The reviewer suggests that the paper\"s results are irrelevant in this context and recommends focusing on problems where the loss function does not decompose as the sum of sample losses. The comment provides a logical reasoning for the claim by pointing out that the paper\"s results are not relevant to the context of interprocess communication. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is specific and offers a concrete direction for the authors to enhance their paper by addressing a potential weakness in the introduction. By suggesting a specific area of focus, the comment empowers the authors to make a meaningful change to their draft. However, it could be more helpful if it provided additional context or examples of how the authors might apply this suggestion to their work. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and potentially fix the links. The comment is specific and concrete, as it clearly identifies the problem and offers a straightforward solution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality of their draft. By pointing out this issue, the reviewer helps the authors ensure that their references are functional and accessible, which is an important aspect of academic writing. However, the comment could be more helpful if it provided additional guidance on how to verify the links or suggested ways to troubleshoot the problem. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it clearly identifies the sections that need revision, and it is specific in detailing what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples of areas that need improvement, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is supported by logical reasoning and specific examples, making the claim 4. However, it could be further strengthened by providing additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is clear and constructive, offering the authors a concrete path to improve the clarity and accuracy of their discussion. By addressing these points, the authors can enhance the comprehensibility and effectiveness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, providing a clear and actionable suggestion for improvement. This feedback is 3 as it points out a specific area that needs attention and offers a concrete way to address it. However, it could be more helpful if it included additional context or examples to help the authors understand the problem more fully. Overall, the comment is 3 as it provides a clear direction for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attentionbased training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is 3 as it points out a potential direction for improvement, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the column header as one type. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type, the column header, should work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the column header as one type. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the inclusion of the column header as one type. While it identifies a potential issue, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the concern or what changes could be made to improve the clarity or organization of the tables. As a result, the feedback is not helpful, as it does not offer constructive advice that could help the authors enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the suggestion is clear, the lack of explicit instructions or detailed guidance on implementation makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests using examples from specific papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or references to support why these methods are considered more effective or why the current methods are inadequate. This makes the claim 3, as the authors would need to further explore the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it included suggestions on how to integrate these alternative methods into the paper or why they are particularly relevant to the context of the paper. Overall, the comment is 4 as it directs the authors to consider a broader range of attack methods, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their mitigation methods. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment where this issue might arise. Without explicit references to sections or experiments, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of this observation is relevant to their work or how it might impact their analysis. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline for their analysis. The action is explicit and concrete, as it specifies the change needed and offers concrete references to support the claim. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline is used. The comment also lacks specificity regarding why the average is not ideal or how the minimum kmeans objective would be more appropriate. Without explicit references to sections or detailed reasoning, the authors cannot confidently determine which parts of the paper need revision. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This provides a logical basis for the claim, as it suggests that using the minimum kmeans objective would be more reasonable. However, the comment could be strengthened by providing more detailed explanations or examples of how the average baseline might be problematic. Overall, the claim is 4, as it is supported by references and logical reasoning, but it could be further substantiated with additional details.", "helpfulness_rationale": "The review comment provides a minor suggestion to improve the paper by recommending the use of the minimum kmeans objective over multiple seeds as a baseline instead of the average. The reviewer supports this suggestion by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This feedback is 3 as it offers a specific improvement that could enhance the robustness and accuracy of the analysis. However, it could be more helpful if it provided additional context or explanation on why the average baseline is not ideal or how the minimum kmeans objective would be more appropriate. Overall, the comment provides a clear and actionable suggestion, but it could be more comprehensive to fully address the authors\" needs for improvement. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, but temperature calibration is applied after training. The reviewer asks the authors to clarify this point, which is a clear and explicit action. Additionally, the comment suggests that reducing the entropy of the regularization term (H) may lead to overconfident predictions, which contradicts the paper\"s motivation to calibrate the networks. This feedback is concrete and provides specific guidance on how the authors can address the confusion and improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 155160,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, particularly in the context of the regularization term H. The comment further clarifies the potential contradiction between reducing entropy and the paper\"s motivation to calibrate the networks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. The reviewer questions whether temperature calibration is required for both uncertainty calibration and the regularization term H, as stated in lines 155160. The comment suggests that this is confusing because the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. The reviewer also points out that reducing the entropy of the regularization term (H) may lead to overconfident predictions, which contradicts the paper\"s motivation to calibrate the networks. The comment provides a logical reasoning and a specific observation, making it 4. However, it could be strengthened by providing references or examples to support the claim about the impact of entropy on overconfidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential source of confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically in the context of the regularization term H. It points out that the training regularization term (H) requires temperature calibration, yet temperature calibration is applied after training. This is a clear and actionable observation that the authors can address to clarify their work. Additionally, the comment highlights a contradiction between reducing entropy and the paper\"s motivation to calibrate the networks, which could be further explored to improve the draft. Overall, the comment provides valuable insights and actionable feedback, making it 4. However, it could be more comprehensive by offering suggestions on how to clarify the confusion or address the contradiction. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. While the comment identifies the missing reference and the need for contextualization, it does not provide specific guidance on how to integrate these elements into the paper. The action is clear but lacks detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the reference and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer suggests that the paper should discuss similarities and differences with \"Lista\" and place itself in appropriate context. While the comment identifies the missing reference, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of discussing similarities and differences, and the contextualization of the paper. Therefore, the comment is 3, as it provides a starting point but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include a missing reference and provide a more comprehensive discussion of their work in relation to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these elements into the paper or provided examples of how similarities and differences might be discussed. Overall, the comment is 4 as it guides the authors toward improving the clarity and contextualization of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing element in the paper, specifically the FLOT cost matrix in Algorithm 1, which is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of the FLOT cost matrix in Algorithm 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of the FLOT cost matrix in Algorithm 1. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By pointing out this missing element, the comment provides valuable guidance for the authors to enhance the quality and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to define or present the FLOT cost matrix, which would provide even more detailed guidance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what alternative terminology might be more appropriate. While it points out a relevant concern, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that the authors should address these issues, but without further guidance or suggestions, the comment lacks depth and actionable advice. This makes it 3, as it points out areas for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. The reviewer suggests that these decisions should be explained in the paper to help readers understand them without needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue, including the use of a normalization factor of 1/T and how this affects the distance metric. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides specific observations, such as the use of padding to compare trajectories and the lack of a normalization factor of 1/T, which affects the distance metric. These observations are supported by logical reasoning and specific examples from the code, making the claim 4. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the paper, namely the lack of clarity regarding how the authors handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides a detailed explanation of the problem, noting that the authors pad the shorter sequence by replicating its last state to compare both trajectories, and that the lack of a normalization factor of 1/T can lead to distance increases with T, favoring longer trajectories. This feedback is clear and actionable, as it guides the authors to clarify their methodology and provide necessary explanations in the paper. By addressing these points, the authors can significantly improve the clarity and comprehensibility of their work, making the comment 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. [7], but the evaluation is slightly different because no human starts are used. This is a clear and direct action for the authors to take, as it provides a specific point to address in their draft. The comment is concrete, as it specifies the exact part of the paper where the mention should be made and the issue with the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. [7], despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] because no human starts are used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation in SI 6.5, noting that the preprocessing is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to make a specific mention in the paper to clarify this difference. By addressing this point, the authors can improve the clarity and accuracy of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively communicate this difference in evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper claims advantages over previous work in terms of efficiency but does not provide any metrics to substantiate these claims. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not explicitly instruct the authors to include these metrics or specify which metrics should be used. While the action is implied, it is not as clear as it could be, as the authors may not be entirely sure which metrics would be most relevant or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or references to previous work that demonstrate the efficiency of the proposed method, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not provide any metrics to substantiate these claims. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the efficiency claims. The comment is clear and actionable, as it directs the authors to include metrics to demonstrate the efficiency of their proposed method. However, it could be more helpful if it provided specific suggestions on which metrics to use or how to present them effectively. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these changes or what specific details should be included. The authors are left to infer the exact steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be more detailed, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDARbased segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need attention or how to address the suggestion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, citing the ability of LiDAR to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to support why LiDARbased segmentation is considered superior to object detection. The claim is 3, as it provides a logical argument but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a subjective opinion on the choice of downstream task, suggesting that LiDARbased segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might need adjustment. While the feedback identifies a potential area for improvement, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be helpful to include additional benchmarking tasks outside of AitW. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but without detailed instructions on what those tasks should be or how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide specific tasks or examples of what these tasks could be, nor does it explain why these tasks are necessary or how they would enhance the paper. Without detailed guidance or examples, the authors are left with a general suggestion but no clear path for implementation. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing a footnote. This feedback is explicit and provides concrete guidance on how to address the confusion. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as it is not mentioned in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to another paper, \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by pointing out the correct name. This provides a clear and verifiable basis for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their draft. By addressing this issue, the authors can improve the clarity and accuracy of their figure captions, which is valuable guidance for improving the paper. However, the comment could be more helpful if it suggested how to handle the potential confusion with the existing literature or provided additional context on the significance of the name. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or lines, the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect, which could be a significant contribution to the paper. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification and potential improvements, it lacks specific guidance on how to address these issues or what specific changes should be made. The feedback is 3 as it highlights areas for improvement but could be more actionable with additional details. Therefore, it is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a change, it implies that they should consider this possibility and clarify the differences between the two distributions. The action is implicit but concrete, as it provides a clear direction for the authors to explore and address the question. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this assumption is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the difference between the two distributions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not express an opinion, judgment, or suggestion that requires verification. It is a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what the implications of this assumption might be. The comment lacks actionable feedback or context that would help the authors understand the significance of this distinction or how it might impact the paper\"s conclusions. As a result, the comment is 2, as it points out a potential area for improvement but does not offer specific guidance for addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, noting that it may be a risky choice that assumes strong coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples to support the claim about the risks involved. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of the decisionmaking process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that the authors should provide an explanation for this choice, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples of alternative approaches that could be considered. Overall, the comment is 4 as it guides the authors toward a clearer explanation of their methodology, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or justification to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach\"s universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction for improvement but not detailed guidance on execution.", "grounding_specificity_rationale": "The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also mentions the heavy reliance on FEniCS and compares it to current operator learning methods. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the issues with the approach, such as the need for careful choice of basis functions and meshes, and the reliance on FEniCS. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also notes that the approach heavily relies on FEniCS, a specific solver, and compares it to current operator learning methods. The comment provides a logical reasoning by pointing out the limitations of the proposed approach compared to specialized numerical solvers, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out the heavy reliance on FEniCS, a specific solver. The comment also compares the proposed approach to current operator learning methods, suggesting that the latter are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the approach. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the agent can plan ahead is too vague to be understood concretely. While the comment provides some guidance on what is unclear, it does not offer explicit instructions on how to clarify or improve the paragraph. The authors are left to infer that they need to make the paragraph more understandable, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a general direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L156166,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the paragraph, including the difficulty in understanding the content and the vagueness of the description. The comment provides specific suggestions for improvement, such as clarifying the Gittins strategy and making the figure more understandable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and lacks clarity, such as the phrase \"Dashed lines indicate that the agent can plan ahead...\". However, the comment does not provide specific examples or references to support the claim that the description is unclear or vague. Without additional context or detailed reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3, as it highlights a potential problem but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and lacks clarity, such as the phrase \"Dashed lines indicate that the agent can plan ahead...,\" which is too vague to be understood concretely. This feedback is 3 as it highlights an area where the authors need to improve the clarity and understandability of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the paragraph or improve the figure, such as by offering specific examples or alternative explanations. Overall, the comment identifies a weakness but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper discusses these bounds, making it difficult for the authors to pinpoint the exact section that needs attention. The comment also lacks specificity regarding what aspects of the bounds are problematic or how they might limit the applications of the approach. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applications of the approach. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the bounds of the approach, noting that they have o(1) terms and improve over previously known results for arbitrarily long inputs. However, it does not provide specific guidance on how this might limit the applications of the approach or what steps the authors could take to address this concern. While the comment highlights a potential limitation, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual observation or request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this aspect or what aspects of DVP performance should be examined. Without actionable feedback or detailed direction, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific changes should be made to improve the clarity. As a result, the authors are left without clear instructions on how to improve the draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects of the paper are unclear. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what aspects of the paper are unclear. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or improve the connection between sections. The comment implies that the authors should make the theoretical analysis more robust or provide additional context, but it does not offer concrete steps or suggestions on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The mention of a specific reference, [1], provides some grounding, but the comment is still not fully grounded as it does not explicitly identify the parts of the paper being addressed. The comment is specific in pointing out the issues with the theoretical analysis and its relation to the reference, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference, [1]. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to a specific reference. While it points out a potential weakness, it lacks specific guidance or suggestions on how to address this issue or improve the theoretical analysis. The comment could be more helpful if it provided examples of how the connection could be strengthened or how the theoretical analysis could be expanded. As it stands, the feedback is 3 as it highlights an area for improvement but does not offer detailed guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more information about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the losses in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area of interest, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for further exploration and explanation in the paper. However, the comment lacks specific guidance on how to conduct this discussion or what aspects of the losses should be highlighted in specular areas. While it points out a potential gap in the paper, it does not provide detailed instructions or examples to help the authors effectively address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference [30]. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference [30]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference [30]. This claim is 3 as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or references to the exact phrases or sections that need clarification. The reviewer could provide more detailed guidance on how to improve the clarity of the algorithm, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference [30]. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered additional guidance on how to address the issue. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the transparency of their work. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential problem but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments. It suggests that the evidence provided is limited, which is a clear indication that the authors need to provide more robust data or analysis to substantiate their claims. However, the comment does not specify what additional evidence or analysis would be needed or how to present it. While the action is implicit, it is clear that the authors need to address this issue, but the lack of concrete guidance on how to do so makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient support for these claims in the experiments and the limited evidence provided to practitioners. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims about the mixing time being better in practice, noting that the evidence provided is insufficient and limited. This is a critical observation that highlights a gap in the paper\"s experimental support, which is crucial for practitioners to understand the practical implications of the claims. However, the comment does not provide specific suggestions on how to address this issue or what additional evidence might be needed. While it points out a critical area for improvement, it lacks actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it points out a potential area for improvement in the paper. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might bring. Without further explanation or examples, the authors may find it challenging to fully understand and act upon the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it can be improved to enhance its novelty. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel because it is related to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning, specifically selftraining methods. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might address this concern or improve the novelty of their method. Without actionable feedback or constructive guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the authors may struggle to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some indication of an issue but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison in the paper, noting that it is shallow and lacks depth. It also mentions the absence of two relevant papers, which could enhance the comparison. While the comment highlights a clear area for improvement, it does not provide detailed guidance on how to address this issue or which papers should be included. This limits the comment\"s helpfulness, as it points out a problem but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification when making such claims. This feedback is clear and actionable, as it points out a potential weakness in the paper\"s language and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to verify the equivalence or provided examples of how to use the word more cautiously. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects should be considered. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the multiview clustering approach is not effective and that the paraphrase similarity view dominates over other views. The reviewer provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but notes that there is no further analysis of the differences and similarities between the views. This lack of analysis makes it difficult to draw solid conclusions about the effectiveness of the different views. The comment is 3 as it provides a specific example and highlights a gap in the analysis, but it lacks detailed evidence or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the effectiveness of the multiview clustering approach, specifically the dominance of the paraphrase similarity view over other views. It highlights the need for a more detailed analysis of the differences and similarities between the views, as well as the lack of such analysis in the paper. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what aspects should be considered. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in typesetting these terms throughout the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it provided examples of how the inconsistency affects the paper or suggested alternative ways to maintain consistency. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspect of the Greek language might be causing issues in other multilingual setups. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as 2, as it identifies a potential area of interest but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\"s helpfulness, as it offers some direction but lacks depth and actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct experiments on realworld datasets, but the lack of explicit instruction means the action is not as direct as it could be.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the synthetic versus realworld datasets or the outofdistribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for realworld datasets but does not provide detailed guidance on how to implement this change. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be limiting the paper\"s conclusions. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it, making the feedback 3 but not fully actionable. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these points, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague understanding of what changes are needed to make the explanation clearer. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the last paragraph in question. This level of detail helps the authors understand what needs to be clarified or improved in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how it affects the clarity of the explanation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is valuable as it points out a specific area where the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanations or examples of what might be unclear. Despite this, the feedback is 3 as it directs the authors\" attention to a specific area that needs improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is 3, as it implies an action but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the paper should consider multiple trucks and drones, which is a suggestion for extending the analysis. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors cannot confidently determine which part of the paper needs to be addressed, making this comment weakly grounded. The suggestion is specific in terms of what needs to be added, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, which is described as a more interesting and practical setting. This feedback is 3 as it identifies an area for potential expansion and improvement in the paper. However, it lacks specific guidance or suggestions on how to implement this change or what specific benefits it might bring. While it points out a potential enhancement, the comment could be more helpful if it provided more detailed advice on how to incorporate multiple trucks and drones into the analysis. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. It also mentions that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer implies that the current setup is confusing and suggests that the authors should address this issue. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to implement these changes or what aspects of the volume and biases need clarification. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. Additionally, it points out the confusion regarding the number of biases and the fact that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the volume should be WxHx1 and that the bias is a scalar, based on the authors\" belief. The reviewer questions the number of biases, noting that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The comment suggests that the current setup is confusing, as the number of biases does not align with the authors\" intent. However, the comment lacks specific examples or references to support the claim that the volume and biases are incorrect. The reasoning is based on logical deduction and inference, but without concrete evidence or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the volume calculation and the number of biases, suggesting that the volume should be WxHx1 and that the bias is a scalar. It points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4, which is confusing. This feedback is 3 as it highlights a potential issue with the paper\"s mathematical representation, which could be clarified for readers. However, the comment lacks specific suggestions on how to address the discrepancy or improve the clarity of the volume and biases. While it provides some insight, it could be more helpful with additional guidance or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it does not explicitly instruct the authors to conduct experiments or provide specific guidance on how to address these questions, the questions themselves are clear and actionable. The authors can infer that they need to conduct experiments to investigate the effect of these factors on performance and potentially include this analysis in their paper. Therefore, the comment is 3, as it provides a clear direction for the authors to follow but lacks explicit instructions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors may infer that it relates to the experimental section, but this inference is not direct. The comment is specific in its request for empirical evidence and analysis, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for empirical evidence and analysis regarding the impact of the number of MC samples and the network structure on performance. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to conduct empirical investigations. By asking for empirical evidence and analysis, the comment highlights areas where the authors could enhance their draft. However, it does not provide specific guidance on how to conduct these experiments or what specific aspects of the network structure should be examined. While the questions are clear, the comment could be more helpful by offering detailed suggestions or examples. Therefore, it is rated as 3, as it provides a starting point for the authors but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which may be a suggestion for further improvement, but it is not the primary focus of the action. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure. 3\" and \"Figure. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of smoothed GT shapes to enhance the understanding of the reconstruction quality. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the understanding of the reconstruction. The comment lacks specific examples or detailed explanations, making it difficult for the authors to fully understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This is a clear and direct piece of feedback that can help the authors improve the visual representation of their results, which is crucial for effectively communicating the quality of the reconstruction. Additionally, the comment acknowledges a minor concern, which could be further elaborated upon to provide even more detailed guidance. Overall, the comment is 4 as it offers a concrete and actionable way to improve the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to conduct these comparisons, leaving the action implicit. The comment is 3 as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prior approach PRANC, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is 3 as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including such comparisons to demonstrate the improvement over the baseline that is directly modified by the authors. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct these comparisons or what metrics to focus on. Overall, the comment is 4 as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is 3, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed advice on how to investigate or improve the model. As a result, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that certain aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what is unclear or poorly motivated about the corpora and datasets, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand which aspects are unclear or poorly motivated. Without specific examples or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that certain aspects, such as corpora and datasets, are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs clarification."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide specific suggestions on how to address this issue or improve the results. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical works mentioned, such as Bartlett et al. (2017), which would provide context and support for the claim. Without these references, the authors may find it challenging to verify the claim or understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this issue or improve their work. Without specific advice or constructive criticism, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\"s understanding and engagement with their research. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. It provides a rationale for this suggestion, noting that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it does not provide specific guidance on how to implement this change or what additional considerations might be necessary. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of dataset, suggesting that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP for their testbed. The reviewer provides a logical reasoning by explaining that WebQuestions would be more intuitive and straightforward for the task at hand, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or examples to support the claim that WebQuestions is more suitable for the task. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP for their testbed. It offers a logical reasoning that using WebQuestions would be more intuitive and straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to make a more appropriate choice for their dataset, which could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the claim that WebQuestions is a better choice. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or present evidence to support their claims. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It clearly states the need for verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This provides a direct and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the analysis or results section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet1k or ImageNet100. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It argues that verifying the effectiveness of the framework on these datasets is important and recommends presenting these results in the main paper. However, the comment does not provide specific examples or references to support why ImageNet derivatives are crucial or how they would impact the paper\"s conclusions. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. The authors would need to make a significant effort to understand and address the suggestion, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include analysis or results on other datasets, such as ImageNet derivatives. It highlights the importance of verifying the effectiveness of the framework on these datasets, which could enhance the paper\"s credibility and impact. The comment is clear and actionable, providing a direct suggestion for the authors to expand their analysis and results section. However, it could be more helpful if it offered specific guidance on how to present these results or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. The comment is 3 as it logically points out a discrepancy in the paper\"s description of these models. However, it lacks specific examples or references to support the claim that the models should be considered datasets rather than models. This makes the claim 3, as the authors would need to make a logical inference to address the issue.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be more appropriate to state them as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it directs the authors to correct the discrepancy in their description of these models. By following this suggestion, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided additional guidance on how to present the extended explanation or why the models are being extended. Overall, the comment is 4 as it offers a concrete suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggesting that it depends on the method/features used for answer detection, such as POS/dependency parse features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" conclusion may depend on the method or features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional experiments or analyses might be needed. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or that the related work section is incomplete. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is 3 as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections should be prioritized or how to incorporate additional related work. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\"o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these claims, such as examples or references to similar studies. This makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what alternative assumptions might be considered. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without explicit references to sections or details, the authors may struggle to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. The comment provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks detailed reasoning or evidence to support why the authors should explore these areas or how they might achieve improvements. The suggestion is 3, as it provides a logical direction for exploration but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers a concrete example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully explored these areas. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 because it provides a clear direction for the authors to consider testing this assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to address this assumption but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption that \"d_e are good replacements for entity embeddings,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether this assumption was tested and provides a clear direction for the authors to consider testing it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s conclusions. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of testing would be appropriate. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the methodology. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the scoring function and threshold values. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the components and threshold values/ranges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"scoring function\" and different threshold values/ranges are unclear, but it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specificity and does not offer any evidence or references to substantiate the claim. As a result, the authors may find it challenging to understand and address the issue without further guidance. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the components of the \"scoring function\" and the different threshold values/ranges. It highlights a lack of clarity in the methodology, which is an important aspect for readers to understand. However, the comment does not provide actionable suggestions or guidance on how the authors might clarify these aspects in their paper. While it points out a potential weakness, it lacks depth and specificity, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting ways to improve the simulation. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, which could be a relevant consideration for the authors. However, it lacks depth and does not provide any context or guidance on how this information might impact the paper or what specific aspects of the simulation should be considered. Without further explanation or suggestions, the authors are left without actionable feedback or direction on how to address this question. Therefore, the comment is rated as 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison in the paper is inadequate due to the selection of datasets, which lacks categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the omission of one hot encoding for the dataset with categorical features could negatively affect performance. This reasoning is logical and based on common knowledge, providing a clear rationale for the claim. However, the comment could be strengthened by referencing specific studies or examples that support the importance of categorical features in deep learning. Despite this, the claim is 4, as it provides a solid foundation for the authors to address the issue.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or what specific datasets would be better options. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete suggestions or examples of suitable datasets. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange and unhelpful choice, as they are not widely followed or used. The reviewer supports this claim by referencing specific datasets and their publication dates, which provides some evidence for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of why these datasets are not suitable for benchmarking. As it stands, the claim is 4, as it provides some evidence but lacks comprehensive justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets for benchmarking, specifically the two unpopular IoT datasets mentioned. It provides a specific critique of these choices, noting that they are relatively recent but not widely followed and that one of them is quite old. The comment suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is clear and actionable, as it guides the authors to consider alternative datasets that may be more suitable for benchmarking. However, the comment could be more helpful if it provided specific examples of alternative datasets or detailed reasoning for why the current choices are problematic. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it points out a potential problem but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the improvement in sensitivity provided by the dropout probe and its ability to identify a causal role for syntactic representations that previous approaches might have missed. However, it also points out the potential risk of false positives due to the increased sensitivity. The reviewer suggests that this should be a substantial part of the discussion. While the comment implies that the authors should address this issue in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its ability to improve sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential risk of false positives due to the increased sensitivity. This provides clear guidance on what needs to be addressed in the discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity and identifies a causal role for syntactic representations that previous approaches might have missed. However, the comment suggests that this improvement also increases the risk of false positives, which is a valid concern. The reviewer provides a logical reasoning by pointing out that all other things being equal, this increased sensitivity could lead to false positives. This claim is 3 as it provides a logical argument, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant improvement in sensitivity provided by the dropout probe, which allows it to find a causal role for syntactic representations that previous approaches might have missed. However, it also points out a potential risk of false positives due to the increased sensitivity. This is a valuable observation that could lead to a substantial part of the discussion. The comment highlights an important aspect of the paper that the authors should consider, but it does not provide specific guidance on how to address the risk of false positives or how to incorporate this discussion into the paper. While it offers a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not included in the supplementary material and references a specific work by Zalan Borsos et al. to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer supports this claim by referencing a specific work by Zalan Borsos et al. that discusses online variance reduction for stochastic optimization. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work by Zalan Borsos et al. to support their claim, which adds credibility to the critique. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending the inclusion of the regret bound or explaining why it is important. Despite this, the feedback is 3 as it points out a potential gap in the paper that the authors should address to improve its clarity and completeness."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"exploration methods in RL literature\" and specifically mentions \"countbased methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper does not discuss or compare these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not 5, as it relies on general knowledge of RL literature. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending which methods to discuss or how to integrate them into the paper. While it points out a significant gap, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks for clarification on the inference process and the coefficient of the p(L, E | X) term in line 307, but it does not instruct the authors on how to address these questions. The comment also mentions the lack of hyperparameter details, the need for baseline tuning, and the writing style, but it does not provide specific guidance on how to improve these aspects. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" but does not provide context on where this line is located in the paper. The comment also lacks specificity in terms of what is unclear or missing, such as the coefficient of the p(L, E | X) term or the hyperparameter details. Without clear references or specific guidance, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the hyperparameter details. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claims made. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several concerns about the paper, including the inference process, the coefficient of the p(L, E | X) term, and the hyperparameter details. It questions the clarity of the writing and suggests that the authors should provide more information on these topics. However, the comment lacks specific guidance or suggestions on how to address these issues, such as recommending specific sections to clarify or providing examples of how to improve the writing. While it identifies areas for improvement, the feedback is not actionable and does not offer detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the performance or suggestions for potential modifications to the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is that the proposed compression performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method, which is important for the authors to address. However, the comment lacks depth and does not provide suggestions or guidance on how to improve the performance or address this issue. While it points out a critical area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the statements. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the laborintensive nature of designing effective architectures, and the uncertainty regarding when to fuse multiscale features. The reviewer also suggests that models with skip connections could be considered implicit multiscale methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or examples makes the claims 3, as the authors would need to make a significant effort to understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides clear and actionable feedback by instructing the authors to provide a detailed explanation to verify these statements. This guidance is valuable as it directs the authors to address specific areas that need clarification and improvement. However, the comment could be more helpful if it offered specific suggestions on how to present the explanation or what aspects of the subjective statements are problematic. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as it points to a specific aspect of the analysis that could be enhanced. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis, suggesting that the \"language/nationality\" section could be more detailed by exploring potential biases across different languages/nationalities. It implies that there might be interesting observations to be made about these biases, which could enhance the analysis and contribute to the paper\"s overall quality. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it points out an area for improvement but does not provide detailed guidance on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, it does not provide any explicit guidance or suggestions on what other properties could be considered or how to incorporate them into the approach. The action is implicit and vague, as the authors are left to infer that they should explore other feature properties but without specific instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to consider other properties, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this could be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it could be beneficial. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a relevant question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative ways to enhance their methodology. However, the comment lacks specificity and does not provide guidance on which properties might be beneficial or how to incorporate them into the approach. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on which tasks should be discussed or how to integrate this discussion into the paper. The action is implicit and vague, as the authors are left to infer what additional tasks might be relevant and how to incorporate them into their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion where this topic could be addressed. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper that needs revision. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is expected or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on which tasks or aspects of PE should be discussed. The comment is vague and does not offer actionable advice or examples, leaving the authors without clear direction on how to enhance their draft. Therefore, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid point by asking the authors to elaborate on the difference between their work and other works focusing on semantic face editing. This is a constructive suggestion that could help the authors better position their contribution in the context of existing research. However, the comment lacks specific guidance on how to address this difference or what aspects of the work should be compared. While it identifies an important area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the draft. The suggestion to move content to the appendix is also detailed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of excessive use of footnotes and suggests moving important content into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting moving details around parameter settings to the appendix. This suggestion is based on a logical observation that footnotes are not necessary for the main content of the paper. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the suggestion is 3, it could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that footnotes are used excessively and distract from the main content. It suggests that much of the important content should be moved into the main body of the paper. The comment provides a specific example by suggesting moving details around parameter settings to the appendix. This feedback is clear and actionable, offering a concrete way for the authors to improve the organization and readability of their draft. However, it could be more helpful if it provided additional guidance on how to effectively integrate the content into the main body of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions that the inclusion of zeroshot generation results seems strange and might satisfy general curiosity about the capabilities of the LLM in this setting. However, the comment does not provide explicit instructions on how to incorporate these suggestions or what specific aspects of the discussion should be included. While the action is implied, it is not detailed enough for the authors to know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts. It also mentions the inclusion of zeroshot generation results, which seems strange in the context of the paper. However, the comment does not specify which part of the paper these suggestions pertain to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a discussion about fewshot demonstrations and the inclusion of zeroshot generation results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the inclusion of zeroshot generation results seems strange in the context of the paper, implying that it might not be relevant or necessary. However, the comment does not provide specific reasoning or examples to support this claim. It lacks detailed justification or references to similar studies or practices that would help the authors understand why this inclusion might be problematic. As a result, the claim is 3, as it provides a general observation but lacks the necessary evidence or explanation to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive critique by suggesting that the inclusion of zeroshot generation results might be somewhat strange in the context of the paper. It acknowledges the interesting and relevant experiments but questions the necessity of including zeroshot generation results. The comment also suggests that a discussion about a set of fewshot demonstrations to draw from, which could be obtained with the help of domain experts, would be beneficial. While the comment identifies areas for improvement, it lacks specific guidance on how to incorporate these suggestions or what aspects of the discussion should be included. This limits the comment\"s helpfulness, as it provides insight but does not offer detailed instructions for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference [2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. This is an interesting point that could lead to further exploration and analysis of the GS module. However, the comment lacks specific guidance or suggestions on how the authors might investigate or analyze the impact of the GS module on the effective receptive field. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While the comment provides some reasoning by mentioning these factors, it lacks specific examples or detailed explanations to fully substantiate the claim. The authors would need to infer the exact impact of these factors on the time complexity, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. It highlights that these factors could contribute to a high time complexity. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the time complexity. While it points out a potential weakness, it lacks actionable advice or detailed feedback that would help the authors make meaningful improvements to their draft. Therefore, the comment is 3, as it provides some insight but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area for improvement in the clarity of the figures. However, it lacks depth and does not provide detailed guidance on how to effectively communicate this information in the figures or why it is important. The comment could be more helpful if it offered suggestions on how to present this information or provided examples of how other papers handle similar issues. As it stands, the comment provides some direction but could be more actionable with additional details. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison with a NeRFbased method, specifically mentioning the recent Zero1to3 and pointe. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the comment lacks full grounding as it does not explicitly mention the sections being addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that a comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of Zero1to3 and pointe provides some context, but the lack of detailed justification or evidence makes the claim 3. The authors would need to further explore the relevance and potential benefits of these comparisons to fully understand and address the reviewer\"s suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRFbased methods, such as Zero1to3 and pointe. This suggestion is clear and can help the authors enhance the comprehensiveness and relevance of their evaluation. Additionally, the comment questions the relevance of the occlusion experiment, which could be a critical area for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples of how these comparisons could be conducted. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This is a clear and direct request for additional details that the authors can easily address by providing the requested information. The action is explicit and concrete, as it specifies exactly what needs to be added to the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what information is needed, providing clear guidance on what needs to be added to the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it prompts the authors to provide additional information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their work. However, the comment could be more helpful if it included specific suggestions on how to present this information or what aspects to focus on. Despite this, the feedback is clear and actionable, guiding the authors to enhance the transparency and reproducibility of their work. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment implies that the authors should consider these questions and potentially address them in their paper, it does not provide explicit instructions or concrete suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects of the model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the model\"s performance or analysis. The comment is specific in its inquiry about the impact of missing modalities and the potential for leveraging additional modalities. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities affect the model\"s ability to construct higherorder interactions and polynomial tensors. The comment does not make a claim or express an opinion but rather seeks clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. It also inquires whether the model can leverage additional modalities to infer missing ones. This feedback is valuable as it prompts the authors to consider a critical aspect of their model\"s robustness and generalizability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or explore the impact of missing modalities. Overall, the comment is 3 as it directs the authors to consider an important aspect of their model but lacks detailed guidance on how to implement the suggested exploration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. It suggests that the authors should verify the stability of their model on this benchmark, which is a clear and explicit action. However, the comment does not provide specific guidance on how to conduct this verification or what metrics to use. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific benchmark dataset, DrugOOD, and the work by SPE, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of verification of the stability of the OGEAug on OOD benchmarks, such as DrugOOD. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, specifically mentioning DrugOOD. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors have not verified the stability of the OGEAug on outofdistribution (OOD) benchmarks, such as DrugOOD. It points out that the SPE model is validated on this dataset, highlighting a potential gap in the paper\"s evaluation. This feedback is clear and actionable, as it directs the authors to verify the stability of their model on OOD benchmarks, which could strengthen the paper\"s claims. However, the comment could be more helpful if it provided additional guidance on how to conduct this verification or what specific metrics to use. Overall, the comment is 4 as it effectively identifies a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the evaluation by including multiple seed experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and the \"experiments in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the limitation of the experiments being limited to a single seed and the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is 3 as it logically points out the limitation of singleseed experiments and the need for more robust evaluations. However, it lacks specific examples or references to support the claim, such as discussing how multiple seed experiments would impact the results or what specific aspects of the proposed method would be better evaluated with multiple seeds. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s experiments, specifically the use of a single seed for training. It suggests that multiple seed experiments would provide a more robust evaluation, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific guidance on how to implement multiple seed experiments or discussing the potential impact of this change on the results. While it highlights an important area for improvement, it lacks detailed suggestions, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional guidance on how to improve the explanation or rationale for the choice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and adoption of the method by users who may not have access to such a setup. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. It provides a clear and explicit action for the authors to take, which is to compare their system with another that captures semantics. The comment also suggests using Ref[2] as a baseline, which provides concrete guidance on how to implement the suggested comparison. However, it does not specify which aspects of the current system should be compared or how to evaluate the performance of the new system. While the action is explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be made. The comment is specific in suggesting a potential baseline and providing a reference, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. This is a clear and actionable suggestion that could help the authors improve the evaluation and comparison of their system. However, the comment could be more helpful if it provided specific guidance on how to implement this comparison or what aspects of the current system should be compared to the baseline. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and offers a potential solution. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the data used for training, validating, and testing. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should clarify the data sources, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the quantitative results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validating, and testing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the quantitative results, specifically questioning the clarity of the data used for training, validating, and testing. This is a relevant point that could impact the reproducibility and interpretability of the results. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might clarify this aspect of their work. While it points out a potential issue, it does not offer actionable guidance or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of model performance and suggesting potential reasons for it, such as assumptions not being met or learning difficulties. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the assumptions are not met or that learning difficulties exist. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether the model is encountering difficulties in learning or if assumptions are not met. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve the model. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps to take to improve the generalization of the approach. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach need to be addressed or improved to enable generalization to more views. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and actionable guidance on how to address this issue. The comment does not provide suggestions or examples of how the authors might improve the generalization of their approach, leaving them without a clear path forward. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer detailed guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind the user decoder\"s information usage but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional information might be needed to clarify the rationale. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on arbitrary hyperparameter \u03b3 is missing, including how to set it in practice and analyzing its sensitivity. This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed justification or examples to fully substantiate the importance of including this discussion. The authors may need to infer the significance of this omission themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of discussion on the arbitrary hyperparameter \u03b3, including how to set it in practice and analyzing its sensitivity. This feedback is clear and actionable, as it points out a critical area that needs to be addressed in the paper to ensure that the research is accessible and understandable. By providing a concrete suggestion for improvement, the comment empowers the authors to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct the sensitivity analysis or provided examples of how other researchers have addressed this issue. Overall, the comment is 4 as it effectively directs the authors to a specific area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head \"location\" in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the impact of head location on ICL performance. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the issue of induction heads and FV heads being located at different layers within the model, which could contribute to differences in ICL performance when ablating induction heads versus FV heads. It suggests that a controlled baseline should be considered to isolate the impact of head location on ICL performance. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the discussion or results related to the model architecture and ablation studies. The suggestion to include a controlled baseline is specific, making the comment fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head \"location\" within the model. The reviewer proposes a controlled baseline that ablates heads at different locations in the model to address this issue. While the comment provides a logical reasoning for the potential confounding factor, it lacks specific examples or references to support the claim that head location is indeed a significant contributor to the observed differences. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads, suggesting that the location of these heads within the model could be a contributing factor. It provides a clear and actionable suggestion to address this issue by proposing a controlled baseline that ablates heads at different locations in the model. This feedback is valuable as it guides the authors to consider a specific methodological approach to isolate the impact of head location on ICL performance, which could lead to a more robust and informative analysis. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully employed controlled baselines for similar purposes. Overall, the comment is 4 as it provides a clear direction for improvement but could be further enhanced with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a section on synonym identification under similarity measurement, which is a clear and direct action for the authors to take. It specifies the missing section and provides a specific suggestion for what should be included, namely a description of how the multiplechoice task is approached. This level of detail makes the action explicit and concrete, allowing the authors to know exactly what needs to be added to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification, and provides a clear direction for improvement by suggesting a description of how the multiplechoice task is approached. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by including a description of how the multiplechoice task is approached. By addressing this gap, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively integrate this section into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides a clear direction for the authors to enhance their draft by including this information. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in suggesting the need for an overview, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is 3 as it identifies a potential area for improvement in presenting the key components of the paper. However, it lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, the comment does not provide detailed suggestions or examples to help the authors effectively implement this feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific guidance on how to modify the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the redefinition of the figure to reflect the expected quantities as scalars rather than a vector. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for improving the clarity of Figure 3. By pointing out that the expected quantities are scalars but shown as a vector, the reviewer offers a clear and concise guidance on how to redefine the figure to better align with the authors\" expectations. This feedback is valuable as it directly addresses a potential source of confusion and ensures that the figure accurately reflects the intended information. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or a particular figure or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the experiment setup should be improved, but without clear grounding, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on what aspects of the experiment setup need improvement or how to address the questions that arise. Without actionable advice or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, as it lacks the necessary depth and specificity to be useful for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for lowfrequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggests exploring this aspect further. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that it would be interesting to explore this aspect further, implying that the absence of empirical evidence is a significant issue. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the importance of the empirical evidence themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a specific area where the paper could be strengthened with additional evidence. However, the comment could be more helpful if it provided suggestions on which experiments or data sets to use for this empirical evaluation. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their figures and metrics reporting. However, the comment could be more helpful if it provided specific guidance on how to present these additional metrics or how to improve the figure\"s clarity. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some details of the proposed method are missing, as noted in the questions section below. However, it does not specify which details are missing or provide any guidance on how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or page number, the authors cannot confidently determine the exact part of the paper being addressed. The comment also lacks specificity as it does not detail what specific details are missing or how they should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not specify which details are missing or provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to identify and address the missing details. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide any further explanation or guidance on what these missing details are or how they might be addressed. Without specific examples or suggestions, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure and the lack of explanation in the text or caption. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide explanations in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, making it more understandable for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the columns or offered examples of how similar figures have been effectively explained. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. However, it does not provide specific guidance on what kind of explanations are needed or how the authors might address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more explanations, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN [4] and fVAEGAND2 [5]. However, the comment does not provide specific references or detailed comparisons to these methods, making it difficult for the authors to understand the basis of the claim. The lack of specific examples or detailed reasoning makes the claim 3, as it requires further elaboration to be fully understood and actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the low results obtained using only ML in the ablation experiments, suggesting that more explanations are needed. It points out that the results are lower than those of simple early methods like fCLSWGAN [4] and fVAEGAND2 [5], which could be useful for the authors to consider. However, the comment lacks specific suggestions or guidance on what kind of explanations might be needed or how the authors might address this issue. While it identifies a potential area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\" understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the convincingness of their results. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively revise their work. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the comment implies that the authors should include such comparisons, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is clear but somewhat vague, as the authors need to infer the exact details of how to implement the comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as the results or discussion sections. The authors can infer that it relates to the results or evaluation sections, but this inference is not direct. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending the authors compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable as it provides a clear direction for enhancing the paper by demonstrating the relevance and impact of the proposed method in the context of existing work. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 4 as it identifies a meaningful area for improvement but lacks depth in its execution. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind using freezing but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of freezing in MLS selection and questions the rationale behind it. However, it does not specify which part of the paper discusses this selection process, making it weakly grounded. The comment is specific in questioning the use of freezing and suggesting an alternative approach, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, the comment lacks specific reasoning or evidence to support why the current approach is ineffective or why an adaptive method would be more beneficial. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically questioning the rationale behind the current approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct an experiment to test the robustness of their model in handling negation or changes in entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further investigation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting an analysis similar to existing work that combines text and KGs, providing a clear direction for improvement. This suggests that the authors should perform an experiment to test the robustness of their model in handling negation or changes in entities in the text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed knowledgeCLIP model should be evaluated by conducting an analysis similar to existing work that combines text and KGs. The comment references an external work, which provides a basis for the claim that such an analysis is relevant and valuable. However, the comment does not provide specific examples or details from the referenced work, which would strengthen the claim. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct an analysis similar to existing work that combines text and KGs. It references an external work that has performed closelyrelated analyses, such as adding negation or changing entities in text to test the robustness of a KGaugmented method. This feedback is valuable as it encourages the authors to explore and validate their proposed knowledgeCLIP model by conducting a similar analysis. By following this suggestion, the authors can enhance the robustness and generalizability of their work. Therefore, the comment is 5 as it offers a concrete and constructive direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational complexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the comprehensive discussion of computational complexity and the potential prohibitive nature of the approach in certain settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a direction to explore but are not provided with actionable steps or detailed advice on how to conduct this discussion. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs more explanation. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this potential source of confusion, the comment provides the authors with a clear and actionable suggestion for improving the draft. However, the comment could be more helpful if it offered additional guidance on how to clarify this aspect or provided examples of how other studies handle similar issues. Overall, the feedback is valuable but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multitask learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multitask learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out that similar methods for multitask learning have already been proposed and were not discussed. This is a relevant observation that could prompt the authors to include a discussion on related work or to address the limitations of their approach in comparison to existing methods. However, the comment lacks specific suggestions or guidance on how to incorporate this discussion or what aspects of the existing work should be considered. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvement of models on the offense detection dataset and the significant improvement on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a critical observation that could lead to a deeper understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the analysis and interpretation of their experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct the indepth analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on a general assumption that a fair comparison requires equal optimization efforts, but it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is 3, as it requires further elaboration to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search and the need to ensure that the baseline is fully tuned with the same resources as the proposed method. This is a relevant point that could impact the fairness and validity of the comparison between the baseline and the proposed method. However, the comment lacks specific guidance or suggestions on how to achieve this goal, such as recommending specific steps or techniques for tuning the baseline. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that can help the authors improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and interpretable data, which is crucial for assessing the significance of their results. However, the comment could be more helpful if it offered suggestions on how to present these deviations or explained why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the theoretical work on sampling and particlebased optimization methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the analysis, specifically mentioning the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This claim is 3 as it references theoretical work on sampling and particlebased optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what kind of information is missing, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper\"s analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed to strengthen the paper. By highlighting these areas, the comment provides the authors with a concrete direction for improving the draft. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to enhance the quality of their images. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically mentioning that the realism of the results is limited. However, it does not specify which part of the paper or supplemental material is being referred to, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without explicit references to sections or figures, the authors may struggle to identify the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or comparisons to other methods or standards that could substantiate the claim. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, particularly in terms of realism. It highlights that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is rated as 3, as it provides insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or clarify their statement. As a result, the authors are left without any guidance on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the paper regarding the Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their description. However, the comment could be more helpful if it provided additional context or examples to explain the implications of this discrepancy or suggested ways to clarify the statement. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging, which is a clear and accurate explanation. However, the comment could be strengthened by providing a specific example or context in which the term \"hyperspectral\" is used, which would further substantiate the claim. Despite this, the comment is 4 due to the clear definition of hyperspectral imaging and the logical reasoning behind the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable as it suggests that the authors should clarify or replace the term with a more appropriate one, which is a straightforward suggestion that can improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered suggestions on how to address the issue in a more detailed manner, such as by providing alternative terms or explaining the context in which the term is used. Overall, the comment is 4 as it provides clear guidance on how to improve the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the w/o perception module and w perception exhibit similar performance, which suggests that the perception module might not be necessary. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific concerns, such as the performance of the w/o perception module and w perception, and the implementation detail of w/o perception. While the comment provides some insight into potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional guidance on how to improve the draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), and suggests including these references for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a potential omission in the paper\"s literature review, but it lacks specific references to the works that should be included. The reviewer provides a specific example of a relevant work, which would strengthen the claim. However, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive analysis. By including these references, the authors can enhance the credibility and depth of their work. However, the comment could be more helpful if it suggested how to integrate these references into the paper or provided additional guidance on how to conduct a more thorough comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed to improve the clarity of the results notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation, but it lacks specific examples or references to support the claim that \"%p\" is unclear. The authors might need to infer the meaning of \"%p\" based on the context, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, particularly regarding the use of \"%p\" in the claim of an improvement for CIFAR10. By pointing out this lack of clarity, the comment highlights an area where the authors need to improve the presentation of their results. However, the comment does not provide suggestions or guidance on how to clarify the notation or what alternative notation might be more appropriate. While it identifies a clear issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the ambiguity in the title regarding whether it refers to human or machine comprehension. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This claim is 3 as it provides a logical reasoning for the clarification needed, but it lacks specific examples or references to support the claim that \"reading comprehension\" and \"readability\" typically refer to human comprehension. The authors might find it challenging to fully understand the basis of the claim without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the title of the paper, suggesting that it is ambiguous and may refer to human reading comprehension rather than machine comprehension of text. It provides a clear and actionable suggestion to clarify the title to avoid confusion. This feedback is valuable as it helps the authors ensure that their title accurately reflects the focus of their work, which is important for clarity and impact. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that it weakens the convincingness of human evaluation. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without such justification, the claim remains 1, as it lacks the necessary information to support the claim. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the evaluation methodology, which could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential problem, it lacks depth and actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is 4 due to the references to external literature, which provide a solid foundation for the critique.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is 4 as it effectively directs the authors toward improving their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide these losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what kind of training losses should be provided or how they would be analyzed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should provide training losses, but without detailed instructions or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper\"s claims regarding the strength of the proposed BC loss, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are the same concept from different viewpoints. The reviewer provides a logical reasoning by explaining that these concepts are essentially the same, but they do not provide specific examples or references to support this claim. While the reasoning is somewhat clear, the lack of detailed evidence or examples makes the claim 3, as the authors may find it challenging to fully understand and address the critique without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the strength of the proposed BC loss in the theoretical analysis. It points out that the paper overclaims the novelty of the proposed BC loss by suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This feedback is 3 as it highlights a potential misrepresentation of the paper\"s claims, but it lacks specific suggestions on how the authors might address this issue or improve their claims. While it provides some insight into a potential weakness, the comment could be more helpful with additional guidance on how to clarify or rephrase the claims to avoid overclaiming. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the running speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. The reviewer supports this claim by referencing the authors\" claim of a 1.5x slower running speed. However, the comment does not provide specific examples or references to other methods or studies that could substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slow running speed compared to other methods. This observation is relevant and highlights a potential source of bias in the comparison with other methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparisons. While it points out a relevant concern, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to consider the differences between classification and regression tasks, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and the potential inaccuracy caused by lower weight for easy samples. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks and suggests that it may not be appropriate due to its classificationspecific properties. The reviewer provides a logical reasoning that focal loss could lead to inaccurate results in regression tasks, as it has lower gradients on easy samples. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its classificationspecific properties. It points out that focal loss has lower gradients on easy samples, which could lead to inaccurate results in regression tasks. The comment highlights a potential oversight in the paper, noting that the authors may have focused on a unified form without considering the differences between classification and regression tasks. While the comment identifies a significant issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. Therefore, the comment is 3, as it provides insight into a potential weakness but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This is an explicit action, as it clearly specifies the need for additional datasets to be included in the paper. However, the comment does not provide specific guidance on which datasets should be used or how to integrate them into the paper. While the action is clear, the lack of concrete details on implementation makes it 3.", "grounding_specificity_rationale": "The comment suggests adding more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional datasets, but without explicit grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed technique should be evaluated on more datasets, specifically mentioning XNLI and XTREME, to demonstrate its generalizability to tasks with different levels of reasoning requirements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these datasets are particularly relevant or how they would impact the evaluation of the technique. Without additional context or explanation, the claim remains 3, as it lacks detailed justification or examples to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending additional datasets to test the technique. However, the comment lacks depth and does not provide specific guidance on how to integrate these datasets or what specific aspects of the technique should be tested on these datasets. While it points out a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what the authors need to include in the implementation details section to address the reviewer\"s concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how they might be presented. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. The comment is explicit in its request for additional empirical work and comparisons, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contributions. However, the comment does not specify which sections or parts of the paper should include these evaluations or comparisons, making it weakly grounded. The comment is specific in its critique of the lack of empirical evaluation and comparison, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a significant issue. The reviewer highlights the lack of clarity regarding the practical value of the theoretical contributions, suggesting that even a theoretical paper should provide some rationale for its significance. The comment is 3 as it identifies a gap in the paper\"s evaluation and comparison, but it does not provide specific examples or references to support the claim. The authors would need to make a significant effort to address this issue, which is not fully substantiated by the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights the absence of any practical value demonstration, even in a theoretical context, and suggests that the theoretical contributions may be significant but are not adequately presented. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of empirical evaluation and comparisons with other methods. This feedback is valuable as it guides the authors to enhance the clarity and impact of their theoretical contributions. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. While the comment identifies a specific issue with the use of P, it does not provide explicit guidance on how to address this confusion. The authors are left to infer that they should clarify the use of P or perhaps use a different notation for the cumulative distribution function. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, such as \"P mostly represents a probability but sometimes for a cumulative distribution function\" and \"L44,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of confusion regarding the use of P for both probability and cumulative distribution function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of P in the manuscript is confusing because it is used to represent a probability but also for a cumulative distribution function. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or references to explain why this confusion is problematic or how it affects the clarity of the manuscript. To fully verify the claim, the reviewer could provide additional context or examples to support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a different notation or explaining the context in which P is used for the cumulative distribution function. Overall, the comment is 4 as it directs the authors to a critical area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their analysis or ablation studies. The comment lacks actionable details, such as recommending the use of natural spurious correlations or suggesting specific methods for identifying and analyzing them. As a result, the authors are left without a clear understanding of how to apply this feedback to improve their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of using artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the use of artificial patterns, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that neural networks learn natural rare spurious correlations, which is unknown to the community. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without such evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve the robustness and generalizability of their results. However, the comment lacks specific suggestions or guidance on how to address this issue or what specific changes could be made to incorporate natural spurious correlations. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\"s applicability to more general tasks, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. However, the comment does not provide specific references or examples from PRMRL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s applicability to navigation problems and suggests that the method discussed is already discussed in PRMRL. It points out that combining RL and planning has been discussed in the literature, which could be relevant to more general tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore more general tasks. While it highlights an area for improvement, the feedback lacks actionable advice or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider whether all feature spaces are wellsuited for 1NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to conduct this evaluation or what metrics to use. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suitability of feature spaces for 1NN and the potential issue with nonspherical Gaussian feature spaces. The comment provides a clear direction for improvement by suggesting standardizing feature dimensions to avoid performance issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the suitability of feature spaces for 1NN and suggests that nonspherical Gaussian feature spaces may perform poorly. The comment provides a logical reasoning by explaining that standardizing feature dimensions can avoid this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the reasoning is not as robust as it could be with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the suitability of feature spaces for 1NN, noting that nonspherical Gaussian feature spaces may perform poorly. It provides a clear and actionable suggestion to standardize feature dimensions to avoid this issue. This feedback is valuable as it directs the authors to a specific area that could impact the performance of their model, offering a concrete step to improve the draft. However, the comment could be more helpful if it included examples or references to similar studies that have addressed this issue or provided guidance on how to standardize feature dimensions. Overall, the comment is 4 as it effectively points out a potential weakness and offers a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but notes that the setting is less convincing and lacks clarity. However, the comment does not provide specific guidance on how to define the contrastive gap or what aspects of the definition should be clarified. While the authors can infer that they need to provide a formal definition, the lack of concrete suggestions makes the action implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear and formal definition for the contrastive gap. The comment provides detailed feedback on the example given and the setting, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is not clearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment suggests that a clear, formal definition is needed. While the comment provides some reasoning by pointing out the lack of clarity in the example, it lacks specific examples or references to support the claim that the contrastive gap is not clearly defined. This makes the claim 3, as the authors would need to further explore the issue to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but notes that the setting is less convincing and lacks clarity. The comment highlights the need for a formal definition to enhance the understanding and credibility of the work. While it provides a clear direction for improvement, it could be more helpful by offering specific suggestions on how to define the contrastive gap or what aspects should be clarified. Overall, the comment is 3 as it points out a significant gap in the paper but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of other baselines and providing a rationale for why they are relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and explicit observation that the authors can easily address by correcting the labeling in both the text and the figure. The action is concrete, as it specifies the exact labeling that needs to be changed, and the authors know exactly what to do to make the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the discrepancy between the labeling of the task loss in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a factual observation that does not require any subjective interpretation or opinion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and actionable observation that the authors can address to ensure consistency in their presentation. However, the comment does not provide any suggestions or guidance on how to resolve this issue or why it might be important to do so. While it points out a specific error, it lacks depth and does not offer additional insights or context that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\"s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered for improvement. While it identifies a potential area for exploration, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider this evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider machine translation as an additional evaluation method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. The comment provides a logical reasoning for why machine translation might be a more appropriate evaluation method, but it lacks specific examples or references to support the claim that machine translation is indeed a more convincing approach. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim that machine translation is a more appropriate evaluation method. Overall, the comment offers a clear direction for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically regarding the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the dropout method used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout method used in the paper, asking for clarification on the dropping rate and the number of masks generated. This feedback is 3 as it prompts the authors to provide additional information that could enhance the clarity and understanding of their method. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how it might be incorporated into the paper. Overall, the comment is 3 as it identifies a potential area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This is a clear and actionable point that the authors can address to improve the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it highlights an important area for improvement but lacks depth in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their explanation. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these changes or what specific aspects of the method should be included in the tables. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bottomup method [9] and the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, which is to include the bottomup method in the tables and evaluate its performance on the MS COCO dataset. The comment is specific because it clearly outlines what needs to be added and why it is important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method [9] has reported results on the crowdpose dataset outperforming all methods, including the paper\"s own method, with a ResNet50. The comment also recommends evaluating the method\"s performance on the standard MS COCO dataset to see if there is a drop in performance in easy settings. While the claim is based on a specific external work, it lacks detailed justification or references to support the claim that the bottomup method outperforms all others on the crowdpose dataset. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottomup method\"s performance is not fully substantiated. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the claim that the bottomup method has reported superior results on the crowdpose dataset, which is a relevant benchmark for the authors to consider. By including this method and evaluating its performance, the authors can enhance the comparability and robustness of their work. However, the comment could be more helpful if it provided additional context or justification for why this evaluation is important or how it might impact the overall analysis. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. However, the comment does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example is used to support the claim that the paper\"s prompts may not fully capture the depth of true guideline understanding. The comment is 4 as it provides a specific example to substantiate the claim, making it clear why the claim might be an overstatement. However, the comment could be strengthened by further elaboration on how the paper\"s prompts compare to the complexity of annotation guidelines in the IE domain. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the use of \"annotation guideline\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This feedback is valuable as it highlights a potential weakness in the paper\"s claims and offers a concrete example to help the authors better understand the nuances of annotation guidelines. However, the comment could be more helpful if it suggested ways for the authors to address this issue, such as by providing more detailed information about their understanding of annotation guidelines or by discussing how their prompts compare to the complexity of annotation guidelines in the IE domain. Overall, the comment is 3 as it provides a clear direction for improvement but lacks detailed guidance on how to address the issue."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any guidance on how the authors should address this issue or what specific weaknesses should be explored. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN, including the differences from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that the authors can address to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this additional information or what aspects of the method should be emphasized in comparison to BGLN. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks actionable guidance or recommendations, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters, particularly the use of only one dropout rate for Moon\"s approach compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting the use of only one dropout rate compared to Variational dropout, which has inputoutput and recurrent dropout parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or inadequate. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. This is a valid point that could prompt the authors to reconsider their choice of hyperparameters and potentially improve the robustness and generalizability of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design or what specific aspects need attention. The action is implied but not clearly stated, leaving the authors to infer the necessary steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the binder design, noting that ProtPainter only provides empirical conformation estimation and that further optimization and validation are required. This feedback is clear and actionable, as it points out a gap in the current work and suggests specific areas for enhancement. However, the comment could be more helpful if it provided examples or guidance on how to optimize or validate the binder design. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. While the comment implies that additional evaluation is needed, it does not provide specific guidance on what aspects of the evaluation should be conducted or how to conduct it. The authors are left to infer that they should conduct more evaluation, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify why this additional evaluation is necessary or how it would improve the paper. Without specific examples or detailed explanations, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more evaluation, specifically on CIFAR10 in the full label and lower label scenarios, would be beneficial. This feedback identifies a potential area for improvement by recommending additional experiments that could enhance the paper\"s robustness and credibility. However, the comment lacks specific guidance on how to conduct these evaluations or what aspects to focus on, such as which metrics to use or how to interpret the results. While it points out a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. Additionally, it points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they should clarify the placement of Alg 1, add a reference to Laplacian eigenmaps, and mention iterative algorithms. The actions are concrete but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. It also points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. While the comment does not explicitly mention specific sections or lines, the authors can infer that it relates to the discussion of Alg 1 and the introduction. The comment is specific in detailing what needs to be addressed, such as the placement of Alg 1 and the need for a reference to Laplacian eigenmaps. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps, and the absence of a reference to iterative algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to it in the introduction. It also points out that the authors do not mention the use of iterative algorithms, which typically run until some criterion is fulfilled, with T >> 2. These observations are clear and actionable, as they provide specific areas for improvement and guidance on how to address them. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or presentation of these issues. Overall, the comment is 4 as it directs the authors to specific areas needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in its critique of the inclusion of Section 2.1 and the need for more motivation and intuition for the CBN approach, but without clear references, it is difficult for the authors to pinpoint the exact issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that Batch Normalization is a general technique or that the ResNet architecture is not relevant to the proposed methodology. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential weakness in the paper\"s organization and suggests a way to enhance the motivation and intuition for the proposed methodology. However, the comment could be more helpful if it provided specific guidance on how to reorganize the paper or what specific aspects of the ResNet architecture should be emphasized. Overall, the comment offers some direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or potential solutions to the confusion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. The comment provides a clear issue to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the assumption that multiplying in equation (1) by a dense projection matrix would result in a sparse matrix, given that the projection matrix is assumed to be dense. The reviewer points out that multiplying by a dense matrix would ensure everything is dense. However, the comment lacks specific examples or references to support the claim, making it 3. The authors might find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the assumption made in equation (1) regarding the expected outcome of multiplying by a dense projection matrix. It points out that this assumption might lead to a sparse matrix, which is counterintuitive given the nature of dense projection matrices. This feedback is valuable as it highlights a potential source of confusion in the paper, prompting the authors to clarify or reconsider their assumptions. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative explanations. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to better present the initialization aspect. While the comment implies that the authors should reconsider their statement about initialization, it does not explicitly instruct them to do so or provide detailed guidance on how to improve the statement. The reference to the external work is helpful, but the action is implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization and references a specific paper ([1] Kunstner et al., 2019) to provide context and guidance on how to better present the initialization aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pretraining. The reviewer supports this claim by referencing a specific paper ([1] Kunstner et al., 2019) that discusses the limitations of empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects NGD. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It provides a specific reference to a relevant paper ([1] Kunstner et al., 2019) to support its claim. This feedback is valuable as it points out a potential oversight in the paper and offers a clear direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to rephrase the statement or what specific aspects of initialization should be considered. Overall, the comment is 4 as it highlights an important area for clarification and provides a useful reference for further exploration."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an Englishproofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and actionable in that the authors know they need to provide more information or improve the readability of the paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an Englishproofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an Englishproofreading would significantly improve the readability of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an Englishproofreading to enhance the readability of the paper. While it highlights these issues, the comment lacks detailed guidance or suggestions on how to address them. Providing specific examples or examples of how to improve the clarity of the extraction process or the readability of the paper would be beneficial. As it stands, the comment is 3 as it points out areas for improvement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and direct action for the authors to take, ensuring that the terms are consistently defined and styled throughout the paper. The comment is specific and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the definition and styling of the terms \"L\" and \"E.\" This provides clear guidance on how to improve the clarity and consistency of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the definition and styling of the terms \"L\" and \"E\" in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting and consistency of the terms \"L\" and \"E\" in the paper. It points out that these terms are sometimes italicized and sometimes not, which can lead to confusion and inconsistency in the document. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it offered suggestions on how to standardize the formatting or provided examples of how other authors have handled similar issues. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons could be added, the comment lacks specificity in terms of what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies an area where the manuscript could be strengthened by expanding its comparisons to include a broader range of models and techniques. However, the comment lacks specific suggestions on which models or techniques to include or how to conduct these comparisons. While it points out a potential area for improvement, it does not provide detailed guidance on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" and \"We refer to multiway arrays.\" Additionally, it points out that \"HPFN to a even deeper ConAC\" should be corrected to \"HPFN to an even deeper ConAC.\" The reviewer also notes that \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct and is unclear. These corrections are direct and concrete, providing the authors with clear guidance on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Additionally, the comment provides specific guidance on how to correct these errors, such as changing \"Despite of being compact\" to \"Despite being compact\" and \"We refer multiway arrays\" to \"We refer to multiway arrays.\" This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, such as incorrect grammar and spelling, and provides clear and actionable feedback to correct them. It also points out that the phrasing \"Effect of the modelling mixed temporalmodality features\" is not grammatically correct and is unclear. This level of detail and specificity helps the authors improve the clarity and accuracy of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of Eqs. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or correct the issue. Without any guidance or direction, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the context of the equations, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the context of Eqs. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. While this question highlights a potential confusion in the paper, it does not provide any actionable feedback or suggestions for improvement. The authors are left with a vague inquiry that does not guide them on how to address the issue or improve the clarity of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison between the two designs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without explicit references to sections or figures, the authors may struggle to identify where this information should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the method may perform better in combinational logic. The comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to conduct this comparison or what specific aspects to focus on. The comment is 3 as it points out a potential area for further exploration, but it does not offer detailed suggestions or examples to guide the authors in conducting the comparison. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline, LDA+LSTM, can capture sequential information and provide topic assignment for each word. However, it does not provide any supporting evidence, such as data or references, to substantiate this claim. The comment is based on the reviewer\"s understanding, which lacks the necessary evidence to be 5. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline model, LDA+LSTM, in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the model\"s performance in their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results, such as potential limitations or areas for further exploration. Overall, the comment is 4 as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include references to the TD3GA algorithm and emphasize the comparison to TD3GA, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of reference to the TD3GA algorithm and the need for a central comparison to TD3GA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of reference to the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion of the TD3GA algorithm, which is crucial for understanding the synergies. However, the comment lacks specific examples or references to the TD3GA algorithm to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a specific gap in the paper\"s discussion and provides a direction for improvement. By addressing these points, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered suggestions on how to incorporate the TD3GA algorithm or provided examples of how it could be integrated into the discussion. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it pertains to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it pertains to model confidence or human interpretability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the word \"confident\" in the sentence, suggesting that it may not be clear whether it pertains to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, but it lacks specific examples or references to support the claim. The comment is 3, as it highlights a potential issue but does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the sentence, specifically the use of the word \"confident.\" It suggests that the word may not be clear whether it pertains to model confidence or human interpretability. While the comment highlights a potential source of confusion, it does not provide specific suggestions for rephrasing the sentence to improve clarity. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with concrete guidance on how to rephrase the sentence. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to enhance the novelty or what specific aspects of the findings could be expanded upon. As a result, the authors are left without any actionable steps to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work and its findings, specifically mentioning the expected outcome of taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, such as specific sections or results where the findings are presented. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention or improvement. The comment is specific in its critique of the novelty, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcome of taskspecific finetuning. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific examples or references to similar studies or observations that would help the authors understand the basis of the critique. As a result, the claim is not verifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. It suggests that this expected outcome is a result of generalizing taskspecific finetuning, which reduces generalizability. While the comment identifies a potential limitation in the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their findings. The feedback is 3 as it highlights a potential weakness, but it lacks actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also points out the need to explore the effects of varying the number of InContext Examples. While the comment provides a clear list of areas that need improvement, it does not offer specific guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the experiment setup and explore different scenarios, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the need to explore the effects of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment identifies some issues, it lacks specific examples or references to support the claim that the evaluation is insufficient or lacks transparency. This makes the claim 3, as the authors would need to further explore and address these points to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also points out the need to explore the effects of varying the number of InContext Examples. These are all valid observations that could significantly improve the paper by providing more detailed information and addressing potential limitations. However, the comment could be more helpful if it offered specific suggestions on how to improve the evaluation or provided examples of how other studies have addressed similar issues. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on execution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to integrate these references into the paper or why they are relevant. The comment does not offer suggestions on how to effectively incorporate the references or what aspects of the related work could be particularly useful for the paper. As a result, the feedback is 3, as it points out a potential area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after this introduction. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper. Without concrete evidence or references, the claim is 3, as it provides a logical basis but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on what aspects of the algorithmic aspects should be covered or how they could be integrated into the paper. While it points out a potential weakness, it does not offer detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the \"present paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely, making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s originality is improved by comparing it to the most closely related work of Zemel et al. (2013) and explaining how it differs. The comment suggests that the comparisons could be made more systematic by comparing the best performance of each method. This claim is 3 as it provides a logical reasoning for improvement, but it lacks specific examples or references to the original work or the current paper\"s comparisons. The authors would need to infer the specifics of the comparisons and the need for systematic analysis, making the claim 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely, the comparisons with the most closely related work. It suggests that the paper could be more original by making these comparisons more systematic, specifically by comparing the best performance of each method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the originality and depth of the paper. By addressing this point, the authors can significantly improve the comprehensiveness and rigor of their comparative analysis. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore this connection or what specific aspects of the universal kernel properties should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the connection between their work and universal kernels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a connection to properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann, which discusses the ability of universal kernels to separate an arbitrary finite dataset with a margin arbitrarily close to one. This provides clear guidance on what aspect of the paper needs attention and how it relates to the broader literature. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, the comment does not provide any detailed reasoning or evidence to support this claim. It lacks specific examples or references to the relevant sections of Steinwart and Christmann, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification or context for the authors to address it effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding and exploration of the relationship between the two concepts. However, the comment lacks specific guidance on how to explore this connection or what aspects of the universal kernel properties should be considered. While it points to a relevant reference, it does not provide detailed instructions or examples on how to integrate this information into the paper. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
