{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more analysis around the quality of the collected dataset and the potential noise it might contain. While the comment implies that the authors should conduct additional analysis, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the artificially created dataset and its potential noise, specifically mentioning the \"pristine\" set of tweets and outofcontext images. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that more analysis is needed around the quality of the dataset and the amount of noise it might have. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset might have noise due to the artificial creation process, and it provides a specific example of the \"pristine\" set of tweets that might contain misinformation or outofcontext images. However, the comment lacks specific examples or references to support the claim that the dataset is indeed noisy. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, suggesting that it might contain noise due to its artificial creation process. It provides a specific example of the \"pristine\" set of tweets that might not be pristine enough and could contain misinformation or outofcontext images. This feedback is valuable as it highlights a potential weakness in the dataset that the authors should address. However, the comment could be more helpful if it offered suggestions on how to analyze the dataset or how to mitigate the potential noise. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical aspects to explore or methods to demonstrate convergence. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these aspects should be addressed. Without explicit references, the authors cannot confidently determine which parts of the paper need revision. The comment is specific in identifying the lack of theoretical analysis and convergence properties, but it is 1 as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it does not delve into the theory profs and does not show the convergence properties of the proposed algorithm. This feedback is clear and actionable, as it points out a critical area where the paper could be strengthened by providing more theoretical analysis and experimental evidence. However, the comment could be more helpful if it offered specific suggestions on how to address this gap, such as recommending specific theoretical frameworks or methods to explore. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. While it implies that the authors should reconsider their choices, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"261\" and \"272,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the authors\" choice of operators and suggesting that the \"and\" operator or elementwise max might be better options. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. However, it does not provide any reasoning or evidence to support why these alternatives might be better options or how they relate to the current choices. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" choice of operators and suggests considering the \"and\" operator or elementwise max. This feedback is 3 as it prompts the authors to reconsider their choices, which could potentially lead to a more effective or efficient approach. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might incorporate these alternatives or why they might be beneficial. While it points out a potential area for improvement, it does not fully support the authors in making that improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of HIERENC is unclear and suggests that it might introduce noise due to the averaging of multiple contextual representations. However, it does not provide explicit guidance on how to clarify the description or address the issue of noise. The authors are left to infer that they need to clarify the description and possibly reconsider the averaging approach. While the comment identifies a potential problem, it lacks concrete instructions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, explaining that the averaging of multiple contextual representations might introduce noise and suggesting that only one instantiation is likely correct. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging multiple contextual representations might introduce noise. The reviewer provides a logical reasoning by explaining that only one instantiation is likely correct and that averaging multiple representations could lead to noise. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning and potential consequences to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the averaging of multiple contextual representations might introduce noise. It provides a logical reasoning that only one instantiation is likely correct, which could lead to noise. This feedback is clear and actionable, as it points out a potential weakness in the description and suggests a possible improvement. However, the comment could be more helpful if it provided additional guidance on how to clarify the description or address the issue of noise. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification or explanation for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors mention selecting 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the potential impact of this selection on the underestimation of performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the selection of only 10 answers from all correct answers and its potential impact on performance underestimation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the selection of only 10 answers from all correct answers and asks if this affects the underestimation of performance. This is a relevant question that could prompt the authors to reconsider their methodology or provide additional context to explain their choice. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the description of the data sources, specifically mentioning that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be revised to make the description more accurate and precise. The action is concrete and leaves no ambiguity, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (226238 and 242244) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issue with the description of the data sources, suggesting that the authors should revise the description to mention Li et al. (2019a) earlier to clarify and improve the precision of the information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a discrepancy in the description of the data sources, specifically mentioning that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that the description can be revised by mentioning Li et al. (2019a) earlier to clarify and improve the precision of the information. This claim is 3 as it provides a logical reasoning for the suggested revision, but it lacks specific examples or references to support the claim fully. The authors would need to make a logical deduction to understand the issue and the suggested revision. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the data sources, noting that line 226238 suggests the authors selected sentences from raw data, while line 242244 states that these sources already have syntactic information. The reviewer suggests that this discrepancy can be resolved by mentioning Li et al. (2019a) earlier in the description to clarify and improve the precision of the information. This feedback is clear and actionable, providing the authors with a specific and concrete suggestion for revising the description to avoid confusion and ensure accuracy. By addressing this issue, the authors can enhance the clarity and precision of their work, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not provide explicit instructions or suggestions for the authors to follow, but it implies that the authors should clarify the purpose and include relevant information in their draft. While the action is implicit, it is concrete because it specifies what needs to be addressed\u2014the purpose of the average duration and the potential inclusion of user waiting time. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of the average duration reported in Table 1 and asking for a supporting explanation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and asks for a supporting explanation. It does not make any subjective claims or opinions but rather seeks clarification on the methodology. Therefore, it is a factual request for information and does not require verification. It is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the purpose of the average duration reported in Table 1, noting the lack of a supporting explanation. It highlights an area where the authors could provide additional clarity and context to enhance the understanding of their results. While the comment identifies a potential gap in the paper, it does not offer specific suggestions or guidance on how to address this issue. Therefore, it is 3 as it points out a potential weakness but lacks actionable advice for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests clarification on the splits used for obtaining the ATIS numbers in Table 4. This is a direct and concrete action for the authors to take, as it clearly identifies the specific area that needs clarification. The comment is specific in detailing what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the splits used for obtaining the ATIS numbers. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding Table 4, specifically asking for clarification on the splits used for obtaining the ATIS numbers. This feedback is clear and actionable, as it directs the authors to provide additional information that could improve the clarity and understanding of their work. By addressing this point, the authors can enhance the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it points out a critical area for clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It suggests that there may be a cognitive bias among NLP researchers to phrase results in a certain way, and it recommends correcting the wording. However, the comment does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the action is implicit, as the authors can infer that they need to revise the wording, the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.791,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording in the experimental results, suggesting that the phrase \"on par or better\" should be corrected. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a general cognitive bias among NLP researchers to phrase results in a certain way, specifically by mapping instances where they perform worse to \"on par\" and the rest to \"better.\" The reviewer suggests that the wording in the paper should be corrected, but does not provide specific examples or references to support this claim. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. The authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the wording in the paper, specifically the use of \"on par or better\" (l.791). It points out a potential cognitive bias among NLP researchers to phrase results in a certain way, which could lead to misinterpretation. The comment suggests that the wording should be corrected, but it does not provide specific guidance on how to rephrase the sentence or what alternative phrasing would be more appropriate. While the feedback highlights a potential problem, it lacks actionable advice or detailed suggestions for improvement, making it 3. The authors are given a direction to correct the wording but are not provided with detailed guidance on how to achieve this. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the interpretation of results shown in Table 3, specifically regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they need to clarify or explain these points, but without concrete guidance, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the interpretation of results, such as the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about the results presented in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the interpretation of results presented in Table 3, particularly regarding the comparison between NVSB and GT Mel A for Chinese MOSQ and the overlapping 95% CI for Baseline and NVSB for Chinese and English MOSV. By pointing out these discrepancies, the comment provides the authors with clear and actionable feedback on areas that need clarification or further explanation. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context or examples to aid in interpretation. Overall, the comment is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a formatting issue in Tables 2 and 3, specifically noting the inconsistent spacing between accuracy and standard deviation. This is an explicit observation that the authors can directly address by ensuring consistent spacing in their tables. The comment provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation in these tables, which affects the presentation\"s aesthetics. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are inconsistencies in the spacing between accuracy and standard deviation in Tables 2 and 3, which affects the presentation\"s aesthetics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a formatting issue in Tables 2 and 3, specifically noting inconsistent spacing between accuracy and standard deviation. This is a clear and actionable observation that the authors can address to improve the presentation of their data. However, the comment could be more helpful if it provided suggestions on how to standardize the spacing or offered guidance on how this formatting change might impact the overall readability and clarity of the tables. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the quality of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a missing antecedent in the text and suggests checking the references for format issues, such as capitalization and bibliographic details. While the comment explicitly identifies the missing antecedent and provides specific guidance on what to check, it does not offer detailed instructions on how to implement these checks or what specific issues to focus on. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact details of how to address the formatting issues. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number \"781,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the references, suggesting that they should be checked for format, such as capitalization and bibliographic details. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing antecedent in the text and suggests checking the references for formatting issues, such as capitalization and bibliographic details. However, the comment does not provide any specific examples or references to support the claim that the references are missing or incorrectly formatted. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent is missing and suggesting that the references should be checked for capitalization and bibliographic details. This feedback is clear and actionable, as it provides a concrete step for the authors to take in order to improve the quality of their references. However, the comment could be more helpful if it included examples of what the correct formatting should look like or suggested specific resources for checking formatting guidelines. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. The reviewer suggests that the only new effort is to apply similar ideas to videotext models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the novelty or what specific aspects of the paper could be revised to enhance its originality. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models, and that the paper summarizes this work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered a lack of novelty, namely the application of similar ideas to videotext models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty, specifically mentioning that adversarial attacks on text have been done on many NLP and imagetext models. The reviewer supports this claim by referencing related work in the paper, which summarizes the existing literature. However, the comment does not provide specific examples or references to the existing work, making it 3. The authors would need to infer the specific works mentioned and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that adversarial attacks on text have been done on many NLP and imagetext models. It highlights that the paper summarizes existing work in this area and only offers a new effort by applying similar ideas to videotext models. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem, but it lacks actionable advice or detailed insights to help them improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It provides a clear and concrete suggestion to improve the organization of the section by recommending separate paragraphs for lexical features and sentencelevel features. This explicit guidance offers a direct action for the authors to take, making the comment 5. Authors know exactly what changes to make to improve the clarity and coherence of their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the intertwined explanations for features and the suggestion to organize the section with separate paragraphs for lexical features and sentencelevel features. This provides clear guidance on how to improve the clarity and coherence of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations for features in Section 3.2 are confusing due to their intertwined nature. It suggests that the section would be more coherent with separate paragraphs for lexical features and sentencelevel features. While the comment provides a logical reasoning for the suggested improvement, it lacks specific examples or references to support the claim that the current organization is confusing. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and clarity of the explanations for features in Section 3.2. It suggests that the section would be more coherent and easier to understand with separate paragraphs dedicated to lexical features and sentencelevel features. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and readability of their draft. By following this advice, the authors can enhance the clarity and comprehensibility of their explanations, which is valuable for improving the overall quality of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a more concise presentation or offering suggestions for prioritizing content. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not specify which section or part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the assumptions or experimental results are problematic or how they could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that dedicating a whole section and experimental results for the assumptions is a significant amount of space. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern about the dedication of a whole section and experimental results for the assumptions, suggesting that it is a significant amount of space. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as by streamlining the content or focusing on more critical aspects. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct an ablation study but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients to measure attribution and the proposed postprocessing steps to filter out \"falsepositive\" neurons. It also suggests an ablation study, providing clear guidance on what needs to be addressed. However, the comment does not specify which part of the paper should include the ablation study, making it fully grounded but underspecific. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point claims that using integrated gradients to measure attribution has been studied in existing papers and suggests that an ablation study may be needed to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. However, the comment lacks specific references to these existing studies or detailed reasoning to support the claim that an ablation study is necessary. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the use of integrated gradients to measure attribution has been studied in existing papers. It also suggests that the paper should include an ablation study to evaluate the importance of the postprocessing steps proposed to filter out \"falsepositive\" neurons. This feedback is clear and actionable, as it provides a specific direction for the authors to consider conducting an ablation study to address the identified weakness. However, the comment could be more helpful if it provided examples of how such an ablation study might be conducted or what specific aspects of the postprocessing steps should be evaluated. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it suggests a method of matching the head of noun phrases. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the method. The comment lacks concrete instructions or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but does not specify which part of the paper this issue is discussed in. While the authors might have an idea of where this issue is discussed, the comment lacks full grounding as it does not explicitly mention a section or figure. The comment is specific in detailing the issue with identifying antecedents, but it is 1 enough to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about identifying antecedents in the context of a prediction involving a pronoun. It suggests a method of matching the head of noun phrases, but does not provide any supporting evidence, reasoning, or references to justify the claim. The comment lacks detailed explanation or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the method proposed by the authors, specifically regarding the identification of antecedents in the context of a prediction involving a pronoun. It raises a valid point about the potential limitations of the proposed method when the head word is not a pronoun. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. While it highlights a potential weakness, it does not offer actionable advice or detailed feedback that could help the authors enhance their draft. Therefore, the comment is 3, as it points out a specific area for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It implies that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to incorporate these baselines or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MST baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison between the proposed models and models that only consider different senses but not sememes. The comment suggests that the paper would be stronger with the inclusion of more baselines based on related work. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is unclear about how the proposed models compare to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. The comment provides a logical reasoning by pointing out the potential comparison between the proposed models and existing models that only consider different senses. However, it lacks specific examples or references to support the claim that the MST baseline is an example of such a model. Additionally, it does not provide detailed guidance on how to incorporate more baselines or what specific aspects of the comparison should be addressed. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the comparison between the proposed models and models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their comparison and strengthen their paper. By suggesting additional baselines and emphasizing the importance of sememes, the comment offers a constructive way for the authors to improve their draft. However, it could be more helpful if it provided specific examples of related work or detailed guidance on how to incorporate these baselines. Overall, the comment is 4 as it effectively guides the authors in enhancing their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract could be improved by providing an example of the inconsistency between evaluating with gold answers and human evaluation. While the comment implies that the authors should include this example, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an example to make the abstract more effective. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: adding an example of the inconsistency between evaluating with gold answers and human evaluation. This specificity helps the authors understand what aspect of the abstract needs attention and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract is wellwritten and invokes intrigue, but it provides a specific suggestion for improvement. The reviewer recommends adding an example of the inconsistency between evaluating with gold answers and human evaluation, such as models being ranked differently. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by providing a more detailed example or reference to support the claim. Overall, the claim is 4, as it is supported by a logical suggestion for improvement.", "helpfulness_rationale": "The review comment acknowledges that the abstract is wellwritten and invokes intrigue, which is a positive observation. It also provides a specific suggestion for improvement by recommending the inclusion of an example to illustrate the inconsistency between evaluating with gold answers and human evaluation. This feedback is actionable and constructive, as it guides the authors on how to enhance their abstract to better convey the significance of their work. However, the comment could be more helpful if it provided a concrete example of the inconsistency or suggested how to present it effectively. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect of their work. The comment lacks actionable details, such as recommending specific ways to present the selection process or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve the clarity of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the selection of frame similarity factors and attributes similarity factors is unclear, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or sections need clarification, making the comment weakly grounded. However, it is specific in detailing what needs to be addressed regarding the selection process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors. It points out that the explanation of these choices is unclear, which is a valid observation that could help the authors improve the clarity and transparency of their work. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the selection process. While it highlights an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This provides a clear and direct action for the authors to take, which is to include these discussions in their draft. The comment is specific and provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"joint learning process\" for RNN and CopyRNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the convergence of the proposed joint learning process and how stable points in the probabilistic metric space are obtained. This provides clear guidance on what the authors need to clarify or expand upon in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that discussions are required on the convergence of the proposed joint learning process, specifically for RNN and CopyRNN, to clarify how stable points in the probabilistic metric space are obtained. This claim is 3 as it logically suggests that understanding the convergence process is crucial for reproducing results. However, the comment lacks specific examples or references to support the claim, making it somewhat challenging for the authors to fully grasp the importance of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that discussions on the convergence of the proposed joint learning process are required. This feedback is clear and actionable, as it directs the authors to clarify how stable points in the probabilistic metric space are obtained. By addressing this point, the authors can enhance the clarity and reproducibility of their results. However, the comment could be more helpful if it provided additional guidance on how to structure these discussions or what specific aspects should be covered. Overall, the comment is 4 as it effectively points out a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). Additionally, it mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides explicit actions to take, it does not offer concrete guidance on how to implement these suggestions or what specific terminology should be used. The authors are left with a clear understanding of what needs to be done but without detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, \"681\" and \"778,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the results for the task of inferring knowledge on objects and the inclusion of results for model (B). Additionally, it provides a suggestion to use the same terminology for the model in Tables 1 and 2. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also mentions that it would be better to use the same terminology for the model in Tables 1 and 2. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that using the same terminology would be beneficial. This makes the claim 3, as the authors would need to make a logical inference to understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors discuss the results for the task of inferring knowledge on objects and include results for model (B). It also points out that it would be beneficial to use the same terminology for the model in Tables 1 and 2. This feedback is clear and directs the authors to specific areas for improvement, making it 5 in guiding them to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or examples on how to implement these suggestions effectively. Overall, the comment is 5 as it offers concrete steps for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific sentence in line 212 that is not correct and suggests a correction. It provides a clear and explicit action for the authors to make the sentence more accurate by suggesting that they should say they do a bidirectional encoder instead of a GRU. The comment also references Figure 2, which provides a concrete example of what the correct sentence should look like. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 212,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the sentence, suggesting that it should be revised to accurately reflect the process. The comment provides a clear suggestion for correction, which is to use a bidirectional encoder instead of a GRU. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in line 212 is not correct and suggests a correction. The reviewer provides a specific example from Figure 2, which supports the claim by showing the correct methodology. This provides a clear and concrete example of what is incorrect, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar work, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the sentence in line 212, noting that it is not strictly correct. It suggests a correction by proposing that the authors should say they do a bidirectional encoder instead of a GRU. This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy of the sentence. Additionally, the comment references Figure 2, which could be helpful for the authors in verifying the correctness of the suggestion. However, the comment could be more helpful if it explained why the current sentence is incorrect or provided additional context on the significance of the correction. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear path for correcting it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment implies that the authors should consider including these baselines, it does not provide explicit instructions or detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include additional baselines but are not given specific steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, it does not specify which part of the paper this extension or the baselines should be added to, making it weakly grounded. The comment is specific in suggesting the inclusion of character embeddings as a baseline, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this extension is necessary or how character embeddings would enhance the work. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends adding additional baselines, specifically mentioning character embeddings. While the comment identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how to implement these additional baselines or why they are necessary. The suggestion is 3 as it points out a potential area for enhancement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models: the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. It explicitly instructs the authors to compare their work with Campos et al. and to include comparisons with other domain adaptation methods mentioned in Section 8. The comment provides concrete guidance on what needs to be added to the paper, making it 5. The authors know exactly what steps to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 277,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison to Campos et al. (2020) and the absence of comparison with other domain adaptation methods. This provides clear guidance on what needs to be improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline models are weak and suggests that the authors should compare their work with Campos et al. (2020) and other domain adaptation methods. While the comment identifies a potential issue with the baseline models, it lacks specific examples or references to Campos et al. or other domain adaptation methods to fully substantiate the claim. The suggestion to compare with these works is logical, but the lack of detailed evidence or references makes the claim 3. The authors would need to make a significant effort to verify the claim themselves, as the comment does not provide enough guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the baseline models used in the paper, noting that they are weak and lack comparison to relevant works. It specifically points out the absence of a comparison with Campos et al. (2020), which also uses feedback in QA tasks, and the lack of comparison with other domain adaptation methods mentioned in Section 8. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is 5 as it clearly specifies what needs to be done to enhance the clarity of the figure.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the yaxis label, and suggests using \"Exact Match ratio\" directly. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the yaxis label in Figure 5 should use \"Exact Match ratio\" directly. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of Figure 5 by recommending that the yaxis label use \"Exact Match ratio\" directly. This feedback is clear and direct, offering a straightforward way for the authors to enhance the readability and understanding of the figure. By addressing this point, the authors can improve the clarity and accessibility of their visual presentation, which is valuable for the overall quality of the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they could take to ensure that their knowledge bases are free from societal biases. Additionally, the second part of the comment mentions liking the approach but expressing skepticism about the example in Fig., but it does not provide any further details or suggestions for improvement. Overall, the comment lacks actionable guidance, making it 1.", "grounding_specificity_rationale": "The comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment mentions a specific example from Fig., but it does not provide details on what aspect of the example is problematic or how it relates to the issue of societal biases. This lack of specificity and grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the potential societal biases in the knowledge bases used and questions whether the issue is affected by such biases. While it identifies a relevant area for consideration, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure their knowledge bases are free from societal biases. Additionally, the comment mentions liking the approach but expressing skepticism about the example in Fig., but it does not provide any further details or suggestions for improvement. Overall, the comment provides some insight but lacks actionable feedback, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while it is easier to show that something (e.g., attention in seq2seq MTL) is not working, the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to modify the attention mechanism. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the discussion of attention mechanisms, but this inference is not direct. The comment is specific in its suggestion to investigate and modify the attention mechanism, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to show that something (e.g., attention in seq2seq MTL) is not working, but the true value lies in finding out why it fails and changing the attention mechanism to make it work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment highlights a common issue in research, where it is easier to show that something is not working but more challenging to identify the underlying reasons and make improvements. It suggests that the true value lies in finding out why a particular aspect (e.g., attention in seq2seq MTL) is not working and changing the attention mechanism to make it work. While the comment identifies a general problem, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the attention mechanism need improvement. The feedback is 3 as it points out a common problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, it does not provide explicit guidance on which specific baselines should be included or how to justify the omission of others. The action is implicit and somewhat vague, as the authors need to infer that they should include more baselines and justify the exclusion of others. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3\" and \"MCNC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. The comment provides a clear direction for improvement by asking the authors to justify the reason for not including these baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 3 should include many strong baselines that are not currently compared, such as those mentioned in reference [1]. However, the comment does not provide specific examples of these baselines or explain why they are considered strong. Without this additional context or justification, the claim is 3, as the authors may need to infer the relevance of the suggested baselines and the reasoning behind their inclusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that Table 3 should include many strong baselines that are not currently compared. It specifically mentions a reference [1] that lists additional baselines, which could provide a more comprehensive comparison. However, the comment lacks specific guidance on which baselines should be included or how to justify their exclusion from the current comparison. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper relies on supplemental space to contain the paper, which makes it not truly independent. It specifically mentions the issue with S3.1 and the model comparison, as well as other details of the span vs. sentence investigation. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the independence of the paper. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the structure and content of their paper to ensure independence, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper relying on supplemental space to contain the paper, which affects its independence. It specifically mentions S3.1 and the model comparison as examples of this reliance. However, the comment does not specify which sections or details of the paper are problematic, making it difficult for the authors to pinpoint the exact areas that need improvement. While the authors can infer that the sections mentioned are relevant, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the issue of reliance on supplemental space. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, which affects its independence. The reviewer supports this claim by referencing specific sections, such as S3.1 and the model comparison, where the paper references supplemental figures. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the paper is not truly independent due to its reliance on supplemental space. While the reference to specific sections provides some support, the comment could be strengthened by offering more detailed analysis or examples to fully justify the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it relies on supplemental space to contain the content, which affects its independence. This is a critical observation, as it highlights a potential weakness in the paper\"s structure and credibility. The comment specifically references S3.1 and the model comparison as examples of this reliance, which provides the authors with clear areas to address. However, the comment could be more helpful by offering suggestions on how to improve the independence of the paper, such as suggesting ways to integrate the supplemental material more seamlessly or proposing alternative approaches to present the content. Overall, the comment is 4 as it points out a critical issue and provides some direction for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The authors are instructed to correct Figure 3. While the comment provides explicit actions to take, it does not specify how to implement these changes or what specific details should be added to the input or figure. The authors are given clear guidance on what to do, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as adding information about the input being word embeddings and clarifying the KNs in source language or English. The comment also provides a clear request for correction, which adds to its specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also asks about the KNs in source language or in English, as the mentions have been translated to English. The comment is 3 as it provides a logical suggestion for clarifying the input and references a specific model for comparison. However, it lacks specific examples or references to support the claim that adding this information would be beneficial. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add information about the input being word embeddings, similar to the Lample et al. BiLSTMCRF model. It also raises a question about the KNs in source language or in English, given that the mentions have been translated to English. This feedback is clear and offers a concrete way for the authors to improve their draft by clarifying the input and potentially enhancing the clarity of their work. However, the comment could be more helpful if it provided additional context or examples of how this information would benefit the paper. Overall, the comment is 4 as it offers specific and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not provide explicit guidance on how the authors should address these weaknesses or expand their experiments. It lacks specific suggestions or actions for improvement, leaving the authors uncertain about how to enhance their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and the potential of the augmentation method, but without clear grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are the main weaknesses of the paper, as they are limited to an extremely lowresource regime and sentence classification, which are not the only cases for data augmentation in realworld applications. The reviewer also suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment provides some logical reasoning by pointing out the limitations of the experiments and the potential of the augmentation method, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several weaknesses in the paper, particularly in the experiments, which are limited to an extremely lowresource regime and sentence classification. It suggests that the proposed augmentation method has potential to be used on more NLP tasks, but this potential is not demonstrated. The comment highlights the need for the paper to address these limitations and provide more comprehensive experiments. However, it does not offer specific suggestions or guidance on how the authors might expand their experiments or demonstrate the potential of the augmentation method. While it points out areas for improvement, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether concept map extraction should be treated as a separate task, considering that generic summarization systems often build knowledge graphs and generate summaries accordingly. The reviewer suggests that with the increase in node numbers, concept maps become harder to distinguish, making general summaries more readable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider their approach to concept map extraction, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion that general summaries should be more readable due to the difficulty in distinguishing concept maps. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether concept map extraction should be treated as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. The comment provides a logical reasoning by comparing it to generic summarization systems that build knowledge graphs and generate summaries accordingly. However, it lacks specific examples or references to support the claim that general summaries should be more readable due to the difficulty in distinguishing concept maps. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of treating concept map extraction as a separate task, considering the challenges of distinguishing concept maps with increasing node numbers. It suggests that general summaries might be more readable due to these challenges. While the comment identifies a potential issue with the current approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is 3 as it prompts the authors to consider the tradeoffs between treating concept map extraction as a separate task versus incorporating it into general summarization systems. However, it could be more helpful if it provided actionable steps or examples to enhance the clarity or feasibility of the proposed solution. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It also asks specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. These questions provide clear guidance on what the authors need to address to improve their draft. The action is explicit and concrete, as it specifies exactly what needs to be added or clarified. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of the traits of the experts and the justification for why annotation must be carried out by them, outside of its commercial value. The comment also raises questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This level of detail provides clear guidance on what the authors need to address to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises questions about the expertise of the annotators and the justification for why annotation must be carried out by them, outside of its commercial value. It suggests that the authors should provide more information about the traits of the experts and the linguistic challenges introduced by the annotation process. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the annotation process introduces linguistic challenges. This makes the claim 3, as it provides a direction for improvement but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improvement by asking the authors to describe the traits of the experts and justify why annotation must be carried out by them, outside of its commercial value. It raises specific questions about the expertise of the annotators, whether annotation differs from what nonexperts would do, and if it introduces any linguistic challenges. This feedback is valuable as it prompts the authors to clarify and substantiate their claims about the expertise and process involved in annotation. By addressing these points, the authors can enhance the transparency and credibility of their work. Therefore, the comment is 4, as it provides clear and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that lines 102106 are misleading, as \"such distribution\" cannot refer to the discussion in the previous section. However, it does not provide any explicit guidance or suggestions on how the authors should correct this issue. The comment lacks actionable details, such as recommending specific changes or clarifications to be made to the text. As a result, the authors are left without a clear understanding of what needs to be done to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 102106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the misleading statement regarding \"such distribution\" and provides guidance on how to correct it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that lines 102106 are misleading, specifically mentioning that \"such distribution\" cannot refer to the discussion in the previous section. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is misleading or how it affects the paper\"s clarity or accuracy. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text, pointing out that lines 102106 are misleading due to the use of \"such distribution.\" It provides a clear and actionable suggestion for the authors to correct this issue by specifying what \"such distribution\" refers to, ensuring that the discussion is accurate and clear. This feedback is valuable as it helps the authors improve the clarity and precision of their writing, which is an important aspect of scientific communication. However, the comment could be more helpful if it included additional context or examples to guide the authors in making these corrections. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. While the action is implied, it is clear and provides a concrete direction for the authors to take. The comment explicitly states what the authors should do, which is to include examples of the system on actual texts. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, rather than focusing on other components and models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where examples could be included. Without explicit references, the authors may struggle to identify the exact areas that need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that it would be beneficial to include examples of the system on actual texts, rather than focusing on other components and models. This feedback is 3 as it points out a potential area for improvement in the paper, which could enhance the reader\"s understanding of the system\"s capabilities. However, the comment lacks specific guidance on how to implement this suggestion or what specific examples would be most effective. While it identifies a potential improvement, it does not provide detailed instructions or examples to fully support the authors in making these changes. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s claims would benefit from more indepth analysis. However, it does not provide specific examples of which claims need more analysis or what aspects of the claims should be explored further. The comment lacks concrete guidance on how to improve the analysis or what specific aspects to focus on. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a number of claims from the paper would benefit from more indepth analysis, but it does not specify which claims or parts of the paper are being referred to. Without explicit references to sections, figures, or specific claims, the authors cannot confidently determine which parts of the paper need further analysis. Additionally, the comment lacks specificity regarding what aspects of the claims should be analyzed more deeply. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not provide specific examples or detailed reasoning to support why these claims need further examination. Without specific claims or examples, the authors may find it challenging to understand which parts of the paper require additional analysis. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a number of claims from the paper would benefit from more indepth analysis. However, it does not specify which claims or aspects of the paper need this additional analysis. Without specific guidance or examples, the authors are left without actionable feedback on how to improve their draft. The comment lacks depth and specificity, making it 2 for the authors in terms of identifying areas for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies two specific areas where the presentation of the model needs improvement: the pooling method used for embedding features (line 397) and the clarity of Equation (7) in line 472. It provides explicit questions about the pooling method and the definition of E_i in Equation (7), asking whether it represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability. This feedback is clear and provides concrete actions for the authors to take, such as clarifying the pooling method and the definition of E_i. The explicit nature of the questions and suggestions makes this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be improved, namely the clarity of the pooling method used for embedding features and the definition of E_i in Equation (7). The comment provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the pooling method used for embedding features (line 397) and the definition of E_i in Equation (7) in line 472. It suggests that the LHS of Equation (7) should be a conditional probability. The comment provides logical reasoning by pointing out that the pooling method and the definition of E_i are unclear, and it questions whether they represent the type or identity of AC i. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the context and details to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the presentation of the model needs improvement, providing clear and actionable feedback. It points out that the pooling method used for embedding features is not clearly defined and that Equation (7) in line 472 is not clear enough, questioning whether E_i represents the type or identity of AC i. The reviewer also suggests that the LHS of Equation (7) should be a conditional probability, which is a valuable suggestion for clarifying the model presentation. This feedback is detailed and constructive, offering the authors a clear path to enhance the clarity and understanding of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not actually study them or discuss them further. It suggests that the hypotheses could be tested as given and that the paper should go deeper into the respective topics. While the comment identifies a gap in the paper, it does not provide explicit instructions on how to address this issue or what specific aspects of the hypotheses should be explored. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the hypotheses and discuss them in more depth. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper raises two hypotheses but does not study them or discuss them further, nor are they mentioned or discussed again. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias but does not study or discuss them further. The reviewer suggests that the hypotheses could be tested as given and that the paper should go deeper into the respective topics. However, the comment lacks specific examples or references to support the claim that the hypotheses are not studied or discussed adequately. While the reviewer provides some reasoning, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it raises two hypotheses about multilinguality and country/languagespecific bias but does not study or discuss them further. This is considered misleading, as the hypotheses are not followed up on or even mentioned again in the paper. The comment suggests that the paper should go deeper into these topics, at least to some extent, to provide a more comprehensive exploration of the hypotheses. While the feedback highlights a critical gap in the paper, it could be more helpful by offering specific suggestions on how to address this issue or what aspects of the hypotheses should be discussed. Overall, the comment is 3 as it points out a significant oversight but lacks detailed guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to enhance their results. While the comment implies that the authors should explore this possibility, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the same feature set from the cited work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to enhance their results. However, the comment does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the use of a particular feature set, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using feature engineering could improve the performance of the paper, citing an example from Uto et al. (2020) where a QWK of 0.801 was achieved using a set of handcrafted features. This provides a logical basis for the claim, as it suggests that using similar features could potentially enhance the results of the current work. However, the comment lacks specific details on how the feature engineering could be implemented or which features from Uto et al. (2020) could be adapted. This makes the claim 3, as it provides a reasonable suggestion but requires further elaboration for full verification.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using feature engineering to improve the performance of the paper. It suggests that the authors could consider using the same feature set from Uto et al. (2020) to enhance their results. While the comment identifies a potential area for improvement, it lacks specific guidance on how to implement this suggestion or what specific features from Uto et al. (2020) could be adapted. The feedback is 3 as it points out a potential direction for improvement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of the Challenge Set (CS) and seeks clarification on its role in the evaluation process. It implies that the authors should provide more information about how the CS is used, whether it is used for augmenting the training material, and the data split used. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the CS. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Challenge Set\" (CS), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how the CS is used, whether it is used for augmenting the training material, and the data split used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the use of the Challenge Set (CS) in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set (CS) in the paper, specifically inquiring about its role in evaluation and whether it is used for augmenting the training material. It also asks for clarification on the data split used. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the paper, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. It also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to clarify the terminology. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the terminology but are not given specific steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim of generalization to different knowledge and questions the use of constituent parse as knowledge. It also mentions the term \"knowledge\" and its potential misuse in the context of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the terminology and its implications, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words. The reviewer also questions the use of constituent parse as knowledge and points out that the term \"knowledge\" may be misleading in this context. The comment provides a logical reasoning for why the terminology might be misleading and suggests a more accurate description. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim of generalization to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also points out that the term \"knowledge\" may be misleading in this context, as it is typically used to refer to external knowledge sources such as a knowledge base of entities. The comment highlights a specific terminological issue that could be clarified to improve the paper\"s clarity and accuracy. While it does not provide detailed suggestions on how to address these concerns, it does offer valuable insights that could guide the authors in refining their terminology and improving the clarity of their work. Therefore, the comment is 4, as it provides actionable feedback that can help the authors enhance the clarity and accuracy of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the poor performance on nouns and questions the generalizability of the clustering approach to all parts of speech. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete details on how to improve the draft, such as recommending specific analyses or experiments to better understand the gap between the oracle GAP and the clustering approach. As a result, the authors are left without a clear path forward, making this comment 1.", "grounding_specificity_rationale": "The comment addresses the performance on nouns and the contradiction between the claim of generalizability and the performance on specific parts of speech. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the oracle GAP and the contradiction with the claim of generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It references the oracle GAP for PPDBClus and the fact that it is higher than most clustering approaches, which is a logical point of concern. However, the comment does not provide specific examples or references to support the claim that the clustering approach is not generalizable. The lack of detailed evidence or examples makes the claim 3, as the authors would need to further investigate the issue themselves to fully understand and address the concern.", "helpfulness_rationale": "The review comment identifies a concern about the performance on nouns and questions the generalizability of the clustering approach to all parts of speech. It highlights the contradiction between the claim of generalizability and the performance on specific parts of speech, as evidenced by the oracle GAP for PPDBClus being higher than most clustering approaches. This feedback is 3 as it points out a potential weakness in the paper\"s claims, but it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it prompts the authors to consider the generalizability of their approach, the comment could be more actionable with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It explicitly requests examples of spurious structures to help clarify the discussion. This feedback is clear and provides a specific action for the authors to take, which is to provide examples of spurious structures to support their claims. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is too abstract and does not provide insights into why the new model is better than MH. The comment also requests examples of spurious structures to help clarify the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in Section 5.2 is too abstract and does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. However, the comment lacks specific examples or references to support the claim that the discussion is abstract or unclear. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstractness of the discussion in Section 5.2, noting that it does not provide insights into why the new model is better than MH. It suggests that examples of spurious structures could be provided to clarify the discussion. While the comment highlights a clear area for improvement, it lacks depth and does not provide specific guidance on how to address the issue or what kind of examples would be helpful. This limits the comment\"s usefulness, as it points out a problem but does not offer detailed suggestions for improvement. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The reviewer provides a specific suggestion for how to implement this baseline, which is to directly parameterize $H, I, J, K, L$ as learned matrices. While the comment provides a clear action, it lacks detailed guidance on how to implement this suggestion or what specific parameters should be adjusted. The authors are given a clear direction but may need to infer additional details to fully execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this baseline could be added. The authors can infer that it relates to the PCFG model or the baseline comparison, but this inference is not direct. The comment is specific in detailing what needs to be added, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. The comment provides a logical reasoning for this suggestion, noting that this baseline could help compare perplexity but not parsing F1. However, the comment lacks specific examples or references to support the claim that this baseline would be beneficial or how it would impact the results. While the suggestion is logical, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by adding a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This suggestion is clear and actionable, as it offers a concrete way to address a potential issue with the comparison of PCFG models. By adding this baseline, the authors can better evaluate the performance of their model and provide a more comprehensive analysis. However, the comment could be more helpful if it included additional details or examples on how to implement this baseline or what specific parameters should be adjusted. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is an explicit action that the authors can directly implement by adding a statement to their paper. The comment is clear and provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a statement about the maximum number of tasks done by any annotator. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. Without explicit references, the authors cannot confidently determine the exact location of the suggestion in the paper. The comment is specific in suggesting what needs to be added, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any supporting evidence, reasoning, or examples to justify why this information is important or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should state the maximum number of tasks done by any annotator. This is a specific and actionable piece of feedback that can help the authors improve the transparency and reproducibility of their results. By including this information, the authors can provide a clearer understanding of the variability in task completion across annotators, which could be important for assessing the robustness of their findings. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the results. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested. However, the comment does not specify which parts of the paper are particularly challenging to understand or where the authors should focus their efforts to improve clarity. Without explicit references to sections or specific analyses, the authors may struggle to identify the areas needing attention. Therefore, the comment is weakly grounded because it does not specify which parts of the paper are being addressed, and it is not specific in detailing what needs to be clarified. This aligns with a score of 2.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and specific hypotheses tested. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in understanding the overall picture of the empirical results and analyses presented in the paper. It highlights the need for clarity on what the experiments reveal about the underlying research question and specific hypotheses tested. The comment also questions how the different pieces of the puzzle fit together, indicating a lack of coherence in the presentation of the results. While the comment provides a clear direction for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. This limits its helpfulness, as it points out a critical area for improvement but does not offer actionable steps to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and direct action for the authors to take, as it provides a specific and concrete step to enhance the presentation of their results. The comment is 5 because it clearly specifies what needs to be added to the table, making it easy for the authors to implement the suggested change.", "grounding_specificity_rationale": "The comment suggests adding the hard prompt baseline to Table 1 to show the increase in performance of each method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion section, but this inference is not direct. The comment is specific in suggesting the inclusion of the hard prompt baseline, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. However, it does not provide any reasoning or evidence to support why this inclusion is necessary or how it would benefit the paper. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the hard prompt baseline should be included in Table 1 to show the increase in performance of each method. This is a clear and actionable suggestion that could enhance the presentation of the results. By including the hard prompt baseline, the authors can provide a more comprehensive comparison of their methods, allowing readers to better understand the performance improvements. However, the comment could be more helpful if it explained why the inclusion of the hard prompt baseline is important or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific improvement that could enhance the clarity and comprehensiveness of their results."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. While it implies that the authors should include numerical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, it does not specify which part of the paper lacks numerical results or where the application to popular algorithms should be discussed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for numerical results and application to popular algorithms, but it is 1 as it does not explicitly mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of numerical results and expresses curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of numerical results and expressing curiosity about how to apply the results to popular algorithms and compare their performance with existing DP algorithms. This feedback is valuable as it highlights an area where the paper could be strengthened by including numerical results, which would provide more concrete evidence and support for the claims made. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these results or provided examples of how similar studies have been conducted. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental comparisons are not sufficient and recommends including results with wider backbones like ResNet50 (2x) and ResNet50 (4x). While the comment implies that the authors should conduct additional experiments with these backbones, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparisons and suggests that the results with wider backbones like ResNet50 (2x) and ResNet50 (4x) should be included. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional experiments are needed and why they would be beneficial. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends including results with wider backbones like ResNet50 (2x) and ResNet50 (4x). However, the comment does not provide any supporting evidence or reasoning to justify why these additional comparisons are necessary or how they would improve the study. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, specifically noting that the proposed method, InvP, has not been tested with wider backbones like ResNet50 (2x) and ResNet50 (4x). This feedback is valuable as it suggests a potential area for improvement and expansion of the experimental results. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what specific insights might be gained from doing so. Overall, the comment is 3 as it points out a potential gap in the experimental analysis but lacks detailed guidance for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need more formalization or how to achieve this. The authors are left to infer the exact actions needed to enhance the clarity of the probabilistic connection. Therefore, the comment is 3, as it provides a general direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection is not wellestablished and recommends either formalizing it more or adjusting the language to clarify the connection. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the probabilistic connection is discussed. The authors can infer that it relates to the discussion of the probabilistic connection, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not wellestablished and suggests that it should be formalized more or clarified in the language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific sections of the paper where the probabilistic connection is discussed or where it could be improved. As a result, the claim is 3, as it points out a potential issue but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the probabilistic connection, suggesting that it is not wellestablished and lacks formalization. It recommends either formalizing the connection more or adjusting the language to clarify it. This feedback is 3 as it points out a specific area for improvement, but it could be more beneficial if it provided more detailed guidance on how to formalize the connection or adjust the language. Overall, the comment offers a clear direction for enhancing the paper, but it lacks depth and specificity in its suggestions, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is explicit in its request for additional evidence, providing a clear action for the authors to take. However, it does not specify what kind of evidence would be sufficient or how to present it, leaving some room for interpretation. Therefore, the comment is 4, as it identifies a specific need for additional evidence but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests providing empirical evidence to support the claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, it does not specify which part of the paper this claim is made in, nor does it provide details on what kind of evidence would be sufficient. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its request for empirical evidence, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide empirical evidence to support their claim that the proposed algorithm works better for Column Subset Selection problem, as stated in the third contribution of the paper. This feedback is clear and actionable, as it identifies a specific area where the paper could be strengthened by providing empirical evidence to substantiate the claim. However, the comment could be more helpful if it provided guidance on what kind of evidence would be most effective or how to present it. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or suggestions for modifications to improve the scalability of the robust training scheme. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the robust training scheme, specifically questioning its scalability to practical datasets, particularly those with highdimensional domains. However, it does not specify which part of the paper this concern is based on, such as a specific section or figure where the robust training scheme is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the potential issue with the scalability of the robust training scheme, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the robust training scheme is unlikely to scale to practical datasets, particularly those with highdimensional domains. The comment provides a logical reasoning by suggesting that the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. However, the comment lacks specific examples or references to support this claim, making it 3. The authors may find it challenging to fully understand and address the concern without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the applicability of the robust training scheme, suggesting that it may not scale to practical datasets, particularly those with highdimensional domains. It points out that the accuracy might scale unfavorably unless the size of V scales exponentially with the dimension. While the comment highlights a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the scalability of their robust training scheme. The feedback is 3 as it alerts the authors to a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of datasets and the duration of four years for studying style shifts. It suggests that without understanding the type of style shifts that occur during this period, it is difficult to appreciate what the model is capturing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or specific actions for the authors to take, such as recommending additional datasets or discussing the type of style shifts that occur during the fouryear period. As a result, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the choice of datasets and the duration of four years for studying style shifts. However, it does not specify which part of the paper this question pertains to, such as a particular section or dataset description. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its question about the type of style shifts that occur during the fouryear period, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of datasets and the duration of four years for studying style shifts, suggesting that it may not be sufficient to capture all style shifts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of datasets and the duration of four years for studying style shifts. It questions whether four years is sufficient to capture all style shifts and suggests that understanding the type of style shifts that occur during this period is crucial to appreciating what the model is capturing. This feedback is 3 as it prompts the authors to consider the adequacy of their dataset choice and the potential limitations of their analysis. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns, such as recommending additional datasets or discussing the types of style shifts that might occur during the fouryear period. Overall, the comment offers a valuable insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the callout to Table 5 should be changed to Table 3 and provides the correct page and section number. Additionally, it points out that the figure 6 callout is not directing properly. This feedback is clear and provides specific actions for the authors to take, ensuring that they know exactly what needs to be corrected. The explicit nature of the instructions and the concrete details on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"figure 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the callout to Table 5 and the figure 6 callout, providing detailed guidance on how to correct these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the callout to Table 5 should be changed to Table 3 and that the figure 6 callout is not directing properly. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by pointing out a mistake in the callout to Table 5, which should be changed to Table 3, and noting that the figure 6 callout is not directing properly. This feedback is clear and directs the authors to correct specific errors in their paper, ensuring that the references are accurate and easy to follow. By addressing these issues, the authors can improve the clarity and accuracy of their work. Therefore, the comment is 4, as it provides clear guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant concern with the experiments, specifically the lack of comparisons with other models, such as SketchRNN. It explicitly states that the paper should include comparisons with other models to provide a more comprehensive understanding of its results. The comment is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of comparisons with other models, such as SketchRNN. The comment provides a clear direction for improvement by suggesting that comparisons with other models should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are a significant concern due to the lack of comparisons with other models, specifically SketchRNN. The comment suggests that this lack of comparison adds to the poor motivation problem. However, the comment does not provide specific examples or references to support the claim that the lack of comparisons is a significant issue. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern. Therefore, the claim is 3, as it provides a logical reasoning but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s experiments, specifically the lack of comparisons with other models, such as SketchRNN. It points out that the paper\"s selfcomparisons are insufficient and that the absence of comparisons with other models contributes to the poor motivation problem. The comment provides a clear and actionable suggestion for improvement by recommending the inclusion of comparisons with other models. This feedback is valuable as it directs the authors to enhance the comprehensiveness and robustness of their experimental analysis. However, the comment could be more helpful if it explained why comparisons with SketchRNN are particularly important or how they might impact the paper\"s conclusions. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment recommends conducting more analysis and providing comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors\" viewpoint regarding the benefits of increased model capacity and provides specific examples from Figure 3 to support this disagreement. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While it provides some guidance, the action is implicit and lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the disagreement with the authors\" viewpoint regarding the benefits of increased model capacity and provides specific examples from Figure 3 to support this disagreement. The comment also suggests more analysis and comments on the performance trending of increasing the number of parameters for ViT (DeiT) in Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim that the authors\" viewpoint regarding the benefits of increased model capacity is incorrect, based on specific examples from Figure 3. The reviewer provides a detailed analysis of the performance trends for different models, including DeiTB, DeiTS, and CNNs, across various datasets. This analysis and comparison provide a robust basis for the claim, making it 5. The comment is supported by specific examples and data, which makes it clear and easy for the authors to understand and address the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed critique of the authors\" viewpoint regarding the benefits of increased model capacity, specifically in the context of ViT (DeiT) models. It offers specific examples from Figure 3 to support the claim that the DeiTB models do not outperform DeiTT in APTOS2019 and do not outperform DeiTS on multiple datasets. This feedback is 5 as it not only challenges the authors\" assumptions but also provides concrete evidence to support the critique. By offering actionable suggestions for further analysis and comments, the comment guides the authors to address the issue and improve their draft. Therefore, it aligns with a score of 5, indicating that the comment is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but points out specific areas that may cause confusion. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve clarity or what specific changes should be made to avoid confusion. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not specify which sections or parts of the paper these areas are located in, making it difficult for the authors to pinpoint the exact issues. The comment is specific in identifying potential areas of confusion but lacks grounding as it does not specify where these issues are located in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the identified areas of confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas that may cause confusion. However, it does not provide any detailed guidance or suggestions on how to address these areas of confusion. Without actionable feedback or specific examples, the authors are left without a clear path to improve the clarity of their draft. Therefore, the comment is 2, as it points out an issue but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the claim of \"no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This feedback is clear and directs the authors to review the references mentioned, which can help them understand the existing tools in the reinforcement learning setting. The action is explicit and concrete, as the authors know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of \"no corresponding set of tools for the reinforcement learning setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides references to support the claim, which helps the authors understand the context and the basis of the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"there is no corresponding set of tools for the reinforcement learning setting\" is false, providing references to support this claim. This provides a clear and specific justification for the claim, making it 5. The references and logical reasoning offered by the reviewer provide sufficient evidence to support the claim, making the comment 5. Therefore, the label is 5.", "helpfulness_rationale": "The review comment challenges the claim that there is no corresponding set of tools for the reinforcement learning setting, providing references to support the assertion. This feedback is valuable as it not only corrects an apparent misconception but also directs the authors to relevant references that could enhance their understanding of the existing tools in the reinforcement learning setting. By addressing this point, the authors can improve the accuracy and completeness of their draft. However, the comment could be more helpful if it provided additional context or analysis on why these references are relevant or how they could be integrated into the paper. Overall, the comment is 4 as it identifies a specific issue and offers a path for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the results more accessible or how to improve the technical competency required to understand them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the results require a higher level of technical competency or how to address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency. This feedback highlights a potential weakness in the paper\"s presentation, as it may not be accessible to a broader audience. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to address this issue. Without detailed feedback or examples, the authors may struggle to understand and implement the necessary improvements. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. While the comment implies that the authors should make this distinction, it does not provide explicit instructions or concrete steps on how to implement this distinction. The authors are left to infer that they should make this distinction, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 148,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this distinction is necessary or how it would improve the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests making a distinction between hard prompt work updates that affect the frozen model (such as those by Schick and Sch\u00fctez) and those that do not. This feedback is 3 as it identifies a potential area for clarification and differentiation in the paper. However, the comment lacks specific guidance on how to implement this distinction or why it is important for the paper. While it points out a potential issue, it does not provide detailed suggestions or examples on how to address it, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the amount of data used to train the text disambiguation model and compares it to the data used for the endtoend system. It questions the conclusion that the direct model is clearly better, but still acknowledges that both systems are demonstrably superior to the baseline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the data usage and the conclusion regarding the direct model, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the amount of data used to train the text disambiguation model is significantly lower than the data used for the endtoend system, which raises questions about the conclusion that the direct model is clearly better. However, the comment does not provide specific data or references to support this claim, making it difficult for the authors to verify the validity of the assertion. The lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system, questioning the conclusion that the direct model is clearly better. It highlights that the difference between the two proposed systems is only a few percentage points, but still acknowledges that both systems are demonstrably superior to the baseline. This feedback is 3 as it points out a potential issue with the data usage and the conclusion, prompting the authors to reconsider their findings. However, the comment could be more helpful if it provided suggestions on how to address this issue or what additional analyses might be needed to substantiate the conclusion. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues with the paper: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. While the comment highlights specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to provide more detailed explanations and evidence for GaRare\"s advantages over GaLore, as well as clarify the process of updating parameters. However, the comment lacks specific guidance on how to achieve these improvements, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the paper, such as the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for GaRare and provides a specific example of the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. The comment suggests that this lack of detail hinders understanding. However, the comment does not provide specific examples or references to support the claim that GaRare\"s advantages over GaLore are unclear or that the algorithmic presentation is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved: the lack of motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. By pointing out these gaps, the comment provides actionable feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples or references to support the motivation or detailing the algorithmic presentation more clearly. Overall, the comment is 3 as it directs the authors to specific areas needing improvement, but it lacks detailed guidance on how to achieve those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides explicit actions, it does not offer detailed guidance on how to conduct the ablation study or the specific experiment with ATT(+H). The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 4 left\" and \"visDial dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely conducting an ablation study on the visDial dataset and conducting an experiment on the performance of ATT(+H) in figure 4 left. The comment provides detailed guidance on what needs to be done, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. While the comment provides a logical request for additional experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact experiments and analyses required to address the suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model in realworld datasets. It also requests an experiment on the performance of ATT(+H) in figure 4 left, specifically asking about the result if the model did not consider relevant attention retrieval from the attention memory. This feedback is clear and offers a concrete direction for the authors to improve their draft by conducting additional experiments and analyses. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it offers valuable suggestions for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of a reference to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add these references to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"Continuous Conditional Random Fields [Ristovski 2013]\" and \"Continuous Conditional Neural Fields [Baltrusaitis 2014],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of references to similar work that shares a similar structure and inference capabilities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the relevance or significance of these references. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a missing link to similar work on Continuous Conditional Random Fields (CCRF) and Continuous Conditional Neural Fields (CCNF) that share a similar structure with the CRF and have the ability to perform exact inference. This feedback is 3 as it points out a gap in the literature review that could enhance the authors\" understanding and comparison of their work. However, the comment lacks specific suggestions on how to incorporate these references or what aspects of the similar work are relevant to the current paper. While it highlights an area for improvement, it does not provide detailed guidance on how to address it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. It also questions whether any input serves as white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the authors spend a lot of time showing WPA improves the test performance of the original model but do not provide insights into how WPA works. This feedback highlights a gap in the paper that needs to be addressed, suggesting that the authors should provide more detailed explanations or analysis to support their claims. The comment is explicit in its request for clarification and actionable, as it clearly identifies areas where the authors can improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"np.ones input,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of why WPA works and the implications of the results shown in Figure 2. The comment provides a clear direction for the authors to improve their draft by explaining the model\"s predictions and the limitations of Gaussian noise input. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the effectiveness of WPA and suggests that the authors should provide more insights into how it works. It references Figure 2, which appears to suggest that Gaussian noise input does not work as well as WPA. The reviewer also points out that the paper spends a lot of time showing WPA improves test performance but lacks insights into its mechanism. This claim is 3 as it provides a logical basis for the suggestion to explain WPA, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper, highlighting several areas where the authors could improve their work. It suggests that the authors should attempt to explain why WPA works, specifically with np.ones input, and what the model is predicting. The comment also questions whether any input serves as a white paper and points out that Figure 2 suggests Gaussian noise input does not work as well as WPA. The reviewer notes that the paper spends a lot of time showing WPA improves the test performance of the original model but fails to provide useful insights into how WPA works. This feedback is highly valuable as it identifies specific areas where the authors can enhance their draft, particularly by providing more detailed explanations or analysis to support their claims. By addressing these points, the authors can significantly improve the clarity and impact of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method part of the paper is similar to a related work mentioned, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification on this similarity. While the comment implies that the authors should provide more information or explanation regarding the similarities, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification, but it is concrete in that it specifies the need for more information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"method part\" of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the similarity to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the method part of the paper is similar to a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and asks for clarification. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential similarity between the method part of the paper and a related work, \"Generating Adversarial Disturbances for Controller Verification,\" and requests clarification on this similarity. While the comment highlights an area of potential concern, it does not provide specific guidance or suggestions on how the authors might address this issue or differentiate their work from the related work. The feedback is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide a comparison with other methods and consider promoting existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed method, such as the use of a proposal generator pretrained on MSCOCO and its potential impact on existing class incremental semantic segmentation methods. It also mentions the authors\" adequate addressing of limitations and potential negative societal impact. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its questions about the fairness of comparison and the potential promotion of existing methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with other methods and whether it can promote existing class incremental semantic segmentation methods. It also acknowledges that the authors have addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about fairness or the potential impact on existing methods. This makes the claim 3, as the authors would need to infer the basis of the critique and potentially conduct additional research to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the fairness of comparing the proposed method with other methods and its potential impact on existing class incremental semantic segmentation methods. It also acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it points out areas for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a critical issue regarding the absence of discussion on how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. While it identifies a specific area that needs attention, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they should include a discussion on these parameters in the experimental section, but the comment lacks concrete guidance on what aspects of this discussion should be included or how to present it effectively. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"End of Sec.2\" and the \"experimental section (Sec. 3),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the absence of discussion on how the two important parameters/thresholds (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental section does not discuss how the two important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This claim is 3 as it highlights a gap in the experimental discussion, but it lacks specific examples or references to support the assertion that these parameters are critical or how their absence affects the results. The authors would need to infer the importance of these parameters and their potential impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper, specifically the absence of discussion on how the two important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is to these parameters. This is a significant oversight, as these parameters are crucial for understanding the experimental results and the robustness of the method. The comment provides clear and actionable feedback by pointing out the need for a discussion on these parameters, which is essential for the authors to address. However, it could be more helpful if it offered suggestions on how to incorporate this discussion or what specific aspects of the parameters should be discussed. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 could benefit from a slower development to improve readability. However, it does not provide specific guidance on how to achieve this or what aspects of the section need more development. The comment lacks concrete details on how to implement this suggestion, such as recommending additional content or a different structure. As a result, the authors are left without clear instructions on how to enhance the readability of the section. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the section is \"very tersely written\" and could benefit from a slower development for easier readability. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 4 is \"very tersely written\" and could benefit from a slower development to improve readability. However, the comment does not provide any specific reasoning or examples to support this claim. It lacks detailed justification or references to similar works that might have addressed this issue, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the writing style of Section 4, noting that it is \"very tersely written\" and could benefit from a slower development to improve readability. While it highlights a potential problem, it lacks specific suggestions or guidance on how to achieve this improvement. The comment could be more helpful if it provided examples of how to develop the content more gradually or offered specific recommendations for enhancing the readability. As it stands, the feedback is 3, as it points out an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific changes could be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the use of reinforcement learning, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to studies that have demonstrated the inefficiency or difficulty of using reinforcement learning for static VQA tasks. Without such support, the claim remains 1, as it is based on a personal opinion without sufficient evidence or justification. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the use of reinforcement learning for a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train. While the comment identifies a potential issue, it lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this concern. Without detailed feedback or constructive advice, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback provides clear and concrete actions for the authors to take, making it 5. The comment is specific about what needs to be added and explained, giving the authors a clear path to improve their draft. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the distribution of videos of different lengths within the benchmark and the explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an explanation of the distribution of videos of different lengths within the benchmark, which is crucial for assessing reasoning ability and robustness. The reviewer suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This claim is 3 as it logically points out the importance of this information for assessing the paper\"s claims. However, it lacks specific examples or references to similar studies that have addressed this issue, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the lack of an explanation regarding the distribution of videos of different lengths within the benchmark. It suggests that the authors should include a table showing the distribution of video lengths across the dataset and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is clear and actionable, providing the authors with a specific and meaningful suggestion for improving their draft. By addressing this issue, the authors can enhance the transparency and robustness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify how the implemented billinear layer differs from other approaches that perform billinear pooling. It raises questions about the major difference, whether it is the dimensionality of embeddings, and how the billinear layer is swapped out with other approaches. Additionally, it asks about the compression of representations using Equation (3) in this case. While the comment provides specific questions that need to be addressed, it does not offer explicit guidance on how to implement these clarifications or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the differences between the billinear layer and other approaches that perform billinear pooling. The comment raises questions about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done in this case. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the differences between the billinear layer and other approaches that perform billinear pooling. It suggests that the major difference might be the dimensionality of embeddings, and it asks about the compression of representations using Equation (3) in this case. The comment is 3 as it provides logical reasoning by questioning the differences between the billinear layer and other approaches, but it lacks specific examples or references to support the claim. The authors might need to provide more detailed explanations or references to fully address the questions raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable set of questions that the authors need to address to clarify the differences between the billinear layer and other approaches that perform billinear pooling. It raises important points about the dimensionality of embeddings, how the billinear layer is swapped out with other approaches, and whether the compression of representations using Equation (3) is still done in this case. By addressing these questions, the authors can significantly improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify these points or what additional details should be included. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the availability of the promised dataset, suggesting that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. However, it does not provide any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how to address the issue, such as suggesting ways to make the dataset more accessible or how to mitigate the potential impact of this limitation. As a result, the authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the availability of the promised dataset, suggesting that a cautious approach should be taken until the dataset is publicly accessible. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the dataset\"s availability, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting that a cautious approach should be taken regarding the contribution until the dataset is accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment highlights a potential issue with the paper\"s contribution, specifically the availability of the promised dataset. It suggests that a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. While this feedback identifies a critical aspect of the paper\"s contribution, it lacks specific guidance or suggestions on how the authors might address this issue or mitigate the potential impact of the dataset\"s unavailability. The comment could be more helpful if it provided suggestions on how to make the dataset more accessible or how to handle the potential limitations of the contribution. As it stands, the comment is 3, as it points out a significant concern but does not offer actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited novelty of the proposed method and its similarity to other attentional modules in previous works. It specifically mentions that the group attention design is related to ResNeSt but not discussed in the paper. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should discuss the similarities and differences between their work and previous ones, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"group attention design\" and \"ResNeSt,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty and the similarity to other attentional modules in previous works, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules in previous works. The reviewer supports this claim by referencing specific works, such as ResNeSt, and noting that the group attention design is related to these works but not discussed in the paper. However, the comment lacks detailed comparisons or specific examples from these works to fully substantiate the claim. While the references provide some context, the comment could be strengthened with more detailed comparisons or specific examples to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the proposed method, noting that it is too similar to other attentional modules in previous works. It specifically mentions the group attention design and its relation to ResNeSt, which is not discussed in the paper. This feedback is valuable as it highlights a potential weakness in the originality of the work, prompting the authors to address this issue. However, the comment could be more helpful if it provided suggestions on how to differentiate the method or discuss its unique aspects. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should directly illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials, resulting in high cosine similarity. This feedback is explicit and provides a clear action for the authors to take, which is to illustrate the results of the latter loss term. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 3 e.\" and \"Eqn 13,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the illustration of the results of the latter loss term in Eqn 13, given that the preactivation values of two networks are the same membrane potentials. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results of the latter loss term of Eqn 13 should be illustrated, given that the preactivation values of two networks are the same membrane potentials, resulting in high cosine similarity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this illustration is necessary or how it would enhance the understanding of the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, specifically suggesting that the authors should illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the results. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it explained why this illustration is important or how it would benefit the reader. Overall, the comment is 4, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. It suggests that a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a comparison with TTA methods to prove the superiority of data processing over model parameter adjustment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with testtime adaptation (TTA) methods, specifically mentioning [AB]. The reviewer suggests that such a comparison should be made based on experimental results to prove that data processing is superior to model parameter adjustment. However, the comment does not provide specific examples or references to support the claim that TTA methods are relevant or how they could be applied to the paper. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of comparison with testtime adaptation (TTA) methods, such as [AB]. This is a critical observation as TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise. The reviewer suggests that a comparison with TTA methods could provide valuable insights into the effectiveness of data processing versus model parameter adjustment. While the comment highlights an important area for improvement, it does not offer specific guidance on how to conduct such a comparison or what specific aspects to focus on. This limits the comment\"s helpfulness, as it points out a significant weakness but does not provide actionable steps for the authors to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific error in the first expression for J (\u03b8) and suggests that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This provides a clear and concrete action for the authors to correct the mistake in their draft. The comment is explicit and provides a direct action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J (\u03b8), suggesting that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first expression for J (\u03b8) is incorrect and should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the first expression for J (\u03b8) in Section 3.2.1, noting that it should be Q(s_t^0, \u03c0_\u03b8(s_t^0)). This is a clear and actionable piece of feedback that can help the authors correct a mistake in their draft. By pointing out the error, the reviewer provides the authors with a direct path to improve the accuracy and clarity of their work. However, the comment could be more helpful if it included a brief explanation of why this correction is necessary or how it affects the overall understanding of the paper. Overall, the comment is 4 as it directs the authors to a specific area needing correction, but it could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with capitalization in the paper, including specific references that need capitalization. It also mentions that various words in the references need capitalization. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues. The authors are left to infer that they should review and correct the capitalization in the references and in the text. The action is implicit and somewhat vague, as it lacks detailed guidance on how to implement the corrections. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p. 8\" and \"Various words in many of the references need capitalization,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the capitalization issues in the references and the text, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about capitalization issues in the paper and references. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several capitalization errors in the paper and references, which is a clear and actionable piece of feedback. It provides specific guidance on where these errors occur, allowing the authors to easily correct them. Additionally, the reviewer points out that many references need capitalization, which is a helpful observation that can improve the overall presentation of the paper. However, the comment could be more helpful if it included suggestions on how to consistently apply capitalization rules throughout the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the missing parameter values for task 1 and the Boltzmann policy, specifically asking about the model parameters and the method used to choose them. While it identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more information about the parameter choices and methodology, but the comment lacks concrete guidance on how to present this information. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tasks, such as \"task 1\" and the Boltzmann policy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking about the model parameters and the method used to choose them, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification about specific parameter values and the method used to choose them. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity, specifically regarding the model parameters and the method used to choose them. It asks about the parameters for task 1 and the Boltzmann policy, as well as how the parameters were chosen (e.g., maximum likelihood estimates). This feedback is clear and actionable, as it directs the authors to provide more detailed information about the methodology and parameter choices. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar details have been addressed in similar works. Overall, the comment is 4 as it effectively guides the authors to improve the clarity and completeness of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors can infer that they need to conduct comparisons to validate their results, making the action implicit but still clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. However, the comment does not specify which part of the paper this claim is made in, nor does it provide details on what specific comparisons should be conducted. While the authors might have an idea of where this claim is made, the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact section that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. The reviewer implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment provides a logical reasoning for the need for such comparisons, it lacks specific examples or references to support the claim that the performance is mainly due to the first step. This makes the claim 3, as the authors would need to conduct the suggested comparisons to fully understand and address the reviewer\"s concern.", "helpfulness_rationale": "The review comment questions the authors\" claim of achieving stateoftheart results on challenging scene text recognition tasks, suggesting that the performance is mainly due to the first step. It implies that the authors should conduct comparisons experiments with existing detection methods to substantiate their claims. While the comment identifies a potential weakness in the paper\"s claims, it lacks specific guidance on how to conduct these comparisons or what aspects of the experiments should be compared. This limits the comment\"s helpfulness, as it provides a direction for improvement but does not offer detailed instructions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why they believe applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 deteriorates performance compared to only applying it to layers 3 and 4. It provides a clear and direct action for the authors to take, which is to provide an explanation or rationale for this observation. The comment is specific and actionable, as it guides the authors on how to address the issue by offering a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the deterioration in performance when Conditional Batch Norm (CBN) is applied to layers 2, 3, and 4 compared to only layers 3 and 4. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that applying Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2 deteriorates performance compared to only applying it to layers 3 and 4. However, the comment lacks specific details or evidence to support this claim, such as data or analysis that demonstrates the performance difference. Without such supporting information, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of Conditional Batch Norm (CBN) to layers 2, 3, and 4 in Table 2, noting that this deteriorates performance compared to only applying it to layers 3 and 4. It prompts the authors to explain why they believe this is happening and suggests that the authors provide an explanation or rationale for this observation. This feedback is clear and actionable, as it directs the authors to address a specific issue that could impact the paper\"s conclusions. However, the comment could be more helpful if it provided additional guidance on how to investigate or resolve the issue. Overall, the comment is 4 as it highlights a potential area for improvement and offers a clear direction for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. The reviewer clearly states that the authors should include a comparison of their method with the one proposed in [1]. This feedback provides a direct and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, specifically mentioning [1] and its proposed approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with the method proposed in [1]. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comparison with a highly relevant method, specifically mentioning [1] and its approach of utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparison with a highly relevant method, [1], which proposes a method for utilizing previous knowledge with intertask ensemble and enhancing current tasks with intratask ensemble. By highlighting this omission, the comment provides the authors with a clear and actionable suggestion to include a comparison with the method proposed in [1]. This feedback is valuable as it directs the authors to a potential enhancement that could strengthen their work. However, the comment could be more helpful if it included specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it effectively points out a gap in the paper and offers a concrete suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the required implicit call to the Witness oracle is confusing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or suggesting a specific approach to improve the clarity. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"Witness oracle,\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the Witness oracle is confusing or how it could be clarified. The comment lacks specificity regarding the issue and does not provide guidance on how to address it. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the required implicit call to the Witness oracle being confusing. This feedback is 3 as it points out a potential source of confusion for readers, which could impact the clarity and accessibility of the paper. However, the comment lacks depth and does not provide suggestions on how to clarify or improve the explanation of this concept. While it highlights an area for improvement, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed method\"s inability to handle headpose and questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method. The comment implies that the authors should consider incorporating headpose control into their method, but it lacks concrete steps or detailed instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"headpose,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the method cannot handle headpose and why it cannot be conditioned like a previous work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that a previous work (e.g., Gafni et al. ICCV 2021) is able to control both facial expression and headpose. The reviewer questions why the NeRF method cannot condition the headpose parameters beyond facial expression, similar to the previous work. This claim is 3 as it references a specific work, providing some basis for the comparison. However, the comment lacks detailed explanation or examples of how the NeRF method could be adapted to handle headpose, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, specifically its inability to handle headpose. It questions why the authors cannot condition the headpose parameters in the NeRF beyond facial expression, similar to a previous work. This feedback is 3 as it points out a gap in the methodology and suggests a potential area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or incorporate headpose control into their method. While it highlights an important area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It references specific examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific actions to take. The authors are left to infer that they should investigate the impact of these spurious features and consider ways to mitigate their influence on the model. Therefore, the comment is 3, as it implies an action but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the similarity between the spurious features and backdoor triggers, and it provides examples from Chen et al. (2017) and Gu et al. (2019) to support its claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns that only appear a few times in the training set. The reviewer supports this claim by referencing specific examples from Chen et al. (2017) and Gu et al. (2019), where backdoor triggers are used. This provides a logical basis for the claim, as it highlights a known issue in the literature that could impact the model\"s performance. However, the comment could be strengthened by providing more detailed examples or additional references to further substantiate the claim. Therefore, the comment is 4, as it provides a solid foundation but lacks complete evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers. It provides a clear and actionable suggestion by referencing specific examples from Chen et al. (2017) and Gu et al. (2019), which are wellknown studies on backdoor triggers. This feedback is valuable as it alerts the authors to a potential problem in their work and suggests a direction for further investigation or mitigation. However, the comment could be more helpful if it offered additional guidance on how to address this issue or what specific steps the authors should take to investigate or mitigate the impact of these spurious features. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization component is emphasized several times but notes that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The comment lacks concrete actions or detailed suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses this component, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which could be confusing and reduce the contribution. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization component is emphasized several times but that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the emphasis on structural optimization and the direct use of an optimization algorithm from previous works. This observation highlights a potential confusion in the contribution of the paper, which could be clarified or addressed by the authors. However, the comment lacks specific suggestions or guidance on how to improve the clarity or originality of the contribution. While it points out a potential weakness, it does not provide actionable feedback for the authors to enhance the paper. Therefore, the comment is 3, as it offers insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue with the baseline models or how to improve the pipeline style method. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the pipeline style method, which includes two models, and notes that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the pipeline style method, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what needs to be addressed regarding the baseline models or the pipeline style method. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. Additionally, it notes that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the pipeline style method, which includes two models, not yielding better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. However, the comment lacks specificity and actionable suggestions for improvement. It does not provide guidance on how the authors might address the issue with the pipeline style method or improve the baseline models. Without detailed feedback or constructive advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve their methodology. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their methodology but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. It questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. However, the comment does not specify which part of the paper this observation is made in, nor does it provide details on what specific aspects of the methodology are problematic. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in the methodology. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the authors are reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that this observation is unnecessary. The authors may find it challenging to fully understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for reproducing a wellknown result about left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology of passing a binary stance classifier over ChatGPT\"s output. The reviewer questions why this observation needs to be made using the authors\" methodology, as it has been made in previous works. This feedback highlights a potential redundancy in the authors\" approach and suggests that they might need to reconsider their methodology or provide a more novel contribution. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing a specific work ([A]). This direct suggestion provides a clear and concrete action for the authors to take, ensuring that they are aware of the relevant literature and can incorporate it into their introduction. The comment is 5 as it clearly specifies what needs to be added to the paper, making it easy for the authors to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of related work on modular networks for VQA, such as [A]. This provides clear guidance on how to improve the introduction by adding relevant references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is crucial to mention related work on modular networks for VQA, specifically referencing work [A]. This claim is 3 as it logically suggests that including this work would provide a more comprehensive overview of the related literature. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as explaining why this work is particularly relevant or how it relates to the current paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section of the paper, noting that it seems to imply that no one does modular architectures for VQA. It suggests that the authors should mention related work on modular networks for VQA, such as [A], to provide a more comprehensive overview of the literature. This feedback is clear and actionable, as it directs the authors to include relevant references that could enhance the introduction section. However, the comment could be more helpful if it explained why this reference is particularly important or how it relates to the current work. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and do not compare their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons to other methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the need to contrast the method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of comparison with other methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being compared. Without detailed comparisons or references, the claim is not fully substantiated, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the authors primarily focus on SSC and do not contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are also computationally efficient and come with similar guarantees. This feedback is 3 as it points out a gap in the paper\"s comparison with other methods, which could enhance its comprehensiveness and relevance. However, the comment lacks specific suggestions on how to address this issue or which methods to include in the comparison. To be more helpful, the comment could provide examples of how these other methods might be integrated or what specific aspects to focus on in the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to clarify the distinction between when the proposed method is trained using only weak supervision and when it is semisupervised trained. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction. Additionally, the reviewer proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. These suggestions are clear and provide specific guidance on how to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between weak supervision and semisupervised training and the renaming of the column in Table 1. The comment also provides a detailed suggestion for improving the clarity of the table by suggesting the creation of two columns for data sources. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the distinction between weak supervision and semisupervised training, specifically in Table 1. The reviewer provides a specific example of the proposed framework row in Table 1, suggesting that it refers to the semisupervised version of the method and recommends renaming the column to \"Fully supervised\" from \"Supervised.\" The reviewer also proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This suggestion is based on logical reasoning and common knowledge about the distinction between weak supervision and semisupervised training. The comment is 4 as it provides a clear rationale for the claim and offers a concrete suggestion for improvement.", "helpfulness_rationale": "The review comment is 5 as it provides clear and actionable feedback on improving the clarity of the paper. It identifies a specific issue with the distinction between weak supervision and semisupervised training, which is important for understanding the methodology. The reviewer suggests renaming the column in Table 1 to \"Fully supervised\" from \"Supervised\" to reflect this distinction, and proposes a more detailed approach by suggesting the creation of two columns, \"Mixture training data\" and \"Single source data,\" to specify the data used for each model. This feedback is detailed and constructive, empowering the authors to make significant improvements to their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment implies that the authors should address this issue by improving the novelty or differentiating aspects of their work, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should focus on enhancing the novelty or differentiating aspects of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. It also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. However, the comment does not specify which part of the paper discusses these contributions or how they are evaluated. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, the comment does not provide specific examples or detailed reasoning to support these claims. It mentions that it is difficult to differentiate the paper from its predecessors, but it does not explain why this is the case or how the paper could be improved in this regard. The lack of specific examples or detailed reasoning makes the claim 3, as the authors would need to infer the basis of the critique and potentially make additional efforts to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper makes small contributions over previous methods (NCNet [6] and Sparse NCNet [21]) and that it is mostly good engineering. However, it also notes that it is difficult to differentiate the paper from its predecessors, as it performs similarly in practice. While the comment identifies a potential weakness in the paper\"s novelty or differentiating aspects, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove the statement about semantic segmentation being a lowlevel cue, as it is not accurate given that categories are specified for each pixel. This feedback is clear and concrete, providing a direct action for the authors to take. The comment is specific and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the term \"semantic\" segmentation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the statement about semantic segmentation being a lowlevel cue is incorrect, given that categories are specified for each pixel. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about semantic segmentation being a lowlevel cue is incorrect, as categories are specified for each pixel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is valid. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the use of the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, making the statement about semantic segmentation being a lowlevel cue inaccurate. This feedback is clear and actionable, as it directs the authors to remove or revise the statement to avoid misleading the reader. However, the comment could be more helpful if it provided additional context or suggestions on how to rephrase the statement to be more accurate. Overall, the comment is 4 as it effectively guides the authors on how to improve the clarity and accuracy of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the tables. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or correct the results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance without reinforcement learning (RL) dropped lower than without dependency tree, and that the tables do not list the cases where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning (RL) dropped lower than without dependency tree in the ablation experiment. However, it does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Additionally, the comment mentions that the two tables do not list the cases where dependency tree and RL are not used, but it does not explain why this is a concern or how it affects the results. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the results of the ablation experiment, noting that the performance without reinforcement learning (RL) dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights an area where the authors need to clarify or correct their results. However, the comment lacks specific suggestions on how to address the discrepancy or what additional information should be included in the tables. While it provides some direction, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies the main weakness of the paper as the lack of comprehensive experimental evaluation, specifically the limited consideration of datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. While the comment provides a clear direction for improvement by recommending specific works to consider, it does not explicitly instruct the authors on how to incorporate these works into their evaluation or how to address the identified weakness. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the main weakness of the paper, which is the lack of comprehensive experimental evaluation on different datasets and model types. The comment suggests that the authors should consider relevant works like FedProx and FedMAX for details on different datasets and model types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main weakness of the paper is the limited scope of the experiments, specifically the use of only the CIFAR10 dataset and the lack of consideration of other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. While the comment provides a logical reasoning for the need to consider additional datasets, it lacks specific examples or references to these works, making it 3. The authors would need to infer the relevance of these works and how they might impact the evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments, which only consider the CIFAR10 dataset and do not consider other datasets from Federated learning benchmarks. It suggests that the authors should consider relevant works like FedProx and FedMAX to expand the experimental evaluation. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the comprehensiveness and relevance of their experiments. By addressing this feedback, the authors can significantly improve the quality and impact of their paper. However, the comment could be more helpful if it provided additional details on how these works might be integrated or what specific aspects of the experiments should be considered. Overall, the comment is 4 as it effectively directs the authors to a valuable area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve their draft. The comment implies that the authors should consider using another dataset, but it lacks concrete details on how to implement this suggestion or what specific aspects of the claim need to be revised. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the table and the claim about accuracy and completeness, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the claim and suggests using another dataset for the ablation study. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed modules improve both accuracy and completeness, suggesting that another dataset could be used for the ablation study. This is a constructive suggestion that could help the authors strengthen their argument by providing additional evidence or comparisons. However, the comment lacks specific guidance on which dataset to use or how to conduct the ablation study, which would make it more actionable. Overall, the comment is 3 as it identifies a potential weakness in the claim but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. It also questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer asks whether the authors argue that identifying one vulnerability at a time is an intended use case. While the comment highlights areas of concern, it does not provide explicit guidance on how the authors should address these issues or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should consider multiple vulnerabilities and justify their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vulnerability discovery methodology\" and the \"single vulnerability\" approach, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the ecological validity of the study and suggesting that previous work has considered multiple vulnerabilities. The comment further highlights the difficulty in interpreting the results and whether the authors are arguing for a singlevulnerability approach. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the vulnerability discovery methodology, specifically questioning the authors\" approach of considering only a single vulnerability at a time. The reviewer questions the ecological validity of such a study and suggests that previous work has considered multiple vulnerabilities simultaneously. The comment also points out that the results are difficult to interpret, or at best, marginal improvements. While the comment provides a logical basis for questioning the methodology, it lacks specific references to external works or detailed reasoning to fully substantiate the claim. This makes the comment 3, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the vulnerability discovery methodology, questioning the authors\" approach of considering only a single vulnerability at a time. It highlights the potential problem of ecological validity and suggests that previous work has considered multiple vulnerabilities simultaneously. The reviewer also points out that the results are difficult to interpret, or at best, marginal improvements. This feedback is valuable as it challenges the authors to reconsider their methodology and potentially improve the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or improve the methodology. Overall, the comment is 3 as it prompts the authors to reevaluate their approach, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It suggests that additional explanations are needed to address this issue. However, the comment does not provide specific guidance on how to provide these explanations or what aspects of the relationship should be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations but without concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in understanding the relationship between degree bias and the clearer community structure demonstrated by the theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2 is not intuitive enough. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or explanation to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the relationship between degree bias and the clearer community structure demonstrated by Theorem 1 and 2. It points out that while the theorems prove conformity to a clearer community structure, the relationship with degree bias is not intuitive. This feedback is valuable as it highlights a potential gap in the paper\"s explanation, which the authors can address to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify this relationship or examples of how other works have addressed this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors are left to infer that they need to clarify this aspect of their work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the construction of clean exemplar manifolds for a nonstochastic network and how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for a nonstochastic network, specifically asking about the denominator of Figure 2.c for the ResNet50 and ATResNet50 networks. The comment is 3 as it highlights a potential inconsistency in the paper, but it lacks specific examples or references to support the claim that the construction of clean exemplar manifolds is unclear. The authors might need to provide additional clarification or examples to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the construction of clean exemplar manifolds for a nonstochastic network. It raises a specific question about how the denominator of Figure 2.c is computed for the ResNet50 and ATResNet50 networks, which is a critical aspect of the methodology. By pointing out this discrepancy, the comment provides the authors with a clear and actionable step to address a potential weakness in their work. However, the comment could be more helpful if it offered suggestions on how to clarify this issue or provided examples of how similar questions have been addressed in related literature. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, it does not provide explicit guidance on what additional information is needed or how to clarify this notation. The comment implies that the authors should provide more information, but it lacks concrete steps or suggestions on how to address the issue. As a result, the action is implicit and vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it is confusing. However, it does not specify which part of the paper this notation is used in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does provide some specificity by indicating that more information is required, such as what S and Xt represent. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its request for additional information. This aligns with a score of 3.", "verifiability_rationale": "The review point expresses confusion about the notation used to separate \"static\" and temporal features into two variables, specifically mentioning that it requires more information than is provided in the paper. However, the comment does not provide any specific reasoning or examples to support this claim, nor does it offer suggestions for how the authors might clarify the notation. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the notation used to separate \"static\" and temporal features into two variables. It points out that this notation is confusing and requires more information than what is provided in the paper. While the comment highlights a potential issue, it lacks specific guidance or suggestions on how the authors might clarify this notation or provide additional information. The feedback is 3 as it directs the authors to a specific area that needs clarification, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be more detailed, particularly in the definitions of the resistance distance and explanations of Algorithm 1. While it implies that more details should be provided, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper deals with many graph notions and is somewhat hard to understand, but the writing is generally good. It provides specific feedback by mentioning the need for more details, particularly in the definitions of the resistance distance and explanations of Algorithm 1. The authors can infer that these are areas that need attention, but the comment does not explicitly mention which sections or parts of the paper these issues pertain to. Therefore, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the need for more detailed explanations. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is difficult to understand due to its focus on graph notions, but it also acknowledges that the writing is generally good. The comment provides a specific suggestion for improvement by recommending more detailed explanations, particularly for the definitions of the resistance distance and Algorithm 1. This feedback is 3 as it identifies a potential area for improvement but lacks detailed guidance on how to achieve it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s complexity, noting that it deals with many graph notions and is somewhat hard to understand. However, it acknowledges that the writing is generally good. The comment provides specific suggestions for improvement by recommending the inclusion of more detailed explanations, particularly for the definitions of the resistance distance and Algorithm 1. This feedback is actionable and can help the authors enhance the clarity and accessibility of their paper. However, the comment could be more helpful if it provided examples or guidance on how to present these explanations. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the originality or suggest alternative approaches to improve the paper. As a result, the authors are left without any clear direction on how to improve the originality of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of originality, specifically mentioning that the main idea of variable splitting is not new and the algorithm is not new. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is considered unoriginal, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the originality of the paper is limited due to the main idea of variable splitting being not new and the algorithm not being new. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a limitation in the originality of the paper, specifically noting that the main idea of variable splitting is not new and the algorithm is not new. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the evaluation of shape model invariance, specifically asking if there are any quantitative results on testing images. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide quantitative results on testing images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the evaluation on transformations of training images and asks for quantitative results on testing images. This provides clear guidance on what additional information is needed to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the evaluation on transformations of training images for the shape model invariance study. It suggests that quantitative results on testing images might be needed to fully prove the point. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the evaluation of shape model invariance, specifically questioning the use of transformations of training images to prove the point. It suggests that quantitative results on testing images might be necessary to fully substantiate the claim. This feedback is 3 as it identifies a potential gap in the evaluation process and prompts the authors to consider additional evidence. However, the comment could be more helpful if it provided specific suggestions on how to conduct the testing or what types of quantitative results might be relevant. Overall, the comment offers a constructive direction for improvement, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the omission of a related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. The comment is clear and provides a direct action for the authors to take, which is to include a discussion of the related work. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of this related work and its potential impact on the understanding of the stateoftheart. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati is a related work that should be discussed and compared with the current work. The reviewer provides a logical reasoning by suggesting that the AAAI15 paper deals with hypergraph data with tensors, which is relevant to the current work. However, the comment lacks specific examples or references to the content of the AAAI15 paper, making it 3. The authors would need to conduct additional research to fully understand the relevance and potential contributions of the related work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific related work, the AAAI15 paper titled \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which is relevant to the current work but has been overlooked. It suggests that this paper should be discussed and compared with the current work to provide a better understanding of the stateoftheart. This feedback is clear and actionable, as it directs the authors to include a discussion of the related work and its implications. By addressing this suggestion, the authors can enhance the comprehensiveness and relevance of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it would be beneficial to test its scalability on normal machines with a few cores. It also questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific tests should be conducted. The action is implicit and somewhat vague, as the authors need to infer that they should test scalability and clarify the computation of optimal transport. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Approach\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the scalability of the method and questions how the authors compute the optimal transport distance, particularly in relation to the Sinkhorn method. The comment provides clear guidance on what needs to be addressed, such as testing scalability on normal machines and clarifying the computation of optimal transport. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the scalability of the method and the computation of optimal transport distance, suggesting that it is not clear how scalable the method is. The reviewer questions how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. While the comment identifies potential issues, it lacks specific examples or references to support the claim that the method is not scalable or how it could be improved. The lack of detailed evidence or examples makes the claim 3, as the authors would need to make a significant effort to understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of the method and its computation of optimal transport distance. It raises questions about how the authors compute the exact optimal transport, given that the Sinkhorn method produces a doubly stochastic matrix. This feedback is valuable as it prompts the authors to consider the scalability of their method on normal machines with a few cores, which is an important aspect for practical applications. Additionally, the comment highlights the need to clarify the computation of optimal transport, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to test scalability or how to address the computational issue. Overall, the comment is 4 as it provides actionable feedback on areas that need further exploration and clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is extremely hard to follow, indicating that the authors need to improve the clarity and accessibility of their experimental procedures and evaluations. However, it does not provide specific guidance on how to achieve this improvement, such as recommending changes to the structure, language, or presentation of the paper. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the paper is difficult to follow, specifically mentioning the experimental procedures and evaluations. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without explicit references to sections or details, the authors cannot confidently determine which parts need improvement. The comment is specific in identifying the issue of clarity but lacks grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" suggesting that the experimental procedures and evaluations are unclear. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific references or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is \"extremely hard to follow.\" This feedback highlights a critical weakness in the clarity and accessibility of the experimental procedures and evaluations, which is crucial for readers to understand and replicate the work. However, the comment lacks specific suggestions or guidance on how the authors might improve the clarity or structure of their paper. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path to address it. Therefore, the comment is 3, as it points out a significant issue but does not provide enough detail for the authors to make meaningful improvements."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide specific guidance on what aspect of the claim is questionable or how it could be improved. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made in section 2 that INRs operate on a perdatainstance basis, suggesting that this is not an advantage. The reviewer points out that a model that can only handle a single time series data is almost useless. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors might address this concern or what aspects of the claim might be misleading or inaccurate. As a result, the comment is not helpful, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to consider introducing specific aspects of their model that are relevant to the example model. It provides a clear and concrete action for the authors to take, specifying that they should clarify the model\"s specificity in relation to the infinite subdivisions and bounded parameters. This guidance is direct and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of specific aspects of the model that are relevant to the example model. The comment provides guidance on what should be clarified, such as the setting with infinite subdivisions and bounded parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should introduce specific aspects of their model that are relevant to the example model, such as clarifying the setting with infinite subdivisions and bounded parameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they impact the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors introduce specific aspects of their model that are relevant to the example model. It highlights the need to clarify the setting with infinite subdivisions and bounded parameters, which are crucial for understanding the model\"s applicability. This guidance is clear and constructive, as it directs the authors to enhance the clarity and comprehensiveness of their draft. By addressing these points, the authors can improve the transparency and accessibility of their work, making the comment 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. Additionally, it recommends including more analysis and discussion for GPT2, specifically asking for the results of Figure 2 for GPT2. While the comment provides explicit actions and concrete details on what needs to be done, it could be more helpful if it explicitly instructed the authors on how to conduct these analyses or provided examples of what such analyses might entail. Overall, the comment is 4 as it clearly outlines specific steps for improvement, but it could be more detailed in its guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1.1\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to investigate whether the results can be generalized to other models, differences in model size, objective function, and architecture, and the inclusion of more analysis and discussion for GPT2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and questions whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture. The reviewer provides a logical reasoning by pointing out that the experiments should be expanded to include more models, such as GPT2, to test generalizability. However, the comment lacks specific examples or references to support the claim that these differences would significantly impact the results. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically that most of them are limited to RoBERTabase and question whether the results can be generalized to other models. It suggests that the authors should investigate whether the results can be generalized to differences in model size, objective function, and architecture, and recommends including more analysis and discussion for GPT2. The comment provides clear and actionable feedback by specifying what needs to be addressed and offering a concrete suggestion for improvement. By recommending additional analyses and discussions, the comment empowers the authors to enhance the robustness and generalizability of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. While the comment implies that the authors should explore these applications, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their work to include these other areas. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the model and the experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the applicability of the model and experiments to other research areas, such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. However, the comment lacks specific examples or references to support the claim that the model and experiments are limited to image data and ViT. Without such evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the model and experiments to other research areas, specifically NLP and simpler models in the image domain (CNNs). It suggests that the authors should consider applying the same principles to these areas to demonstrate generalizability. This feedback is valuable as it encourages the authors to expand their work beyond the current focus on image data and ViT, which could enhance the method\"s versatility and broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might explore these other areas. Overall, the comment is 4 as it directs the authors to consider a broader applicability of their work, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should evaluate TTA methods on more conditions of natural distribution shift, like WILDS [9], to strengthen the paper. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Performance of TTA methods,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, like WILDS [9], which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using nonstandard benchmarks breaks popular TTA methods and proposes evaluating TTA on more conditions of natural distribution shift, like WILDS [9]. While the comment provides a logical reasoning for the importance of this evaluation, it lacks specific examples or references to support the claim that nonstandard benchmarks break popular TTA methods. This makes the claim 3, as the authors would need to make a significant effort to understand and verify the claim on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies an interesting observation about the performance of TTA methods under nonstandard benchmarks, suggesting that evaluating these methods on more conditions of natural distribution shift could strengthen the paper. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to implement this evaluation or what specific conditions should be considered. The feedback is 3 as it points out a potential enhancement but does not provide detailed instructions or examples for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. The reviewer suggests that this condition is not realistic and may lead to unreasonably large learning rates when learning on largescale datasets. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on whether the authors should adjust the condition, provide a rationale for its necessity, or explore alternative approaches. As a result, the authors are left without actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. It provides a clear rationale for why this condition is not realistic, as it leads to unreasonably large learning rates when learning on largescale datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the learning rate condition and its implications, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the condition on the learning rate is not scalable, as it does not grow with the number of samples in practice. The reviewer provides a logical reasoning by explaining that this condition leads to unreasonably large learning rates when learning on largescale datasets. However, the comment lacks specific examples or references to support the claim that this condition is not realistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the condition on the learning rate, noting that it does not scale with the number of samples in practice. This is a critical observation, as it highlights a potential flaw in the methodology that could lead to unreasonably large learning rates when learning on largescale datasets. The reviewer provides a logical reasoning for why this condition is not realistic, which is valuable for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or explore alternative approaches. Despite this, the feedback is 4 as it points out a critical weakness in the methodology and provides a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects of the paper need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of tensor networks to represent PMF of discrete variables and questions the significance of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the utility of tensor networks and the significance of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the utility of tensor networks in representing PMF of discrete variables and questions the significance of the paper. It highlights a potential weakness in the paper\"s contribution, which could impact its impact and relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the paper\"s significance. While it points out a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use a more convincing setting for training, similar to that used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. It provides a specific reference to the paper by He et al. (EMNLP 2018) as an example of a convincing setting. This feedback is explicit and provides a clear action for the authors to take, which is to adopt a more convincing setting for their training process. The comment is concrete and provides a concrete example of what the authors should do to improve their draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version)\" and suggests that the label distribution of unlabeled data during training is impractical in realworld applications. It also provides a specific suggestion to use a more convincing setting, such as that used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unlabeled data from the preprocessed Amazon review dataset is perfectly balanced, which is impractical in realworld applications. The reviewer suggests that the authors should use a more convincing setting, such as that used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. The comment provides a specific reference to the paper by He et al. (EMNLP 2018) to support the suggestion. This reference provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the unlabeled data from the preprocessed Amazon review dataset, noting that it is perfectly balanced, which is impractical in realworld applications. It suggests that the authors should use a more convincing setting, such as that used in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification. The comment provides a clear and actionable suggestion for improvement by referencing a specific paper, which can guide the authors in making their dataset more realistic and applicable to realworld scenarios. However, the comment could be more helpful if it explained why this setting is more convincing or how it might impact the results. Overall, the comment is 4 as it provides a clear direction for improvement but could be expanded to be fully comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity regarding how to sample from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the sampling process, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq (10) line 130,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar problem with sampling from the leverage score in [3]. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar issue in [3]. However, it does not provide specific examples or detailed reasoning to support the claim that sampling from the DPP is more difficult than sampling from the leverage score. The comment lacks explicit evidence or references to substantiate the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide clear guidance on how to improve the draft. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of sampling from the DPP when the eigenfunctions e_n are inaccessible, referencing a similar problem in [3]. It questions the ease of sampling from the DPP compared to the leverage score, suggesting that the authors should clarify this aspect. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it points out a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the submission\"s contributions regarding understanding the properties of episodic training. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to evaluate the generalizability. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation to include other fewshot learners, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation on the generalizability of observations to fewshot learners beyond Prototypical Networks. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the evaluation section. However, the comment is not specific as it does not detail what specific aspects of the evaluation are missing or how the authors could address this issue. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the observations presented do not evaluate the generalizability to fewshot learners beyond Prototypical Networks, which may limit the scope of the paper\"s contributions regarding understanding the properties of episodic training. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the generalizability of observations to fewshot learners beyond Prototypical Networks. It points out that this limitation may impact the scope of the paper\"s contributions regarding understanding the properties of episodic training. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing examples of other fewshot learners or offering suggestions on how to evaluate generalizability would enhance the helpfulness of the comment. As it stands, the comment is 3, as it directs the authors\" attention to a critical area for improvement but does not fully support them in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address this issue, specifically asking for guidance on how to deal with the problem. However, the comment does not provide explicit instructions or concrete suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to consider the contribution of different modalities and address the problem, but the comment lacks detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the contribution of different modalities of different instances, specifically mentioning modalities A and B and their performance in different instances. It raises a question about how to deal with the problem of removing the modal subset of all instances, as described in Equation 3. This provides full grounding as it clearly identifies the part of the paper being addressed, which is the discussion of modalities and their contribution. The comment is also specific because it details the issue of removing the modal subset and asks for guidance on how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the contribution of different modalities of different instances, specifically mentioning that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer questions how to address the problem of removing the modal subset of all instances, as described in Equation 3. However, the comment lacks specific examples or references to support the claim that the contribution of different modalities is different. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the contribution of different modalities of different instances. It points out that some instances perform well with modality A, which is considered strong, while others perform well with modality B, also considered strong. The reviewer raises a question about how to address the problem of removing the modal subset of all instances, as described in Equation 3. This feedback is 3 as it highlights a potential weakness in the paper and prompts the authors to consider how to handle this issue. However, the comment could be more helpful if it provided suggestions or examples on how to address this problem or how to incorporate this information into the paper. Overall, the comment is 3 as it directs the authors to consider a specific aspect of their work but lacks detailed guidance or actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback provides clear and concrete actions for the authors to take, such as adding a description of the evaluation process and addressing language issues. The comment is specific and direct, giving the authors a clear understanding of what needs to be added or improved. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues on page, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it does a good job explaining the proposed idea but lacks a description of how the idea was evaluated and what the outcome was. It also mentions minor language issues on page. This feedback is clear and actionable, as it provides the authors with a concrete direction for improving their draft by adding a description of the evaluation process and addressing language issues. However, the comment could be more helpful if it offered suggestions on how to structure the evaluation section or provided examples of what such a description might look like. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the absence of experiments on a specific setting. It highlights the need for experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. While the comment identifies a specific issue with the experimental section, it does not provide explicit guidance on how to address this concern. The authors are left to infer that they should include experiments on these settings, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific setting of the POMDP problem with nonconvex value functions. It also specifies the issue with the experiments section, noting the absence of experiments on surveillance in museums with thresholded rewards and privacypreserving data collection. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the experimental results, specifically the absence of experiments on specific settings. It references the examples of surveillance in museums with thresholded rewards and privacypreserving data collection as motivating cases for the paper. However, the comment lacks specific evidence or detailed reasoning to support why these examples are insufficient or why the experiments are not useful. The claim is 3, as it highlights a potential issue but does not provide sufficient justification or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, questioning the validity of the paper\"s claims. It points out the absence of experiments on specific settings, such as surveillance in museums with thresholded rewards and privacypreserving data collection, which are used as motivating examples. This feedback highlights a critical gap in the experimental section, making it clear that the authors need to address this issue to strengthen their paper. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors\" attention to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. It questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper. The comment implies that the authors should clarify this confusion by providing more detailed explanations or examples. However, it does not explicitly instruct the authors to make these changes or suggest specific ways to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should address the confusion and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Method Section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the use of sparse labels and the notation for target domain \u03c4. The comment further questions the use of unlabeled data in source domains and references the original MFDA paper by Yue et al. (2021a) for clarification. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of the MFDA setting in the first paragraph of the Method Section is confusing, particularly regarding the notation for target domain \u03c4 and the use of sparse labels. The reviewer questions whether the unlabeled data in source domains are used during training, as in the original MFDA paper by Yue et al. (2021a). The comment is 3 as it provides a logical basis for the confusion, referencing the original paper for clarification. However, it lacks specific examples or detailed explanations to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for target domain \u03c4 is unlabeled and questions the use of sparse labels, which is not consistent with the original MFDA paper by Yue et al. (2021a). The comment also highlights the confusion regarding the use of unlabeled data in source domains during training. By pointing out these inconsistencies and questions, the comment provides clear and actionable feedback for the authors to improve the clarity and accuracy of their description. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how the description could be improved. Overall, the comment is 4 as it directs the authors to a critical area needing clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that an epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It proposes that this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the comment provides a clear rationale for why an epochwise analysis could be valuable, it does not explicitly instruct the authors on how to implement this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the steps to take to incorporate this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an epochwise analysis could be beneficial for understanding the behavior of optimization algorithms, particularly in finite sum settings. It provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms after each full pass of data. Additionally, it suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The suggestion is specific, as it clearly outlines the potential benefits of an epochwise analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. The reviewer provides a specific example of how this analysis could help investigate the effect of batch size or different sampling strategies on the progress of algorithms. The comment also suggests that this approach could aid in comparative analysis of deterministic and stochastic methods. While the suggestion is logical and provides a clear rationale, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence or examples to be fully convincing.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It suggests that an epochwise analysis, particularly in finite sum settings, could help provide insights into the behavior of optimization algorithms. The reviewer highlights the potential benefits of such an analysis, including investigating the effect of batch size or different sampling strategies on the progress of algorithms and aiding in comparative analysis of deterministic and stochastic methods. This feedback is clear and offers a concrete direction for the authors to enhance their analysis and understanding of their results. By incorporating this suggestion, the authors can significantly improve the clarity and depth of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the immense workload, the incremental contribution, and the lack of citation of key baselines. It also points out that the paper focuses on RAG for EHR and suggests that essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG should be introduced. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific details to include. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"details in the article\" and \"your workload is immense,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the contribution being incremental and the lack of citation of key baselines, as well as the need to introduce essential RAG algorithms like MedRetriever and KGRAG. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is incremental and essentially a combination of GraphRAG and GraphCare, referencing the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG. The reviewer supports this claim by referencing specific works, which provides a logical basis for the critique. However, the comment could be strengthened by providing more detailed reasoning or examples of how these algorithms would enhance the paper. Overall, the claim is 4 due to the reference to specific works, but it could be further substantiated with additional details or examples.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the immense workload and the incremental contribution, which are not fully explained. It also points out the lack of citation of key baselines and the absence of essential RAG algorithms like MedRetriever and KGRAG, which are relevant to the paper\"s focus on RAG for EHR. The comment provides specific suggestions for improvement, such as introducing these algorithms and explaining their relevance to the work. However, it could be more helpful if it offered guidance on how to integrate these suggestions into the paper or provided examples of how they could be effectively incorporated. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance on execution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the distinction between the three classes of extreme speech, particularly the difficulty in differentiating between derogatory and exclusionary extreme speech. It questions the annotation of a specific instance in the sample data file and seeks clarification on the local regulation over speech that might influence the classification. The reviewer implies that the authors should provide more detailed explanations or examples to clarify this distinction. While the comment does not explicitly instruct the authors to make changes, it implies a clear action for the authors to take, such as providing additional context or examples to clarify the distinction. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and the \"sample data file,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the distinction between derogatory and exclusionary extreme speech, and it provides a specific example from the sample data file to illustrate the confusion. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the distinction between the three classes of extreme speech, specifically questioning the classification of a specific instance as exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, asking for clarification on the local regulation over speech and its impact on zeroshot crosscountry classification. While the comment identifies a specific issue, it lacks detailed reasoning or references to support the claim that the distinction is unclear. The authors would need to provide additional context or examples to fully address the concern. Therefore, the comment is 3, as it provides a starting point for the authors to improve their draft but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the distinction between the three classes of extreme speech, particularly in the context of the sample data file provided. It questions the classification of a specific instance as exclusionary extreme speech and highlights the potential influence of local regulation on the classification. The comment is 4 as it prompts the authors to clarify the distinction and provide additional context or examples to support their classification. However, it could be more helpful if it offered suggestions on how to address this issue or provided examples of how the distinction could be clarified. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be included in the graph and why it is important. The comment also offers a rationale for why this graph is necessary, helping the authors understand the potential sources of performance improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be included in the graph and why it is important to understand the sources of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This claim is 3 as it logically suggests that such a graph would help clarify whether the performance improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to create a graph showing the plot of T vs. the number of images and the Expectation(T) over the ImageNet test set. This is a specific and detailed piece of feedback that can help the authors better understand the performance improvement and its potential sources. By including this graph, the authors can address the reviewer\"s concern about whether the improvement is solely due to the network design or whether it is influenced by the nature of ImageNet. The comment is also helpful as it provides a rationale for why this graph is important, which can guide the authors in making their work more comprehensive and insightful. Overall, the comment is 5 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper needs to be mathematically correct and provides a specific example by questioning the notation \"L_l\" instead of just \"L.\" It also suggests introducing the notation beforehand. While the comment identifies areas for improvement, it does not provide explicit instructions on how to make these changes or what specific changes should be made. The authors are left to infer that they need to make these corrections, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"L_l instead of just L,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be changed, namely the notation \"L_l\" and the need for mathematical correctness. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper needs to be mathematically correct and questions the notation \"L_l\" instead of \"L.\" It provides a specific example of the notation issue and suggests introducing the notation beforehand. However, the comment lacks detailed reasoning or references to support why this change is necessary or how it would improve the paper. The suggestion is 3 as it identifies a specific issue but does not provide a comprehensive rationale or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"L_l\" instead of \"L\" and suggests that the paper needs to be mathematically correct. It also points out that the notation should be introduced beforehand. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the clarity and correctness of their mathematical expressions. However, the comment could be more helpful if it offered suggestions on how to introduce the notation or provided examples of how it should be used. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of studying the effect of noise accumulation in the context of homomorphic encryption for sequential ensembling. It also notes that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific steps they should take to study the effect of noise accumulation. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sequential ensembling\" and \"homomorphic encryption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of noise accumulation in the context of homomorphic encryption, which prevents the use of even single deep neural networks on homomorphically encrypted data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that noise accumulation in the context of homomorphic encryption is a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the paper regarding the use of deep neural networks on homomorphically encrypted data due to noise accumulation. It highlights the importance of studying this effect in the context of homomorphic encryption. While the comment points out a potential issue, it lacks specific suggestions or guidance on how the authors might address this limitation or what specific experiments could be conducted to study the effect of noise accumulation. The feedback is 3 as it directs the authors\" attention to a relevant area for further exploration, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should consider different timesteps for training and evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the relevance of different timesteps and how they might impact the effectiveness of the proposed methods. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the proposed methods, noting that the performance of the baseline model and the timeaware model is similar when trained and evaluated with the same timestep. This observation raises questions about the novelty and practical relevance of the proposed methods. The comment suggests that the proposed method might make more sense in scenarios where the training and evaluation timesteps are different. While the comment highlights an important point, it lacks specific suggestions or guidance on how the authors might address this issue or explore different timesteps. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of clarity regarding the disentanglement aspect of the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed. The reviewer suggests that the authors should clarify this aspect by explaining how disentanglement is realized and what types of bias are involved. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Broader Impacts and Limitations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how disentanglement is achieved and guaranteed without certain bias types. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that disentanglement is not clearly explained and questions how it is achieved and guaranteed without certain bias types. While the comment references the \"Broader Impacts and Limitations\" section, it does not provide specific examples or detailed reasoning to support the claim that disentanglement is unclear. The reference to the \"Broader Impacts and Limitations\" section suggests that the authors have acknowledged the limitation, but the comment lacks further elaboration or evidence to substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of the disentanglement aspect in the paper. It points out that while the \"Broader Impacts and Limitations\" section acknowledges a limitation related to disentangled latent vectors, it does not provide sufficient detail on how disentanglement is achieved and guaranteed without certain bias types. The comment suggests that the authors should clarify this aspect to enhance the clarity and comprehensiveness of their work. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their paper that could impact its understanding and impact. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, the authors should use a standard regularization trick. While the comment implies that the authors should apply this standard technique, it does not provide explicit instructions on how to implement it or which specific regularization trick to use. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the use of a standard regularization trick, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this standard technique is necessary or how it would improve the comparison. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should use a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case. This feedback is 3 as it identifies a specific area for improvement, namely the need to standardize the regularization technique to ensure a fair comparison. However, the comment lacks depth and does not provide detailed guidance on which specific regularization trick to use or how to implement it effectively. Additionally, it does not address other aspects of the paper, such as its theoretical or empirical contributions. While the comment points out a potential issue, it could be more helpful with additional context and suggestions for improvement. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a clear and concrete action for the authors to take, as it provides a specific enhancement to the figure that would help clarify the impact of mean teacher on learning. The suggestion is direct and leaves no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3\" and \"left graph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, which is a learning curve for a model without mean teacher or pi regularization. This provides clear guidance on how to enhance the figure and compare the impact of mean teacher on learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This is a request for additional data or analysis, which is a factual observation rather than an opinion or claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends adding a learning curve for a model without mean teacher or pi regularization to compare with the current model. This additional information would help clarify the impact of mean teacher on learning, providing valuable insights for the authors. The comment is clear and direct, offering a concrete way to enhance the figure and improve the draft. Therefore, it is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and the disorderly citation style. While the first point suggests a specific area for improvement, it does not provide explicit guidance on how to address it, such as recommending a particular approach or method. The second point about the citation style is more of a general observation, and while it highlights an issue, it does not offer specific suggestions for improvement. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete details on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss how to handle different types of inputs, such as biomedical signals or speech, and suggests that the citation style is disordered. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to discuss solutions for handling different input types and the disorderly citation style. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims: the need to discuss how to handle different types of inputs and the disorderly citation style. The first claim is 3 as it suggests a potential area for improvement, but it lacks specific examples or detailed reasoning on how to address the issue. The second claim about the citation style is more vague, as it does not specify what constitutes disorderly citation or how it could be improved. Therefore, the comment is categorized as 3, as it provides some justification but lacks detailed guidance or examples.", "helpfulness_rationale": "The review comment identifies two areas for improvement: discussing how to handle different types of inputs, such as biomedical signals or speech, and addressing the disorderly citation style. While the comment highlights these issues, it does not provide specific guidance or suggestions on how to address them. The feedback is 3 as it points out areas that could be improved, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, specifically mentioning the OfficeHome dataset where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the implications of Eq. 4 and potentially improve the results in Table 5, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the implications of Eq. 4 and noting the lack of significant improvement in the designed solutions in Table 5, particularly on the OfficeHome dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This claim is 3 as it provides some logical reasoning and examples to support the suggestion that the improvement is not significant. However, it could be strengthened by providing more detailed analysis or references to substantiate the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the implications of Eq. 4 and suggests that the u^l in Eq. 3 might tend to be 1. It also notes that the improvement of the designed solutions in Table 5 is not significant, providing specific examples like the OfficeHome dataset where the CSAC achieves 64.35, and the proposed solution achieves 64.71, indicating a marginal improvement. This feedback is 3 as it points out a potential issue with the results and suggests that the authors might need to reconsider their approach. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or improve the results. Overall, the comment identifies a potential area for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of specific stateoftheart references in the face recognition experiment, particularly mentioning \"Baidu\"s work\" and its reported results. It also highlights the use of the triplet loss and the similarity to the Webface dataset. The comment provides a clear and specific action for the authors to include these references in their work. Additionally, it suggests that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. The action is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment of face recognition\" and the specific references that are missing, such as \"Baidu\"s work\" and the reported results on the dataset containing 9K identities and 450K images. It also provides specific details about the triplet loss and the reported results, which allows the authors to identify the exact parts of the paper that need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some stateoftheart references are missing in the face recognition experiment, specifically mentioning \"Baidu\"s work\" and its reported results. The reviewer provides a specific reference to the work, which is a clear and verifiable claim. Additionally, the comment provides details about the triplet loss and the reported results, which further strengthens the claim. This level of detail and specificity makes the claim 4, as it provides a clear rationale for the claim and supports it with relevant information. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup in the paper, noting the absence of certain stateoftheart references, such as \"Baidu\"s work\" on face recognition. It provides a detailed description of the missing references and their relevance to the current work, including the use of the triplet loss and the reported results on a dataset with 9K identities and 450K images. Additionally, the comment highlights that the VRF achieved a better result than reported in Table 3, which could be a valuable comparison for the authors to make. This feedback is clear and actionable, guiding the authors to include these references and potentially improve the results presented in their paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the generalization. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their approach to question answering, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with the question answering process, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process, which involves template mapping to transform questions into masked statements, might lead to poor generalization to questions that are not \"Whtypes\" or transformable. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to studies or literature that demonstrate the limitations of this approach or how it affects generalization. As a result, the claim is 3, as it requires further elaboration and evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the use of template mapping to transform questions into masked statements. It suggests that this approach might lead to poor generalization to questions that are not \"Whtypes\" or transformable. While the comment highlights a relevant concern, it lacks specific guidance or suggestions on how the authors might address this issue or improve the generalization of their question answering process. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the comment is about: the use of a volumetric representation in the deformation field and its relation to VolumeDeform. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or references to VolumeDeform, making it difficult for the authors to understand the context or relevance of the reference. Without additional information or explanation, the claim lacks verifiability, as it relies solely on a vague reference. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that using a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any constructive feedback or suggestions for improvement. It lacks depth and actionable guidance, leaving the authors without a clear understanding of how to address the issue or enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. It suggests that this issue should be discussed or at least acknowledged in the main text in more detail. This feedback provides a clear and direct action for the authors to take, which is to address this issue in their draft. The comment is specific and provides concrete guidance on how to improve the paper by discussing or acknowledging the impact of the ICLHAR on accuracy scores. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ICLHAR, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ICLHAR, noting that it has impeded accuracy scores and dropping them from 70.4 to 55.6 on TRIP. This provides clear guidance on what needs to be addressed in the paper, namely the discussion or acknowledgment of this issue in more detail. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This claim is supported by the provided data, which shows a significant decline in accuracy scores. However, the comment could be strengthened by providing more detailed analysis or explanation of why this decline occurred or how it affects the overall contribution of the paper. While the data itself is a strong indicator, additional context or reasoning would enhance the verifiability of the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that it has impeded accuracy scores, dropping them from 70.4 to 55.6 on TRIP. This is a clear and actionable observation that the authors should address in their draft. The comment suggests that the issue should be discussed or acknowledged in more detail in the main text, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what aspects of the ICLHAR might be contributing to the accuracy drop. Overall, the comment is 4 as it highlights a significant issue that the authors should address to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to cite the source of the rockpaperscissors example, which is clearly inspired by previous work. This is a direct and concrete action, as it specifies the exact source that needs to be cited. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rockpaperscissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to cite the source of the example. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rockpaperscissors example is inspired by previous work and suggests that the source should be cited appropriately. However, the comment does not provide specific examples or references to the previous work that inspired the example, making it difficult for the authors to verify the claim. Without additional context or evidence, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rockpaperscissors example is inspired by previous work and should be appropriately cited. This is a clear and actionable piece of feedback, as it directly instructs the authors to cite the source of the example. By addressing this point, the authors can ensure that their work is properly credited and that they are not inadvertently plagiarizing others\" work. Therefore, the comment is 5, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the innovations in network architecture design and constraint embedding are limited and that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the innovations or how to improve the performance of the oracle expert. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the innovations in network architecture design and constraint embedding, suggesting that they are limited. It also mentions the performance being constrained by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or the performance constraints, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in identifying the issue of limited innovation and the performance constraint, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback or detailed insights into potential improvements, leaving the authors without a clear path forward. As a result, the comment is 2, as it points out a weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that comparing the performance of a model pretrained on synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors instead. It further suggests that the authors should provide the performance of the model pretrained on synthetic data but finetuned on realworld datasets with different losses. While the comment provides a clear action\u2014to demonstrate the importance of the projection errors and finetune the model on realworld datasets\u2014it does not specify how to implement this action or what specific steps to take. The authors are left with a general idea of what needs to be done but without detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of comparing the performance of a model pretrained on synthetic data, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the need to demonstrate the importance of the proposed three projection errors and suggests providing performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that comparing the performance of a model pretrained on synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors instead. The comment provides a logical reasoning by suggesting that finetuning the model on realworld datasets with different losses is necessary to showcase the model\"s performance. However, the comment lacks specific examples or references to support the claim that the current comparison is unfair. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s comparison of model performance, suggesting that comparing a model pretrained on synthetic data is unfair. It recommends demonstrating the importance of the proposed three projection errors and provides a clear suggestion for improvement by suggesting that the authors should provide performance metrics for models pretrained on synthetic data but finetuned on realworld datasets with different losses. This feedback is actionable and offers a clear direction for the authors to enhance their analysis and presentation of results. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or what specific metrics to use. Overall, the comment is 4 as it effectively points out a weakness and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, it does not explicitly instruct the authors to average over the subword representations or provide guidance on how to implement this suggestion. The action is implied and somewhat vague, as the authors need to infer that they should consider averaging over subword representations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider averaging over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is actionable and provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). However, the comment does not provide specific examples or detailed reasoning to support why this is a common practice or how it would benefit the current work. The reference to Hewitt and Manning is provided, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in the paper, noting that it is common in similar cases to average over subword representations, as done by Hewitt and Manning (2019, footnote 4). This feedback is clear and actionable, as it suggests a potential improvement by recommending the authors consider averaging over subword representations. However, the comment could be more helpful if it provided additional context or examples of how this approach might be beneficial or relevant to the current work. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct calibration curves to demonstrate the consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. It also encourages the authors to discuss the difference between their method and traditional methods. While the comment provides a clear action to take, it lacks specific guidance on how to conduct the calibration curves or what aspects of the traditional method should be discussed. The authors are given a general direction but may need to infer the exact steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC and its ability to assess model discriminant ability, as well as the consistency between predicted scores and actual risks. It suggests conducting calibration curves to demonstrate this consistency, which is crucial for the clinical scoring system. The comment also mentions the difference between the traditional method and the authors\" method, which could be discussed in the paper. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as conducting calibration curves and discussing the difference between traditional and novel methods. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess the model discriminant ability but may not demonstrate consistency between predicted scores and actual risks. It suggests that this consistency is crucial for the clinical scoring system and recommends conducting calibration curves to show the agreement. The comment also mentions the importance of discussing the difference between the traditional method and the authors\" method. While the comment provides a logical reasoning for the need to demonstrate consistency, it lacks specific examples or references to support the claim about the importance of calibration curves. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of demonstrating consistency between predicted scores and actual risks, which is crucial for the clinical scoring system. The comment suggests conducting calibration curves to show this consistency, offering a specific and concrete step for the authors to take. Additionally, it encourages the authors to discuss the difference between their method and traditional methods, providing a direction for further exploration. While the comment could be more helpful by offering examples of how to conduct calibration curves or suggesting specific aspects of the traditional method to discuss, it still provides valuable guidance for improving the draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. While the comment identifies specific areas that need attention, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to discuss these conditions and consider how sparsification affects them, but the comment lacks detailed guidance on how to implement these improvements. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out the lack of discussion on how to ensure DICE meets certain conditions, particularly regarding the mean and the range of ID and OOD with sparsification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification and that Lemma 2 requires an identical mean. These claims are based on observations from Figure 4 and the text, respectively. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the significance of these observations and the implications for DICE, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of discussion on how to ensure that the conditions for DICE are met, and the observation that the range of ID and OOD does not change much with sparsification. It points out that Lemma 2 requires an identical mean, which is crucial for DICE. By highlighting these areas, the comment provides the authors with clear and actionable feedback on what needs to be discussed and explored in the paper. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar conditions have been discussed in other works. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment implies that the authors should consider these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes to improve the readability and clarity of their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the integration of updates across all possible environments and suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. However, it does not specify which part of the paper these sections are located in, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what changes should be made to the bolded sections or how they should be structured. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the integration of updates across all possible environments and suggests that it might be for space reasons. It also suggests that the bolded sections in page 6 should be broken out into paragraphs for better readability. While the comment provides some logical reasoning by questioning the integration across all environments, it lacks specific examples or references to support the claim about the need for space or the benefits of breaking out the sections. This makes the claim 3, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the integration of updates across all possible environments and suggests that it might be for space reasons. It also points out that the bolded sections in page 6 are currently a huge wall of text and should be broken out into paragraphs for better readability. While the comment identifies a potential issue with the formatting and organization of the paper, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it highlights areas that could be improved, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these issues, but without specific guidance on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues related to the experiments, including the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels and the absence of certain baselines. It also suggests that the paper lacks discussion on limitations and societal impacts. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique to address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the strength and fairness of the experiments, the use of position kernels, the absence of certain baselines, and the lack of discussion on limitations and societal impacts. It provides specific suggestions for addressing these issues, such as using default settings of baselines in the literature and comparing the proposed approach with other baselines. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how similar studies have addressed these concerns. Overall, the comment is 4 as it provides actionable feedback that can help the authors improve their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the correlation drop needs to be addressed or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation about the correlation drop after a short period of training, which increases with more training iterations. This is a valuable insight that could be relevant to the authors, as it may indicate a potential issue with the model or training process. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that all sparsity patterns seem to perform equally well and questions whether this is unique to the sparsity detection problem or applies to GNNs in general. It also notes a discrepancy in the presentation of \"presentation bits\" as \"representation bits\" in Section 4.3. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more insight into the results and clarify the terminology in the paper. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the uniqueness of the results and suggesting that the authors provide more insight into the sparsity patterns. Additionally, it points out a discrepancy in the presentation of \"presentation bits\" as \"representation bits\" in Section 4.3. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the uniqueness of the results and suggests that all sparsity patterns perform equally well. However, it does not provide any evidence or reasoning to support this claim or suggest how the authors might address it. The comment also points out a discrepancy in the presentation of \"presentation bits\" as \"representation bits\" in Section 4.3, but this does not pertain to the main claim. Therefore, the comment lacks verifiability and is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that all sparsity patterns seem to perform equally well. It questions whether this is unique to the sparsity detection problem or applies to GNNs in general. This is a relevant point that could prompt the authors to further explore the implications of their findings and potentially provide more insight into the results. Additionally, the comment points out a discrepancy in the presentation of \"presentation bits\" as \"representation bits\" in Section 4.3, which could be clarified for readers. While the comment highlights areas for improvement, it does not offer specific suggestions or guidance on how to address these issues. Therefore, it is 3, as it provides some direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, ensuring that they either include the temperature or acknowledge its absence in the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing temperature parameter, \u03c4, and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on how to improve the derivation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature parameter, \u03c4. The reviewer suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the temperature should be included or why its absence is problematic. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature parameter, \u03c4, is missing. It suggests that either the temperature should be shown in a rigorous way or that the paper should mention its absence. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the rigor and clarity of their derivation, which is valuable for the overall quality of the paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add a citation on differential privacy, specifically mentioning a standard work like [2]. This is a clear and direct action for the authors to take, as it provides a specific reference to include in the paper. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, providing a specific example like [2]. This level of detail provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like [2]. This is a factual suggestion that does not involve an opinion, judgment, or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting the addition of a citation on differential privacy. By mentioning a standard work like [2], the reviewer provides a clear and actionable suggestion that can enhance the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how it could be integrated into the existing content. Despite this, the feedback is valuable as it directs the authors to a specific area for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer provides a specific example of an additional assumption (the test set being drawn from the same distribution as the query set) and points out that this is a natural assumption in many machine learning settings. The reviewer also notes an issue with the inequality on line 310, suggesting that it has the wrong sign. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and correct the inequality. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of Section 3.2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim, suggesting that it is too extreme and provides a specific example of an additional assumption that is natural in many machine learning settings. Additionally, it points out an issue with the inequality on line 310, which is incorrect. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim that \"this methodology requires significant additional assumptions,\" suggesting that the additional assumption of using the same distribution for the test and query sets is natural in many machine learning settings. The reviewer provides a logical reasoning by pointing out that this assumption is common in practice. However, the comment lacks specific examples or references to support the claim that this assumption is not significant. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific critique of the claim made in the first paragraph of Section 3.2, suggesting that it is too extreme. The reviewer offers a logical reasoning by pointing out that the additional assumption of using the same distribution for the test and query sets is a natural assumption in many machine learning settings. This feedback is valuable as it challenges the authors to reconsider their claim and potentially revise it to align with common practices in the field. Additionally, the comment identifies an issue with the inequality on line 310, which is incorrect. However, the comment could be more helpful by providing suggestions on how to address these issues or improve the draft. Overall, the comment is 4 as it offers actionable feedback on the claim and the inequality, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. Additionally, it recommends including a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides explicit actions, it lacks concrete details on how to conduct these comparisons or what specific aspects of the advantages and disadvantages should be discussed. The authors are given a clear direction but need more guidance on how to implement these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of Shapely values over other methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experimental comparisons with other methods and a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values over other methods. It also recommends a discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that Shapely values are superior to other methods. This makes the claim 3, as the authors would need to make a significant effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the need for experimental comparisons with other methods, such as CaCE or raw gradients, to support the authors\" argument for using Shapely values over other methods. Additionally, it recommends a significant discussion on the advantages and disadvantages of the three ways of transforming highdimensional data to lowdimensional latent space, which could enhance the paper\"s comprehensiveness and depth. While the comment identifies specific areas for improvement, it could be more helpful if it provided examples of how these comparisons or discussions might be structured or conducted. Overall, the feedback is 4 as it guides the authors toward making meaningful enhancements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that the authors should make this comparison, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 needs this comparison or what aspects of the prior efforts should be compared. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the prior efforts should be compared or how this comparison would enhance the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks the necessary evidence or justification to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in Section 6 by suggesting that the perspective taken in the manuscript could be compared to the contributions of prior efforts. This feedback is 3 as it points out a specific area where the authors could enhance their work by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but not detailed steps for implementation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the exact change needed (examining performance with different numbers of scenarios), but it is somewhat vague because it does not provide detailed guidance on how to conduct the experiment or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the training process or results, but this inference is not direct. The comment is specific in its suggestion to examine performance with different scenarios, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the performance is closely related to the number of scenarios used for training and recommends examining the performance with different numbers of scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential relationship between the performance and the number of scenarios used for training, suggesting that examining performance with different numbers of scenarios could be interesting. This is a valuable observation that could lead to a meaningful experiment or analysis. However, the comment lacks specific guidance on how to conduct this experiment or what aspects of the performance to focus on. While it points out a potential area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or test their model under such disturbances. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relationship between generating a quality label and the model\"s ability to predict it, suggesting that disturbances in the training data might affect the model\"s ability to generate the correct quality label. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the model\"s ability to predict quality labels and the potential impact of training data disturbances. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between generating a quality label and the model\"s ability to predict it. It suggests that disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the relationship between generating a quality label and the model\"s ability to predict it. It questions whether disturbances in the training data might affect the model\"s ability to generate the correct quality label, potentially indicating a decrease in quality. This is an important consideration for the authors to address, as it could impact the reliability and accuracy of their results. However, the comment lacks specific guidance or suggestions on how the authors might test or mitigate this issue. While it identifies a potential weakness, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, additional experiments, or guidance on how to enhance the validation process. As a result, the authors are left without any clear direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the comprehensive experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not specify which part of the paper these experiments are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in detailing the types of experiments conducted, but it lacks grounding as it does not specify where in the paper this information is presented. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch and crossdomain imitation. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that these experiments are comprehensive. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and crossdomain imitation. However, it lacks specificity and actionable feedback. It does not provide guidance on how the authors could improve or expand upon these experiments, nor does it offer suggestions for further validation or analysis. As a result, the comment is 3, as it identifies a strength but does not provide detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting described in the paper is only partially strategic or game theoretic, as the opponent does not behave strategically. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the strategic nature of the setting or what specific changes should be made to make it more game theoretic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the setting described in the paper, suggesting that it is only partially strategic or game theoretic because the opponent does not behave strategically. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the setting, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the setting described in the paper is only partially strategic or game theoretic because the opponent does not behave strategically. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s setting, noting that it is only partially strategic or game theoretic because the opponent does not behave strategically. This is a relevant observation that could prompt the authors to reconsider the nature of their setting and explore ways to enhance its strategic depth. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional strategic elements or gametheoretic approaches. While it points out a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a direct and concrete action for the authors to take, which is to improve the clarity of the illustration in Appendix A.2. The comment is specific about what needs to be addressed, making it 5. Authors know exactly what needs to be done to enhance the clarity of their illustration.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be improved in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. It points out that the illustration is not clear, which is a critical aspect of the paper\"s presentation. This feedback is actionable as it directs the authors to improve the clarity of the illustration, ensuring that readers can better understand the environment\"s state space. However, the comment could be more helpful if it provided suggestions on how to enhance the clarity or examples of how similar illustrations have been effectively presented. Despite this, the comment is 4 as it highlights an important area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors\" approach is only applicable to small or mediumscale problems, as it cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach to handle larger problems. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to address this issue. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the applicability of the approach, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or reasoning, the claim remains 1, as it does not provide sufficient justification for the authors to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and cannot handle truly large problems that would overwhelm current LPsolvers. This feedback highlights an important area for improvement, as it points out a potential weakness in the applicability of the authors\" work. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand their approach to handle larger problems. While it provides some insight into a potential issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the bounded noise assumption in the paper, noting that it is common but somewhat restrictive in the stochastic optimization literature. It suggests that the authors should consider extending the noise conditions, referencing specific works that have explored this topic. While the comment provides explicit references to external works, it does not offer concrete guidance on how to incorporate these references or what specific aspects of the bounded noise assumption should be addressed. The authors are left with a general direction to explore but without detailed instructions on how to implement these suggestions. Therefore, the comment is 3, as it provides a clear direction but lacks specific details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bounded noise assumption, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear rationale for the critique, noting that the assumption is somewhat restrictive in the stochastic optimization literature and suggesting that the authors consider extending the noise conditions. The comment references specific works that have explored this topic, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature and suggests that there have been efforts to extend these noise conditions. The reviewer provides specific references to external works, such as A. Khaled and P. Richt\"arik, R. Gower, O. Sebbouh, and N. Loizou, which support the claim by offering examples of recent research on the topic. This provides a robust foundation for the claim, making it 4. However, the comment could be further strengthened by explaining why the bounded noise assumption is restrictive or how these references might be relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the bounded noise assumption is somewhat restrictive in the stochastic optimization literature. It suggests that the authors should consider extending the noise conditions, providing specific references to recent works that have explored this topic. This feedback is valuable as it encourages the authors to broaden their perspective and consider alternative approaches that could enhance their work. However, the comment could be more helpful if it offered additional guidance on how to incorporate these references or what specific aspects of the bounded noise assumption should be addressed. Overall, the comment is 4 as it provides actionable suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the motivation for using characteristic function regularization is not clear. However, it does not provide any explicit or implicit suggestions for how the authors might clarify this motivation or what specific aspects of the motivation are unclear. There is no guidance on how to address this issue, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the motivation for using characteristic function regularization is not clear, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine whether it relates to the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the motivation are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity in the motivation for using characteristic function regularization, which is an important aspect of the paper. However, it does not provide specific guidance or suggestions on how the authors might clarify this motivation or what aspects of the methodology are unclear. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, as it points out an area for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the contribution is incremental because these techniques are not novel. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation or improve their draft. There is no guidance on how to differentiate their work from existing techniques or how to enhance the contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is problematic: the paper\"s limited contribution due to the combination of existing techniques. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the claim. Additionally, the reasoning is not fully articulated, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it appears to be limited to a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that these results are not surprising and that the contribution is incremental. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance their contribution. The feedback lacks actionable advice or detailed critique, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referred to. This feedback is clear and concrete, as it specifies exactly what needs to be added or clarified in the paper. The authors know exactly what information is missing and how to address it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"aggregation operation after \"Integration,\"\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the details of the aggregation operation and the acknowledgment of other architectures if they are referred to. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the aggregation operation after \"Integration\" needs further clarification and that if other architectures are referred to, their structure should be acknowledged properly. However, the comment does not provide specific examples or detailed reasoning to support why these clarifications are necessary or how they would improve the paper. Without additional context or examples, the claim is 3, as it requires the authors to infer the importance of the suggested clarifications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the aggregation operation after \"Integration.\" It suggests that the authors provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is clear and actionable, as it directs the authors to enhance the clarity and completeness of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on what additional details should be included. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out severe writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The authors are left to infer that they need to improve their writing, but without concrete suggestions or examples, they may struggle to know where to focus their efforts. The lack of explicit instructions or detailed feedback makes this comment 1.", "grounding_specificity_rationale": "The comment identifies specific issues with the writing, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing the writing issues but lacks grounding as it does not specify where these issues occur. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address them effectively. Without specific examples or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. While it highlights these problems, it does not provide specific examples or guidance on how to address them. The comment lacks actionable feedback that would help the authors improve their draft, such as suggesting specific corrections or improvements. Without detailed suggestions or examples, the authors are left with a general understanding of the problems but without clear direction on how to resolve them. Therefore, the comment is rated as 2, as it points out a significant problem but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It explicitly instructs them to run the corresponding experiments and add the results to the figures and Table 1. It also clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. These actions are clear and specific, leaving no ambiguity about what the authors need to do to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures, \"Fig 3c\" and \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying whether the figures show results for untrained networks and whether the network was trained on random data. The comment also provides detailed guidance on how to clarify the results and suggests adding examples of random data in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification and additional experiments. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying areas where the paper could be improved. It points out that the figures do not show results for untrained networks and suggests running the corresponding experiments and adding them to the figures and Table 1. Additionally, it clarifies specific aspects of the figures, such as whether the network was trained on random data or unaltered data, and whether the data was normalized. The comment also suggests adding examples of random data in the appendix. This level of detail and guidance is highly beneficial for the authors, as it helps them understand and address the issues raised in the review. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"100 steps\" in the context of a search model comparison. It does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or address this issue. Without guidance on what the authors should do to improve the draft, the comment lacks actionability. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Search models comparison 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on what \"100 steps\" means in the context of the search model comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"100 steps\" in the context of a search model comparison. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"100 steps\" in the context of a search model comparison, specifically in section 5.1. This question highlights a potential area of confusion or ambiguity in the paper, which could be clarified to enhance the reader\"s understanding. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and suggests that it is less explored compared to GANs and VAEs. However, it also points out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. While the comment implies that the authors should consider this similarity and potentially address it in their work, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should address the similarity to the prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of energy models for image generation, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the motivation and goals of the model are similar to a prior VAE paper, which is discussed in the related work review section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it acknowledges that the motivation and goals of the model are similar to a prior VAE paper. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the comparison to the prior work. The lack of specific examples or detailed justification makes the claim 3, as the authors would need to infer the basis of the comparison and potentially conduct additional research to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the potential of exploring energy models for image generation and notes that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model, which involve compositional generation through logical combination of concepts learned through data subsets, are similar to a prior VAE paper. This feedback is 3 as it highlights an area of potential interest and a similarity to prior work, which the authors could consider addressing. However, the comment lacks specific suggestions or guidance on how to address the similarity or how to further explore the use of energy models. While it provides some insight, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should repeat the experiments and conduct statistical significance analysis on the numbers to determine whether the results are statistically significant. This feedback is explicit and provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is also concrete, as it specifies the need for statistical analysis and the importance of determining statistical significance. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of reporting of mean and standard deviation in Table 1 and Fig. 5, and the need for statistical significance analysis. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation. The reviewer suggests repeating the experiments and conducting statistical significance analysis to determine whether the results are statistically significant. This claim is 3 as it provides a logical reasoning for the need to repeat the experiments and conduct statistical analysis. However, it lacks specific examples or references to support the claim that the improvement is small or that the results are not statistically significant. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely the limited novelty and marginal improvement over previous methods. It points out that the improvement is only about 0.2%1%, which is not considered significant. Additionally, it highlights the lack of reporting of mean and standard deviation in Table 1 and Fig. 5, making it difficult to determine statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis to address these concerns. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it included suggestions on how to conduct the statistical analysis or what specific metrics to focus on. Overall, the comment is 4 as it identifies critical areas for improvement and offers a constructive suggestion for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends conducting experiments on a different benchmark, such as Atari, to verify the generalizability of the method. This suggestion is clear and provides a specific action for the authors to take. Additionally, it highlights the importance of evaluating the method on a diverse set of domains to ensure its applicability beyond the Meta World domain. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation on a single domain, Meta World, and suggests running experiments on a different benchmark, such as Atari. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for generalizability testing and the importance of evaluating the method on a diverse set of domains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is evaluated only on the tasks from Meta World, a robotic manipulation domain, which makes it difficult to judge whether the results will generalize to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion is based on the need to verify whether the method works with discrete action spaces and highdimensional observations. The claim is 3 as it provides a logical reasoning for the need to test generalizability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the evaluation of the method, noting that it is evaluated only on the tasks from Meta World, a robotic manipulation domain. This observation highlights the need for generalizability testing to ensure that the method can be applied to other domains. The comment provides a clear and actionable suggestion by recommending running experiments on a different benchmark, such as Atari, which is commonly used in the literature. This suggestion not only addresses the issue of generalizability but also provides a specific test that could verify the method\"s applicability to discrete action spaces and highdimensional observations. By offering a concrete and constructive suggestion, the comment is 5 in guiding the authors towards improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The comment implies that the authors should add more depth to the explanation of the model, but it lacks concrete instructions or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, nor does it provide details on what aspects of the model should be analyzed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is specific in suggesting the need for an analysis but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an analysis of what the model does, which could be interesting. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while the method is presented well and the experiments are thorough, there is a lack of analysis on what the model does. This feedback highlights an area for improvement, suggesting that the authors should include an analysis of the model\"s functionality, which could be interesting. However, the comment does not provide specific guidance or examples on how to conduct this analysis or what aspects to focus on. While it points out a potential weakness, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the task setup, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the task setup is not described clearly, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the task setup is not described clearly, specifically mentioning the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issue and how to address it. Therefore, the claim is 3, as it provides a general direction but lacks the necessary detail for full verification.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup, particularly regarding the input notes from the EHR (only the current admission or all previous admissions) and the distance of outcomes from the last note date. This feedback is clear and actionable, as it points out areas where the authors need to provide more detailed information to ensure that their task setup is understandable. However, the comment could be more helpful if it suggested ways to clarify these aspects or provided examples of how similar tasks have been addressed in the literature. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of the approach section in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the approach section. The comment implies that the authors should include the approach section in the main paper, but it lacks concrete details on how to integrate it or what specific content should be included. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" and the \"supplementary material,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the approach section in the main paper and the use of supplementary material as additional information rather than an extension to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant oversight in the main paper, noting the absence of the approach section. It suggests that the supplementary material should be used as additional information rather than an extension to the paper. While the comment highlights an important issue, it lacks specific guidance on how to address this oversight or what content should be included in the approach section. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the statement regarding the biological plausibility of backpropagation in the introduction may be too weak and points out that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the statement and provide more robust evidence or reasoning to support it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the introduction regarding the biological plausibility of backpropagation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the weakness of the statement and the need to provide more robust evidence or reasoning to support it. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding the biological plausibility of backpropagation in the introduction is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the introduction regarding the biological plausibility of backpropagation. It points out that the statement may be too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is 3 as it highlights an area where the authors may need to provide more robust evidence or reasoning to support their claims. However, the comment could be more helpful if it suggested specific ways to strengthen the statement or provided examples of alternative perspectives or evidence that could be considered. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the scalability issue or suggestions for improving the modulator design. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of scalability in the modulator design, specifically questioning whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the scalability issue and the potential need for hyperparameter tuning, but without clear grounding, the authors cannot confidently determine which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the modulator is heuristically designed and questions whether there is a scalability issue that might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the modulator design, suggesting that it might require tedious hyperparameter tuning for diverse training data. This is a relevant concern that could impact the practicality and applicability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the scalability of the modulator. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in making improvements to their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that f_R and f_P can be adapted over time but highlights the incorporation of domain knowledge into their structure. It suggests that a less informed f_R/f_P might require an impractical amount of data to learn. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or suggestions for improving the experiments. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of domain knowledge being incorporated into the structure of the experiments, specifically mentioning f_R and f_P. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the impractical amount of data required for a less informed f_R/f_P. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments performed here incorporate a great deal of domain knowledge into their structure, which could require an impractical amount of data to learn for a less informed f_R/f_P. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the incorporation of domain knowledge into the experiments and highlights the potential impracticality of learning for a less informed f_R/f_P. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their experiments. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit instructions or suggestions on how the authors should conduct these experiments or what specific aspects to focus on. The action is implicit and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for experiments on the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these aspects are discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that obtaining labeled data is necessary for imitation learning and suggests that experiments should be conducted to determine the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the difficulties in obtaining labeled data and how performance changes with the size of the labeled data. It highlights the importance of conducting experiments to address these issues. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on. While it points out an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it directs the authors to a potential area for enhancement but does not fully support them in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the necessary conditions and generalization bounds, suggesting that the constructions of ReLU networks for robust memorization may not lead to robust generalization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the connection between necessary conditions and generalization bounds, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of overparameterization and its implications on generalization bounds, suggesting that the necessary conditions may have stronger implications if they are connected to generalization. It mentions the constructions of ReLU networks for robust memorization and questions whether this leads to robust generalization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the connection between necessary conditions and generalization bounds, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. The reviewer acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the constructions of ReLU networks for robust memorization may not lead to robust generalization. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the connection between necessary conditions and generalization bounds, suggesting that overparameterization can lead to powerful memorization and good generalization performance. It acknowledges that the authors acknowledge this in the conclusion but considers it a serious question. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness in the paper, it lacks actionable feedback that would help the authors address the concern effectively. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. However, it does not provide specific guidance on how the authors should address this issue or what additional exploration is needed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to enhance the generalizability of their results. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s exploration of the implications of the proposed method for other NLP tasks, suggesting that the paper\"s generalizability is somewhat limited due to this lack of exploration. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of limited generalizability, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which somewhat limits its generalizability. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it does not explore the implications of the proposed method for other NLP tasks. This observation highlights a potential weakness in the generalizability of the results, which could limit the impact of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what additional exploration could be conducted. While it points out an area for improvement, the lack of actionable advice makes the comment 3, as it provides insight but not a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the use of the terminology \"certificate\" in the paper, as it has a strong meaning in complexity theory. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to avoid misinterpretation. The action is implicit and vague, as the authors are left to infer that they need to reconsider the use of this terminology and possibly provide clarification or alternative terminology. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the terminology \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of the terminology \"certificate\" in some contexts could be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of terminology in the paper, specifically the term \"certificate,\" which could be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors avoid confusion or misunderstanding in their work. However, the comment lacks specific guidance on how to address this issue, such as suggesting alternative terminology or providing examples of where the term might be misinterpreted. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should mention the recent work on untrained NNs for inverse problems in imaging, specifically mentioning the paper by Ulyanov et al. (CVPR 2018). It also recommends placing the current method in context and potentially comparing it with these methods. While the comment provides a clear action\u2014mentioning the relevant work and potentially comparing the method\u2014it does not specify how to integrate this information into the paper or what specific aspects of the method should be compared. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OOD experiments\" and the \"untrained NNs\" for inverse problems in imaging, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely mentioning the recent work by Ulyanov et al. (CVPR 2018) and placing the current method in context. Additionally, it suggests comparing the current method with those class of methods. This provides clear guidance on how to enhance the paper by incorporating relevant references and comparisons. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the OOD experiments are interesting because the trained network can provide strong OOD generalization. However, it also suggests that recent work by Ulyanov et al. (CVPR 2018) has shown that untrained NNs can be used for inverse problems across a wide range of images. The reviewer recommends mentioning this work in the paper and comparing the current method with those class of methods. While the comment provides a logical reasoning for the importance of including this information, it lacks specific examples or references to the Ulyanov et al. paper to fully substantiate the claim. This makes the claim 3, as the authors would need to follow up on the suggestion to fully understand and address the critique.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the interesting aspect of the OOD experiments and notes that the trained network demonstrates strong OOD generalization. However, it also points out that recent work by Ulyanov et al. (CVPR 2018) has shown that untrained NNs can be used for inverse problems across a wide range of images. The reviewer suggests that mentioning this work in the paper and comparing the current method with those class of methods would enhance the context and relevance of the paper. This feedback is valuable as it encourages the authors to broaden their perspective and incorporate relevant references to strengthen their work. Therefore, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. While it implies that the authors should consider testing the method in realworld settings, it does not provide specific guidance on how to implement this suggestion or what specific aspects of real data should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the comment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, it does not specify which part of the paper discusses the experiments or where the limitation is mentioned, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of real data should be considered or how the method should be tested in those settings. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and recommends expanding the scope to include real data. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this is necessary or how it would improve the study. Without such evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are currently limited to toy data. It suggests expanding the scope to include realworld data, which could provide valuable insights into the method\"s performance in more practical settings. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what aspects of real data should be considered. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment implies that additional experiments are necessary, it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The references provided are relevant but do not offer detailed instructions on how to implement the suggested experiments. The action is implicit and somewhat vague, as the authors need to infer the specific details of how to proceed with the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results discussion. The references provided are relevant but do not directly address the comment\"s suggestion. Therefore, the comment is weakly grounded because it does not specify where in the paper these experiments should be conducted, and it is not specific in detailing what aspects need to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. The reviewer provides references to relevant works, which supports the claim that these experiments could enhance the paper. However, the comment lacks detailed reasoning or specific examples of how these additional experiments would benefit the paper. While the references provide some context, the claim could be strengthened with more detailed justification or examples of how these experiments would contribute to the paper. Therefore, the comment is 3, as it provides some support but lacks full justification.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks (e.g., ResNet50) and other network structures (e.g., MobileNet) are needed to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance on which aspects of the paper would benefit from these additional experiments or how they should be conducted. The references provided are relevant but do not offer detailed instructions or suggestions for the authors to follow. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sample selection mechanism is not clearly explained in terms of how it preserves the label distribution. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific ways to clarify the mechanism or suggesting alternative explanations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed sample selection mechanism, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding how the mechanism preserves the label distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the proposed sample selection mechanism in preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the proposed sample selection mechanism, noting that it is not clear how it preserves the label distribution. This feedback is 3 as it points out a potential weakness in the paper that the authors should address to improve clarity and understanding. However, the comment lacks depth and does not provide specific suggestions or examples on how to clarify the mechanism or what aspects of the explanation are unclear. While it highlights an area for improvement, it does not fully guide the authors on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any explicit or implicit suggestions for improvement or additional models to consider. The authors are left without guidance on how to enhance the scope or relevance of their evaluation. As a result, the comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the results and analysis, noting that they are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not specify which part of the paper this critique pertains to, such as the results or analysis sections. Without explicit references to sections or figures, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the evaluation are limited by the choice of models. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive but only evaluate two relatively old and small models. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to other models or studies that could be considered, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the evaluation of results and analysis, noting that only two relatively old and small models are considered. This feedback highlights an area where the authors could potentially expand the scope and relevance of their work by including more diverse or contemporary models. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending additional models or methods to consider. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer implies that this makes the motivation for Algorithm 1 unclear. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. It lacks actionable details, such as suggesting how to clarify the motivation or how to incorporate this insight into the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making the motivation unclear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. The reviewer suggests that this makes the motivation for Algorithm 1 unclear. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact basis of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem can be reformulated using the conjugate function, making it equivalent to the subproblem in Algorithm 1. This observation could lead to a significant improvement in the clarity and coherence of the paper. However, the comment lacks specific guidance on how the authors might address this issue or what changes they should make to improve the motivation. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS, particularly when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take based on this observation. There is no guidance on how to incorporate this understanding into the paper or what specific aspects of the paper should be revised to reflect this view. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion that LS and KD are equivalent under certain conditions, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that KD can be considered a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of this assertion. Without additional context or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to address it effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment acknowledges that KD and LS are not identical but suggests that KD can be considered a special form of LS under certain conditions. It provides a specific example of when this equivalence occurs, which is when the teacher network is uniformly distributed and the temperature is set at 1. This feedback is 3 as it offers a potential insight into the relationship between KD and LS, which could be useful for the authors to consider when discussing their method. However, the comment could be more helpful if it provided suggestions on how to incorporate this understanding into the paper or how to address any implications of this equivalence. Overall, the comment offers a valuable observation but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. This feedback is explicit and provides a clear action for the authors to take, which is to include results on larger datasets. The comment also mentions that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. However, it does not specify which recent works should be included or how to incorporate them into the paper. While the action is clear, the lack of detailed guidance on how to implement it makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamicpruning methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of results on largescale datasets, such as ImageNet, and the need to consider more recent works on dynamicpruning methods. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Competing dynamicpruning methods are kind of outofdate\" and suggests that more recent works should be included. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current methods are considered outdated. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include results on largescale datasets, such as ImageNet, to verify the effectiveness of their proposed method. It also points out that competing dynamicpruning methods are outdated, implying that the authors should consider more recent works. This feedback is clear and constructive, as it guides the authors on how to enhance the comprehensiveness and relevance of their results. However, the comment could be more helpful if it provided examples of recent works or detailed guidance on how to incorporate them into the paper. Overall, the comment is 4 as it effectively directs the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide an explanation for why the performance degrades when using additional information about missing, wrong, or redundant data. This is a clear and direct request, giving the authors a specific action to take. The comment is specific in its request for an explanation, which provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the performance degrades when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance degradation when using additional information about missing, wrong, or redundant data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance degradation when using additional information about missing, wrong, or redundant data. It prompts the authors to provide an explanation for this phenomenon, which is a clear and actionable request. This feedback is valuable as it directs the authors to clarify an aspect of their results that may be confusing or misleading. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have handled similar challenges. Overall, the comment is 4 as it guides the authors to improve the clarity and understanding of their results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. The reviewer explicitly asks for clarification on these points, providing a clear direction for the authors to improve the clarity of their explanations. The action is explicit and concrete, as it specifies exactly what needs to be addressed to improve the readability of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues with the clarity of the explanations, providing examples of unclear statements and asking for clarification. This level of detail helps the authors understand what needs to be addressed to improve the clarity of their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are hard to read due to unclear explanations of previous approaches. It provides specific examples of unclear statements, such as the stacked LSTM in Fig 2(a) and the sentence in line 96. These examples are detailed and provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support the critique. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity and readability of the first two sections of the paper. It provides examples of unclear explanations, such as the stacked LSTM in Fig 2(a) and the sentence in line 96, and asks for clarification on these points. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensibility of their explanations. By addressing these issues, the authors can enhance the readability and accessibility of their paper, which is valuable guidance for improving the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and provides a specific example of the issue, noting that it is \"annoying to have to search through the text for your interpretation of the figures, which is usually on a different page.\" Additionally, it requests an explanation of the scramble network. While the comment provides a clear action to make the captions more descriptive and an explicit request for an explanation of the scramble network, it does not offer detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specifics of how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captions and the issue of having to search through the text for interpretations of figures, which are usually on a different page. It also mentions the need to explain the scramble network, providing clear guidance on what aspects of the paper need attention. However, the comment lacks specificity regarding how to make the captions more descriptive or how to explain the scramble network. While the authors can identify the parts of the paper being addressed, the lack of detailed guidance on how to implement the suggested improvements limits the comment\"s specificity. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point suggests that the captions are not descriptive and that it is \"annoying\" to search through the text for interpretations of figures, which are usually on a different page. It also requests an explanation of the scramble network. While the comment identifies a specific issue with the captions, it lacks detailed reasoning or examples to support why this is a problem or how it could be improved. The suggestion to make the captions more descriptive is somewhat vague, and the explanation of the scramble network is not provided. This makes the claim 3, as it provides a general direction but lacks sufficient evidence or detailed guidance.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, namely the captions and the explanation of the scramble network. It points out that the captions are not descriptive and that it is frustrating to have to search through the text for interpretations of figures, which are usually on a different page. This feedback is clear and actionable, as it provides a concrete suggestion for making the captions more descriptive and easier to understand. Additionally, it requests an explanation of the scramble network, which could enhance the paper\"s clarity and comprehensibility. However, the comment could be more helpful if it offered specific examples or guidance on how to improve the captions or explain the scramble network. Overall, the comment is 4 as it provides clear and actionable feedback, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It raises a valid point about the interest of this particular dimension of difficulty, but it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks actionable details, such as recommending alternative methods or explaining why this choice might be less interesting. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of CIFAR images as backgrounds, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind this choice and seeks clarification on why this particular dimension of difficulty is interesting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that this choice is not wellmotivated and raises a valid point about the interest of this particular dimension of difficulty. However, the comment lacks specific examples or references to support the claim that this choice is not wellmotivated. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 3, as it provides a logical argument but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that this choice is not wellmotivated. It raises a valid point about the interest of this particular dimension of difficulty, which could be an important consideration for the authors. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a more compelling justification for their choice. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is explicit and provides a clear action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the analysis about flatness\" and \"the loss used for training base model,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the losses of the noiseinjected models after training to substantiate the claim about the flatness of the minima found by the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis about the flatness of the minima is missing, and it suggests that minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima. The reviewer provides a logical reasoning by explaining that the loss used for training the base model is the averaged loss for the noiseinjected models, and that the convergence analysis on this loss does not guarantee the flatness of the minima. However, the comment lacks specific examples or references to support the claim that the analysis on the losses of the noiseinjected models after training is necessary to substantiate the claim about the flatness of the minima. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s argument regarding the flatness of the minima found by the proposed method. It points out that while the authors claim that the method finds the flat minima, the analysis about flatness is missing. The reviewer provides a logical explanation of why minimizing the averaged loss across the noiseinjected models does not ensure the flatness of the minima, and suggests that the authors should provide an analysis of the losses of the noiseinjected models after training to substantiate their claim. This feedback is clear and actionable, guiding the authors to address a crucial aspect of their argument that could significantly impact the paper\"s credibility. Therefore, the comment is 4, as it provides a concrete direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to make the text inside the figure and labels roughly the same size as the manuscript text. This is a clear and direct action that the authors can take to improve the readability of their figures. The comment provides concrete guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text inside the figure and the labels,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the size of the text compared to the manuscript text. This provides clear guidance on how to improve the readability of the figures. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and labels is too small to read without zooming, suggesting that it should be roughly the same size as the manuscript text. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the readability of the figures. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the figures, noting that the text inside the figure and the labels are too small to read without zooming. It provides a clear and actionable suggestion to make the text roughly the same size as the manuscript text. This feedback is valuable as it directly addresses a usability concern that could impact the accessibility and comprehension of the figures. However, the comment could be more helpful if it included examples or additional guidance on how to achieve this improvement. Overall, the comment is 4 as it effectively points out a specific issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a direct and concrete action for the authors to take, which is to revise the introduction to clarify the motivation. The comment is specific in identifying the issue and offers a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the motivation. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, namely that the motivation is not clear. It suggests that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it lacks specific guidance on how to address the issue or what aspects of the motivation are unclear. Providing more detailed feedback on what specific aspects of the motivation need clarification or how to improve the introduction would make the comment more helpful. As it stands, the comment is 3, as it points out a significant weakness but does not offer actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improving the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of features and positions differing across categories, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that using multiple local prompts can be beneficial but notes that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it affects the paper\"s conclusions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the use of multiple local prompts and notes that the features and their positions differ across categories. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to validate the alignment or what specific steps to take to ensure its validity. As a result, the authors are left without any clear direction on how to improve their draft in this area. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the alignment of relabeled reward data with human annotator judgments, indicating that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of insufficient validation, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the insufficient validation of the alignment between relabeled reward data and human annotator judgments. This is a critical point that could impact the reliability and robustness of the results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional validation methods or providing examples of how to validate the alignment more effectively. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and recommends improving its presentation in Section 4, possibly by referring to the supplement. It also provides specific suggestions for enhancing the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These explicit actions and concrete details provide clear guidance on how the authors can improve the presentation of their model, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, such as suggesting the use of notation and breakout diagrams to enhance the presentation of the model. This level of detail provides a clear direction for the authors to follow, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and recommends improving its presentation in Section 4. It provides a specific suggestion to replace natural language descriptions with notation and adds breakout diagrams to illustrate the attention mechanisms. This claim is 3 as it offers a logical suggestion for improving the presentation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to explore the specific benefits of using notation and diagrams to understand the full impact of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the model in Section 4, noting that it is somewhat complicated and requires careful reading. It provides specific suggestions for improving the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. These suggestions are actionable and can help the authors enhance the clarity and accessibility of their presentation. However, the comment could be more helpful if it explained why these changes are necessary or how they would benefit the reader. Overall, the comment is 4 as it provides clear and constructive feedback, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or expand their experiments to include more molecules. The action is implicit and vague, as the authors are left to infer that they should consider expanding their experiments to include more molecules. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limited scope of the experiments conducted in the paper, specifically mentioning that only a few molecules are tested and that indistribution testing is provided for these samples. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limited scope of the experiments and the potential limitations of the method if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing for these samples. It suggests that the method\"s value would be limited if it requires training for each molecule individually. This feedback is 3 as it points out a potential weakness in the paper\"s scope and suggests an area for improvement. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this limitation or expand their experiments to include more molecules. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or how to make them more accessible to the reader. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the complexity of the symbols used in the paper, suggesting that they are difficult to understand. However, it does not specify which symbols or parts of the paper are causing this issue, making it difficult for the authors to pinpoint the exact areas that need attention. The comment lacks specificity regarding which symbols or sections are problematic, leaving the authors without clear guidance on how to address the issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and take a lot of time to understand. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the complexity of the symbols used in the paper, suggesting that they are difficult to understand and take a lot of time to comprehend. While this feedback identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how to simplify the symbols or improve their clarity. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the origin of the red line in Figure 3 and whether there is a ground truth for the test data. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the source of the red line and the ground truth, but it lacks specific instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the red line in the figure and asks for clarification on the origin of the test data and the existence of a ground truth. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the origin of the red line in Figure 3 and the existence of a ground truth for the test data. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the red line in Figure 3, asking where the test data comes from and whether there is a ground truth. This is a clear and actionable point that can help the authors clarify the origin of the data and provide more transparency in their methodology. By addressing this question, the authors can improve the clarity and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to present this information or what additional details might be needed. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear direction for the authors to take action."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to take. It lacks actionable details, such as recommending specific modifications or experiments to address this concern. As a result, the authors are left without a clear path forward, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as specific experiments or sections where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the role of periodicity in the results, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a logical basis for the question but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It suggests that adding periodicity to the spectral kernel might be enough to capture all the results at a similar level to the explicitly compositional model. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve their results. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending experiments or modifications to the model. While it provides a thoughtprovoking insight, it could be more helpful with additional actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues, such as suggesting particular formatting changes or improvements to the figures and tables. The authors are left to infer that they need to improve the writing and formatting, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It mentions specific areas for improvement, such as presentation and formatting, particularly in figures and tables. However, the comment does not explicitly mention which sections or parts of the paper are problematic, making it weakly grounded. The authors can infer that it relates to the sections on presentation and formatting, but this inference is not direct. The comment is specific in detailing what needs to be improved, such as the figures and tables, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not wellwritten and suggests that it may have been rushed, making it difficult to read. It also mentions that there is a lot left desired in presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues or how to address them. The lack of specificity and detailed evidence or references makes the claim 2, as it provides some indication but not enough detail for the authors to fully understand and act upon the feedback. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s writing quality, suggesting that it may be rushed and difficult to read. It highlights specific areas for improvement, such as presentation and formatting, particularly in figures and tables. While the comment provides some insight into the areas needing attention, it lacks detailed guidance or specific suggestions on how to improve the writing and formatting. The authors are left with a general understanding of the issues but without actionable steps to address them. Therefore, the comment is 3, as it points out areas for improvement but does not provide comprehensive guidance for the authors to make significant improvements to their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the introduction to orthogonality in Part 2 could be more detailed. This provides a clear and direct action for the authors to take, which is to expand or clarify the introduction to make it more comprehensive. The comment is specific in identifying the need for more detail, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Part 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction to orthogonality. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning or examples to support why this detail is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the introduction to orthogonality in Part 2. It suggests that the introduction could be more detailed, providing a clear direction for the authors to enhance their draft. However, the comment lacks specific guidance on what aspects of the introduction need more detail or how to achieve this improvement. While it points out a potential weakness, it does not offer actionable steps or examples to help the authors address it effectively. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. It acknowledges that the authors may have made a correct observation but points out the need for better communication of this contribution. However, the comment does not provide specific guidance on how to highlight the novelty or what aspects of the paper should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the novelty of their result in relation to prior work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical results of samplewise multiple descent in linear regression, which provides a clear reference point for the authors to identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should highlight the novelty of its result in relation to prior work, particularly regarding the removal of double descent in certain anisotropic settings. The comment is specific in its critique of the paper\"s contribution and the need for better communication of the novelty. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s main contribution is the result that optimal regularization can remove double descent even in certain anisotropic settings. However, the comment lacks specific references or detailed reasoning to support this claim. It mentions prior work on samplewise multiple descent in linear regression but does not provide specific examples or detailed analysis of how the current work builds upon or differs from these prior results. The lack of detailed evidence or references makes the claim 3, as the authors would need to further explore the literature to fully understand and address the reviewer\"s point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s contribution, noting that the main result about removing double descent in certain anisotropic settings may not be novel if prior work has already shown samplewise multiple descent in linear regression. The reviewer acknowledges that they are not familiar with the particular techniques and tools used in the paper, but suggests that the paper should better highlight the novelty of its result in relation to prior results. This feedback is 3 as it points out a potential weakness in the paper\"s contribution and suggests a way to enhance its novelty. However, it lacks specific guidance on how to effectively communicate the novelty or what aspects of the paper should be emphasized. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the methods or improve their connection. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed methods, specifically contrastive training objective and contrastive search, and notes that they are independent methods with little inner connection on both the intuition and the algorithm. However, it does not specify which part of the paper these methods are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of lack of connection between the methods, but it is 1 as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, contrastive training objective and contrastive search, are independent and lack a clear connection on both the intuition and the algorithm. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, contrastive training objective and contrastive search, noting that they are independent and lack a clear connection on both the intuition and the algorithm. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful if it offered specific suggestions or examples of how to integrate the methods or improve their connection. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern regarding the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment implies that the authors should provide a comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or methodology sections. The comment is specific in detailing what needs to be addressed, such as the need for a comparison and justification. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. The reviewer suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. While the comment identifies a potential issue with the paper\"s goal and suggests improvements, it lacks specific examples or references to support the claim that the method is not comparable to existing DAS earthquake detectors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal, specifically the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and the absence of a justification for the benefits of the proposed method over these existing methods. It suggests that if the paper claims to be a foundation model, it should clarify this and demonstrate a future useful application. This feedback is clear and actionable, as it points out a critical gap in the paper that needs to be addressed to strengthen its claims. By suggesting a comparison with existing methods and a justification for the proposed method\"s benefits, the comment provides the authors with a concrete direction for improvement. However, it could be more helpful if it offered specific examples or references to existing methods that could be used for comparison. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: why the results of Table 6 are not aligned with Table 1 (MCTpair) and what about the ablation studies of MCT without the adaptive metrics. While these questions imply that the authors should address these issues, they do not provide explicit instructions or concrete guidance on how to do so. The authors can infer that they need to clarify the discrepancy in the results and potentially include ablation studies, but the comment lacks specific details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCTpair),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the alignment of results and asking about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two questions that are relevant to the paper\"s content and methodology. First, it questions the alignment of results between Table 6 and Table 1 (MCTpair), which could indicate a discrepancy or inconsistency in the data. Second, it asks about the ablation studies of MCT without the adaptive metrics, suggesting that this could be a valuable addition to the paper. While the questions are valid, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their work. It provides some direction but could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. The reviewer also mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. While the comment highlights the existing work, it does not provide explicit guidance on how the authors should address this issue or improve their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should either expand on the existing analyses or provide new insights to differentiate their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific analyses and references prior works, such as RobustBench and Croce et al. (2021), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that similar analyses have been conducted in prior works, which may not be surprising due to the limited scale. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that similar analyses have been conducted in prior works, specifically mentioning the robustness of CIFAR10 models on distribution shifts. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. The comment provides specific references to external works, which supports the claim that the analyses are not novel. However, the comment could be strengthened by providing more detailed comparisons or insights into how the current work differs from the prior works. Overall, the claim is 4 due to the references provided, but it could be further substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the work, noting that similar analyses have been conducted in prior works, specifically on a smaller scale. It references specific works, such as RobustBench and Croce et al. (2021), where similar analyses were conducted on a smaller scale. Additionally, it mentions that [A, B] have evaluated the robustness of adversarially trained models to unseen attacks. While the comment highlights a potential weakness in the novelty of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or differentiate their work from prior studies. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not provide any specific guidance on what kind of discussions are needed or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, it does not specify which part of the paper these subtasks are discussed in, nor does it provide details on what kind of discussions are needed. Without explicit references to sections or specific subtasks, the authors cannot confidently determine which parts of the paper need revision. The comment is not specific about what needs to be addressed or how the authors should improve the discussion. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for bAbi and that more discussions are required. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or examples to substantiate the assertion that the subtasks are simplistic or why additional discussions are necessary. Without such support, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the 10 subtasks presented in the paper, suggesting that they may be simplistic for bAbi and that more discussions are required. However, the comment lacks specificity and does not provide any guidance on what kind of discussions are needed or how the authors might address this issue. Without actionable suggestions or detailed feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It asks whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. While the comment implies that the authors should consider this limitation and potentially explore alternatives, it does not provide explicit instructions or concrete suggestions on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in its inquiry about whether the limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It does not present an opinion, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a valid concern about the limitation of the approach, specifically the restriction to triplets or a sliding window of length 3. It questions whether this limitation is fundamental or if an extension to longer subsequences without a sliding window is straightforward. This feedback prompts the authors to consider whether their approach is limited by the choice of window size or if it can be extended to accommodate longer sequences. While the comment identifies a potential weakness, it does not provide specific suggestions or guidance on how to address this limitation or explore alternative approaches. The feedback is 3 as it points out an area for consideration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper and suggests that related work might be relevant but not necessarily detrimental to the novelty of the paper. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions to take. The comment lacks concrete steps or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the definition of \"sequence of episodes\" and suggesting that related work might be relevant but not detrimental to the novelty of the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the definition of \"sequence of episodes\" and the relevance of related work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"sequence of episodes\" in the context of the paper, which is a relevant point for clarity. It also suggests that related work might be relevant but not detrimental to the novelty of the paper. While the comment identifies a potential area for improvement by suggesting the inclusion of related work, it lacks specific guidance or suggestions on how to address this issue or incorporate related work. The feedback is 3 as it points out a potential gap in the paper, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the classification of the study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what changes should be made to the study. The comment lacks actionable advice or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the study\"s classification but lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the classification of a study as an \"ablation\" study, suggesting that it does not involve removing a component of the method. While it identifies a potential issue with the study\"s designation, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or reframe their study. The feedback is 3 as it points out a potential misclassification, but it does not offer actionable advice or detailed critique to help the authors improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation, that uses similar operators. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific steps to consider. The authors are left without any clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it would make sense to include and learn AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the inclusion of AccNet in a larger predictor. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of AccNet as part of a larger predictor, such as for semantic segmentation. It suggests that it might make sense to include AccNet in this context. However, the comment lacks specific guidance or suggestions on how to address this question or what potential benefits or drawbacks such an inclusion might have. While it prompts the authors to consider this aspect, it does not provide actionable steps or detailed reasoning to support the claim. Therefore, the comment is 3, as it points out a potential area for consideration but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed metric is only tested on a single dataset, which is a limitation. However, it does not provide any guidance on how the authors should address this issue or suggest ways to expand the testing to other datasets. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the proposed metric, noting that it is only tested on a single dataset. However, it does not specify which dataset or which part of the paper discusses this metric, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the testing of the metric, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed metric is only tested on a single dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s validity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically noting that the proposed metric is only tested on a single dataset. This is a relevant observation that could impact the generalizability and applicability of the metric. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional datasets for testing or discussing the implications of this limitation. While it points out a potential weakness, the feedback could be more helpful with additional context or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the proposed TransferNorm architecture to similar architectural competitors like AutoDial and AdaBN. This feedback provides a clear and explicit action for the authors to take, which is to extend the evaluation to include these additional comparisons. The suggestion is concrete, as it specifies exactly what needs to be done to enhance the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"comparing several base DA methods with and without the proposed TransferNorm architecture.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. This provides clear guidance on what additional comparisons should be made to enhance the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation could be strengthened by including comparisons with other architectural competitors like AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these comparisons would enhance the evaluation. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the exact benefits of including these comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the evaluation section by suggesting that the base DA methods should be evaluated with and without the proposed TransferNorm architecture, as well as with other architectural competitors like AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by including additional comparisons. By doing so, the authors can better demonstrate the strengths and limitations of their proposed method in the context of existing architectures. However, the comment could be more helpful if it explained why these additional comparisons are important or how they would impact the evaluation\"s conclusions. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6. It also mentions that the lack of definitions hindered understanding in an initial read. The reviewer provides specific references to similar works that have defined these terms, which offers a clear direction for the authors to address these issues. By explicitly mentioning the undefined terms and providing examples of how they have been defined in other works, the comment offers concrete guidance on how to improve the clarity and accessibility of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"L73\" and \"L166,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue of undefined abbreviations and the lack of definition for superscript notation in Equation 6, which hindered understanding. Additionally, it provides examples of similar works that have defined these terms, offering clear guidance on how to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. The reviewer provides references to similar works that have defined these terms, offering a logical basis for the claim. However, the comment could be strengthened by providing more detailed explanations or examples of how these terms are defined in the referenced works. As it stands, the claim is 4 due to the references, but it could be further substantiated with additional details. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as undefined abbreviations and undefined superscript notation in Equation 6, which hindered understanding in an initial read. It provides examples of similar works that have defined these terms, offering clear guidance on how to improve the clarity and accessibility of the paper. By pointing out these specific issues and providing references to similar works, the comment offers actionable feedback that can help the authors enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it included suggestions on how to address these issues, such as recommending specific definitions or approaches. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue. There is no guidance on what specific changes could be made to improve the evaluation or how to ensure that the baselines are appropriate for fair classification. Without actionable advice or concrete steps, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the evaluation and the use of baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation being weak and the baselines not being designed for fair classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, noting that the baselines used in the paper are not designed for fair classification. This is a critical observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific guidance on how to clarify the setting or what aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the setting but may not be entirely sure of the exact details to address. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first three paragraphs of section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting needs to be spelled out more clearly and suggesting that the authors may be trying to present something in greater generality than what is actually presented, which muddles the exposition. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors are trying to present something in greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may find it challenging to understand the exact issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It suggests that the authors may be presenting something in greater generality than what is actually shown, which muddles the exposition. This feedback is clear and actionable, as it points out a specific area where the authors need to clarify their work to improve the reader\"s understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the setting or what specific aspects need to be addressed. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the convincing nature of the experiments and questions the choice of the old baseline, R3D and C3D. It suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc., and compare its advantages to those approaches. While the comment implies that the authors should conduct additional experiments or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or comparisons to address the concerns raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the old baseline and suggesting that the proposed method should be evaluated on other 3D CNNs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the convincing nature of the experiments and suggests that the authors should consider whether their proposed method works on other 3D CNNs, such as X3D, SlowFast, etc. The comment also raises a logical question about the advantage of the proposed method compared to these approaches. However, the comment lacks specific examples or references to support the claim that the baseline is outdated or that the proposed method is not convincing. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experiments, questioning the choice of the old baseline and suggesting that the proposed method should be evaluated on other 3D CNNs, such as X3D, SlowFast, etc. It also raises a logical question about the advantage of the proposed method compared to these approaches. While the comment provides a clear direction for improvement by suggesting additional experiments, it lacks specific guidance on how to conduct these experiments or what specific aspects to focus on. This limits the comment\"s helpfulness, as it points out an area for improvement but does not offer detailed instructions on how to address it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the attention module is attached to the backbone ResNet20 architecture, including the number of attention modules used, their placement (after each block or stage), and how they are integrated into the overall architecture. This feedback provides clear and specific guidance on what the authors need to address to improve the clarity of their draft. The action is concrete, as it details the exact information that needs to be clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module attached to the backbone ResNet20 architecture\" and the need to clarify how many attention modules are used, where they are placed, and after which stages. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be clarified, such as the number of attention modules, their placement, and how they are integrated into the architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how the attention module is attached to the backbone ResNet20 architecture, specifically asking about the number of attention modules, their placement, and how they are integrated into the overall architecture. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the integration of the attention module with the backbone ResNet20 architecture. It asks for clarification on the number of attention modules used, their placement, and how they are integrated into the overall architecture. This feedback is clear and actionable, as it provides the authors with specific questions to address in order to improve the clarity of their draft. By addressing these points, the authors can enhance the understandability and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information in the paper. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. It also asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment provides explicit actions\u2014asking for clarification and suggesting a related work for discussion\u2014it does not offer specific guidance on how to implement the contentadaptive algorithm or what aspects of the method need improvement. The authors are given clear directions but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"BDrate comparison,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the method\"s performance at low bitrates and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance at low bitrates, suggesting that it is close to the baselines in this range. The reviewer asks for clarification on the precise bitrate range used for BDrate comparison and suggests discussing a related work about implementing contentadaptive algorithms in learned video compression. While the comment identifies a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to discuss a related work is helpful but does not fully address the initial concern. Therefore, the comment is 3, as it provides some evidence but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it performs stronger at high bitrates but is close to the baselines at low bitrates. This is a valuable observation that prompts the authors to reconsider the method\"s performance range and potentially adjust their claims. Additionally, the comment suggests discussing a related work about implementing contentadaptive algorithms in learned video compression, which could provide a valuable context for the authors to consider. While the comment does not offer specific suggestions on how to address the issue or implement the contentadaptive algorithm, it provides clear and actionable feedback that can guide the authors in improving their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While the comment implies that the authors should make this distinction, it does not provide explicit instructions on how to do so or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors need to infer that they need to make a distinction but are not given specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, it does not specify which part of the paper this distinction should be made in, nor does it provide detailed guidance on how to make this distinction. The authors can infer that it relates to the discussion or analysis of results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or how it would benefit the paper. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making the suggested distinction. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds that the machine learning and NeurIPS community is familiar with. While this feedback identifies a potential area for clarification and differentiation, it lacks specific guidance on how to achieve this distinction or what aspects of the paper need to be revised. The comment does not provide detailed suggestions or examples of how to effectively distinguish these concepts, leaving the authors with a general direction but without actionable steps. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what additional analysis should be conducted. The comment lacks concrete details or specific actions for the authors to take, leaving them uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not specify which tasks, previous works, or selfimplemented baselines are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what additional analysis should be conducted or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal and that further analysis beyond the main experiments is not sufficient. However, it does not provide specific examples or details on what aspects of the analysis are lacking or how the authors could improve it. The comment lacks actionable guidance or suggestions for enhancing the analysis, leaving the authors without clear direction on how to address the critique. As a result, the feedback is not helpful, as it does not provide the authors with a path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should make the proof of Theorem 8 clearer, but it lacks specific instructions on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the clarity of the proof, but without concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the linear convergence rates relying on Theorem 8, which is buried in the appendix and whose proof is unclear. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that all the linear convergence rates rely on Theorem 8, which is buried in the appendix and whose proof is unclear. This is a clear and actionable point that the authors can address to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the proof or how to better integrate Theorem 8 into the main text. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the inaccuracy of a statement about the Walkman algorithm and the lack of clarity in the reference to \"it\" in Section 3. The comment explicitly instructs the authors to correct the inaccuracy regarding the Walkman algorithm, specifying that it is solved by ADMM with two versions. It also points out the lack of clarity in the reference to \"it\" in Section 3, suggesting that the authors clarify the intended reference. These actions are explicit and provide concrete guidance on what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about the Walkman algorithm, noting that it is solved by ADMM with two versions, and that it is inaccurate to say that these works are all based on simple SGD for decentralized optimization. Additionally, it points out the lack of clarity in the reference to \"it\" in Section 3. This provides clear guidance on what needs to be addressed in these parts of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that \"these works are all based on the simple SGD for decentralized optimization.\" It provides a specific correction by noting that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement. This is a logical and factual observation that requires no additional evidence or references to support the claim. Therefore, the comment is 5, as it provides a clear and accurate correction to the authors.", "helpfulness_rationale": "The review comment is 4 as it identifies specific inaccuracies in the paper, particularly in the Related Work section. It points out that the Walkman algorithm is solved by ADMM with two versions, which contradicts the statement that these works are all based on simple SGD for decentralized optimization. This feedback is clear and actionable, as it directs the authors to correct the inaccuracy in their claims. Additionally, it highlights a lack of clarity in the reference to \"it\" in Section 3, which could be improved for better understanding. However, the comment could be more helpful if it provided suggestions on how to clarify the reference or improve the explanation in Section 3. Overall, the feedback is valuable in guiding the authors to correct their claims and improve the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant issue with the theoretical result, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. It also suggests that the authors should compare their rates to existing rates in the literature. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific rates should be compared. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the result only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. Additionally, it suggests that the authors should compare their rates to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main theoretical result in the paper provides utility guarantees only when the features and noise are Gaussian, which is a strong requirement on the data. The reviewer suggests that this assumption is not necessary for previous algorithms and that the authors should compare their rates to existing rates in the literature. The claim is 3 as it provides a logical reasoning for the requirement and suggests a potential area for improvement. However, it lacks specific examples or references to existing works that support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical result of the paper, noting that it only provides utility guarantees for the proposed algorithm when the features and noise are Gaussian, which is a strong requirement on the data. This is a critical observation that highlights a potential weakness in the paper\"s theoretical foundation. Additionally, the comment suggests that the authors should compare their rates to existing rates in the literature, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples or references to existing works that demonstrate the necessity of this requirement or how it affects the utility of the algorithm. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This implies that the authors should include such a comparison in their paper. However, the comment does not specify how to conduct this comparison or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, as it lacks detailed guidance on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with the original approach, but it lacks detailed guidance on how to implement this comparison or what aspects to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be useful to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparison that could enhance the paper\"s credibility and rigor. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, such as which specific aspects of the original approach should be compared or how to interpret the results. While it provides a general direction for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it implies that the authors should include additional experiments, it does not specify which specific baselines or comparisons should be included. The action is clear but lacks concrete details on which additional experiments to conduct or how to present them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding more experimental comparisons to demonstrate the effectiveness of the proposed method, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should add more experimental comparisons to demonstrate the effectiveness of their proposed method. While it references specific works that focus on similar questions, it does not provide detailed reasoning or evidence to support why these additional comparisons are necessary or how they would enhance the paper. The reference to specific works is a helpful starting point, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the suggestion but requires more detailed explanation to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section, suggesting that the authors should include more experimental comparisons to demonstrate the effectiveness of their proposed method. It references specific works that focus on similar questions, providing a clear direction for the authors to expand their experimental analysis. However, the comment could be more helpful by offering specific suggestions on which additional baselines or comparisons to include, or how to present the results in a more comprehensive manner. Overall, the feedback is 3 as it points out a gap in the experimental section but lacks detailed guidance on how to address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This is a clear and explicit action for the authors to take, as it provides a specific direction for improving the presentation of results. The comment is concrete because it specifies the exact changes needed to be made, such as presenting average results on the test set and defining error bars under different random seeds. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on how to improve the presentation of results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not present convincing results due to the reporting of best results on the development set with hyperparameter search and model selection on the development set. The reviewer suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it logically points out a potential issue with the presentation of results, but it lacks specific examples or references to support the claim. The suggestion for presenting results on the test set is reasonable, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the authors report the best results on the development set with hyperparameter search and model selection on the development set, which is not enough to be convincing. The comment suggests that the paper should present average results on the test set with clearly defined error bars under different random seeds. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results, which could enhance the credibility and impact of the paper. However, the comment could be more helpful if it explained why presenting results on the test set is crucial or how it would impact the conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors provide more values of the parameter \u03b1, specifically suggesting values of 1e2 and 1e3. This guidance is clear and concrete, as it specifies exactly what additional values should be included and why (to bridge the gap between 1e4 and 1e1). The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient ablation study on \u03b1 and recommends providing more values of \u03b1, such as 1e2 and 1e3. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study on \u03b1 is insufficient, as it only considers values of 1e4, 1e1, and 5e1 with a large gap between 1e4 and 1e1. The reviewer recommends providing more values, specifically 1e2 and 1e3, to bridge this gap. This claim is 3 as it logically suggests that more values would provide a better understanding of the parameter\"s effects. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study on the parameter \u03b1, noting that it only considers values of 1e4, 1e1, and 5e1 with a large gap between 1e4 and 1e1. The reviewer recommends providing more values, specifically 1e2 and 1e3, to bridge this gap and improve the understanding of the parameter\"s effects. This feedback is clear and actionable, as it directly suggests specific values to include in the ablation study. By addressing this point, the authors can enhance the robustness and comprehensiveness of their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the questions are explicit, the comment lacks concrete guidance on how to address them. The authors know they need to provide this information but are not given specific steps to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the dataset and methodology sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the dataset used in the paper, including the number of topics, the method for obtaining topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test set and the number of vocabulary words. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given direction but not detailed steps on how to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback implies that the authors should expand their analysis to include more comparisons and consider additional NAS approaches. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on which NAS approaches to include or how to conduct the analysis. While the action is implied, it is not as concrete as it could be, leaving the authors with a general idea of what needs to be done but without detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis on BRPNAS, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the analysis is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. However, the comment does not provide specific examples or references to these other NAS approaches, nor does it explain why these comparisons are necessary or how they would enhance the analysis. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the analysis section of the paper, specifically noting that the BRPNAS analysis only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot approaches. This feedback is valuable as it highlights an area where the paper could be expanded to provide a more comprehensive analysis. However, the comment does not offer specific suggestions on how to address this issue or which NAS approaches to consider, leaving the authors with a general idea of what needs to be improved. While it points out a potential weakness, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, stating that it distracts from the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes, if any, should be made to the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the distraction but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the zeroshot version and its connection to density estimation are distracting from the main point of the paper, which is about learning effective prototypes for fewshot learning. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective opinion about the zeroshot version and its connection to density estimation, suggesting that these elements are distracting from the main point of the paper. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks specificity and does not guide the authors on how to address the issue or improve the clarity of the paper. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors need to provide more information on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for details on the translation and filtering methodology to assess the dataset quality. This feedback is clear and concrete, as it specifies exactly what information is missing and what needs to be added. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of details on the filtering process used to create the dataset and the need for more information on the translation and filtering methodology to assess dataset quality. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"details around the filtering process used to create the Arabic climate change QA dataset are lacking.\" This is a factual observation about the paper, as it highlights a gap in the description of the dataset creation process. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this detail is important or how it affects the quality of the dataset. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the lack of details on the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the transparency and credibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be enriched by adding attacks with different strengths and by exploring how different thresholds influence detection performance. While the comment implies that these additions would improve the results, it does not provide specific guidance on how to implement these changes or what specific types of attacks or threshold analyses should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to enhance their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or figures where these additions could be made. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting improvements. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by adding attacks with different strengths and exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support the claim that these additions would improve the results. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it. Therefore, the claim is considered 2, as it provides a general direction but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting the addition of attacks with different strengths and an exploration of how different thresholds influence detection performance. This feedback is clear and actionable, as it provides specific suggestions for enhancing the experimental analysis. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or what specific types of attacks or threshold analyses should be considered. Despite this, the feedback is 4 as it directs the authors toward improving their experimental design and results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer notes that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. While the comment provides a clear action\u2014to evaluate the claim by training a discriminator\u2014it does not offer specific guidance on how to implement this evaluation or what metrics to use. The authors are left to infer the details of execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the claim to reduce exposure bias and the need to train a discriminator on generations from the learned model. The comment provides a clear direction for the authors to follow, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should evaluate their claim of reducing exposure bias by training a discriminator on generations from the learned model, similar to Figure 1. The reviewer explains that this is different from Figure 4, as the discriminator is coadapting with the generator, which could lead to getting stuck at a local optimum. This claim is 3 as it provides a logical reasoning for the need to evaluate the claim and explains the difference between Figure 1 and Figure 4. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of the paper, which is to train a discriminator on generations from the learned model to confirm if the paper successfully reduces exposure bias. The reviewer explains the difference between Figure 1 and Figure 4, noting that the former involves coadaptation between the discriminator and generator, while the latter is a static representation. This feedback is valuable as it guides the authors on how to test their claim and provides a specific method for evaluation. However, the comment could be more helpful if it offered additional insights or examples on how to implement this evaluation or what metrics to use. Overall, the comment is 4 as it provides a clear direction for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. While the action is implicit, it is clear and concrete, as it specifies what additional information is needed to be included in the paper. The authors know exactly what to do to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance difference resulting from using different image sizes and variations of ResNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide information on the performance difference resulting from using different image sizes and variations of ResNets. This feedback is 3 as it identifies a specific area where the paper could be improved by including additional data or analysis. However, the comment lacks depth and does not provide specific guidance on how to present this information or what specific metrics or analyses would be most relevant. While it points out a potential area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to present and describe the Algorithm in detail, which is helpful for understanding the proposed method. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the algorithm is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to present and describe the algorithm in detail, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and comprehensibility of their work. By addressing this suggestion, the authors can improve the reader\"s ability to understand and evaluate the proposed method. However, the comment could be more helpful if it included specific examples or guidance on how to present and describe the algorithm in detail. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper. While it implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a runtime comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison at test time, which is related to the use of Chebyshev polynomials to achieve a speedup. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where the comparison could be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a runtime comparison, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that a runtime comparison at test time would be interesting to include in the paper, given the mention of using Chebyshev polynomials to achieve a speedup. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a runtime comparison at test time would be interesting to include in the paper, given the mention of using Chebyshev polynomials to achieve a speedup. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. While it points out a potential improvement, it could be more actionable and comprehensive with additional explanation or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or suggestions on how to address this concern. The authors can infer that they need to consider the applicability of their method to a broader range of image types, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, it does not specify which part of the paper this question pertains to, such as the methodology or results sections. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the applicability of the method to natural images, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. However, the comment lacks any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without such information, the claim remains 1, as it does not provide a clear basis for the authors to address the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the applicability of the proposed method to natural images, specifically questioning whether it can be used on datasets like CIFAR10. This is an important consideration for the broader applicability of the method in realworld scenarios. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or expand the applicability of their method. While it points out a potential limitation, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a relevant issue but lacks comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, it does not provide any explicit guidance or suggestions on how to improve the organization of the prompts or what specific changes should be made. The authors are left to infer that they need to reorganize the prompts, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 6, 7,\" providing full grounding as it allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the organization of the prompts, noting that all sentences are squeezed together. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the prompts in Table 6 and 7 are not wellorganized, with all sentences squeezed together. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks the necessary evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Tables 6 and 7, noting that all sentences are squeezed together. This feedback is 3 as it points out a clear area for improvement in the presentation of the prompts. However, the comment lacks depth and does not provide suggestions on how to address this issue or improve the organization. While it highlights a potential problem, it does not offer actionable guidance or detailed advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to improve the clarity of the figures and label the modules, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"CMAF, L_BT, VoLTA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the clarity of the figures, particularly the confusion regarding the relation between subfigures in Figure 2 and the lack of labeling for certain modules. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning Figure 2 and the confusion regarding the relation between subfigures. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the basis of the confusion and the importance of labeling the modules. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relation between subfigures is confusing. It also points out that some modules, such as CMAF, L_BT, and VoLTA, are not labeled in the figures. This feedback is clear and actionable, as it directs the authors to improve the clarity of the figures by labeling the modules and ensuring the subfigures are properly labeled. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the figures or offered examples of how to label the modules effectively. Overall, the comment is 4 as it guides the authors on how to enhance the visual presentation of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that if FFNs are omitted due to a linear decomposition issue, the authors should consider whether there is existing work that offers a way around this limitation. If not, the comment recommends adding a line or two acknowledging the lack of a solution and describing it as an open (hard) problem. This feedback provides a clear and explicit action for the authors to take, ensuring they know exactly what steps to consider to improve their draft. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of FFNs being omitted due to a linear decomposition problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering existing work for a way around the issue and proposes adding a line or two to acknowledge the problem as an open (hard) problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that FFNs are omitted due to a linear decomposition issue and questions whether there is existing work that offers a way around this limitation. The comment suggests that if not, a line or two should be added acknowledging the problem as an open (hard) problem. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific references or examples to fully substantiate the claim. The authors might need to conduct additional research to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper regarding the omission of FFNs due to a linear decomposition problem. It suggests that the authors should consider whether there is existing work that offers a way around this limitation or if it is an open (hard) problem. The comment provides a clear and actionable suggestion for improving the paper by acknowledging the issue and offering a potential solution. This feedback is valuable as it helps the authors enhance the readability and clarity of their work by addressing a potential gap in the literature. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to control domain drift. The comment lacks actionable details, such as recommending specific methods or experiments to explore, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the use of perplexity and the need to control domain drift, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. However, the comment does not provide specific examples or references to support the claim that perplexity is an inappropriate measure or that domain drift is a significant issue. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of perplexity as a measure of semantic information retention after finetuning, noting that there are also factors such as domain drift that need to be controlled. This is an important point that could impact the validity and reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or control domain drift. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that the first appearance of BYOL in the abstract should be explained. While these questions imply that the authors should investigate the effect of image number and provide an explanation for BYOL, the comment does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an analysis and provide an explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific questions about the cluster structure and its impact on model performance, as well as the first appearance of BYOL in the abstract. However, it does not explicitly mention which part of the paper these questions pertain to, such as specific sections or figures. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for an explanation of BYOL and the impact of the number of images on performance, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment also requests an explanation of BYOL in the abstract, but it does not provide any justification or examples to support this request. As a result, the claim is 1, as it lacks the necessary evidence or reasoning to be considered valid. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises important questions about the impact of the number of images on model performance and suggests that more training images might worsen performance. It also requests an explanation of BYOL in the abstract, which is a relevant point for clarity. While the comment identifies potential areas for improvement and provides a clear direction for the authors to explore, it lacks specific guidance or suggestions on how to conduct the analysis or address the BYOL explanation. This limits the comment\"s helpfulness, as it points out potential issues but does not fully support the authors in resolving them. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to address the reviewer\"s concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of understanding the underlying mechanisms of the method, specifically regarding the L_pixel component. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the understanding of the method\"s underlying mechanisms, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial to clarify why the method works. However, the comment does not provide specific examples or references to support the claim that the current explanation is insufficient. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of the method\"s underlying mechanisms, particularly regarding the L_pixel component. It suggests that providing stronger arguments or intuitions to explain why the method works would be beneficial. This feedback is 3 as it points out a specific area where the authors could enhance their draft, but it lacks detailed guidance on how to provide these arguments or intuitions. The comment highlights an important aspect of the paper that could be clarified, but it does not offer specific suggestions or examples to guide the authors in making those improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically mentioning sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. The comment is clear and concrete, giving the authors specific details to include in their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more comprehensive overview of existing methods and their limitations, including sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This provides clear guidance on what needs to be improved in the Related Work section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section is lacking details, specifically mentioning the need for a more comprehensive overview of existing methods and their limitations. The reviewer provides a list of specific methods to consider, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This detailed list of examples and references provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these methods are relevant to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the Related Work section, noting that it lacks details and suggesting that the authors should provide a more comprehensive overview of existing methods and their limitations. The comment lists several specific approaches, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, which should be discussed in the context of the paper. This detailed guidance helps the authors understand what aspects of the related work are important to include and how to present them effectively. By addressing these points, the authors can significantly improve the clarity and comprehensiveness of their Related Work section, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It suggests that LLMs are typically trained on trillions of tokens and questions whether 44k dialogues can capture the combinations of personalities and topics. The reviewer implies that the dataset needs to be massive to cover varied domains. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern, such as suggesting additional data collection or alternative methods for training. The action is implicit and somewhat vague, as the authors can infer that they need to consider the sufficiency of their training data but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training data, specifically the number of dialogues (44k) and the need to capture a wide range of user traits and personalities across different content topics. It also questions whether this dataset is sufficient and compares it to the typical training data for LLMs, which are typically trained on trillions of tokens. This provides clear guidance on what aspect of the training data is being questioned. However, the comment lacks specificity regarding how the authors should address this concern or what specific improvements could be made to the dataset. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. The reviewer compares this dataset to the typical training data for LLMs, which are typically trained on trillions of tokens, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues are enough to capture a wide range of user traits and personalities across different content topics. It highlights the typical training data for LLMs, which are typically trained on trillions of tokens, and suggests that the dataset needs to be massive to cover varied domains. While the comment identifies a potential weakness in the dataset, it lacks specific suggestions or guidance on how the authors might address this issue or improve the dataset. The feedback is 3 as it points out a potential limitation but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the use of binary classification as a baseline metric, questioning its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what alternative metrics or approaches might be more suitable. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of binary classification as a baseline metric and expresses skepticism about its ability to assess models\" understanding of finegrained errors like technique errors. However, it does not specify which part of the paper this concern is related to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or discussion of the results, but this inference is not direct. The comment is specific in its critique of the binary classification as a baseline, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the appropriateness of using binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to alternative metrics or methods that could be used instead. As a result, the claim is 3, as it raises a valid concern but lacks the necessary justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the use of binary classification as a baseline metric, suggesting that it may not be adequate for assessing models\" understanding of finegrained errors like technique errors. While it raises a valid concern, the comment lacks specific suggestions or alternatives for how the authors might address this issue. It does not provide guidance on how to improve the baseline metrics or what other metrics might be more appropriate for assessing the models\" performance. As a result, the comment is 3, as it points out a potential weakness but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work only uses binary features and questions whether the method is applicable to real and categorical features. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to consider real and categorical features. The comment lacks concrete details on how to incorporate these features or what specific modifications are needed. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of binary features in the work and questions whether the method is applicable to real and categorical features. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of binary features and suggesting that the method may not be applicable to real and categorical features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses binary features, which is a factual observation. However, it questions whether the method is applicable to real and categorical features, suggesting that this limitation needs to be addressed. The comment does not provide specific examples or references to support this claim, making it 3. The authors may need to infer the importance of considering real and categorical features, but the lack of detailed evidence or reasoning makes the claim 3.", "helpfulness_rationale": "The review comment identifies a limitation in the work, noting that it only uses binary features while realworld data typically includes a mix of binary, real, and categorical features. This is a relevant observation that could impact the applicability and generalizability of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate real and categorical features into their analysis. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not provide specific examples or guidance on what aspects of the writing are unclear or how to improve it. The comment lacks concrete details on how to address the issues, leaving the authors without a clear understanding of what changes to make. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing should be improved and points out that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide examples of what needs to be clarified. Without specific references to sections, figures, or other elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and mentions that some points in the paper are unclear. However, it does not provide specific examples or detailed reasoning to support why the writing is unclear or how it could be improved. Without specific references or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing should be improved, indicating that some points in the paper are unclear. However, it does not provide specific examples or detailed feedback on what aspects of the writing are unclear or how they could be clarified. Without this information, the authors are left without actionable guidance on how to enhance their draft. The comment lacks depth and specificity, making it 2 as it points out an area for improvement but does not offer concrete steps for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback provides a clear and explicit action for the authors to take, which is to consider using additional metrics for evaluating their results. The suggestion is concrete, as it specifies a specific metric to use, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation of results, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the use of BERTScore as an alternative metric, providing some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. However, the comment does not provide any supporting evidence or reasoning for why BERTScore is a better choice or why the current metrics are insufficient. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics to evaluate the results, specifically mentioning BERTScore as an example. This feedback is 3 as it identifies a potential area for improvement by suggesting the use of a different metric for evaluating the results. However, the comment lacks depth and does not provide detailed guidance on why BERTScore might be a better choice or how it could be integrated into the evaluation process. Additionally, it does not address other potential metrics or discuss the implications of using a different metric. While the suggestion is a step in the right direction, it could be more helpful with additional context and explanation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, specifically mentioning metrics like MMLU and Big Bench for language generation. While the comment does not explicitly instruct the authors to conduct this comparison, it provides a clear direction for how to enhance the evaluation of their metric. The action is implicit but concrete, as it specifies the metrics to compare and the conditions under which SynTextBench should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"large amount of work on LLM evaluation\" and references specific metrics like MMLU and Big Bench, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely comparing the SynTextBench metric to other metrics proposed in the literature and clarifying under what conditions SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there has been a large amount of work on LLM evaluation and mentions specific metrics like MMLU and Big Bench. It also claims that some of the metrics in the literature do not satisfy the proposed desiderata, but it does not provide specific examples or detailed reasoning to support this claim. The comment suggests comparing the SynTextBench metric to other metrics proposed in the literature, but it lacks specific examples or detailed guidance on how to conduct this comparison. This makes the claim 3, as it provides a direction for improvement but lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the evaluation of the SynTextBench metric compared to other metrics proposed in the literature, specifically mentioning MMLU and Big Bench for language generation. It suggests that the authors should clarify under what conditions SynTextBench should be used over other metrics. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the evaluation and comparison of their metric. However, the comment could be more helpful if it offered suggestions on how to conduct the comparison or what specific conditions to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, it does not provide any guidance on how the authors should address this issue or what specific changes could be made to enhance the novelty of their work. The comment lacks explicit or implicit actions, leaving the authors without direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions the \"algorithm for construction of coresets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, stating that the algorithm is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the algorithm for constructing coresets is not novel because it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the novelty of the paper, noting that the algorithm for constructing coresets is not novel as it is an extension of existing frameworks for classical kmeans and (k,z) clusterings to the kernelized setting. This feedback is clear and actionable, as it points out a weakness in the paper\"s originality and suggests that the authors should consider how to enhance the novelty of their work. However, the comment could be more helpful if it provided suggestions on how to differentiate their approach or what aspects of the existing frameworks could be improved. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the writing and annotations are difficult to follow, but it does not provide any specific guidance on how to improve them. It lacks actionable advice or suggestions on how to make the writing and annotations clearer or more accessible. Without concrete steps or examples, the authors are left without a clear understanding of what changes to make to enhance the clarity of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"poor writing and annotations,\" but it does not specify which parts of the paper are affected by this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing and annotations are difficult to follow. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are difficult to follow. However, it does not provide any specific examples or detailed reasoning to support this claim. Without such evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a general issue with the writing and annotations being difficult to follow. However, it lacks specificity and does not provide any guidance on how to improve the clarity or accessibility of the content. Without actionable suggestions or examples, the authors are left without a clear understanding of what changes to make to enhance the readability of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should provide an explanation or analysis to clarify this discrepancy. The action is implicit and somewhat vague, as it lacks concrete steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. The comment does not present any claims or opinions but rather seeks clarification or explanation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically questioning why the proposed method achieves the best overall F1 score but not the best F1 in all single types under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This is a valid point that could lead to a deeper understanding of the method\"s performance and its limitations. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the discrepancy. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to the methodology. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this methodology is discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its question about the methodology but lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the methodology used to select ECG segments with only one label assigned, suggesting that this approach might be less challenging than including all reports. This feedback prompts the authors to reconsider their methodology and potentially explore alternative approaches that could improve the robustness of their results. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative methods might be considered. While it identifies a potential weakness, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to enhance the paper. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this acknowledgment pertains to, making it weakly grounded. The comment does provide a specific suggestion for improvement, which is to consider the relaxation proposed by Guzman et al. This provides some level of specificity, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a minor suggestion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the proposed solution as an incremental step considering the relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. It identifies a minor suggestion, but without further elaboration or guidance, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability, specifically mentioning the need for a discussion on memory requirements and computational complexity. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include a discussion on scalability bounds, memory requirements, and computational complexity, but the comment lacks concrete details on how to structure or conduct this discussion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper limits of FedDES\"s scalability\" and \"memory requirements and computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a thorough exploration of scalability bounds and the need for a discussion on memory requirements and computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a thorough exploration of the upper limits of FedDES\"s scalability and does not provide a clear discussion on memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some indication of a potential issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of a thorough exploration of the upper limits of FedDES\"s scalability and the absence of a clear discussion on memory requirements and computational complexity. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to provide a more comprehensive understanding of its capabilities and limitations. However, the comment could be more helpful if it offered suggestions on how to address these gaps, such as recommending specific analyses or discussions to include. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should generate instances with more constraints and variables, as the paper currently has few instances with more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a clear and explicit action. The comment also raises a concern about LLMs\" ability to model problems with large instance sizes, providing a specific direction for improvement. However, it does not offer detailed guidance on how to implement this suggestion or what specific constraints and variables should be included. While the action is clear, the lack of concrete details on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. This implies that the authors should expand their dataset to include larger instances, which is a specific suggestion for improvement. However, the comment does not explicitly mention which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more variables and constraints, but without clear grounding, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks instances with more than 7 variables, which raises concerns about LLMs\" ability to model problems with large instance sizes. However, the comment does not provide specific examples or references to support this claim, nor does it explain why this limitation is significant or how it affects the paper\"s conclusions. Without additional context or evidence, the claim remains 3, as it requires the authors to infer the significance of the issue themselves.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the number of variables used in the instances, suggesting that the authors should generate instances with more constraints and variables to test the ability of LLMs to model larger instance sizes. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting the addition of more complex instances. However, the comment could be more helpful if it offered suggestions on how to generate these instances or what specific constraints and variables should be included. Overall, the comment is 4 as it highlights an important area for improvement but lacks detailed guidance on execution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the presentation of results, such as labeling the yaxis in Figures 2 and 3 and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. These actions are explicit and concrete, providing clear guidance on how to enhance the clarity and interpretability of the results. The authors know exactly what changes to make to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be improved, such as labeling the yaxis and using a scatter plot with runtime/performance axes. The comment also suggests highlighting the best results in tables, providing clear guidance on how to enhance the presentation of results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the results presentation in Figures 2 and 3 could be improved by labeling the yaxis more clearly and using a scatter plot with runtime/performance axes. It also recommends highlighting the best results in tables. While the comment provides a logical suggestion for improving the clarity of the results, it lacks specific examples or references to support the claim that these changes would indeed improve the presentation. The suggestion is 3, as it provides a reasonable direction for improvement but could be strengthened with more detailed justification or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the presentation of results in the paper. It identifies ambiguities in the yaxis labeling in Figures 2 and 3 and suggests using a scatter plot with runtime/performance axes to enhance clarity. Additionally, it recommends highlighting the best results in tables, which is a helpful suggestion for readers. The comment is clear and provides detailed guidance, making it 4 for the authors to improve the clarity and interpretability of their results. However, it could be more helpful if it included examples of how the suggested changes would enhance the results presentation. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It seeks clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment implies that the authors should provide more information or clarification on this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement \"NodeSort differentially sorts nodes depending on the base node,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the implications of this statement, including whether the base node affects the ordering, key nodes for attention, and model performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the implications of a statement regarding \"NodeSort differentially sorting nodes depending on the base node.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implications of the statement \"NodeSort differentially sorts nodes depending on the base node,\" seeking clarification on whether the base node affects the ordering, key nodes for attention, and model performance. This is a relevant question that could help the authors better understand the potential impact of their method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out a potential area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the arrow in Figure 2, asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer implies that the main purpose is to influence n^(i), but the current arrow seems to be misplaced. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the figure. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the arrow direction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the direction of the arrow in the figure, which is a clear indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space into the latent space rather than the other way around. The reviewer implies that the main purpose is to influence n^(i), but the current arrow seems misplaced. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the direction of the arrow in Figure 2, which is a clear and specific observation. It points out that the arrow currently goes from a Gaussian space into the latent space, rather than the other way around, which seems to contradict the main purpose of influencing n^(i). This feedback is valuable as it prompts the authors to reconsider the figure and potentially adjust the arrow direction to better align with their intended message. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current direction is problematic or offering alternative directions. Overall, the comment is 3 as it identifies a potential issue but lacks depth and actionable guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. It provides a clear and specific action for the authors to take, which is to define these abbreviations in the text or provide a glossary. This guidance is direct and concrete, leaving no ambiguity about what needs to be done to improve the clarity of the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abbreviation \"AR\" in Table 5, noting that it stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definitions and cause confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that many abbreviations lack definitions and cause confusion. It provides a concrete example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is valuable as it highlights a clear area for improvement in the clarity and accessibility of the paper. By addressing this issue, the authors can enhance the readability and comprehensibility of their work. However, the comment could be more helpful if it suggested ways to improve the definitions or provided examples of how to clarify the abbreviations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific technical considerations should be explored or how to address them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine whether it relates to a specific section, table, or figure. Additionally, the comment lacks specificity regarding what technical considerations are being questioned or how they might impact the analysis. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the technical considerations for conducting the analysis using advantage instead of q value. However, it does not present any claims, opinions, or suggestions that require verification. It is a request for clarification, which is not a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for conducting the analysis using advantage instead of q value, which is a relevant point for the authors to address. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might explore or justify their choice of using advantage over q value. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the setting of Unsupervised Online Adaptation is strange, as it requires a training set, including documents, queries, and labels. The reviewer suggests that this is not \"Unsupervised\" because the training set also requires annotations. While the comment identifies a potential issue with the labeling of the adaptation process, it does not provide explicit guidance on how to address this issue or suggest specific changes to improve the clarity or accuracy of the description. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the nature of the training set and its annotation requirements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The comment provides clear guidance on what needs to be addressed, namely the clarification of the adaptation process and its unsupervised nature. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. The reviewer supports this claim by referencing Section 3.1, where the model\"s training requirements are described. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a logical basis for the critique, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set, including documents, queries, and labels, which seems to contradict the unsupervised nature of the adaptation process. This feedback is 3 as it points out a potential inconsistency in the paper\"s description, prompting the authors to clarify or adjust their terminology. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or improve the clarity of the description. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an issue with the performance comparison in Table 1, specifically noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This implies that the comparison is unfair and suggests that the authors should address this issue to ensure fairness in their evaluation. However, the comment does not provide explicit guidance on how to rectify this issue or what specific changes should be made to the evaluation process. While the action is implied, it is not detailed enough for the authors to know exactly how to implement the suggested change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the performance comparison, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS sets different sample weights while most baselines use a uniform weight of 1. This claim is 3 as it provides a logical reasoning for the unfairness, but it lacks specific examples or references to support the assertion that this difference significantly impacts the comparison. The authors would need to make a concerted effort to understand and address the issue, which requires more detailed evidence or explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that VINS sets different sample weights while most baselines use a uniform weight of 1. This is a relevant observation that could impact the fairness and validity of the comparison. However, the comment does not provide suggestions or guidance on how the authors might address this issue, such as recommending a standardized weighting scheme or explaining the potential impact of this difference. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the system if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the time complexity or suggestions for adjusting the buffer size. Without actionable advice or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"reply buffer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of high time complexity if the buffer is too large, providing clear guidance on what needs to be addressed. However, the comment could be more specific by suggesting ways to mitigate the time complexity or providing examples of how other similar systems have handled this issue. Therefore, the comment is 4, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the system if the reply buffer is too large. This is a relevant concern that could impact the performance and scalability of the system. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue. It does not offer actionable advice or examples of how to mitigate the time complexity, leaving the authors without a clear path forward. Therefore, the comment is 3 as it points out a potential problem but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a specific direction for improvement, it does not offer concrete guidance on how to implement these changes or which specific baselines to consider. The authors are left to infer the necessary steps to take, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting alternative approaches to consider, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why these alternative approaches would be beneficial or how they would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with a different perspective, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a specific direction for improvement by suggesting alternative approaches to consider. However, the comment could be more helpful if it offered examples of how these alternative approaches have been applied in similar contexts or provided guidance on how to implement them effectively. While the suggestion is actionable, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion and a summary of the article\"s contributions are needed. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, as it specifies the exact content that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for a brief conclusion and a summary of the article\"s contributions, providing full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be added, namely a conclusion and a summary of the paper\"s contributions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the article\"s contributions are needed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these elements are necessary or how they would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a brief conclusion and a summary of the paper\"s contributions. This feedback is clear and actionable, as it directly guides the authors on how to enhance the final section of their paper. By providing a concrete suggestion for enhancing the paper\"s conclusion, the comment offers valuable insight that can help the authors improve the clarity and impact of their work. However, the comment could be more helpful if it provided additional guidance on what elements should be included in the conclusion or how to effectively summarize the paper\"s contributions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case and questions how the data distribution illustrated in Figure 1 is inseparable from the network model. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific analyses or modifications to the experiment. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthetic experiment in a nonseparable case, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the synthetic experiment in a nonseparable case, specifically questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to similar studies that might have addressed this issue, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the synthetic experiment in a nonseparable case, questioning how the data distribution illustrated in Figure 1 is inseparable from the network model. This is a valid point that could lead to a deeper understanding of the model\"s behavior and limitations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. It does not provide actionable feedback or detailed advice on how to clarify or improve the explanation of the results. As a result, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. This feedback implies that the authors should include this comparison in their paper to enhance the results\" meaningfulness. While the action is implicit, it is clear that the authors need to make this addition to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what specific aspects of the framework should be compared. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting a potential comparison, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the research on defense against multiple attacks. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a comparison would be beneficial. The absence of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of this comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending a comparison with a method designed to defend against multiple attacks. This feedback is actionable as it points out a specific area where the authors could enhance their study, which could lead to more meaningful results. However, the comment could be more helpful if it provided examples of such methods or detailed guidance on how to conduct the comparison. Overall, the comment is 4 as it identifies a clear area for improvement and offers a direction for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. However, it does not provide any guidance on how to address this issue or suggest improvements to the presentation. The comment lacks explicit instructions or concrete details on what changes should be made to improve the clarity or comprehensiveness of the results. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"results\" and the \"first 1000 episodes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes and questioning the reason for presenting them in this way. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way, specifically mentioning that the results disregard safety violations of the agent in the first 1000 episodes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this presentation is problematic or how it affects the results. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that the results disregard safety violations of the agent in the first 1000 episodes. It highlights the unclear reason for presenting the results in this way, which is a critical observation that could impact the clarity and comprehensiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the presentation of results. While it points out a potential problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \tau_i^l, which is important for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on what needs to be added, ensuring that the authors know exactly what is expected of them. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests the definition of the bounds for \tau_i^l, which is important for understanding the timewarp function. However, the comment does not provide any supporting evidence or reasoning to justify why this definition is necessary or how it would impact the understanding of the function. Without additional context or explanation, the authors may find it challenging to fully understand the basis of the request. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area where the paper could be improved. By pointing out the lack of definition for the bounds of \tau_i^l, the reviewer highlights an important aspect of the paper that could impact its clarity and understanding. This feedback is clear and actionable, as it directs the authors to provide a definition that is crucial for understanding the timewarp function. By addressing this issue, the authors can enhance the clarity and completeness of their draft, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise these sections to correct the errors and add a title. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be corrected, namely the writing errors and the lack of a title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. This feedback is clear and actionable, as it points out specific areas that need correction to improve the clarity and professionalism of the paper. However, the comment could be more helpful if it provided suggestions on how to correct these errors or offered guidance on how to improve the overall writing quality. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, which can enhance the clarity and professionalism of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests elaborating on the reasoning behind the statement on line 134, which pertains to the theorem about the standard sigmoid function. It also mentions that elaborating on why this theorem holds would be useful, particularly in the context of the RNN and URNN convergence. While the comment provides a clear direction for the authors to expand on the explanation, it does not specify exactly how to do so or what additional details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know they need to elaborate but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 134\" and \"Theorem 4.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the reasoning behind the statement regarding the standard sigmoid function and its relation to the RNN and URNN convergence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests elaborating on the reasoning behind a statement on line 134 and Theorem 4.1. It provides a logical basis for the suggestion by explaining that the RNN will converge to the nearest FP, unlike the URNN. However, the comment lacks specific examples or references to support the claim that elaboration is necessary. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors elaborate on the reasoning behind a statement on line 134 and Theorem 4.1. It highlights the importance of elaborating on why the theorem holds, particularly in the context of the RNN and URNN convergence. This feedback is clear and constructive, as it guides the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the understanding and comprehensibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the efficiency of their pairwise matching. There is no guidance on potential solutions, such as optimizing algorithms or data structures, or on how to present this information in the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the efficiency of pairwise matching, which is a specific aspect of the paper. However, it does not explicitly mention which section of the paper discusses this efficiency, making it weakly grounded. The comment is specific in detailing the issue with the low efficiency of pairwise matching, which makes it difficult to use in practical application systems. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to use in practical application systems. This feedback is valuable as it highlights a potential weakness in the paper that could impact its practical applicability. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve the efficiency of their pairwise matching. While it points out a relevant concern, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks concrete details on how to address the issue, leaving the authors uncertain about how to apply the feedback. As a result, the action is implicit and vague, making it difficult for the authors to know exactly what changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, suggesting that it is too naive and could have been edited more wisely. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the critique, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. However, it does not provide specific guidance or suggestions on how to improve the allocation or what aspects of the figure are considered naive. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to address the issue. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest specific actions to improve the generalizability of their method. The authors are left to infer that they need to consider this issue and find ways to improve their method, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it highlights an area for improvement but does not provide explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment addresses the planbased method, specifically mentioning the requirement for manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also compares the learned plan methods to those with predefined plans, indicating that the proposed method may struggle to generalize to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the planbased method or where the comparison to Table 2 is made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the issue with the planbased method and its limitations, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the planbased method is unrealistic in realworld scenarios due to the requirement for manually designing a plan based on the ground truth in advance. It also compares the learned plan methods to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the planbased method is unrealistic or that the learned plan methods are not comparable to those with predefined plans. This makes the claim 3, as it provides some logical reasoning but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the planbased method, noting that it requires manually designing a plan based on the ground truth in advance, which is unrealistic in realworld scenarios. It also highlights a limitation in the learned plan methods compared to those with predefined plans, suggesting that the proposed method may struggle to generalize to new datasets without the ground truth summary. This feedback is 3 as it points out a potential weakness in the methodology and its applicability to realworld scenarios. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve the generalizability of their method. Overall, the comment offers some insight but lacks actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and provides a concrete action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, allowing the authors to accurately identify the part of the paper being addressed. However, it does not provide specific details on what is wrong with the sentence or how it should be rewritten. This lack of specificity makes the comment weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any reasoning, evidence, or examples to support why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim is 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the first sentence of the abstract, suggesting that it needs to be rewritten. While this feedback is clear and actionable, it lacks depth and does not provide any further explanation or guidance on what aspects of the sentence need improvement or how to rewrite it effectively. The comment is 3 as it points out a specific area for improvement, but it could be more beneficial with additional context or suggestions for enhancing the revised sentence. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. While the comment implies that this is a necessary step, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this exercise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the experimental setup, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a change. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider using multiple train/test splits or folds in their experiments, which would provide a more accurate illustration of the method\"s performance. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the results. The suggestion is based on a general understanding of standard practices in the field, but lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some rationale but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental setup by suggesting that the authors should consider using multiple train/test splits or folds to provide a more accurate illustration of the method\"s performance. This feedback is clear and actionable, as it directly suggests an improvement that could enhance the robustness and generalizability of the results. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this change, such as which splits or folds to use or how to handle the increased computational complexity. Overall, the comment is 4 as it points out a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or what specific aspects of the method are overly complex. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in suggesting that the method might be overly complex and that there might be a simpler principle driving the quality gains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The comment suggests that the method seems more involved than necessary and implies that there might be an underlying, simpler principle driving the quality gains. However, it does not provide specific guidance or suggestions on how the authors might simplify the method or explore the underlying principle. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential issue but lacks depth and specificity in its critique."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to improve the contribution. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, method, or result. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is specific in its critique of the contribution, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition is not significant. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the contribution are lacking. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to improve the motivation or clarify the architecture. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the architecture are considered adhoc or poorly motivated, leaving the authors without clear guidance on how to address these concerns. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or references to specific aspects of the architecture that are considered adhoc or poorly motivated, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the hGRU architecture appears adhoc and not wellmotivated. However, it does not provide any specific examples or detailed reasoning to support this claim. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of what aspects of the architecture are problematic or how to address them. This lack of guidance limits the comment\"s usefulness in helping the authors improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and suggests that the authors should provide average return results with more env steps. While the comment implies that the authors should make a change to Line 8 and potentially include additional results, it does not explicitly instruct them to do so. The action is concrete, as it specifies the change needed and the additional information to be provided, but it is somewhat vague because it does not provide detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 8 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of s_t instead of s_n and suggests providing average return results with more env steps. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the use of s_t instead of s_n on Line 8 of Algorithm 1 and a request for average return results with more env steps. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the use of s_t instead of s_n on Line 8 of Algorithm 1, which is a clear and actionable point for the authors to address. It also suggests providing average return results with more env steps, which could be beneficial for understanding the performance of the proposed method. However, the comment could be more helpful if it provided additional context or examples to support the request for more env steps. Overall, the comment is 4 as it identifies a specific area for improvement and offers actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain the challenges and the differences between this analysis and that of Zhang et al. While the comment implies that the authors should provide more detail, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Adam under the (L0,L1)smoothness condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the challenges and differences between this analysis and that of Zhang et al. This provides clear guidance on what the authors need to clarify or improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of Adam under the (L0,L1)smoothness condition is unclear and suggests that the authors should explain the challenges and differences with Zhang et al. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should clarify these challenges, especially in comparison to Zhang et al. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity and depth of their analysis. However, the comment could be more helpful if it offered specific suggestions on how to address these challenges or what aspects of the analysis should be emphasized. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests toning down the statement about the neural network memorizing critical points, as it is not accurate according to the reviewer\"s understanding. Additionally, it advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, focusing on plurals and articles. These are clear and specific actions that the authors can take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"to force the neural network to memorize them,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be toned down and suggests compressing the method section for essential definitions. Additionally, it points out grammatical errors and provides specific examples, such as \"l.\" This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about the neural network memorizing critical points is inaccurate, as it does not memorize exact points as in TopoNet [24]. The reviewer provides a logical reasoning by referencing TopoNet, which suggests that the neural network does not memorize exact points. However, the comment lacks specific examples or references to support the claim that the neural network does not memorize exact points in TopoNet. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the manuscript. It identifies a misleading statement about the neural network memorizing critical points, suggesting that the authors should tone down this statement. This is a clear and important correction that can improve the accuracy of the paper. Additionally, the comment advises the authors to compress the method section, particularly on essential definitions, and to doublecheck for grammatical errors, particularly with plurals and articles. This detailed feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or if it should be incorporated into their draft. As a result, the comment lacks actionability and does not provide any direction for improvement. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not specify which part of the paper this information pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspect of the person reID methods or the mentioned work should be addressed or improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. This is a descriptive statement that does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual statement about the prevalence of person reID methods based on pedestrian detectors and mentions a specific work that combines detection and reID. However, it does not offer any insights, suggestions, or guidance on how this information could be used to improve the paper. Without actionable feedback or a connection to the paper\"s content, the comment lacks utility for the authors. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and direct action for the authors to take, providing them with a specific and concrete step to improve their draft. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce what the section is about, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests adding a first sentence to introduce what Section 3.2 is about. However, it does not provide any reasoning, evidence, or examples to support why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding a first sentence to introduce what Section 3.2 is about. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their paper. By providing a specific and direct recommendation, the comment offers a straightforward way for the authors to enhance the organization and flow of their content. However, the comment could be more helpful if it explained why this introduction is important or how it would benefit the reader. Overall, the comment is 4 as it provides a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide explicit guidance on what the authors should do to address this issue or how to clarify the statement. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the meaning of the term, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this statement is problematic or unclear. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the meaning of the phrase \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback highlights a potential inconsistency or confusion in the paper, which could be clarified to improve the clarity and coherence of the text. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative phrasing might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. The reviewer provides a clear and specific suggestion for how to rephrase the statement to improve clarity. This feedback is explicit and concrete, as it directly instructs the authors on how to revise their draft to better convey the concept of uncertainty. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the uncertainty is defined, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for clarifying the definition of uncertainty by suggesting an alternative phrasing that could be used. This feedback is detailed and actionable, making it 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests updating the description of uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution upon observing data. The reviewer provides a clear and logical explanation of the conceptual shift, which is based on common knowledge in the field. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to make a significant effort to understand and implement the suggested change, but the reasoning is sound. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper by updating the description of uncertainty. It suggests that the authors clarify that epistemic model uncertainty is represented in the prior distribution and updated in the form of a posterior distribution upon observing data. This feedback is clear and constructive, as it offers a precise way to enhance the understanding of the concept of uncertainty in the paper. By following this suggestion, the authors can significantly improve the clarity and comprehensibility of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors experimented with using domain ontologies to avoid placeholder generation in the evaluated responses. It also asks for clarification on the number of questions created for the zeroshot intent classifier and its accuracy. While the comment implies that the authors should provide more information about their experimental setup, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about their experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the usage of domain ontologies to avoid placeholder generation and seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy. However, it does not provide any supporting evidence, reasoning, or references to justify why these questions are relevant or how they could impact the paper\"s findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the usage of domain ontologies to avoid placeholder generation in the evaluated responses, which is a relevant and potentially valuable aspect to explore. It also seeks clarification on the number of questions created for the zeroshot intent classifier and its accuracy, which could provide valuable insights into the robustness and performance of the system. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these questions or improve their work. While it identifies areas for potential enhancement, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and provides concrete actions for the authors to take, including identifying and including relevant citations to enhance the context of their work. The explicit nature of the suggestion and the specific references make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for citations to set the paper in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly details what needs to be addressed by including relevant citations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing citations to set it in the context of other MARL work, specifically mentioning selfplay and populationplay with respect to exploration and coordination. The reviewer provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This provides a clear and concrete basis for the claim, as it offers specific references that can help the authors understand the broader context of their work. Therefore, the claim is 5, as it is supported by explicit and relevant references.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper lacks citations to set it in the context of other MARL work, particularly selfplay and populationplay with respect to exploration and coordination. It provides specific examples of recent papers on these topics, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019.\" This feedback is clear and actionable, as it directs the authors to include relevant citations to enhance the context and relevance of their work. By addressing this point, the authors can significantly improve the comprehensiveness and impact of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. While the suggestion is clear, it lacks specific guidance on which methods to compare with or how to conduct the comparison. The authors are left to infer that they should explore other methods, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is 3, as it provides a direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this comparison could be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a comparison with other methods, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any supporting evidence, examples, or references to justify why this comparison is necessary or beneficial. Without such details, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests comparing the proposed method with other selfsupervised learning methods that are not based on contrastive learning. This is a valuable suggestion as it could help the authors broaden the scope of their work and demonstrate the applicability of their method in a wider context. However, the comment lacks specificity and does not provide guidance on which methods to compare with or how to conduct the comparison. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. While the comment implies that the authors should provide a clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between the two processes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the difference between the abstention process and decision thresholds used by models, and it asks for clarification on this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking for clarification on how it differs from a decision threshold used by the models. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking for clarification on how it differs from a decision threshold used by the models. This is a clear and actionable request for the authors to provide additional explanation or clarification in their draft. By addressing this question, the authors can improve the clarity and understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the comparison with Megatron, suggesting that it is overrated and points out that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer also raises a question about the authors\" claim of parameter efficiency, suggesting that if this claim is valid, it could apply to these other works as well. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the comparison with Megatron and clarify their claims about parameter efficiency. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with Megatron, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the overrating of the comparison and suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment also raises a question about the authors\" claim of parameter efficiency, which is relevant but not directly addressed in the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the overrated comparison with Megatron and suggests that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The comment provides a logical reasoning by comparing the performance of these models, which supports the claim that the comparison with Megatron is overrated. However, the comment could be strengthened by providing specific examples or references to these other models to further substantiate the claim. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between COCOLM and Megatron, suggesting that the performance of these models is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. This feedback is valuable as it highlights a potential overstatement in the comparison, which could lead the authors to reconsider their claims about the superiority of COCOLM. Additionally, the comment raises a question about the authors\" claim of parameter efficiency, prompting them to clarify their reasoning and potentially address a gap in their experimental setup. While the comment could be more helpful by providing specific examples or references to support the comparison, it still offers actionable feedback that can guide the authors in improving their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis from lines 128 to 149 is not convincing and suggests that the GSP50 model has smaller class selectivity score, which means it shares more features with ResNet50. The reviewer also hypothesizes that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the analysis. The reference to external works, while helpful, does not offer detailed instructions on how to apply this information to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of convincingness and consider the implications of the external references. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 128 to 149,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the analysis, noting that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The comment further hypothesizes that additional context may allow the network to reduce its dependency. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis from lines 128 to 149 is not convincing enough, based on the histogram in Figure 3, which shows that the GSP50 model has a smaller class selectivity score compared to ResNet50. The reviewer references external works [1] and [2] to support the claim that GSP50 shares more features with ResNet50, which could indicate that GSP50 learns better representation. However, the comment does not provide detailed reasoning or examples from the referenced works to fully substantiate the claim. While the references offer some support, the comment lacks sufficient explanation and evidence to fully verify the claim. Therefore, the comment is 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from lines 128 to 149 is not convincing enough. It points out that the GSP50 model has a smaller class selectivity score, which suggests that it shares more features with ResNet50. The reviewer hypothesizes that additional context may allow the network to reduce its dependency. While the comment provides a clear direction for improvement by suggesting that the authors address the issue of convincingness, it lacks specific guidance on how to improve the analysis or what aspects of the analysis are lacking. The reference to external works is helpful but does not fully address the critique. Overall, the comment is 3 as it identifies a critical area for improvement but could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of convincing evidence in the paper\"s conclusions, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer suggests that the results might be due to limited exploration of combination methods and points to recent works that have shown the potential of feature replay methods in continual learning. While the comment provides a specific area for improvement by suggesting the exploration of combination methods, it does not offer concrete guidance on how to implement this suggestion or what specific combination methods should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific conclusion about continuous learning with unlabeled data and the claim that it accumulates noise, which is detrimental to representation quality. It also references specific works, such as [R1], [R2], and [R3], to support the claim that feature replay methods have shown great potential in continual learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some conclusions in the paper are not convincing, specifically regarding the claim that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality. The reviewer supports this claim by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1], [R2], and [R3]. These references provide a logical basis for the claim, as they demonstrate the effectiveness of feature replay methods in continual learning scenarios. However, the comment could be strengthened by providing more detailed analysis or specific examples from these references to further substantiate the claim. Overall, the claim is 4, as it is supported by relevant references, but it could be more fully substantiated with additional details.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s conclusions, noting that some are not convincing. It provides a detailed example by referencing recent works that have shown the potential of feature replay methods in continual learning, such as [R1], [R2], and [R3]. This feedback is clear and actionable, as it suggests that the authors should explore the use of combination methods, which could potentially strengthen their conclusions. By referencing specific works, the comment offers a concrete direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of meaningful baselines in the paper, specifically mentioning that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare with a chainofthought prompting approach. While the comment implies that the authors should consider using more advanced baselines, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of meaningful baselines and the suggestion to compare with a chainofthought prompting approach. This provides clear guidance on what the authors need to improve in their comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, specifically mentioning that the authors limit their comparisons to simple naive baselines. The comment suggests that the authors could compare with a chainofthought prompting approach. While the comment identifies a potential issue with the paper\"s comparisons, it does not provide specific examples or references to support the claim that a chainofthought prompting approach would be more meaningful. This makes the claim 3, as the authors would need to make a logical inference to understand the suggestion fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the comparisons are limited to simple naive baselines and suggesting that the authors could consider using more advanced baselines, such as a chainofthought prompting approach. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the paper\"s comparative analysis. However, the comment could be more helpful if it explained why the chainofthought prompting approach is considered more meaningful or how it would benefit the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the model is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the pretraining process and its generalizability. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the pretraining process of the cardiac signal representation learning model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also questions how well this generalizes to settings where the associated labels are not available. This feedback is 3 as it prompts the authors to clarify an important aspect of their methodology, which could impact the robustness and generalizability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to present this information in the paper. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to ensure that the observations and design decisions are not dependent on specific hardware or software. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which part of the paper this pertains to. The authors cannot confidently determine which sections or elements of the paper are being addressed. Additionally, the comment lacks specificity regarding what aspects of the observations or design decisions are dependent on hardware or software. Without clear guidance on what needs to be addressed or improved, the authors cannot effectively address the comment. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the paper, suggesting that some observations and design decisions might be hardware and software dependent. While it identifies a potential weakness, it lacks specificity and does not provide actionable guidance on how the authors might address this issue or what specific aspects of the paper might be affected. Without detailed suggestions or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. While the comment implies that the authors should address these issues, it does not provide explicit instructions or concrete suggestions on how to do so. The authors can infer that they need to investigate the accuracy of the ground truth and the noticeability/measurability of the differences, but the comment lacks specific guidance on how to conduct this investigation or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, it does not specify which part of the paper these questions pertain to, such as a particular section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry about the accuracy and noticeability of the differences, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the noticeability/measurability of a small difference. It also questions the difference between the results reported in the ablation study table. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy and reliability of the results presented in the paper. It questions whether the small differences observed are actually noticeable or due to noise or randomness in the training process. Additionally, it points out a lack of difference between the results reported in the ablation study table. While the comment identifies potential issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve the accuracy of their results. The feedback is 3 as it prompts the authors to consider the reliability of their findings, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of important experimental details in the main text and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8 as examples of missing information. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text and Appendix, but the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of explanations or interpretations for the PCA experiments in these figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. The reviewer provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that highlight the importance of including explanations and interpretations in the main text. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that important experimental details are missing or relegated to the Appendix, and that the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it highlights specific areas where the authors need to improve the clarity and completeness of their experimental details. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending a specific structure or approach for presenting the experimental details in the main text. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of new evaluation metrics and the limited exploration of existing metrics in the experimental analysis section. It suggests that the authors should provide an indepth exploration of the reasons for the experimental results. While the comment implies that the authors should add more depth to their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of new evaluation metrics and the limited exploration of existing metrics. The comment suggests that the authors should provide an indepth exploration of the reasons for the experimental results, which is a clear and specific suggestion for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are linearly combined. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. However, the comment does not provide specific examples or references to support the claim that existing metrics are insufficient or that the exploration is lacking. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of new evaluation metrics and the limited exploration of existing metrics. It suggests that the experimental analysis section needs an indepth exploration of the reasons for the experimental results. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of the experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct this exploration or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, it does not provide explicit guidance on how to address this issue or suggest alternative notations. The action is implicit and vague, as the authors are left to infer that they need to clarify or change the notation to avoid confusion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L166\" and \"L176,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the notation \"K,\" which is being used for both a known kernel function and the number of layers, causing confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation \"K\" is being used inappropriately, as it is used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is being used for both a known kernel function (e.g., L166) and the number of layers (e.g., L176), which can cause confusion. This feedback is clear and actionable, as it points out a potential source of confusion in the paper and suggests a way to clarify the notation. However, the comment could be more helpful if it provided examples of how the notation is being used inappropriately or suggested alternative notations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the concern about the practical impact or suggestions for improving the paper to better demonstrate its relevance. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the theoretical interest and the potential practical impact, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical impact of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the weak recovery problem studied is primarily of theoretical interest and questioning the practical impact of the AMP algorithm for nonGaussian problems. This feedback highlights a potential limitation in the paper\"s relevance and applicability, which could impact its impact on the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or demonstrate the practical relevance of their work. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection to human cognition, questioning the relevance of the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization. It suggests that the authors should provide more evidence or references to support their claim. However, the comment does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to present this evidence or what kind of references would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence or references to support their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the connection to human cognition and the authors\" suggestion that cognitively basic adaptation mechanisms might have a significant impact on selforganization. It questions the relevance of this claim and suggests that the authors need to provide more evidence or references to support their argument. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the authors\" suggestion and the need for more evidence, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of the connection to human cognition, suggesting that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation that humans use. The reviewer argues that it would be surprising for any behavioral economist to ignore these factors and needs more citation for comparison. The claim is 3 as it provides a logical reasoning for why the connection might not be relevant, but it lacks specific examples or references to support the argument fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the relevance of the connection to human cognition, questioning whether it makes sense to bring such connections into the discussion. It points out that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation that humans use, which could affect the authors\" argument. The comment suggests that it would be surprising for any behavioral economist to ignore these factors and implies that more citation is needed to support the claim. While the comment identifies a potential weakness in the argument, it lacks specific suggestions or guidance on how the authors might address this issue or provide more evidence. Therefore, the comment is 3, as it highlights a potential area for improvement but does not offer detailed guidance on how to improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, it does not provide specific guidance on how to tone down the language or suggest alternative phrasing. The comment lacks explicit instructions or concrete examples of what constitutes overly exaggerated or flamboyant language, making it difficult for the authors to know exactly how to address the issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, describing it as overly exaggerated and flamboyant. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or references to overly exaggerated or flamboyant language, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant in multiple places. This feedback is 3 as it points out a potential weakness in the language used, which could be revised to be more appropriate and professional. However, the comment lacks specific examples or suggestions on how to tone down the language or what alternative phrasing might be more appropriate. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need for ablation experiments to compare the proposed method with other methods, specifically mentioning TubeR. This provides full grounding as it clearly identifies the part of the paper that needs attention, allowing the authors to accurately pinpoint the section that requires revision. The comment is also specific because it specifies the aspects to be compared, such as the number of learnable parameters and GFLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR. This claim is 3 as it logically suggests that such an experiment would provide valuable insights into the performance of the proposed method. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as how these comparisons would impact the paper\"s conclusions or contributions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, specifically mentioning TubeR. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including these comparisons. By doing so, the authors can demonstrate the effectiveness of their method in a more comprehensive and rigorous manner. However, the comment could be more helpful if it included suggestions on how to design and conduct these experiments, such as which metrics to use or how to interpret the results. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to compare against or detailing the expected utility measure. The comment lacks concrete steps for the authors to take, leaving them uncertain about how to improve their draft. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for comparison to baselines. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility or some other measure, which is a significant weakness. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific examples or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, namely the lack of comparison to simple feature acquisition baselines like expected utility or some other measure to prove the effectiveness of the proposed approach. This is a critical oversight that could impact the credibility and impact of the paper. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting which baselines to compare against or how to implement the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it does not provide explicit instructions or concrete steps for the authors to follow. The comment mentions that Figure 5a seems strange and asks for more explanations, but it does not specify what aspects of the figure are problematic or how to address them. Similarly, it mentions the handling of DVS input when the input is in AER format but does not offer guidance on how to improve this aspect. The comment also suggests analyzing energy consumption like reference [15] did, but it does not provide details on how to implement this analysis or what specific aspects to focus on. Overall, the comment lacks explicit actions or detailed guidance, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a\" and \"11,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with \"Fig. 5a\" and suggests providing more explanations, as well as addressing the handling of DVS input when the input is in AER format. Additionally, it recommends analyzing energy consumption like reference [15] did, which provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for improvement, rather than making a subjective claim or opinion. It does not contain any claims or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several pieces of feedback that can help the authors improve their draft. It points out that Figure 5a seems strange and suggests that more explanations are needed. Additionally, it questions how the authors handled DVS input when the input is in AER format, which could be a critical aspect to address. The comment also recommends analyzing energy consumption like reference [15] did, which could strengthen the paper\"s foundation. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how to address these issues. Therefore, it is 3, as it provides some direction but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifically mentions the use of separate embeddings and positional encoding, but it does not provide explicit guidance on how the embeddings are combined or how they are fed into the CSCM. The comment implies that the authors should provide more detailed explanations or clarifications, but it does not specify exactly what needs to be clarified or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"text\" and \"CSCM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, how historical observations are combined with inputs known over all time given differences in sequence lengths. The comment provides a clear direction for the authors to address the issue by asking for clarifications on how the embeddings are combined and fed into the CSCM. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about how historical observations are combined with inputs known over all time, given differences in sequence lengths. It mentions the use of separate embeddings and positional encoding, but it does not provide any supporting evidence, reasoning, or references to justify the claim that clarifications are needed. The comment lacks specific examples or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the combination of historical observations and inputs known over all time, given differences in sequence lengths. It points out that the text mentions separate embeddings and positional encoding but lacks clarity on how these are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations or clarifications in the paper. However, the comment could be more helpful if it suggested specific ways to clarify these concepts or provided examples of how similar issues have been addressed in related work. Overall, the comment is 4 as it effectively guides the authors toward improving the clarity and comprehensibility of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what is considered a common approach and what is lacking in the paper, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of multigranularity and multiscale to enhance model performance is a common approach in convolutional networks, and that merely migrating this approach to the field of MLMs is not innovative. The reviewer supports this claim by referencing the article itself, which implies that the authors should have known this. However, the comment lacks specific examples or references to support the claim that the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. This lack of detailed evidence or examples makes the claim 3, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the introduction of multigranularity and multiscale as a common approach to convolutional networks, suggesting that merely migrating this approach to the field of MLMs is not innovative. It also points out that some of the algorithms used in the article from object detection only enhance the input side, while many MLMs can already accomplish the object detection task. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback is 3 as it highlights a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more experiments to address the concerns raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that the authors should conduct more experiments across different downstream tasks and domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the transfer performance of the model. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the model\"s generalization and suggesting additional experiments, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment is 3 as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments to validate the claim, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and generalization performance. It suggests that selecting positive samples without introducing perturbation noise could lead to lower generalization performance. The comment also highlights the need for additional experiments across different downstream tasks and domains to address these concerns. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how to conduct these additional experiments or what specific downstream tasks should be considered. This limits the comment\"s helpfulness, as it provides insight but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the power of different architectures but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the architectures should be discussed. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that fast SMP is less expressive than SMP. Without such evidence or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to SMP and suggests that more discussion on the power of different architectures would be beneficial. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable advice or detailed feedback to help the authors improve their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback provides a clear and explicit action for the authors to take, which is to consider using different splits of the training, validation, and testing datasets to test the robustness of their methods. The comment is specific in detailing what needs to be done to improve the robustness of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the results section. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that evaluating methods across different splits of trainvaltest would be more robust than simply using different initialisation seeds. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be more robust. Without additional context or examples, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that to obtain robust results, it would be better to evaluate the methods across different splits of trainvaltest, rather than simply different initialisation seeds. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the robustness of their results. By suggesting a more comprehensive evaluation approach, the comment offers a concrete way to enhance the quality and reliability of the paper. However, it could be more helpful if it provided additional guidance on how to implement this change or what specific metrics or analyses should be considered. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction should be combined together. This is an explicit action that the authors can directly implement to simplify the introduction. The comment provides a clear and concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests combining the first two bullets about contributions at the end of the introduction. However, it does not specify which part of the introduction these bullets are located in, making it weakly grounded. The comment is specific in suggesting a potential simplification of the introduction by combining these two bullets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests combining the first two bullets about contributions at the end of the introduction. However, it does not provide any supporting evidence, reasoning, or examples to justify why this combination would be beneficial or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first two bullets about contributions at the end of the introduction could be combined together. This is a specific and actionable suggestion that could simplify the introduction and improve the clarity of the paper\"s contributions. However, the comment lacks further explanation or justification for why this combination would be beneficial, such as how it would enhance the overall structure or content of the introduction. While the suggestion is clear, it could be more helpful if it included additional context or reasoning to guide the authors in implementing the change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clearly defined. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should provide more detailed definitions or examples, or how to improve the clarity of these concepts in the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations and social norms mentioned in the paper, such as physical and psychological safety. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in identifying the need for clarity, it lacks grounding as it does not specify where in the paper this issue is addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations and social norms mentioned in the paper, such as physical and psychological safety, are not clear. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity regarding the types of situations and social norms mentioned in the paper, such as physical and psychological safety. This feedback is 3 as it points out an area where the authors could improve the clarity and comprehensibility of their work. However, the comment does not provide specific suggestions or examples on how to address this issue, such as recommending additional definitions or explanations. While it highlights a potential weakness, the lack of actionable guidance limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. However, it points out the need to demonstrate the algorithm\"s improvement over existing solutions by addressing robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment implies that the authors should provide more evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence to substantiate their claims. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment acknowledges the paper\"s focus on a specific problem and its potential benefits to the neuroscience community. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The comment suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or results sections where the authors present their algorithm and its performance. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem. It highlights the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment identifies a critical area for improvement, it lacks specific examples or references to support the claim about the algorithm\"s improvement over existing solutions. This makes the claim 3, as the authors would need to make a concerted effort to address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the paper\"s potential benefits and appreciates its focus on a specific problem in the neuroscience community. It identifies a critical area for improvement, namely the need to demonstrate the algorithm\"s improvement over existing solutions, particularly in terms of robustness against weak boundaries. The reviewer suggests that the authors should refer to recent trends in the vision community to substantiate their claims. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address the issue or what specific trends to reference. This limits the comment\"s helpfulness, as it points out a significant area for improvement but does not offer detailed guidance on how to achieve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more baselines should be compared and more domains should be tested. It also mentions that the choices of weighting and learning density functions are not strongly motivated, and that stronger empirical results are needed. However, the comment does not provide specific guidance on which baselines to compare or how to test the additional domains. The authors are left to infer that they need to expand their experimental setup, but without concrete suggestions on which baselines or domains to include, the action remains vague. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that more baselines should be compared and more domains should be tested, and it mentions the choices of weighting and learning density functions as areas for improvement. However, it does not specify which part of the paper these suggestions pertain to, such as specific sections or experiments where these improvements could be made. Additionally, the comment lacks specific guidance on which baselines or domains should be included, making it weakly grounded. The suggestion to provide stronger empirical results is somewhat specific, as it highlights the need for more comparisons and additional domains, but it does not detail how to achieve this. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more baselines should be compared and more domains should be tested, and it critiques the choices of weighting and learning density functions as not being strongly motivated. However, the comment lacks specific examples or references to support the claim that these choices are not justified or that the current results are insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that more baselines should be compared and more domains should be tested. It also critiques the choices of weighting and learning density functions as not being strongly motivated, implying that stronger empirical results are needed. While the comment highlights areas for improvement, it lacks specific suggestions on which baselines or domains to include or how to strengthen the empirical results. This limits the comment\"s helpfulness, as it provides a general direction but does not offer actionable guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2AB\" and \"fig. 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification about the dashed lines in figures 2AB and 4B. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it directly addresses a specific issue by requesting clarification on the definition of the dashed lines in figures 2AB and 4B. This feedback is clear and actionable, as it guides the authors to provide a necessary explanation for their figures, which could enhance the clarity and understanding of their work. By addressing this point, the authors can improve the readability and comprehensibility of their draft, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the comparability of the results or what specific aspects need to be improved. As a result, the authors are left without any clear direction on how to enhance the significance of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the results are not comparable or how they could be improved. Without clear guidance on where to focus the revision, the authors may struggle to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, which suggests that the significance of the proposed methods is questionable. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the results are not comparable to existing methods, which implies that the significance of the proposed methods is questionable. However, it does not provide any specific examples or guidance on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of novelty in the paper, specifically noting that it is a straightforward application of existing literature, such as DeCorr, in a specific application domain. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment implies that the authors should provide more insights into these challenges, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the lack of unique insights. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DeCorr [1],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems, despite being a straightforward application of existing literature. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is a straightforward application of existing literature, specifically DeCorr. The reviewer supports this claim by mentioning that the contribution is mainly the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also acknowledges that modifications like different penalty coefficients for users and items are proposed. While the claim is 4 due to the mention of DeCorr and the transposition of insights, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it lacks novelty and is a straightforward application of existing literature, specifically DeCorr. It highlights the main contribution as the transposition of DeCorr\"s insights into graph collaborative filtering, with different datasets and backbones. However, the comment also points out that the paper lacks unique insights about the challenges of overcorrelation in recommender systems. While the comment provides some insight into the paper\"s limitations, it does not offer specific suggestions or guidance on how the authors might address these issues or enhance the novelty of their work. The feedback is 3 as it identifies a critical area for improvement, but it lacks actionable advice or detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the clarity of the symbols or the explanation of the process. The authors are left to infer that they need to clarify the symbols and provide more information on the process, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This provides clear guidance on what needs to be addressed in the figure and the process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 2 is ambiguous due to unclear symbols and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support the claim of ambiguity or the need for clarification. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. This feedback is 3 as it points out a potential area for improvement in the clarity and comprehensibility of the figure. However, it lacks depth and does not provide specific suggestions or guidance on how to address the ambiguity or improve the explanation of the symbols. While it highlights an issue, the comment could be more helpful with additional details or examples. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it may be restrictive for other popular classes of kernels, such as Matern kernels. However, the comment does not provide explicit guidance or suggestions on how the authors might address this limitation or expand their results to include other kernel classes. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of this limitation and potentially explore other kernel classes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption of the spectrum of a kernel being subgaussian, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results could be restrictive due to the exclusion of popular classes of kernels, such as Matern kernels. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the assumption of the spectrum of a kernel being subgaussian is a limitation, as it excludes popular classes of kernels like Matern kernels. The comment provides a logical reasoning by pointing out that the results could be restrictive due to this assumption. However, it lacks specific examples or references to Matern kernels or other classes of kernels to fully substantiate the claim. This makes the claim 3, as the authors would need to infer the implications of the limitation and potentially explore the excluded classes themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the assumption that the spectrum of a kernel is subgaussian. It acknowledges that this assumption is reasonable for Gaussian kernels but points out that it could be restrictive for other popular classes of kernels, such as Matern kernels. This feedback is valuable as it highlights a potential limitation in the scope of the results and suggests that the authors should consider expanding their analysis to include other kernel classes. However, the comment could be more helpful if it provided specific suggestions on how to address this limitation or how to incorporate other kernel classes into the analysis. Overall, the comment is 4 as it directs the authors to consider a broader range of kernel classes, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain. While the comment explicitly states the action to take, it lacks concrete details on how to implement this suggestion. It does not provide specific guidance on what aspects of the pretraining method should be discussed or how to integrate it into the main paper. The authors are left with a general idea of what to do but without detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"unsupervised pretraining,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed discussion on the unsupervised pretraining method in the main paper. The comment suggests focusing more on the pretraining method and provides a rationale for why it is important. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, based on data from Table 4. However, it does not provide specific evidence or detailed reasoning to support this claim, such as specific data points or comparisons with other methods. The suggestion to focus more on the pretraining method is logical, but without detailed justification or examples, the claim remains 3. The authors would need to further explore the data and provide additional analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the unsupervised pretraining is a key factor in performance gain but is not discussed in detail in the main paper. It suggests that the authors should focus more on the pretraining method, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific guidance on how to integrate the discussion of the unsupervised pretraining into the main paper or what aspects of the pretraining method should be emphasized. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance or suggestions on how to address this issue. It lacks concrete steps or recommendations for the authors to follow, leaving them uncertain about how to proceed. Therefore, the comment is 3, as it identifies a potential issue but does not offer specific actions for the authors to take.", "grounding_specificity_rationale": "The comment raises a question about how to choose an ELM (male/female) and whether this requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue pertains to, such as a particular section or experiment. While the authors might have an idea of where this discussion might occur, the comment lacks full grounding. It is specific in its critique of the methodology but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. The reviewer suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline. However, the comment lacks specific examples or references to support the claim that this is a drawback or how it affects the accuracy of the model. Without detailed reasoning or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand. It suggests that this could be a drawback as accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is 3 as it identifies a potential issue with the methodology that the authors may not have considered. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered guidance on how to incorporate gender detection models into the pipeline. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment states that the writing is difficult to follow in many places and suggests simplifying it. However, it does not provide specific examples or guidance on how to achieve this simplification. The authors are left to infer that they need to make their writing more accessible, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and suggests simplifying it. However, it does not specify which parts of the paper are particularly challenging or where the simplification is needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests simplifying it. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without specific instances or examples, the authors may find it challenging to understand where the writing is difficult to follow and how to simplify it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper\"s writing, noting that it is difficult to follow in many places and suggests simplifying it. While this feedback highlights a potential problem, it lacks specificity and does not provide actionable guidance on how to improve the writing or which sections are particularly challenging. Without detailed suggestions or examples, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical substance or what specific aspects of the paper are lacking. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the paper are considered incremental or lacking in technical substance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper is incremental and lacks technical substance, specifically mentioning that it adds a new loss to [31]. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve the technical substance of their work. Without actionable guidance or detailed analysis, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more detailed explanations or examples, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide more information or examples. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"the invertible function $f^*$,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the proof of Theorem 1 and the dependence of $f^*$ on the fixed $P^*$. The comment suggests providing intuition for the proof and inquires about the impact of different distributions on determining $f^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. The comment does not contain subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the proof of Theorem 1 and suggests providing intuition for the proof. It also inquires about the dependence of the invertible function $f^*$ on the fixed $P^*$ and whether certain distributions make it easier to determine $f^*$. Additionally, it asks how to determine which $P^*$ to fix in practice. These questions are relevant and could guide the authors in improving the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the comment is 4 as it identifies areas for improvement and offers a direction for the authors to explore, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), noting that they should be analogous but are not. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a specific notation change or explaining why the current notation is problematic. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of notation, suggesting that the equations should be analogous but are not. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the choice of notation in equations (7) and (10), suggesting that they should be analogous but are not. However, the comment does not provide any reasoning or explanation for why this choice is unexpected or problematic. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of notation in equations (7) and (10), suggesting that they should be analogous but are not. This feedback identifies a potential issue with the clarity or consistency of the notation used in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the notation. While it points out a potential area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide empirical evidence to demonstrate the applicability of their model to realworld diffusion processes. While the comment implies that the authors should conduct experiments or provide examples to support their claims, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as the authors know they need to provide empirical evidence but may not be entirely sure of the specifics of what is expected. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to demonstrate its effectiveness. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for empirical evidence, providing clear guidance on what the authors need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the applicability of the model to realworld diffusion processes is a concern, and it acknowledges that the authors have provided an interesting problem with elegant solutions. However, it suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that empirical evidence is necessary. The reasoning is 3, as it highlights a potential gap in the paper but does not provide detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It acknowledges the authors\" efforts in defining an interesting problem and providing elegant solutions, but it suggests that empirical evidence is needed to demonstrate the model\"s effectiveness in realworld scenarios. This feedback is 3 as it points out a critical area for improvement, but it lacks specific guidance on how to conduct the empirical evidence or what kind of evidence would be most relevant. The authors are given a clear direction but could benefit from more detailed suggestions on how to address this issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is implicit, it is clear that the authors need to expand their testing to include more datasets. The comment provides a specific suggestion for improvement, which is to test on additional datasets. However, it does not offer detailed guidance on which datasets to use or how to conduct the additional testing. Therefore, the action is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the testing and evaluation of the method, but this inference is not direct. The comment is specific in suggesting the need for additional testing, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any supporting evidence, reasoning, or references to justify why testing on more datasets would be beneficial or necessary. The claim is based on a logical assumption, but without additional context or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. This is a reasonable suggestion that could improve the robustness and generalizability of the results. However, the comment lacks specificity and does not provide guidance on which datasets to use or how to conduct the additional testing. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to differentiate their contribution from existing work. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the main contribution, which is the combination of attention with other linear mechanisms. However, it does not specify which part of the paper discusses this contribution, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the combination are not novel or how the authors could differentiate their work from existing alternatives. Without clear guidance on where to focus improvements, the authors may struggle to address the critique effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, the comment does not provide specific examples or references to these alternatives, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel, as alternatives already exist. However, it does not provide specific examples or suggestions on how the authors might address this issue or differentiate their work from existing alternatives. Without actionable feedback or guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and concrete action that the authors can take to improve their draft. The comment provides a specific suggestion for visualizing the results, which is a direct and actionable point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing a plot of how different weights of the model move, specifically after unlearning, to see which layers are affected the most. However, it does not specify which part of the paper this plot should be included in, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a plot, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a request for additional visualization to support the understanding of the method. However, the comment does not provide any specific reasoning or evidence to support why this plot is necessary or how it would enhance the paper. Without additional context or explanation, the claim is 3, as it requires the authors to make a leap of faith to understand the importance of the suggested plot. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends that the authors include a plot showing the relative weight change after unlearning to see which layers are affected the most. This is a clear and constructive piece of feedback that can help the authors better understand and communicate the impact of their method. By addressing this point, the authors can enhance the clarity and comprehensiveness of their results, making the paper more informative and valuable to the reader. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. It further points out that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance on how the authors should address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more novelty or depth in their methodology section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"methodology aspect\" and \"ENCODE part,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The comment further highlights the incremental contribution as the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, particularly regarding the ENCODE part, which is already proposed in a previous work. The reviewer further suggests that the incremental contribution lies in the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. This claim is 3 as it references a previous work, providing some basis for the critique. However, the comment lacks specific references to that work or detailed reasoning to fully substantiate the claim. The authors would need to conduct further research to understand the extent to which the ENCODE part is already proposed and how the decomposition part contributes to the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the paper, particularly regarding the ENCODE part, which is already proposed in a previous work. It further highlights the incremental contribution as the decomposition part, which only involves factoring M_v into factor D and slicing Phi_v. While the comment points out a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it alerts the authors to a potential problem but lacks actionable advice or detailed insights. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. While the comment identifies a potential gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the domain of the inputs, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the inputs are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the domain of the inputs. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper\"s validity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned. This is a relevant point that could impact the validity and generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the domain of the inputs. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare the performance of their proposed CLN (region proposal generation algorithm) with that of another work. While the comment implies that the authors should conduct a performance comparison, it does not provide specific guidance on how to conduct this comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not specify which part of the paper discusses the CLN or where the performance comparison should be included. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of a CLN (region proposal generation algorithm) with another work. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct the comparison or what aspects to focus on. The comment is 3 as it points out a potential area for enhancement, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also recommends the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment provides a clear action\u2014adding an illustrative figure\u2014it does not specify which concepts should be illustrated or how the figure should be designed. The authors are given a clear direction to add an illustrative figure but are left to determine the specifics of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the presentation, specifically mentioning that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It also suggests the inclusion of an illustrative figure to help clarify the key concepts in section 3. While the comment does not explicitly mention a specific section or figure, the authors can infer that it relates to the presentation and notation in chapter 3. The suggestion to include an illustrative figure is specific, providing a clear action for the authors to take. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. While the comment identifies specific issues with the presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an illustrative figure is a logical point, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation, noting that it is too equationdriven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would be helpful to clarify the key concepts in section 3. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation by adding an illustrative figure. However, the comment could be more helpful if it offered specific guidance on what elements should be illustrated or how the figure should be designed to enhance clarity. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z\u00e2\u0080\u0099 and the independence of x and y given W. The reviewer suggests that taking Z\u00e2\u0080\u0099 to be the empty set would lead to a contradiction with Eq. (7), which states that x and y are dependent given W. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to resolve the conflict. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the definition of Z\u00e2\u0080\u0099 and possibly revise the equation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, particularly regarding the definition of Z' and the independence of x and y given W. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. The reviewer provides a logical explanation by taking Z' to be the empty set, which would lead to a contradiction with Eq. (7). However, the comment lacks specific references or examples to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the conflict. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically regarding the definition of Z' and the independence of x and y given W. By taking Z' to be the empty set, the reviewer demonstrates a logical contradiction that could be addressed. However, the comment lacks specific guidance or suggestions on how the authors might resolve this issue or improve the clarity of the definitions. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out that the visual presentation, specifically the subscripts, could be improved for better readability and aesthetic appeal. While the comment identifies an area for enhancement, it does not provide explicit guidance on how to achieve this improvement. The authors are left to infer that they should make changes to the subscripts, but without specific suggestions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the visual presentation of the subscripts, for better readability and aesthetic appeal. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point acknowledges the comprehensive nature of the data presented in Figure 3 but suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide specific examples or detailed reasoning to support why the subscripts are problematic or how they could be improved. Without such examples or references, the claim is not 5, as it lacks the necessary evidence or justification to substantiate the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment acknowledges the comprehensive nature of the data presented in Figure 3 but points out a specific area for improvement. It suggests that the visual presentation, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. While the comment identifies a clear area for improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left to infer that they should make changes to the subscripts, but without specific guidance, the feedback is 3. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. However, it does not provide any explicit or implicit actions for the authors to take. The authors are left to infer that they should address this confusion in their paper, but without specific guidance or suggestions on how to do so, the comment lacks actionability. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the problem of gradient bias in Batch Normalization and the potential of Online Normalization. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the difference between Online Normalization and Batch Normalization, asking why Online Normalization is unbiased while Batch Normalization is biased. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that Online Normalization is unbiased and Batch Normalization is biased, suggesting that the authors have not adequately explained this difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically questioning why Online Normalization is unbiased while Batch Normalization is biased. This is a relevant point that could help the authors clarify their understanding of these concepts and their implications. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors have reduced whitespace throughout the paper, resulting in cramped equations and captions too close to the figures. This is considered a grounding comment as it clearly identifies the issue with the spacing. However, the comment does not provide any guidance on how to address this issue, such as suggesting specific adjustments or improvements to the spacing. The action is implicit and vague, leaving the authors without clear direction on how to improve the paper in this regard. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace throughout the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the problem of violating the 9page paper limit due to the reduced whitespace. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper violates the 9page limit due to the reduced whitespace, specifically mentioning cramped equations and captions too close to the figures. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s acceptability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s formatting, noting that the reduced whitespace throughout the document results in cramped equations and captions too close to the figures. This is a clear and actionable observation that could impact the paper\"s readability and adherence to the 9page limit. However, the comment does not provide suggestions on how to address this issue or improve the spacing, such as recommending adjustments to the spacing between elements or providing examples of better spacing practices. While it highlights a significant problem, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical details or formulations, nor are there suggestions for how to better highlight the novelty of the scheme or procedure. As a result, the authors are left without any clear direction on how to improve their draft based on this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the technical details or formulations are lacking or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical details and formulations are limited, implying that the main novelty of the scheme or procedure is reflected in its novelty. However, it does not provide any specific examples or suggestions for how the authors might improve the technical details or formulations to better highlight the novelty. Without actionable feedback or guidance, the authors are left without a clear understanding of what changes to make or how to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the concept of local interactions, asking whether it refers to interactions within a time window or within the same modality. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should clarify this concept in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should provide more clarity on the concept of local interactions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its questioning of the concept, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the concept of local interactions, specifically asking whether it refers to interactions within a time window or within the same modality. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the concept of local interactions, specifically questioning whether it refers to interactions within a time window or within the same modality. This feedback is 3 as it identifies a potential area of confusion in the paper that could be clarified for readers. However, the comment lacks specific guidance or suggestions on how the authors might clarify this concept, such as providing examples or additional context. While it points out a potential weakness, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper claims better results in the Molecule generation experiment but notes that adding the proposed constrained method actually yields lower validity and diversity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the addition of the proposed constrained method actually yields lower validity and diversity in the Molecule generation experiment, as stated in Table.3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the Molecule generation experiment, specifically noting that the addition of the proposed constrained method actually yields lower validity and diversity. This is a critical observation that could impact the paper\"s conclusions and credibility. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it points out a potential problem, it does not provide actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the archetype positions are updated after initialisation in Algorithm 2. It explicitly asks the authors to clarify this aspect, providing a clear action for the authors to take. The comment is explicit in its request for clarification, making it 5. The authors know exactly what needs to be addressed and how to implement the action, as they are prompted to provide a comment on this aspect. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"the query Q consists of the archetypes z_1, \u00e2\u0080\u00a6, z_k,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the update of archetype positions after initialisation. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the clarity of the update process for the archetype positions in Algorithm 2. It does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification, which is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update process for the archetype positions in Algorithm 2. It asks the authors to clarify this aspect, which is important for understanding the methodology. This feedback is clear and actionable, as it prompts the authors to provide additional explanation or clarification in their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These are all clear and concrete actions that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the \"empirical study\" and \"supplement,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details what information is missing, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point makes several claims about the missing information in the empirical study, such as recording parameters, preprocessing steps, and the condition under which the restingstate was recorded. It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. While the comment identifies specific areas that need attention, it lacks detailed justification or references to support the claims. This makes the claims 3, as the authors would need to further explore and address these points to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several important pieces of information that are missing from the empirical study, such as recording parameters for the MRI, preprocessing steps, and the condition under which the restingstate was recorded (eyesopen or eyesclosed). It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the transparency and completeness of their empirical study. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential risk of methods that exploit relationships between action units, specifically noting that the relationships can differ across datasets. It suggests that the paper lacks crossdataset experiments, which would test the generalization of the work. While the comment identifies a potential area for improvement, it does not provide explicit instructions on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct crossdataset experiments to address the risk. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of crossdataset experiments, which is a critical aspect of testing the generalization of the work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that methods that exploit relationships between action units can suffer from differences in cooccurrences across datasets, as seen in Figure 1. The reviewer suggests that crossdataset experiments are necessary to test the generalization of such work. While the comment provides a logical reasoning for the need to test generalization, it lacks specific examples or references to datasets or studies that demonstrate these differences. This makes the claim 3, as the authors would need to infer the specific differences and datasets mentioned. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, noting that these relationships can differ across datasets. It highlights a specific example of this difference by pointing out the cooccurrence of AU1 and AU12 in Figure 1. The comment suggests that crossdataset experiments are necessary to test the generalization of the work. While it provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to conduct these experiments or what aspects of the paper should be focused on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to add more details about the Starcraft environment, but the comment lacks concrete guidance on how to present this information or what specific aspects should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what aspects of the environment should be described. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. However, it does not provide any reasoning, examples, or references to support why this additional information is necessary or how it would enhance the paper. Without such justification, the claim is 1, as it lacks the necessary evidence or explanation to guide the authors in improving their draft. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The comment suggests that the authors should provide more detailed information about the Starcraft environment, potentially in an appendix. While it identifies a potential area for improvement, it lacks specific guidance on what aspects of the environment should be described or how this additional information would enhance the paper. The comment is 3 as it points out a potential gap in the paper, but it does not offer actionable steps or detailed suggestions for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reconsider their statement about overparameterization, which is currently perceived as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. However, the comment does not explicitly instruct the authors to change their stance or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their position. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 47  48,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it challenges the authors\" assertion about overparameterization and provides a rationale by pointing out its benefits in practice and referencing theoretical work. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that overparameterization is beneficial for supervised learning of deep neural networks in practice, citing theoretical work to support this claim. However, the comment does not provide specific references to the theoretical work or detailed reasoning behind the benefits of overparameterization. This lack of explicit references or detailed justification makes the claim 3, as the authors would need to seek out the references themselves to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment challenges the authors\" assertion about overparameterization, which is currently perceived as a negative aspect. The reviewer provides a rationale by pointing out that overparameterization can be beneficial for supervised learning of deep neural networks in practice, and references a theoretical work that supports this claim. This feedback is 3 as it offers a counterpoint to the authors\" current perspective, prompting them to reconsider their stance on overparameterization. However, the comment could be more helpful if it provided specific examples or additional references to support the argument for the benefits of overparameterization. Overall, the comment offers a valuable perspective but could be more actionable with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects of the training and testing process should be described. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed description and comparison with existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of training the shape model and the complexity of the parsing model, suggesting that the processing efficiency of training and testing should be described and compared with existing work. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the training and testing process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is timeconsuming due to its training in pixel level (though sparsity by landmark) and the model being trained independently on all font images and characters. Additionally, it suggests that the parsing model is a highorder factor graph with four types of factors, which affects processing efficiency. The comment further recommends describing and comparing the processing efficiency of training and testing with existing work. While the comment provides some logical reasoning by pointing out the complexity of the models and the need for comparison, it lacks specific examples or references to existing work that could substantiate the claim. This makes the claim 3, as it provides a general idea but requires more detailed evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the timeconsuming nature of training the shape model and the complexity of the parsing model. It suggests that the processing efficiency of training and testing should be described and compared with existing work. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what aspects of the training and testing process should be described and compared. The feedback is 3 as it points out areas that need attention, but it could be more actionable with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should explore other domain adaptation methods, it does not provide specific guidance on which methods to use or how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore other methods but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. However, the comment does not specify which parts of the paper these critiques pertain to, such as sections, figures, or specific techniques. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the use of old and simple methods, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors combine two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. The reviewer suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. The claim is 3 as it provides a specific example of an older method being used and suggests a potential improvement. However, it lacks detailed evidence or references to support the claim that more recent methods are indeed more effective. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the authors for combining two existing techniques without innovation, specifically mentioning the use of an adversarial attack or correction method and a domain adaptation method that is eight years old. It suggests that the authors should consider using more recent and effective domain adaptation methods to improve performance. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on which domain adaptation methods to consider or how to implement them. The feedback is 3 as it points out an area for improvement but does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on what to discuss. The comment is specific and leaves no ambiguity about what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or subsection. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the discussion. The comment is specific in suggesting what needs to be addressed, providing clear guidance on what the authors should include in their paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that a discussion on the prompt dataset creation for the fewshot case, along with its source, should be included in the paper. This feedback is 3 as it identifies a specific area that could enhance the paper by providing more context and detail about the dataset creation process. However, the comment lacks depth and does not offer suggestions on how to structure or present this discussion, nor does it provide examples of what could be included. While it points out a potential improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of the motivation or how to differentiate the paper from incremental engineering papers. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not specify which part of the paper is problematic or where the motivation is unclear. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the motivation or the paper are unclear or how they could be clarified. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and suggests that it appears to be an incremental engineering paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific details or references, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the motivation of the paper is difficult to follow and that it appears to be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or originality of their work. Without actionable feedback or detailed insights into what aspects of the paper are unclear or lacking, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it would be beneficial to see how it affects the performance of the method in a scenario where the game has repetitive background sounds. The reviewer provides a clear rationale for why this ablation is important, noting that the weighting might have helped remedy the underperformance in such scenarios. However, the comment does not explicitly instruct the authors to conduct this ablation or provide detailed guidance on how to implement it. While the action is implied, the lack of concrete steps makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning the scenario where the game has repetitive background sounds. This provides a clear reference to the section where the authors discuss the performance of their method in Atlantis. However, the comment does not specify which part of the paper should include this ablation, making it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, namely the weighting method of the crossentropy loss in the context of repetitive background sounds. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This claim is 3 as it is based on a logical reasoning that the weighting might improve performance in such a scenario. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an ablation on the weighting method of the crossentropy loss, specifically mentioning that it might help remedy the underperformance of the method in a scenario with repetitive background sounds. This is a clear and actionable suggestion that could improve the paper by providing additional insights into the effectiveness of the proposed method. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation or what specific aspects of the weighting method should be explored. Overall, the comment is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors can infer that they need to demonstrate novelty and incremental improvements, but the comment lacks concrete suggestions on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of the lack of novelty and incremental nature of the work, as well as the problem of column operations in designing semantic parsers for TexttoSQL. It also mentions the design of a new dataset, which is a different train/test split of an existing dataset, SQUALL. Additionally, it points out a synthetic benchmark paper based on a single question template. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be improved, such as demonstrating novelty and incremental improvements, and providing suggestions for addressing the issue of column operations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, specifically addressing a problem of column operations in designing semantic parsers for TexttoSQL. The reviewer provides some justification by mentioning that the proposed dataset is a different train/test split of an existing dataset, SQUALL, and that the synthetic benchmark paper is based on a single question template. However, the comment could be strengthened by providing more detailed examples or references to support the claim of lack of novelty. As it stands, the comment is 3, as it provides some evidence but lacks comprehensive justification. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and notes that the proposed dataset is a different train/test split of an existing dataset, SQUALL. Additionally, the comment mentions a synthetic benchmark paper based on a single question template, which further highlights the lack of novelty. This feedback is clear and actionable, as it directs the authors to address the issue of novelty and incremental nature in their work. However, the comment could be more helpful if it provided suggestions on how to demonstrate novelty or incremental improvements, such as by suggesting alternative approaches or datasets. Overall, the comment is 4 as it effectively identifies a critical weakness and offers direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the experiments are limited to one game environment and suggests that more experiments are necessary. This provides a clear and direct action for the authors to take, which is to expand their experimental scope to include additional game environments. The comment is specific in its request for additional experiments, making it 5.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments, but without clear references to specific sections or experiments, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to one game environment and recommends conducting more experiments. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is problematic or how it affects the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on only one game environment. It suggests that more experiments are necessary to provide a broader perspective. While this feedback highlights an area for improvement, it lacks specific guidance on which additional environments should be considered or how to conduct these experiments. The comment is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This is a clear and direct action for the authors to take, as it specifies the need for a detailed explanation with examples. The comment provides a concrete direction for improvement, ensuring that the authors know exactly what needs to be done to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. This allows the authors to accurately identify the part of the paper being addressed, making it fully grounded. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a detailed explanation with examples. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors need to explain why removing certain assumptions like bounded variance and bounded gradients is an important contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these assumptions are important or how removing them would contribute to the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail and explanation. It points out that the removal of certain assumptions like bounded variance and bounded gradients is an important contribution, but it does not provide examples or further explanation of why these assumptions are important. This feedback is 3 as it highlights a gap in the paper that the authors need to address, but it lacks depth and specificity. The comment could be more helpful if it offered suggestions on how to present this information or provided examples of how these assumptions affect the results. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific information about the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This explicit comparison and concrete data provide the authors with a clear action to take: they need to address the issue of slow speed and low accuracy by improving their implementation. The comment is explicit and provides concrete details on how to apply the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of implementing ImageNet for the first time, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of slow speed and low accuracy, providing specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" implementation of ImageNet is slow and has low accuracy, citing specific examples of time and accuracy. However, the comment does not provide any supporting evidence or references to substantiate these claims. Without additional context or detailed analysis, the authors may find it challenging to understand the basis of these claims and address them effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claim of implementing ImageNet for the first time and the actual slow speed and low accuracy. It provides specific examples of the time it takes for SHE to test an ImageNet picture by AlexNet and ResNet18, as well as the accuracy, which is around 70%. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address to improve the credibility and effectiveness of their work. By addressing these points, the authors can enhance the robustness and reliability of their implementation. However, the comment could be more helpful if it offered suggestions on how to improve the speed and accuracy, such as potential optimizations or alternative approaches. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests adding a few more sentences to explain the experimental setting for continual learning, and it explicitly asks for an explanation of the correspondence between the learning curves and MPHATE in Figure 3. The reviewer also questions the rationale behind the learning curves and the accuracy numbers, providing specific questions that the authors should address. These actions are clear and detailed, giving the authors a clear path to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the need for an explanation of the experimental setting for continual learning, the correspondence between the learning curves and MPHATE, and the accuracy numbers. The comment provides detailed questions that guide the authors on what aspects of the paper need clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add a few more sentences to explain the experimental setting for continual learning. It also requests an explanation of the correspondence between the learning curves and MPHATE in Figure 3, questioning the rationale behind the learning curves and the accuracy numbers. This feedback is clear and constructive, as it guides the authors on how to enhance the clarity and understanding of their experimental setup. By addressing these points, the authors can improve the comprehensibility and rigor of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer any explicit guidance or actionable steps for the authors to take. The comment lacks specific instructions or suggestions on how to incorporate this idea into their work. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that labeled data might provide effective information for consistency training, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the paper should be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. The reviewer supports this suggestion by referencing external works, specifically mentioning \"Graph Contrastive Learning Automated\" by You et al. and \"Graph Contrastive Learning with Adaptive Augmentation\" by Zhu et al. These references provide a basis for the claim, but the comment could be strengthened by further elaboration on why labeled data might be beneficial or how it could be integrated into the existing work. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. While it suggests that labeled data might provide effective information for consistency training, it does not offer specific guidance or actionable steps for the authors to explore this idea further. The references to external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" provide some context and support the suggestion, but the comment could be more helpful by offering detailed suggestions on how to incorporate labeled data into the existing work or how to evaluate its impact. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific suggestions for how to do so. It suggests that the experimental content listed in the main text should highlight the superiority of the method, and it provides a list of experimental suggestions that should be included in the main text. These suggestions are concrete and provide clear guidance on what changes the authors should make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental part\" and the \"experimental section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the reorganization and highlighting of the experimental content to showcase the superiority of the method. The suggestions for reorganization and the inclusion of specific experimental content are detailed, providing clear guidance for the authors to make improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part needs to be reorganized and improved, suggesting that the experimental content listed in the main text does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to specific sections of the paper where the issue is apparent, making it difficult for the authors to understand and address the critique. As a result, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental part of the paper, noting that the experimental content listed in the main text does not effectively highlight the superiority of the method. It provides a clear and actionable suggestion to reorganize the experimental section and includes specific experimental suggestions that should be included in the main text. This feedback is valuable as it guides the authors on how to improve the clarity and effectiveness of their experimental results, which is crucial for the paper\"s credibility. However, the comment could be more helpful if it provided additional details or examples of how to implement these suggestions. Overall, the comment is 4 as it offers a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the classification error of the proposed network and suggests reporting the classification accuracy on ImageNet data. It also requests theoretical justifications, if possible. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should report the classification accuracy and provide theoretical justifications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed classification network, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the classification error of the proposed network and suggests reporting the accuracy on ImageNet data. Additionally, it requests theoretical justifications, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. The reviewer suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. However, the comment lacks specific examples or references to support the claim about the classification error or the need for theoretical justifications. This makes the claim 3, as the authors would need to make a significant effort to understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the classification error of the proposed network and questions whether it is as good as the standard softmax network. It suggests reporting the classification accuracy on ImageNet data and provides a theoretical justification for the issue. This feedback is actionable as it prompts the authors to address the concern by providing additional data and theoretical analysis. However, the comment could be more helpful if it offered specific suggestions on how to improve the classification accuracy or provided examples of theoretical justifications. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what specific changes could be made to improve the argument or simulations. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific argument related to the practicality of the recognition process, particularly in the context of old vs. new judgments. However, it does not specify which part of the paper this argument is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the exhaustive list of items and how it relates to concrete predictions through simulations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the practicality of the argument that recognition lists are recalled based on items, particularly in the context of old vs. new judgments. The reviewer points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. This claim is 3 as it provides a logical reasoning for the difficulty in implementing the argument, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the argument presented regarding the recall of recognition lists based on items, particularly in the context of old vs. new judgments. It points out that in the most common case, new items comprise the list of all items available in memory (minus those seen), making it difficult to see how such an exhaustive list could be effectively implemented and used for concrete predictions through simulations. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their argument. The feedback is 3 as it prompts the authors to consider the practicality of their argument, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. It points out that if not, the proposed method without SSL might perform inferior to most of the compared methods, as shown in Table 1. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the initialization process and possibly rerun experiments with different initialization methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental comparison with other methods and the specific issue of initialization with pretrained models. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies the concern about the fairness of the comparison and the potential impact on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the experimental comparison with other methods, specifically questioning whether the proposed method was initialized with the same or similar pretrained model as the compared methods. The reviewer supports this claim by referencing Table 1, which shows that the proposed method without SSL performs inferior to most of the compared methods. This provides a logical basis for the claim, as it highlights a potential issue in the experimental setup. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental comparison, specifically questioning the fairness of the comparison due to the initialization of the proposed method with a pretrained model. It highlights a potential bias in the results if the compared methods were not initialized with the same or similar pretrained model. This feedback is valuable as it points out a critical aspect of the experimental design that could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific method for initialization or suggesting ways to standardize the initialization process across methods. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to resolve the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. It also provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" The comment is explicit in its suggestion to use better metadata embeddings and provides a specific reference to a related work. However, it does not provide detailed guidance on how to implement this suggestion or what specific steps to take. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. The comment provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" and suggests that the authors should consider this approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset, specifically referring to Table 3 on page 7. The reviewer provides a specific example of a related work that used better metadata embeddings, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016.\" This reference provides a clear rationale for the suggestion, as it demonstrates that better metadata embeddings can lead to improved performance. However, the comment could be strengthened by providing more detailed analysis or specific examples of how the proposed method could benefit from these embeddings. Overall, the claim is 4, as it is supported by a specific example and logical reasoning, but it could be further substantiated with additional evidence or detailed analysis.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by recommending the use of better metadata embeddings for the zeroshot learning results on the CUB dataset. It references a specific example from a related work, Table 1 in \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which demonstrates the potential for better performance using better metadata embeddings. This feedback is clear and actionable, as it guides the authors on how to enhance their results and potentially improve their paper\"s impact. However, the comment could be more helpful if it provided additional context or detailed guidance on how to implement this suggestion. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors include a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This explicit suggestion provides a clear and concrete action for the authors to take, as it specifies the exact type of visualization needed to demonstrate the practical benefits of SGC. The comment is specific in detailing what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the limited applicability of SGC and the comparison with PEFT methods. It also specifies the need for a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff but is limited in practicality due to the need for extra tuning. The reviewer suggests including a plot to demonstrate the flexibility of SGC compared to LoRA. This claim is 3 as it provides a logical reasoning for the need to visualize the tradeoff, but it lacks specific examples or references to support the claim about the limitations of PEFT methods. The suggestion for a plot is a clear and actionable step, but the initial claim could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim about the flexibility and performance of SGC, specifically in the context of computeconstrained scenarios. It suggests including a plot to demonstrate the flexibility of SGC compared to LoRA, which could help clarify the practical benefits of SGC\"s finegrained control. This feedback is clear and actionable, providing a specific suggestion for improving the paper by adding a visualization that could enhance the authors\" argument. By addressing this point, the authors can strengthen their case for the practicality of SGC. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computational advantage. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or publish the code to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments\" and \"German and Law school dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the reasonableness of the shorter training time for Gerrymandering compared to Independent, and suggests that the code should be published to demonstrate the computational advantage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. The comment also suggests that the code should be published to demonstrate the computational advantage. However, the comment lacks specific evidence or references to support the claim about the training time or the need for code publication. The reasoning is based on logical reasoning and common sense, but it does not provide detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises a question about the training time of the German and Law school dataset in Gerrymandering compared to Independent, suggesting that it might be unreasonable. It also suggests that the code should be published to demonstrate the computational advantage, which could be beneficial for the authors to address. While the comment identifies a potential issue and provides a suggestion for improvement, it lacks depth and does not offer specific guidance or examples on how to address the issue or improve the code. The feedback is 3 as it points out a potential weakness but does not provide detailed guidance for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and clarifies the additional information that CD captures on top of Predictive Uncertainty. It also questions the use of entropy as a measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples\" and requests clarification on line 113. While the comment provides explicit actions for the authors to take, such as describing possible alternate formulations and clarifying the additional information captured by CD, it does not specify how to implement these actions or provide detailed guidance on what specific formulations should be considered. The action is concrete but could be more detailed, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the additional information captured by Confidence Diversity (CD) and the use of entropy as a measure. The comment provides clear guidance on what needs to be clarified or addressed, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the additional information captured by Confidence Diversity (CD) and the use of entropy as a measure. It suggests that the authors should describe possible alternate formulations for CD and clarify the additional information captured. The reviewer also questions the clarity of line 113, indicating a lack of understanding. However, the comment does not provide specific examples or references to support these claims, making it 3. The authors would need to make a significant effort to understand and address the issues raised, as the comment lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to describe possible alternate formulations for Confidence Diversity (CD) and to clarify the additional information captured by CD on top of Predictive Uncertainty. It also questions the use of entropy as a measure and points out a lack of clarity in line 113. This feedback is specific and offers a clear direction for the authors to improve their draft by addressing these issues. However, the comment could be more helpful if it provided examples of possible alternate formulations or detailed guidance on how to clarify the additional information captured by CD. Overall, the comment is 4 as it identifies specific areas for improvement and offers actionable suggestions, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. It also points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the human baseline. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the human baseline, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. Additionally, it highlights the misleading statement in the abstract about beating a human who learned Kalamang. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the limited amount of speech recordings followed by the human. The reviewer supports this claim by pointing out that the human baseline only closely follows a little more than 1 hour of speech recordings, while the model baseline is evaluated on the full 15 hours. Additionally, the reviewer critiques the abstract statement about beating a human who learned Kalamang, noting that it is misleading due to the limited human data. This claim is 4 as it provides a logical reasoning and specific examples to support the assertion. However, it could be strengthened by referencing the specific sections of the paper where the human baseline is discussed and the abstract statement is made. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the human baseline, noting that it only closely follows a little more than 1 hour of speech recordings, making it considerably weaker compared to the model baseline. This is a critical observation that could impact the validity and applicability of the human baseline. Additionally, the comment points out that the abstract statement about beating a human who learned Kalamang is misleading due to the limited human data. This feedback is valuable as it highlights a potential weakness in the study that the authors should address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to improve the human baseline or how to address the misleading statement in the abstract. Overall, the comment is 3 as it identifies a critical issue and offers some guidance, but it could be more comprehensive with additional suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the assumption for termination states of instructions is quite strong, particularly when it comes to labeling a large number of data manually. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption for termination states of instructions, particularly in the context of labeling a large number of data manually. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue of the assumption being too strong, but it lacks detailed guidance on how to address this issue or what specific changes could be made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption for termination states of instructions is \"quite strong,\" particularly when it comes to labeling a large number of data manually. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the assumption for termination states of instructions, particularly when it comes to labeling a large number of data manually. This is a relevant point that could impact the feasibility and costeffectiveness of the proposed method. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without detailed feedback or constructive advice, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the nature of the contribution with respect to ECE_sweep. It explicitly states that the contribution is not clearly described and suggests that the authors should be more upfront about it. The reviewer provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The comment is explicit in its request for clarification and provides a specific example of what needs to be addressed. Therefore, the comment is 5, as it clearly guides the authors on how to improve the clarity of their contribution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ECE_sweep\" and the issue with the contribution being unclearly described. It specifies the problem by pointing out that the contribution is not clearly described, and it provides a concrete example of what is missing, which is the autotuning of a hyperparameter in the estimate. This level of detail allows the authors to understand exactly what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the contribution with respect to ECE_sweep is not clearly described in the text. It provides a specific example of the issue, which is the autotuning of a hyperparameter in the estimate, and notes that this is not fundamentally different from the contribution. The reviewer acknowledges being confused about the paper\"s point until they realized this. This provides a clear and specific example of the issue, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that might have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the contribution regarding ECE_sweep. It points out that the contribution is not clearly described in the text, and provides a concrete example of what is missing: the autotuning of a hyperparameter in the estimate. This feedback is 5 as it guides the authors to clarify the contribution and its significance in the paper. By addressing this issue, the authors can improve the clarity and understanding of their work. However, the comment could be more helpful if it suggested ways to improve the clarity or provided additional examples of how the contribution could be better explained. Overall, the comment is 4 as it effectively highlights a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, it does not provide explicit guidance on which methods should be used as a baseline or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors can infer that they need to consider using these methods as a baseline but are not given specific instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This provides clear guidance on what needs to be addressed in the paper, namely the inclusion of these methods as baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the related work section, noting that it discusses other methods for training NMT models beyond MLE (e.g., RL methods) but does not use any of them as a baseline. This feedback is 3 as it points out a potential gap in the paper\"s evaluation, which could be addressed by including these methods as baselines. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these methods or why they are important. Additionally, it does not address other aspects of the paper, such as its originality or contributions. Therefore, the comment is 3, as it highlights an area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential ambiguity in the authors\" use of the term \"efficient proxy\" or \"efficient proxies\" in their work. It suggests that the term \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests that it might refer to a family of proxies. The reviewer does not provide explicit guidance on how the authors should clarify this ambiguity or what specific actions they should take to address it. However, the comment implies that the authors should clarify the intended meaning of \"efficient proxy\" or \"efficient proxies\" to avoid confusion. While the action is implicit, it is clear that the authors need to make a clarification to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"efficient proxy\" or \"efficient proxies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ambiguity in the term, suggesting that it might refer to a particular proxy or a family of proxies. This provides clear guidance on what needs to be clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the term \"efficient proxy\" or \"efficient proxies\" in the paper, suggesting that it might refer to a particular proxy or a family of proxies. The reviewer provides logical reasoning by pointing out that the use of \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference. However, the comment lacks specific examples or references to support this reasoning, making it 3. The authors would need to further explore the context and clarity of the term to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the paper regarding the term \"efficient proxy\" or \"efficient proxies.\" It suggests that the use of \"is\" might imply a particular proxy, but the lack of a specific \"Efficient Proxy\" suggests a broader reference to a family of efficient proxies. This feedback is clear and actionable, as it guides the authors to clarify the intended meaning of the term to avoid confusion. However, the comment could be more helpful if it provided suggestions on how to clarify this ambiguity or offered examples of how the authors might address it. Overall, the comment is 4 as it effectively points out a potential issue and provides a direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the authors stacking methods from Mirzasoleiman et al., 2020 and using a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the methodology, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors stack methods from Mirzasoleiman et al., 2020 and use a grouplearning setting, followed by a classical method like DBSCAN for clustering. However, the comment lacks any supporting evidence, reasoning, or references to justify why this approach is problematic or inappropriate. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" methodology, specifically mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the grouplearning setting, followed by the use of a classical method like DBSCAN for clustering. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. It also mentions that the authors might have missed this in the appendix. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the resilience of the metric to the choice of random projection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the chosen random projection matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. The comment also mentions that the authors might have missed this in the appendix, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the variability in results with the chosen random projection matrix and suggests constructing pathological projection matrices to test the resilience of the metric. However, the comment lacks specific examples or references to support the claim that such pathological projection matrices are unlikely with random projections. While it highlights a potential concern, the lack of detailed justification or evidence makes the claim 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results obtained using the chosen random projection matrix, suggesting that pathological projection matrices could skew the MFTMA capacity and width scores. It also points out that the authors might have missed this in the appendix. While the comment highlights an important area for investigation, it lacks specific guidance or suggestions on how to address this issue or what specific tests could be conducted to verify the resilience of the metric. The feedback is 3 as it prompts the authors to consider this aspect, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises questions about the synthetic data used in the paper, specifically asking for examples of what \"support data\" and \"predicted training count data\" might look like. It also requests that the authors explicitly state the model used in the paper, suggesting that this information could be added to the appendix. While the comment provides some guidance on what the authors should include, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide examples and model details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1, as well as requests that the model used be explicitly stated in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific terms used in the paper, such as \"support data\" and \"predicted training count data,\" and requests for more detailed information about the model used. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the clarity and specificity of the synthetic data used in the paper. It specifically asks for examples of what \"support data\" and \"predicted training count data\" might look like, as well as requests that the model used be explicitly stated in the appendix. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and transparency of the paper. By addressing these questions, the authors can enhance the understandability and reproducibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just being limited to the ablation study. While the comment implies that the authors should expand the evaluation to include additional comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden the evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited use of FGT for evaluating the performance of the proposed method and comparative methods. This provides clear guidance on how to improve the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of FGT is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the paper\"s conclusions. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of FGT, noting that it is limited to the ablation study and should be used to evaluate the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a direct suggestion for expanding the evaluation to include additional comparisons. By addressing this point, the authors can enhance the robustness and comprehensiveness of their evaluation, which is valuable for improving the draft. However, the comment could be more helpful if it provided specific examples of comparative methods or detailed guidance on how to conduct these additional evaluations. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to enhance the model\"s complexity or complexity analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as the model description, results, or analysis. Without explicit references to sections or figures, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the model seems overly simple, which is both a feature and a bug. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the model seems overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the model\"s complexity. Without actionable feedback or detailed analysis, the comment lacks depth and does not assist the authors in enhancing their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the scope of the work or how to demonstrate its broader impact. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the narrow focus, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which could limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion and how it affects the paper\"s impact. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential limitation of the work, noting that its focus on a narrow task (climate change QA) in a specific language (Arabic) could limit its broader impact. While this observation highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or broaden the scope of their work. The comment lacks actionable advice or detailed feedback, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it points out a potential weakness but does not offer concrete steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not contribute novelly to the understanding of the winnertakeall property, as it uses extremely simplified settings and reports findings that have been previously reported in other works. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the originality or how to present the findings in a more novel or innovative way. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"winnertakeall property\" and \"Sec 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not contribute novelly to the understanding of this behavior due to the use of extremely simplified settings and the repetition of findings from previous works. This provides clear guidance on what needs to be addressed to improve the originality of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. However, the comment lacks specific references to these previous works or detailed examples of how the findings have been reported elsewhere. Without specific references or detailed reasoning, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 2, as it provides some evidence but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it does not contribute novelly to the understanding of the winnertakeall property due to the use of extremely simplified settings and the repetition of findings from previous works. This is a critical observation that could impact the paper\"s originality and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or differentiate their work from previous studies. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment explicitly states these actions, it does not provide detailed guidance on how to present the information or what specific examples to include. The authors are given a clear direction but may need to infer the exact implementation of these suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and providing a rough example of runtimes in the experiments. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the computational cost discussion or the experimental results, but this inference is not direct. The comment is specific in suggesting the inclusion of computational cost information and examples, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests mentioning the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the importance of including these details, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends mentioning the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it suggests providing a rough example of some runtimes in the experiments to help readers understand the method\"s practicality. This feedback is specific and offers concrete steps for the authors to enhance the clarity and applicability of their work. By addressing these points, the authors can significantly improve the comprehensiveness and accessibility of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors elucidate the EEG token quantization process in greater detail, specifically addressing the ambiguity in interpretation. It suggests that the authors should clarify whether the spatial arrangement of the EEG sensors played a role in this process. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the ambiguity in the interpretation of the EEG topography plots and the need to clarify the role of the spatial arrangement of the EEG sensors in the EEG token quantization process. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpretation due to the EEG topography plots for both the input and output during the EEG token quantization process. The reviewer suggests that the authors should elucidate this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This claim is 3 as it provides a logical reasoning for the need to clarify the process, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both the input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors should clarify this procedure in greater detail, specifically questioning whether the spatial arrangement of the EEG sensors played a role in the process. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and understanding of their results. By addressing this issue, the authors can enhance the transparency and interpretability of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific changes could be made to improve the directness of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" approach to leveraging the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique is based on, such as a specific section or table where this complexity is discussed. Without explicit references, the authors may struggle to identify the exact part of the paper being addressed. The comment is specific in detailing the issue with the approach, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors leverage the complexity of checking on the Witness oracle, which is \"polynomial time\" in the tabular case. This claim is 3 as it suggests that the authors are not addressing the problem directly, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The reviewer could provide more context or evidence to support the assertion that the approach is not direct, such as by explaining how the complexity affects the overall effectiveness of the method. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a potential issue with the authors\" approach, specifically the use of the Witness oracle complexity, which is described as \"polynomial time\" in the tabular case. This observation suggests that the authors may not be addressing the problem directly, as the complexity is not being addressed in a straightforward manner. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss relevant literature on using moment matching (instead of quantile regression) for distributional RL, specifically mentioning the paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This provides a clear and direct action for the authors to take, as they are instructed to include this discussion in their paper. The comment is specific and provides concrete guidance on how to enhance the literature review section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph (lines 2230) and discusses the use of moment matching in distributional RL. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on moment matching and its relevance to distributional RL. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching (instead of quantile regression) for distributional RL. The reviewer supports this claim by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This reference provides a clear and specific example of relevant literature that could be included in the paper. However, the comment could be strengthened by providing more detailed reasoning or examples of how moment matching could be beneficial in the context of distributional RL. Despite this, the claim is 4 due to the reference to a specific work that supports the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks relevant literature, specifically on the use of moment matching instead of quantile regression for distributional RL. It provides a clear and actionable suggestion by referencing a specific paper by NguyenTang et al. AAAI'21, \u201cDistributional Reinforcement Learning via Moment Matching.\u201d This feedback is valuable as it directs the authors to include a discussion on this topic, which could enhance the paper's literature review and depth of analysis. However, the comment could be more helpful if it explained why moment matching is a relevant approach or how it could benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their work with existing code completion commercial applications, such as Copilot, as a baseline. It provides a specific suggestion for testing on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. This feedback is clear and concrete, giving the authors a direct action to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. It specifies that this comparison should be tested on a smaller subset of RepoEval and highlights the importance of comparing with stateoftheart code completion systems. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the evaluation or comparison sections, the lack of explicit grounding makes it weakly grounded. The suggestion is specific, as it clearly identifies what needs to be addressed, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with existing code completion commercial applications, such as Copilot, as a baseline. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test the performance of the proposed system against stateoftheart code completion systems. However, the comment lacks specific examples or references to these existing applications, making it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of baselines, specifically comparing the proposed work with existing code completion commercial applications like Copilot. This feedback is valuable as it highlights a potential gap in the evaluation and offers a specific direction for the authors to enhance their work. By including this comparison, the authors can demonstrate the effectiveness of their approach against existing stateoftheart systems, which is crucial for the credibility and impact of their research. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. While the comment implies that the authors should consider expanding their evaluation to include more datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that understanding the criteria behind the selection and exploring other tasks or datasets might yield different insights. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. However, the comment lacks specific examples or references to support the claim that the current evaluation is limited in scope. While it highlights a potential issue, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation results, specifically questioning the choice to evaluate only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that understanding the criteria behind this selection and exploring other tasks or datasets might yield different insights. This feedback is 3 as it prompts the authors to consider the broader implications of their evaluation approach and how it might impact the generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional tasks or datasets might be relevant to include. Overall, the comment offers a valuable direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the second paragraph in the introduction discusses modelling curves but does not clearly state what is being modelled, presumably tumour growth. While the comment identifies a potential issue with the clarity of the introduction, it does not provide explicit guidance on how to improve the clarity. The authors are left to infer that they should make the modelled content more explicit, but the comment lacks concrete suggestions or examples on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of not being immediately obvious what is being modelled, which is a clear and actionable concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second paragraph in the introduction is unclear about what is being modelled, specifically mentioning \"modelling curves\" and presumably tumour growth. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the introduction, specifically the lack of clarity regarding what is being modelled in the second paragraph. It points out that the mention of \"modelling curves\" does not immediately clarify the context, which is presumably tumour growth. This feedback is 3 as it highlights an area where the introduction could be improved to enhance the reader\"s understanding of the paper\"s focus. However, the comment does not provide specific suggestions or guidance on how to clarify this aspect, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of the shiftedMNIST dataset and suggests that it would be useful to show the model and baselines on test samples from the observational (in) distribution. While the comment implies that the authors should provide additional data or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments or analyses to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"shiftedMNIST,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the performance difference between shift=0 and shift~N (0, \u03c3 2) and suggests showing performance on test samples from the observational (in) distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference is not as significant as claimed. However, the comment does not provide specific reasoning or evidence to support this claim, nor does it offer alternative explanations or comparisons. This lack of detailed justification makes the claim 3, as the authors would need to further explore the issue themselves to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance difference between shift=0 and shift~N (0, \u03c3 2) in the context of the shiftedMNIST dataset. It suggests that both cases incorporate a domain shift, implying that the performance difference might not be as significant as claimed. The comment also recommends showing the performance of the model and baselines on test samples from the observational (in) distribution, which could provide valuable insights into the robustness of the results. While the comment identifies a potential issue and offers a suggestion for improvement, it lacks specific guidance on how to implement these changes or what specific analyses should be conducted. This limits the comment\"s helpfulness, as it provides some direction but not enough detail for the authors to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the experimental description, suggesting that increased clarity would be beneficial. It explicitly states that the current state of the manuscript makes it difficult for readers to judge the results. The reviewer provides a reference to \"Questions\" for further details, which implies that the authors should refer to this section for guidance on how to improve the clarity of their experimental description. However, the comment does not specify which aspects of the experimental description are unclear or how to address these issues. While the action is implicit, it is clear that the authors need to improve the clarity of their experimental description, and the reference to \"Questions\" provides a starting point for further exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental details\" and suggests that they need increased clarity to better judge the results. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental description and the need for further details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental description lacks detail and clarity, making it difficult for readers to judge the results. This claim is 3 as it highlights a specific issue with the manuscript, but it does not provide detailed examples or references to support the claim. The reference to \"Questions\" suggests that further details are available elsewhere, but this does not fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the manuscript, specifically the lack of detail in the experimental description. It highlights the importance of clarity in the results section to enable readers to better understand and judge the findings. The comment suggests that the current state of the manuscript makes it difficult for readers to assess the results, and it provides a reference to \"Questions\" for further details. This feedback is clear and actionable, as it directs the authors to enhance the clarity of their experimental description to improve the comprehensibility and impact of their work. However, the comment could be more helpful if it provided specific examples or suggestions on how to improve the clarity of the experimental description. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide more explanation to clarify the main contributions of the paper, specifically regarding the optimization strategies and their corresponding results. It suggests discussing different scenarios, such as minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is clear and concrete, as it specifies exactly what the authors need to address to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more explanation regarding the optimization strategies and their corresponding results. The comment provides a clear direction for the authors to improve their draft by discussing different scenarios and their implications. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanation regarding the optimization strategies and their corresponding results, specifically mentioning the contribution of the CBR. The reviewer provides a specific example of what could be discussed, such as the consequences of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This claim is 3 as it provides a logical reasoning for the need of additional explanation, but it lacks detailed justification or references to support the importance of these discussions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the optimization strategies and their corresponding results. It suggests that the authors should provide more detailed discussion on the contribution of the CBR, particularly regarding the consequences of different optimization strategies. The comment provides a clear and actionable suggestion by offering an example of what could be discussed, such as the implications of minimizing both inter and intra terms in Eq 3 or only minimizing the first term. This feedback is valuable as it guides the authors to enhance the clarity and depth of their discussion, which can significantly impact the understanding and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is an explicit action, as it clearly specifies what the authors need to do to improve their draft. The comment provides a clear and concrete direction for the authors to add a definition, making it 5.", "grounding_specificity_rationale": "The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, methodology, or results sections. The authors can infer that it relates to the proofs, but this inference is not direct. The comment is specific in suggesting the inclusion of a definition, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including a definition. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a formal or intuitive definition of the treewidth should be included in the paper, as it is central to all the proofs. This is a clear and actionable suggestion that can help the authors improve the clarity and accessibility of their work. By including a definition, the authors can ensure that readers understand the concept and its importance in the context of the paper. However, the comment could be more helpful if it provided additional guidance on how to present the definition or examples of how it has been used in the proofs. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. This feedback provides a clear and explicit action for the authors to take, which is to include an analysis of the quality of the local minima. The comment is specific in detailing what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1 and the local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as the approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima, specifically the approximation ratio under certain assumptions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors analyze the quality of the local minima, particularly the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their analysis and improve the paper. By addressing this suggestion, the authors can strengthen their work by providing more detailed insights into the performance of their algorithm. However, the comment could be more helpful if it included specific examples or references to similar analyses in the literature, which would guide the authors in implementing this suggestion effectively. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper. It also requests the authors to release the source code of their experiments to allow reproduction of their results. While the comment identifies a specific issue with the selfcontainment and provides a clear action for the authors to take, it does not offer detailed guidance on how to improve the selfcontainment or what specific aspects of the supplementary material should be included. The action is explicit but somewhat vague, as the authors need to determine which parts of the supplementary material are most critical for selfcontainment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"supplementary\" material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the selfcontainment of the paper and the need for the authors to release the source code of their experiments for reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not selfcontained and suggests that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. The reviewer also requests the authors to release the source code of their experiments. While the comment identifies a potential issue with the selfcontainment of the paper, it lacks specific examples or detailed reasoning to support why the supplementary material is necessary or how the source code release would enhance reproducibility. The claim is 3, as it provides a general direction for improvement but lacks the necessary evidence or detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the selfcontainment of the paper, noting that the supplementary material is necessary to understand large parts of the main paper and enable reproducibility. It also requests the authors to release the source code of their experiments to allow for reproduction of their results. This feedback is clear and actionable, as it provides specific guidance on how to improve the selfcontainment and reproducibility of the paper. However, the comment could be more helpful if it offered suggestions on how to improve the supplementary material or what specific aspects of the source code should be released. Overall, the comment is 4 as it directs the authors to address a critical aspect of their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, Decode algorithms, and references a specific sentence regarding the performance of the secret model with or without fusion. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the algorithms should be clarified or how the authors might address the issue of information redundancy. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Fill, Propagate, Decode algorithms\" and the specific sentence \"Finally, by comparing the performance of the secret model with or without fusion, we conclude that the robustness of Cans largely comes from the information redundancy implemented in our design of the weight pool.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it asks for clarification on how information redundancy is built into the algorithms and how it affects the performance of the secret model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how information redundancy is built into the Fill, Propagate, Decode algorithms. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, Decode algorithms, specifically asking for clarification on how this redundancy is built into the algorithms. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithms need clarification. The feedback is 3 as it points out a potential weakness, but it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It implies that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment does not provide explicit instructions or concrete guidance on how to conduct this ablation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not explicitly mention which part of the paper this feature is discussed in, making it weakly grounded. The comment is specific in questioning the importance of the added complexity and suggesting an ablation study to determine whether one IN would suffice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. However, the comment lacks any supporting evidence, reasoning, or references to justify why this feature is important or how it affects the model. Without such information, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of the added complexity in using multiple INs at different speeds in the dynamics predictor. It suggests that the authors should consider ablating this feature to determine its impact on the model\"s performance. This feedback is 3 as it prompts the authors to consider an important aspect of their model that could affect its efficiency and effectiveness. However, the comment could be more helpful if it provided specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment offers a valuable direction for improvement but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their experimental design. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the opponent does not aim to maximize the multiagent payoff proposed by the authors, which is a clear and specific critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the opponent in the experiments does not aim to maximize the multiagent payoff proposed by the authors, which is a surprise. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the experimental setup, specifically noting that the opponent does not aim to maximize the multiagent payoff proposed by the authors. This observation highlights a potential weakness in the experimental design, as it suggests that the opponent\"s behavior may not accurately reflect the proposed method. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve their experimental design. Without specific advice or constructive feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. It implies that the authors should clarify the reasoning behind these choices, specifically mentioning the attention model paper that the algorithm iterates on. While the comment does not explicitly instruct the authors to provide this rationale, it clearly points out what needs to be added to improve the draft. The action is explicit and concrete, as it specifies the need for clarification and provides a clear direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"REINFORCE algorithm\" and \"PPO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the rationale behind the choice of algorithms and the potential influence of the attention model paper. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a rationale for why certain choices were made, such as the use of the REINFORCE algorithm versus PPO. The reviewer implies that this choice might be related to the attention model paper that the algorithm iterates on, but does not provide specific evidence or references to support this claim. While the suggestion is logical, it lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft. It points out that the authors should provide a rationale for the choices made, such as the use of the REINFORCE algorithm versus PPO. By doing so, the authors can clarify the reasoning behind their decisions, which could enhance the transparency and understandability of their work. This feedback is clear and constructive, as it directs the authors to a specific area for improvement that could enhance the clarity and comprehensibility of their paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, specifically regarding the potential disadvantage of MMD DRO compared to the variance regularized problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this confusion or clarify the statement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement in the theorem, which could indicate a disadvantage of MMD DRO compared to the variance regularized problem. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO compared to the variance regularized problem. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding a statement in Theorem 5.1, which could be interpreted as a disadvantage of MMD DRO compared to the variance regularized problem. This feedback is 3 as it points out a potential issue that the authors need to clarify or address. However, the comment lacks specific guidance on how to resolve this confusion or what specific aspects of the theorem need clarification. While it highlights an area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more information on how to use morphologic segmentation across different domains and how it should be conducted differently for each domain. It also questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on morphologic segmentation across domains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"morphologic segmentation\" and \"domain\" aspects, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of morphologic segmentation across domains and how it should be conducted differently for each domain. The comment also raises important questions about the assumption of morphologic segmentation invariance across domains, which is relevant to the task of domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks information on how to use morphologic segmentation across domains and how it should be conducted differently for each domain. It questions whether morphologic segmentation is invariant across domains, given the task of domain adaptation. While the comment identifies a gap in the paper, it does not provide specific examples or references to support the claim that the paper assumes morphologic segmentation invariance. The reasoning is 3, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the use of morphologic segmentation across domains and how it should be conducted differently for each domain. It questions the assumption of morphologic segmentation invariance across domains, given the task of domain adaptation. This feedback is valuable as it highlights an important area for improvement in the paper, particularly regarding the applicability of the method across different domains. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as discussing potential variations in morphologic segmentation across domains or offering guidance on how to conduct domainspecific analyses. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique used in LUMP. This is a clear and direct action, as it specifies exactly what needs to be done to improve the draft. The authors know exactly what additional experiments are needed and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results demonstrating the pure contribution of the proposed method without the mixup technique used in LUMP. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mixup technique used in LUMP should be excluded from the proposed method to demonstrate its pure contribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the mixup technique used in LUMP is also adopted for the proposed method in the experiments on SplitCIFAR100 and SplitTinyImageNet. It suggests that the authors should include experimental results demonstrating the pure contribution of their proposed method by excluding the mixup technique. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional experiments. However, the comment could be more helpful if it explained why the mixup technique is important or how its exclusion might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their experimental setup."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the object detectionbased attention being performed on the image or on some convolutional feature map. It suggests clarifying this point and potentially rescaling based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the object detectionbased attention, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on whether the attention is performed on the image or on some convolutional feature map, and whether rescaling is done based on the receptive field. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the object detectionbased attention and its implementation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention, specifically asking whether it is performed on the image or on some convolutional feature map. It also suggests that rescaling might be necessary based on the receptive field to determine which image regions correspond to which spatial locations in the feature map. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to clarify or address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a discussion about Set Transformer and other related works that use summary tokens. This provides a clear and direct action for the authors to take, which is to include a discussion on these topics. The comment is specific in identifying the missing content and provides a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and \"other related works that also use summary tokens,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the use of summary tokens and related works. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that there is a missing discussion about Set Transformer and other related works that use summary tokens. However, it does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a discussion about Set Transformer and other related works that use summary tokens. This feedback is clear and actionable, as it directs the authors to expand their literature review to include relevant works that could enhance their understanding and analysis. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided additional context or examples of how these works could be integrated into the paper. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide explicit guidance on how to address this issue or what specific analysis should be conducted. The action is implicit and somewhat vague, as the authors can infer that they need to provide theoretical support but are not given clear steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It implies that the authors may have overlooked this aspect and suggests that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure where this analysis is discussed. Without explicit references or clear indications, the authors cannot confidently determine the exact part of the paper being addressed. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the theoretical support for Fourier features in accelerating NTK convergence in the highfrequency range. It suggests that the authors may have overlooked this aspect and implies that it is an essential theoretical foundation for the merits of Fourier features. This feedback is valuable as it prompts the authors to consider a potential gap in their analysis and provides a clear direction for further exploration. However, the comment could be more helpful if it offered specific suggestions on how to address this gap or what kind of analysis should be conducted to support the theoretical foundation. Overall, the comment is 4 as it identifies a critical area for improvement and provides a direction for the authors to explore further."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more information about the network\"s training process, but it lacks concrete steps or suggestions for improvement. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of detail regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking details regarding the network\"s training process, but without clear grounding, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of details regarding how the network fits the residual instead of directly learning the inputoutput mapping. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this is a significant issue or a problem that needs to be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of details on how the network fits the residual instead of directly learning the inputoutput mapping. This is a relevant point that could impact the understanding and effectiveness of the network. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional details might be needed. While it highlights a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experiment setup in Section 3.3, specifically asking about data augmentation methods and learning rate. While the comment implies that the authors should provide more details about these aspects, it does not explicitly instruct them to do so. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" provides some context but does not offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the experiment setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for details on the experiment setup, such as data augmentation methods and learning rate, and provides a reference to a related paper for context. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the experiment setup in Section 3.3, specifically asking for details on data augmentation methods and learning rate. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The reference to the paper \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks\" is helpful in providing context but does not offer actionable advice. Overall, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity in its guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider an error in the initial calibration steps (steps 1 and 2) as a possible explanation for the speed disparities observed between the RSPs and FDs. However, it does not provide explicit instructions or concrete guidance on how to investigate or address this potential error. The authors are left to infer that they should look into the initial calibration steps, but without specific suggestions on how to do so or what specific aspects to focus on, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d\u2014RVC paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the claim, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the initial calibration steps, suggesting that an error might explain the speed disparities observed between the RSPs and FDs. While it highlights an area for further investigation, it lacks specific guidance or suggestions on how the authors might address this issue or what specific aspects of the initial calibration steps should be examined. The comment is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges that the artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of artificial networks trained using ASAP (and similar methods) not necessarily resembling biological networks, except for the weight transport problem. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the resemblance of artificial and biological networks, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment acknowledges that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, except for the weight transport problem. However, it does not provide any constructive feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or improve the resemblance between artificial and biological networks. Without actionable advice or specific recommendations, the comment does not assist the authors in enhancing their draft. Therefore, it is rated as 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors conducted statistical significance tests for the numbers presented in the comparison between the proposed method and baselines. While it implies that the authors should consider conducting such tests, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct statistical significance tests. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in its request for statistical significance tests, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. However, it does not provide any evidence, reasoning, or examples to support the claim that statistical significance tests should be conducted. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the statistical significance of the numbers presented in the comparison between the proposed method and baselines. It prompts the authors to consider whether they conducted statistical significance tests, which is an important aspect of evaluating the effectiveness of their method. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to consider conducting statistical significance tests. However, the comment could be more helpful if it provided specific guidance on how to conduct these tests or what statistical tests might be appropriate. Overall, the comment is 3 as it points out a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the paper\"s focus on learning HMMs with nonparametric emission distributions but questions how these distributions affect inference. It specifically asks about the inference tasks that can be computed with an NPSPECHMM, such as filtering, smoothing, and marginal observation likelihood. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the inference tasks should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the impact of emission distributions on inference tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"nonparametric emission distributions\" and the \"common inference tasks in a discrete HMM,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions how these emission distributions affect inference and asks about the inference tasks that can be computed with an NPSPECHMM. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It asks which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the impact of nonparametric emission distributions on inference tasks in a discrete HMM. It specifically questions which inference tasks, such as filtering, smoothing, and marginal observation likelihood, can be computed exactly or approximately with an NPSPECHMM. This feedback is valuable as it prompts the authors to clarify and expand on the implications of their work regarding inference tasks. However, the comment could be more helpful if it provided suggestions on how to address this gap or examples of how the authors might present this information. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results, including identifying the specific reasons for the poor performance. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it is not as concrete as it could be, leaving some ambiguity about the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the analysis, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for a more detailed analysis themselves, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it highlights a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the results. By pointing out the lack of analysis, the comment empowers the authors to enhance their draft by including a more detailed explanation of the underlying reasons for the poor performance. However, the comment could be more helpful if it suggested specific areas to explore or provided examples of how to conduct a more thorough analysis. Overall, the comment is 4 as it directs the authors to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. While the comment implies that the authors should expand their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analyses. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section where the authors discuss the datasets considered, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why only 10 out of 120 datasets are considered and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the limited consideration of only 10 out of 120 datasets in the paper and suggests comparing batch and greedy algorithms in the remaining 110 datasets. This feedback is 3 as it identifies a potential area for improvement in the paper\"s analysis. However, the comment lacks depth and does not provide specific guidance on how to conduct the additional analysis or what specific aspects of the batch and greedy algorithms should be compared. While it points out a potential gap in the analysis, it does not offer actionable steps for the authors to address this issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. It also implies that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the implications of the lowrank factorization in the context of the main result. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"lowrank factorization\" in the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary nature of the lowrank factorization and the potential implications for lowrank matrix factorization. This provides clear guidance on what the authors should consider and discuss in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation in the introduction, specifically the lowrank factorization, is unnecessary given that the main result is about polytopes. The reviewer suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the need for discussing lowrank matrix factorization based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically the lowrank factorization, which may not be necessary given the main result about polytopes. It suggests that if the result has implications for lowrank matrix factorization, it should be explicitly discussed. This feedback is 3 as it points out a potential area for improvement in the paper\"s motivation and alignment with the main results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the lowrank factorization should be discussed in the context of the main result. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. While the comment implies that the authors should clarify these labels, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information about the labels. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the labels for each dataset, including the origin of these labels and whether they are generated or not. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the labels for each dataset in 4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the labels for each dataset in 4.1, specifically asking where they are coming from and whether they are generated or not. This is a relevant inquiry that could help the authors clarify their methodology and provide more transparency about the datasets used. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address this issue. While it points out a potential area for improvement, it does not provide actionable advice or detailed feedback. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of incrementalism or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes or enhancements are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not specify which part of the paper this assessment is based on, such as the methodology or results sections. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide any specific details or references to support this claim, such as how the paper is incremental or how the adaptation affects the results. Without additional context or evidence, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental with respect to a specific reference [31] and notes that the authors adapt an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not explain how the paper\"s incremental nature impacts its contribution or what specific aspects of the adaptation could be improved. Without detailed guidance or constructive feedback, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to the \u03bb parameters, and questions how \u03bb is calculated. It also mentions that the authors explain why ELLA does not increase sample efficiency in a COMBO environment but does not fully understand the implications. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the explanation or calculations. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the process of calculating \u03bb and improve the explanation of the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines on pages 8 and 9, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters, questioning how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment. The reviewer provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific examples or detailed reasoning to support the claim that performance and sample efficiency are sensitive to \u03bb parameters. The references are provided as a means of context, but they do not fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the sensitivity of performance and sample efficiency to \u03bb parameters, which is a critical aspect of the paper. It raises questions about how \u03bb is calculated and the explanation of ELLA\"s sample efficiency in a COMBO environment, which are important areas for clarification. The reviewer also provides references to related works, which could be helpful for the authors to understand the context better. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the explanation. While it points out areas for improvement, it does not offer actionable steps for the authors to take. Therefore, the comment is 3, as it highlights important areas for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. However, it does not provide any guidance or suggestions on how the authors should address this issue or what specific information should be included to clarify the method. The comment lacks explicit instructions or concrete details, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of an alternating direction method to solve the minmin problem, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what needs to be addressed or improved regarding the method, leaving the authors with a clear understanding of the issue but without specific guidance on how to address it. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking for clarification about the method used to solve the minmin problem. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned in passing. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what specific information should be included to clarify the method. The comment lacks actionable feedback or detailed advice, leaving the authors with only a vague indication of a potential area for improvement. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the effectiveness of lower bound double qlearning, specifically mentioning the performance decrease in MsPacman and the convergence of algorithms in other environments. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these concerns or improve the draft. The authors are left without any clear direction on how to respond to the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure2\" and \"MsPacman,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the effectiveness of lower bound double qlearning, noting that the algorithm shows a slight performance decrease in MsPacman and that it may overestimate the true maximum value. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of lower bound double qlearning is doubtful, based on observations from Figure 2 and specific environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. The reviewer provides some evidence by mentioning the slight performance decrease in MsPacman and the convergence of algorithms in other environments. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some support, the authors would need more detailed evidence or examples to fully understand and address the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the effectiveness of the lower bound double qlearning algorithm, specifically noting that it shows a slight performance decrease in MsPacman and may overestimate the true maximum value. It also points out that the algorithm converges into the same solutions in various environments, such as WizardOfWor, Zaxxon RoadRunner, and BattleZone. This feedback is 3 as it highlights a specific concern about the algorithm\"s performance, which the authors can address by providing additional analysis or experiments to substantiate its effectiveness. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative approaches. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or suggest alternative approaches to explore. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the novelty is lacking or how it could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using linear models is not a new approach for model interpretation. This feedback highlights a potential weakness in the paper\"s contribution, which could impact its impact and originality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to clarify or explain the performance behavior in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig.34,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the performance of DNN+MMA becomes worse than vanilla DNN when lambda becomes small, and suggests that it should approach vanilla methods from above but from below. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of DNN+MMA compared to vanilla DNN when lambda becomes small, suggesting that it should approach vanilla methods from above but from below. This feedback identifies a potential discrepancy in the results that the authors may need to address or clarify. However, the comment lacks specific guidance or suggestions on how to resolve this issue or improve the explanation in the paper. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper, noting that it does not compare the results with some earlier research work from 2020. While the authors have explained their reasons for not doing so in the author response, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback provides a clear and explicit action for the authors to take, which is to include comparisons with these systems. The comment is specific and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors have explained their reasons for not comparing their results with some earlier research work from 2020. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the comparison with earlier systems with worse performances, such as Taghipour and Ng (2016). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not compare its results with some earlier research work from 2020, despite the authors explaining their reasons for not doing so. The reviewer suggests that the authors should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). However, the comment lacks specific examples or references to the earlier works that the authors have overlooked, making it 3. The authors would need to infer which systems are being referred to and potentially conduct additional research to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that it does not compare its results with some earlier research work from 2020. While the authors have explained their reasons for not doing so, the comment suggests that they should compare their results to a number of earlier systems with worse performances, such as Taghipour and Ng (2016). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison with existing work. By addressing this point, the authors can strengthen the validity and relevance of their findings. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a paired test setting like the Wilcoxon signedranked test might be more appropriate. While the comment implies that the authors should consider using a different test, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their choice of significance testing method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of significance testing method used in the paper, specifically questioning the appropriateness of the current method. However, it does not specify which part of the paper this critique is based on, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting an alternative test, the Wilcoxon signedranked test, but lacks detailed guidance on why this test might be more appropriate or how it would be integrated into the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed justification or examples to explain why the current test is inappropriate or how the suggested test would be more suitable. As a result, the claim is not verifiable, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment questions the choice of significance testing method used in the paper, suggesting that a different test might be more appropriate. While it identifies a potential issue with the current method, it does not provide specific guidance or examples of alternative tests that could be used. The comment lacks depth and does not offer actionable steps for the authors to address the concern, such as suggesting specific tests or explaining why the current method might be inappropriate. As a result, the feedback is 3, as it points out a potential weakness but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not provide specific guidance on how to expand the experiments or what additional aspects to consider. The action is implicit and somewhat vague, as the authors can infer that they need to broaden the scope of their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the scope of the experiments. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its critique of the limitations of the experiments, but without explicit references to sections or details, it is difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited in scope and that the model size and baselines are restrictive, which limits the comprehensiveness and generalizability of the results. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the limitations and how they might address them. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope and comprehensiveness of the experiments, particularly for the language modeling and image classification tasks. It points out that the model size is limited and the baselines are restrictive, which limits the generalizability of the results. This feedback is 3 as it highlights an area where the authors could potentially expand their experiments to enhance the robustness and applicability of their findings. However, the comment lacks specific suggestions on how to address these limitations or what additional experiments could be conducted. To be more helpful, the comment could provide guidance on how to broaden the scope of the experiments or suggest alternative approaches to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. It provides a clear and specific action for the authors to take, which is to elaborate on the topic. The comment is explicit and provides concrete guidance on what needs to be added to the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be elaborated on, namely the Hoeffding\"s bound and its implications for stochastic algorithms. This provides clear guidance on what the authors need to address in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Hoeffding\"s bound holds true for any w as long as samples are drawn independently, and that stochastic algorithms impose conditioning on the previous iterate to guarantee the inequality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (Line 124125) and suggests that the authors elaborate on the Hoeffding\"s bound and its implications for stochastic algorithms. This feedback is clear and actionable, as it directs the authors to provide additional explanation or context that could enhance the understanding of the paper\"s content. By addressing this suggestion, the authors can improve the clarity and depth of their discussion, making the comment 4. However, it could be more helpful if it provided specific examples or references to support the claim about the Hoeffding\"s bound. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. While the comment implies that the authors should consider adding this information, it does not provide explicit instructions on how to implement this suggestion or what specific details should be included. The action is clear but lacks concrete guidance on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this addition would be relevant. The authors can infer that it relates to the table or data presentation, but this inference is not direct. The comment is specific in suggesting the addition of a particular approach, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it would enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, specifically mentioning MAML and implicitMAML, to Table 1. This is a specific and actionable suggestion that could potentially enhance the paper by providing additional context and insights into the optimization methods used. However, the comment lacks depth and does not explain why this addition would be beneficial or how it would impact the paper\"s overall contribution. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This feedback provides a clear and direct action for the authors to take, which is to include an ablation study to address this issue. The comment is specific and provides concrete guidance on what needs to be added to the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of an ablation study, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of an ablation study to explain why the prompt was chosen in a specific way, such as using fewshot examples for CoT. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining why the prompt was chosen in a specific way, such as using fewshot examples for CoT. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this ablation study is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting the inclusion of an ablation study to explain why the prompt was chosen in a particular way, such as using fewshot examples for CoT. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper by addressing a gap in the experimental design. However, the comment could be more helpful if it included examples or detailed guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be careful with the terms \"causal mechanisms\" and \"temporal relationship,\" as they are not interchangeable. This feedback is clear and provides a specific action for the authors to take, ensuring that they use the terms correctly. The comment is concrete, as it specifies the exact issue and offers a direct way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms like \"causal mechanisms\" and \"temporal relationship,\" providing guidance on how to avoid confusion and ensure clarity in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the use of terms \"causal mechanisms\" and \"temporal relationship,\" suggesting that they are not interchangeable. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it points out a specific issue with the use of terms like \"causal mechanisms\" and \"temporal relationship\" in the paper. It provides a clear and actionable suggestion to avoid confusion by using these terms carefully. However, the comment could be more helpful if it offered additional guidance on how to effectively use these terms or provided examples of how they might be misused. Overall, the feedback is valuable but could be more comprehensive to fully support the authors in improving their draft. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what alternative demonstrations could be used. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific statement from the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the claim that \"better than random\" is a strong demonstration of capability. However, the comment does not provide additional details or suggestions on how to address this concern, such as suggesting alternative methods for demonstrating capability. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is questionable. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim that \"better than random\" is a strong demonstration of capability, suggesting that it may not be sufficient. This feedback is 3 as it points out a potential weakness in the paper\"s argument, prompting the authors to reconsider the strength of their evidence. However, the comment lacks specific suggestions or guidance on how to strengthen the demonstration or what alternative methods could be used to substantiate the claim. While it identifies an area for improvement, it does not provide detailed guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a desire for a discussion on how the results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" While it implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a discussion on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, nor does it provide details on what aspects of the results need to be addressed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, it is not specific, as it lacks detailed guidance on what aspects of the results need to be discussed or how they relate to the lower bounds. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why this discussion is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should discuss how their results relate to the lower bounds on kernel learning using lowrank approximation, as presented in the paper \"On the Complexity of Learning with Kernels.\" This feedback is 3 as it identifies a potential area for further exploration and discussion. However, it lacks specific guidance on how to integrate this discussion into the paper or what aspects of the results need to be addressed. While it points out a relevant reference, it does not provide detailed suggestions on how to effectively incorporate this discussion into the paper. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of using PCA to reduce interaction count and expresses uncertainty about the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to clarify the assumptions. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the assumptions and the significance of their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the use of PCA is intuitive and raises a question about the assumptions made. However, the comment does not specify which part of the paper discusses the use of PCA or where the assumptions are discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the novelty and significance of the results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. The reviewer provides a reference to a related work by Dombrowski et al. (2022) to support their claim about the use of PCA. However, the comment lacks detailed explanation or analysis of why the assumptions are unclear or how they impact the paper\"s significance. The reference to the external work is helpful but does not fully substantiate the claim. Therefore, the comment is 3, as it provides some support but lacks detailed justification or explanation.", "helpfulness_rationale": "The review comment questions the novelty and significance of the paper, suggesting that using PCA to reduce interaction count is intuitive and that the assumptions made are unclear. It references a related work by Dombrowski et al. (2022) to support its claim. While the comment identifies a potential weakness in the paper\"s novelty and significance, it lacks specific guidance on how the authors might address these concerns or what aspects of the assumptions are unclear. The reference to the external work is helpful, but the comment could be more beneficial if it provided more detailed feedback or suggestions for improvement. Overall, the comment is 3 as it points out a potential issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fewshot RC models considered in the paper, noting that they are not stateoftheart models. It asks a question about how the performance of these models compares to relation extraction/generation models in fewshot settings. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the fewshot RC models considered in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the performance of these models compared to relation extraction/generation models in fewshot settings. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the fewshot RC models considered in the paper are not stateoftheart models, referencing external sources. However, it does not provide specific details or comparisons to support this claim, such as which models are considered stateoftheart or how the performance of the models in question compares to those mentioned. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct their own analysis to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the fewshot RC models considered are not stateoftheart models. It raises a relevant question about how the performance of these models compares to relation extraction/generation models in fewshot settings. This feedback is 3 as it prompts the authors to consider the relevance and impact of their model selection, which could influence the paper\"s contribution and significance. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue or improve their model selection. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. However, it does not provide any guidance on how the authors should address this limitation or suggest ways to expand the results to include other network architectures. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the results only apply to shallow fullyconnected ReLU networks, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results section, noting that the results only apply to shallow fullyconnected ReLU networks. This is a relevant observation that could impact the generalizability and applicability of the results. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this limitation or expand their results to include other network architectures. While it points out an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the background knowledge and literature description. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as providing more background knowledge and literature description. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s organization could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the paper. Without concrete evidence or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s organization, suggesting that it could be improved by providing more background knowledge on the proposed method and bringing the description of related literature forward. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide detailed guidance on how to achieve these improvements. The authors are given a general direction but may need to infer the specific steps to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it identifies a potential gap in the comparison, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific models, \"PanopticFPN\" and \"Mask2Former,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these models in the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these models should be included in the comparison. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the paper could be expanded to include more comprehensive comparisons. However, the comment lacks depth and does not provide specific suggestions on how to incorporate these models into the comparison or what aspects to focus on. While it points out a potential weakness, it does not offer actionable guidance for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to provide results or observations regarding the use of sequential MCB versus a single MCT layer for the decision head. This is a clear and direct request, as it specifies exactly what the authors need to include in their discussion. The action is concrete, as it specifies the exact information that should be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB versus a single MCT layer for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation or results regarding the observed differences between the two approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB versus a single MCT layer for the decision head, noting that no results were shown. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is important or how it could be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of interest in the paper, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It points out that while the discussion is interesting, no results or observations are presented, prompting the authors to provide more details. This feedback is 3 as it highlights a gap in the paper that could be addressed with additional information or analysis. However, it lacks specific suggestions on what kind of results or observations would be beneficial, leaving the authors with a general direction but not detailed guidance on how to proceed. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should proofread the paper to fix language issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"the above of (7)\" and \"the above of Theorem 1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the language issues, such as \"we typically considers\" and \"two permutation,\" providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of comments on language usage, such as \"we typically considers\" and \"two permutation,\" without any subjective claims or opinions. It does not present any arguments or evidence to support the need for changes or improvements in the language. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific language issues in the paper, such as \"we typically considers\" and \"two permutation,\" and requests that the authors proofread the paper to fix all language problems. While this feedback is clear and actionable, it does not provide detailed guidance on how to address these language issues or suggest specific improvements. The comment could be more helpful if it offered examples of better phrasing or provided more detailed feedback on grammar and usage. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete steps on how to address them. The authors can infer that they need to consider these questions, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of 20 distribution sets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the number of distribution sets for each class can be controlled and what the implications would be if only a few distribution sets are selected. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the choice of 20 distribution sets and suggests that the authors might need to control the number of distribution sets for each class. It also asks about the implications of selecting only a few distribution sets. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the choice of 20 distribution sets is problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of 20 distribution sets and questions whether the authors can control the number of distribution sets for each class. It also inquires about the implications of selecting only a few distribution sets. This feedback is 3 as it prompts the authors to consider the potential limitations and consequences of their choice. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending alternative approaches or discussing potential consequences. While it points out a relevant area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation or expand the scope of their framework. The action is implicit and somewhat vague, as the authors need to infer that they should consider broadening the scope of their framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluative framework, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limited scope of the framework, which is restricted to only three QuestionAnswering tasks and two language models, and raises concerns about its broader applicability. The comment suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluative framework is limited in scope, restricted to only three QuestionAnswering tasks and two language models, which raises concerns about its broader applicability. The reviewer suggests that the method may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. However, the comment lacks specific examples or references to substantiate these claims, making it 3. The authors would need to infer the potential applicability of the framework to other tasks and models, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three QuestionAnswering tasks and two language models. This observation raises concerns about the method\"s broader applicability, as it may not generalize to other reasoning or generation tasks or more advanced models like Vicuna or Alpaca. The comment highlights a potential weakness in the framework\"s applicability, which is important for the authors to address. However, it does not provide specific suggestions or guidance on how to expand the scope of the framework or what additional tasks or models should be considered. While it points out a relevant issue, the comment could be more helpful with actionable advice. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also highlights the issue with using obsolete language models, which adds context and guidance for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"perplexity experiments\" and the specific language models used, such as ngram HMM and RNN, which are considered obsolete. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the perplexity experiments are carried out on obsolete language models, specifically ngram HMM and RNN, which are not commonly used nowadays. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models to align the paper with current NLP trends. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to current NLP trends or the relevance of transformerbased models. The authors would need to make an effort to understand and address the suggestion, which justifies a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the perplexity experiments, noting that they are carried out on obsolete language models (ngram HMM, RNN) that are no longer commonly used in NLP. The reviewer suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more current and relevant in NLP trends. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the relevance and impact of the paper. By addressing this point, the authors can better align their work with current research trends and demonstrate the applicability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions the need to cite the result in Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or citing relevant work to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplified selfattention model\" considered in the theoretical analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The mention of Kaplan et al. 2020 provides additional context and guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests the need for more empirical experiments or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The reviewer references Kaplan et al. 2020 as a potential source for empirical results. However, the comment lacks specific examples or detailed reasoning to support why the current experiments are insufficient or how additional experiments would address the issue. The reference to Kaplan et al. 2020 provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental setup, noting that the experiments are insufficient to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that more empirical experiments or toy experiments are needed to address this gap. Additionally, it references the result in Kaplan et al. 2020 as a potential source for empirical evidence. This feedback is clear and actionable, providing the authors with a specific direction for improving their experimental design and substantiating their claims. However, it could be more helpful if it offered suggestions on how to design these additional experiments or what specific aspects of the theoretical analysis need validation. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a direction for addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify or address this issue, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion on the misestimation of mu, which is a specific part of the paper. However, it does not explicitly mention which section or part of the discussion this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the estimation of mu as the proportion of missing observations, which is a clear and actionable point. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the discussion on the misestimation of mu, noting that it is the proportion of missing observations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the discussion is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the discussion on the misestimation of mu, noting that it is the proportion of missing observations, making it unclear how it can be estimated. This is a relevant point that could lead to confusion in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the discussion. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion to randomly sample a matrix M^0 within a certain distance range (0.01:0.01:0.1) from M^* as initialization and report the performance accordingly. This feedback is explicit and provides concrete guidance on how to implement the suggested approach. The authors know exactly what steps to take to address the issue of sensitivity to initialization. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sensitivity to initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, with a detailed explanation of how to implement this approach. This includes randomly sampling a matrix M^0 within a specific distance range and reporting performance accordingly. The comment is specific in detailing what needs to be addressed and how to implement the suggested approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*. It provides a specific suggestion for how to implement this approach, including randomly sampling a matrix M^0 within a certain distance range and reporting performance accordingly. This suggestion is based on logical reasoning and common knowledge about the relationship between initialization and performance. However, the comment lacks specific examples or references to support the claim that the mean error and variance increase as the quality of initialization decreases. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for addressing the issue of sensitivity to initialization. It suggests presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, which is a clear and concrete approach. The comment also specifies the distance range to be considered (0.01:0.01:0.1) and provides a rationale for the expected increase in mean error and variance as the quality of initialization decreases. This feedback is 5 as it offers a clear and detailed direction for the authors to improve their draft, ensuring that the sensitivity to initialization is adequately addressed. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This provides a clear and direct action for the authors to take, which is to remove the absolute value operation. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the unnecessary use of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is unnecessary because tensor entries are real numbers. This is a factual observation about the mathematical definition of the Frobenius norm, which does not require an opinion or subjective judgment. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of the Frobenius norm in line 77, noting that the absolute value operation is unnecessary because tensor entries are real numbers. This is a clear and actionable point that can help the authors improve the clarity and accuracy of their draft. By pointing out this oversight, the comment provides the authors with a concrete step to take in revising their manuscript. However, the comment could be more helpful if it offered suggestions on how to better explain or justify the use of the absolute value operation in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds by using ensemble methods, as demonstrated in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide highprobability bounds by using ensemble methods, as demonstrated in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the use of ensemble methods and the inclusion of robustness measures, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide highprobability bounds by using ensemble methods, as demonstrated in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to ensemble methods or existing studies that have successfully used these methods. This makes the claim 3, as the authors would need to infer the specifics of how to implement these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It recommends adding highprobability bounds by using ensemble methods, as demonstrated in the experiments. This is a valuable suggestion that could enhance the robustness and credibility of the results. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is specific and constructive, providing the authors with a clear path to improve their draft. However, the comment could be more helpful if it explained why ensemble methods are particularly effective or how they could be integrated into the existing experimental setup. Overall, the comment is 4 as it offers actionable guidance for enhancing the paper\"s robustness and credibility."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for the work is good but that the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so or provide specific guidance on how to implement these evaluations. The action is implicit and somewhat vague, as the authors need to infer the need for these additional evaluations and determine how to incorporate them into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for the work is good but the results are less impressive, and it recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specific areas for improvement, it lacks full grounding as it does not explicitly mention where these aspects should be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for the work is good but the results are less impressive. It also recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. However, the comment lacks specific examples or detailed reasoning to support why the results are less impressive or how these additional aspects should be evaluated. Without specific examples or references, the claim is 3, as it provides a general direction for improvement but lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, suggesting that they are less impressive despite a good motivation. It recommends evaluating the results from additional aspects, such as latency, memory consumption, and network size. While the comment provides some insight into areas that could be improved, it lacks specific guidance on how to address these issues or what specific metrics should be considered. The feedback is 3 as it points out a potential weakness but does not offer detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might incorporate diversity into their model or what specific changes could be made to improve the paper. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s motivation for diversity, specifically mentioning that the model does not enforce diversity explicitly. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the model\"s lack of diversity enforcement, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model. The reviewer expresses disappointment that the diversity term is not present in the model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s motivation for diversity, noting that the model does not enforce diversity explicitly. This is a critical point as it undermines the paper\"s claims about promoting diversity. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their model to enforce diversity. Without actionable feedback or detailed advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on how the authors should address this issue or what specific experiments should be included. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments should be included in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these experiments might fit, the comment lacks full grounding. It is specific in identifying the missing experiments but does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence affects the paper\"s contribution. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is 3 as it highlights a potential gap in the experimental setup, which the authors should address to strengthen their work. However, the comment lacks depth and does not provide suggestions on how to incorporate these experiments or what specific aspects of the paper might benefit from their inclusion. While it directs the authors\" attention to a potential area for improvement, it does not offer detailed guidance or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The suggestion to use DinoV2 Frechet Distances is specific and provides a concrete detail for the authors to implement, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simplistic Inception network\" and \"FIDs,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of DinoV2 Frechet Distances for comparisons in addition to the widely used FID metric. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are \"clear flaws associated with FIDs and the simplistic Inception network,\" but it does not provide specific examples or references to support this claim. The suggestion to use DinoV2 Frechet Distances is made without further explanation or justification, leaving the authors without a clear understanding of why this alternative is preferred or how it would address the issues mentioned. The lack of detailed reasoning or evidence makes the claim 1, as it does not provide sufficient support for the authors to understand and address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of FIDs and the simplistic Inception network, noting that there are clear flaws associated with these methods. It provides a clear and actionable suggestion by recommending the use of DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is valuable as it directs the authors to consider a more robust evaluation method, which could improve the accuracy and reliability of their results. However, the comment could be more helpful if it explained why DinoV2 Frechet Distances are preferred over FIDs or provided additional context on the flaws associated with FIDs. Overall, the comment is 4 as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the novelty of the paper and asks for clarification on how it differs from a specific reference. While it implies that the authors should provide a comparison with the reference, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed comparison or explanation of the novelty. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not specify which part of the paper should address this issue, such as the introduction, methodology, or results sections. The authors can infer that it relates to the paper\"s novelty and comparison with the reference, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its request for clarification on the novelty. This aligns with a score of 3.", "verifiability_rationale": "The review point questions the novelty of the paper and seeks clarification on how it differs from a specific reference. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the novelty is incremental. Without such information, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the novelty of the paper and seeks clarification on how it differs from a specific reference. While it identifies a potential issue with the paper\"s novelty, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the paper\"s originality. The comment lacks actionable feedback or detailed insights into what aspects of the paper could be improved or expanded upon. As a result, it offers limited value to the authors in terms of enhancing the draft. Therefore, the comment is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them without a clear path forward. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"CUB and SOP datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the reported ablation studies, where the complete loss function performed worse than those with missing terms. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the validity of the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy in the reported ablation studies, specifically noting that the complete loss function performed worse than those with missing terms on the CUB and SOP datasets. This observation raises a valid concern about the validity of the results and prompts the authors to question why this might be the case. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions that this would allow for inspection of the longrange inference capacity of the model. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. The action is explicit and concrete, as it clearly specifies what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, which simulates irregularity in neural/behavioral data. It also mentions the need to inspect the longrange inference capacity of the model. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the need for the experiment. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the longrange inference capacity of the model. The reviewer provides a logical reasoning for why this experiment would be beneficial, noting that it would simulate realworld scenarios where keypoint detection may fail. However, the comment lacks specific examples or references to similar experiments in the literature, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by suggesting an experiment where the image is occluded to simulate irregularity in neural/behavioral data. This experiment would allow the authors to inspect the longrange inference capacity of the model, which is a valuable addition to the study. The reviewer explicitly states that these experiments should be included in the final version unless the authors can provide a convincing reason not to. This feedback is 5 as it offers a specific and meaningful enhancement to the paper, providing clear guidance for the authors to improve their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not specify which alternative visualization should be used or how to implement the change. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which implies negative rates, and suggests using a second yaxis or another visualization that is more physically accurate. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why Figure 6C is awkward or why the current visualization is inaccurate. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not the case. The reviewer suggests using a second yaxis or another visualization that is more physically accurate. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the accuracy and clarity of their visual representation. However, the comment could be more helpful if it included additional context or examples of alternative visualizations that could be used. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should test inverse triples in other embedding models besides CP. While it implies that the authors should conduct additional experiments, it does not provide specific guidance on which models to test or how to implement these tests. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should test inverse triples in other embedding models besides CP, but it does not specify which part of the paper this suggestion pertains to. The authors can infer that it relates to the experimental section, but without explicit references to sections or specific experiments, the comment lacks full grounding. It is specific in suggesting the need for additional testing, but without detailed guidance on which models to test or how to implement these tests, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that introducing inverse triples might be useful in other embedding models besides CP, but it does not provide any evidence or reasoning to support this claim. The comment lacks specific examples or references to other models where this approach might be beneficial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors test inverse triples in other embedding models besides CP. While it highlights a potential contribution, it lacks specific guidance or examples of other models to test, making it 3. The authors are given a direction for further exploration but are not provided with detailed instructions or examples on how to implement this suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. It also implies that technical details are not necessary for the abstract. While the comment provides a clear action\u2014to clarify the statement and simplify the abstract\u2014it does not offer specific guidance on how to achieve this clarity or what aspects of the statement are unclear. The authors are left to infer the necessary changes, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement in the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement regarding the lowrank feature subspace, a small number of attacked samples, and other mild assumptions. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technical details are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that it should be revised to be more highlevel. The reviewer provides a specific example of the technicality in question, \"with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions,\" which is not explained in the abstract. However, the comment lacks detailed reasoning or examples to support why this technicality is unnecessary or how it affects the clarity of the abstract. While the claim is 3, it could be strengthened with additional justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, pointing out that the statement regarding a lowrank feature subspace, a small number of attacked samples, and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technical details are not necessary. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a more concise and simplified abstract. However, the comment could be more helpful if it offered specific guidance on how to achieve this clarity or what aspects of the statement are confusing. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific guidance or suggestions on how to achieve this improvement. The authors are left to infer that they need to make changes to the algorithm, but without concrete steps or examples, they may struggle to determine what exactly is required. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that there is room to improve the complexity of Algorithm 2, but it does not specify which part of the paper discusses Algorithm 2 or where it is located. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of Algorithm 2 need improvement or how to achieve this improvement. Without clear guidance or examples, the authors may struggle to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there is room to improve the complexity of Algorithm 2. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that there is room to improve the complexity of Algorithm 2, which is a valuable observation. However, it lacks specificity and does not provide any guidance or suggestions on how to achieve this improvement. Without actionable advice or examples, the authors are left without a clear path to follow, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as relevant. However, the comment does not provide explicit guidance on which modalities to include or how to present these results. While it suggests a direction for improvement, the lack of concrete steps or detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, specifically mentioning languagerelated tasks. It also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment does not specify which part of the paper should include these results or how they should be presented. While the authors might have an idea of where to integrate these suggestions, the lack of explicit guidance makes it weakly grounded. The comment is specific in suggesting the inclusion of results in other modalities and the potential relevance of OOD performance, but it lacks detailed guidance on implementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. The comment also mentions that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. However, the comment lacks specific examples or references to support the claim that OOD performance is more important for languagerelated tasks. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, specifically mentioning languagerelated tasks. It also points out that people might care more about OOD performance for languagerelated tasks, implying that expected test loss might not be as meaningful. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of results in other modalities. However, the comment lacks specific guidance on how to implement this suggestion or what specific modalities to consider. While it provides a direction for improvement, the lack of detailed instructions or examples limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. It highlights the importance of considering how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment implies that the authors should provide more detailed justification for their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more justification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fewshot situation for graph link prediction,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method does not consider how to effectively use \"fewshot\" and how to ensure the trained model can generalize well to new tasks with 0/few training steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified by explaining how the proposed method leverages the concept of \"fewshot\" in graph link prediction. The reviewer suggests that the paper defines and creates a fewshot situation but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. While the comment identifies a potential gap in the paper, it lacks specific examples or references to support the claim that the method does not effectively use \"fewshot.\" This makes the claim 3, as the authors would need to further develop the reasoning to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the motivation of the work, specifically in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to ensure the trained model can generalize well to new tasks with 0/few training steps. This feedback is valuable as it highlights a gap in the paper that the authors need to address to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to effectively use \"fewshot\" or how to ensure generalizability. Overall, the comment is 4 as it directs the authors to a critical area needing improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not provide explicit guidance on how the authors should address this critique or improve their approach. It lacks actionable details, such as recommending specific ways to enhance the novelty or suggesting alternative approaches. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. However, the comment does not specify which part of the paper discusses the use of GP, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where GP is discussed, the comment lacks full grounding. It is specific in detailing the critique of the approach, but without explicit references to the paper sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of Gaussian Processes (GP) is straightforward and naive, suggesting that the approach is not novel. The reviewer supports this claim by referencing the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. This reference provides a basis for the claim, but it does not offer detailed reasoning or examples to fully substantiate the critique. The authors might need to explore the literature further to understand the specific aspects of the critique. Therefore, the comment is 3, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment critiques the use of Gaussian Processes (GP) as straightforward and naive, suggesting that the approach is not novel. It references the community\"s work on dynamical modeling, specifically mentioning the Gaussian Process Dynamical Model in NIPs from 2005. While the comment identifies a potential weakness in the paper\"s contribution, it lacks specific guidance on how the authors might address this critique or improve their approach. It does not provide actionable suggestions or examples of how the authors might enhance the novelty or innovation of their work. As a result, the comment is 3, as it points out a potential issue but does not offer detailed feedback for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the statement in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. It points out that this claim is not supported by the authors\" experience, as evidenced by the training of 1500dimensional LSTMs on PTB. The reviewer also asks about the application of dropout to both embeddings and hidden states. While the comment identifies a specific issue with the statement, it does not provide explicit guidance on how to address it or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the claim and provide evidence or clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplemental section D.4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that smaller architectures are necessary for LM compared to GAN models, suggesting that the baseline models are not properly regularized. The reviewer also asks about the application of dropout to both embeddings and hidden states. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made in the supplemental section D.4 regarding the need for smaller architectures in LM compared to GAN models to avoid overfitting. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, suggesting that the baseline models are not properly regularized. This provides a logical and 3 argument against the claim, as it challenges the basis of the statement. However, the comment could be strengthened by providing more detailed evidence or references to support the counterexample. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in the supplemental section D.4 that is questionable, suggesting that the statement about smaller architectures being necessary for LM compared to GAN models is not supported by the authors\" experience. The reviewer provides a counterexample by citing the training of 1500dimensional LSTMs on PTB, which challenges the claim that baseline models are not properly regularized. Additionally, the comment asks about the application of dropout to both embeddings and hidden states, which could be a relevant area for clarification or discussion. While the comment identifies a potential weakness in the paper, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their analysis. Therefore, the comment is 3, as it points out a potential problem but does not provide comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the ablations mentioned in previous sections are difficult to locate in the following content, suggesting that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to locate. The action is implicit and vague, as the authors are left to infer that they need to improve the clarity of the writing, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"previous sections\" and \"the following contents,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that some ablations are difficult to locate in the following content, suggesting that the writing could be improved in this part. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following content, suggesting that the writing could be improved in this part. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without specific examples or references, the claim lacks verifiability, making it challenging for the authors to effectively improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some ablations mentioned in previous sections are difficult to locate in the following content. It suggests that the writing could be improved in this part, providing a clear and actionable feedback point. However, the comment lacks depth and does not offer specific suggestions on how to improve the clarity or organization of the content. While it highlights an area for improvement, it could be more helpful if it provided more detailed guidance on how to address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty of the online algorithm and robustness, which should be integrated into the main paper. However, the comment does not provide specific guidance on how to improve the differential privacy application or what aspects need more clarity. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to address the issues. As a result, the comment is 3, as it identifies areas for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also mentions the online algorithm and robustness as being interesting and novel, and suggests that the experimental results in the appendix would be better in the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application, making it weakly grounded. The comment is specific in its critique of the differential privacy application and the suggestion to integrate the online algorithm and robustness into the main paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. However, the comment does not provide specific reasoning or examples to support this claim. It mentions the online algorithm and robustness as being interesting and novel, but this does not directly address the issue of the differential privacy application being \"halfbaked.\" The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the differential privacy application, suggesting that it is currently \"halfbaked\" and encourages the authors to think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, which should be integrated into the main paper. While the comment provides some insight into areas that need improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but are not provided with actionable steps or detailed feedback to enhance the draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their work. There is no explicit or implicit action for the authors to take, such as suggesting ways to enhance the contribution or providing examples of how to differentiate the two approaches. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, but it does not specify which part of the paper this comparison is made in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its claim about the incremental nature of the contribution. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this comparison and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthough, suggesting that the former is incremental. However, it does not provide any context or explanation for this comparison, nor does it offer suggestions or guidance on how the authors might address this issue or improve their work. Without additional information or actionable feedback, the comment lacks utility for the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the methodology need to be adjusted. The action is implied and somewhat vague, as the authors need to infer that they should consider using robotic manipulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to use robotic manipulation, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed methodology may not be specific to bimanual manipulation and recommends using robotic manipulation instead. However, the comment does not provide any supporting evidence, reasoning, or references to justify why bimanual manipulation is more appropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential weakness in the paper by suggesting that the proposed methodology may not be specific to bimanual manipulation. It recommends using robotic manipulation instead, which could be more appropriate. This feedback is 3 as it points out a potential area for improvement, but it lacks specific guidance on how to implement this change or what aspects of the methodology need to be adjusted. The authors are given a direction to consider, but the comment could be more actionable with additional details. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include the METEOR results, which are reported in recent works. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is specific and provides concrete guidance on how to implement the action, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the inclusion of METEOR results, which is a specific aspect of the paper. However, it does not specify which part of the paper should include these results, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact location of the METEOR results in the paper. The comment is specific in its request for the inclusion of METEOR results, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include the METEOR results, which are reported in recent works. However, the comment does not provide any supporting evidence, references, or reasoning to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the METEOR results, which are reported in recent works. This is a clear and actionable suggestion that can help improve the paper by providing additional context and comparisons. However, the comment lacks depth and does not explain why the inclusion of these results is important or how they might enhance the paper. While it identifies a specific area for improvement, it could be more helpful if it provided more detailed guidance or justification for the inclusion of these results. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting ways to improve the comparability of Geffect values or recommending specific analyses to be conducted. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of Geffect values across various unlearning objectives and approaches. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the comparability of Geffect values across various unlearning objectives and approaches. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the comparability of Geffect values across various unlearning objectives and approaches. It points out that studying Geffects of each learning objective in isolation raises questions about the validity of these comparisons. This feedback is 3 as it highlights an area that the authors should consider addressing, but it lacks specific suggestions or guidance on how to improve the comparability of Geffect values. The comment could be more helpful if it provided examples or additional analysis to support the claim or offered suggestions on how to address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a clear direction for the authors to address the issue with UNIFORM in the 1shot setting. The explicit request for clarification and the concrete suggestion to address the issue make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"tables\" and the \"1shot setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the advantage of UNIFORM over other procedures and the need for a theory to explain its effectiveness in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting. The comment also praises the clarity and welldesigned experiments, providing a positive assessment of the paper. However, the claim about the inconsistency in the advantage of UNIFORM is not fully substantiated by specific examples or detailed reasoning, making it 3. The authors would need to further explore the tables and data to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables. It suggests that the authors should clarify why the method is not as effective in the 1shot setting, which is a critical area for improvement. The comment also praises the clarity and welldesigned experiments, providing positive feedback that can help the authors improve their draft. However, the comment could be more helpful by suggesting specific ways to address the issue with UNIFORM in the 1shot setting or providing examples of how other methods have successfully addressed similar challenges. Overall, the comment is 4 as it highlights a critical area for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, and if there is any existing linguistic theory that could explain it. It also recommends adding this information to make the paper stronger. While the comment implies that the authors should explore this topic, it does not provide specific guidance on how to integrate this information into the paper or what specific linguistic theories to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This provides clear guidance on what the authors need to consider and explore in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. The comment implies that adding this information would strengthen the paper. However, it does not provide specific examples or references to existing linguistic theories or studies that could support this claim. Without such evidence or detailed reasoning, the claim is 3, as it requires the authors to make a significant effort to explore and substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a potential area for improvement by suggesting that the authors consider the reason why information value is a stronger predictor for dialogue and whether there is any existing linguistic theory that could explain it. This feedback is clear and actionable, as it prompts the authors to explore a specific aspect of their work that could enhance its theoretical foundation and depth. However, the comment could be more helpful if it provided specific suggestions on how to integrate this information or what linguistic theories to consider. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived lack of discussion on the potential benefits of using AutoML approaches beyond improving raw performance, specifically mentioning the extraction of hints for future network architecture design. It explicitly suggests that the authors should spend more time discussing these aspects, such as the biggest takeaways from the found architecture. This feedback provides a clear and concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AutoML approaches and the potential benefits beyond raw performance, such as extracting hints for future network architecture design. It also specifies the issue by pointing out that the authors did not spend much time discussing these aspects, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main reason for using AutoML approaches is not just improving raw performance but also extracting hints for future network architecture design. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper does not adequately discuss the potential benefits of using AutoML approaches beyond improving raw performance. It suggests that the authors should spend more time discussing the extraction of hints for future network architecture design, which could be a valuable contribution to the field. While the comment highlights an important aspect that could enhance the paper, it lacks specific suggestions or guidance on how to address this issue. The authors are given a direction but not detailed steps on how to implement the feedback. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is an explicit observation that the authors can directly address by providing the definition in the appropriate section. The comment is clear and concrete, as it specifies the exact issue and suggests a straightforward action for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that T_a(t) is used in Section 3.1 but only defined in Section 4. This is a factual observation that does not require any subjective judgment or opinion. It is a statement of fact that can be verified by the authors themselves, as it is directly observable from the paper. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper where T_a(t) is used in Section 3.1 but only defined in Section 4. This is a clear and actionable observation that the authors can address to improve the consistency and clarity of their work. By pointing out this inconsistency, the comment provides the authors with a specific area to focus on for revision. However, the comment could be more helpful if it offered suggestions on how to resolve this issue, such as suggesting a way to integrate the definition into the earlier section or providing additional context for the use of T_a(t). Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While the action is implicit, it is clear that the authors should aim to make their introduction more concise and include empirical results. However, the comment does not provide specific guidance on how to achieve this concision or what specific empirical results should be included. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, it does not specify which part of the introduction is too long or where empirical results should be included. The authors can infer that the introduction and empirical results sections might be the focus, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. However, the comment does not provide any specific examples, reasoning, or references to support why the current introduction is too long or how empirical results could enhance it. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and include empirical results. While it identifies a potential area for improvement, it lacks specific guidance on how to achieve this concision or what empirical results should be included. The comment provides a general direction for improvement but does not offer actionable steps or detailed suggestions. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusion regarding the empirical analysis in Figure 3 and requests additional clarification on the adjustments made to the input series and forecasting target based on the Frequency Stability score. It also asks for an explanation of why these adjustments enhance the model\"s performance. While the comment provides a clear direction for the authors to provide additional clarification and explanation, it does not specify how to implement these changes or what specific details should be included. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be addressed but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the confusion regarding the empirical analysis and the adjustments made to the input series and forecasting target based on the Frequency Stability score. The comment also asks for clarification on why these adjustments enhance the model\"s performance and provides a reference to a related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning the adjustments made to the input series and forecasting target based on the Frequency Stability score. The reviewer requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also references a specific work by Liu et al. (2022) to provide context. While the comment identifies a potential issue and seeks clarification, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the empirical analysis presented in Figure 3, noting that the adjustments to the input series and forecasting target based on the Frequency Stability score are not clearly explained. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. The comment also points out that Equations (9) and (10) have large spacing from the preceding text, which could be improved. While the comment provides clear guidance on what needs to be clarified and improved, it could be more helpful if it offered specific suggestions on how to present this information or what additional details should be included. Overall, the comment is 3 as it directs the authors to specific areas needing clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the recent related work, CoCoOp, should be compared in the experiments. It provides a clear and direct action for the authors to take, specifying that they should include a comparison with CoCoOp in their experiments. The comment is specific and provides concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the related work \"CoCoOp\" and its comparison with CoCoOp in the experiments. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison with CoCoOp in the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work, CoCoOp, should be compared in the experiments. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the recent related work CoCoOp, which is a CVPR\"22 work, should be compared in the experiments. This is a clear and actionable suggestion that could significantly enhance the paper\"s comprehensiveness and relevance. By including a comparison with CoCoOp, the authors would demonstrate a more thorough understanding of the stateoftheart in their field. However, the comment could be more helpful if it provided additional context or rationale for why this comparison is important or how it might impact the paper\"s conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation and manual check, demonstration selection with ground truth scores, and automatic scoring along with where model training is used to optimize the selection modules. While the comment provides a clear direction for improvement, it does not specify how to enhance the figure or what specific elements should be added or changed. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved, including suggestions for enhancing the figure to show the processing pipeline more clearly. The comment details the elements that should be included, such as prompt generation, manual check, demonstration selection, ground truth scores, and model training optimization. This level of detail provides a clear direction for improvement, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Fig. 1 could be improved by showing the processing pipeline more clearly, including prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring along with model training optimization. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these elements are necessary or how they would enhance the figure. Without additional context or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is categorized as 3, as it provides a general direction for improvement but lacks the necessary detail to be 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to improve the clarity and comprehensiveness of Fig. 1. It suggests adding elements such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring along with model training optimization to enhance the figure. This detailed guidance helps the authors understand what specific improvements are needed to better illustrate the processing pipeline and make the figure more informative. However, the comment could be more helpful if it provided examples or references to similar figures or studies that effectively showcase these elements. Overall, the comment is 4 as it offers clear and actionable suggestions for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the need for testing on more complex games, but it is somewhat vague in detailing how to implement this additional testing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing on more complex games, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems, specifically mentioning the issue of input size for value and policy functions. However, the comment lacks specific examples or references to support the claim that these complex problems are necessary for testing ReBeL. Without detailed evidence or reasoning, the claim remains 3, as the authors may find it challenging to fully understand and address the issue without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games and did not test ReBeL on more complex problems. It suggests that the author should consider testing ReBeL on games with larger depth to address the issue of input size for value and policy functions. This feedback is 3 as it points out a potential gap in the experimental setup and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples of complex games or detailed guidance on how to implement the additional testing. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to remove abbreviations like \"MoCo\" from section headers, as they might not be familiar to readers. This is a clear and direct action that the authors can take to improve the clarity of their draft. The comment provides concrete guidance on what to remove, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of abbreviations like \"MoCo\" in section headers. This provides clear guidance on what the authors need to change to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that abbreviations like \"MoCo\" should not appear in section headers because readers might not know what they mean. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the reader\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper. By pointing out that abbreviations like \"MoCo\" should not appear in section headers, the reviewer highlights a potential source of confusion for readers who might not be familiar with the term. This feedback is clear and direct, offering a straightforward way for the authors to enhance the accessibility of their work. However, the comment could be more helpful if it provided additional context or examples of how this change would improve the clarity of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or make the analysis more novel. There is no explicit or implicit action for the authors to take, such as suggesting alternative analyses or explaining the novelty of their approach. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are unclear or where the analysis is standard. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need clarification or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide specific examples or detailed feedback on how the authors could clarify the technical contribution or make the analysis more novel. Without actionable suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not provide specific guidance on what kind of evidence or arguments would be sufficient or how the authors should present them. The action is implicit and somewhat vague, as the authors can infer that they need to provide more substantial evidence or arguments but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, and it implies that more substantial evidence or arguments are needed to establish this as a significant contribution. However, it does not specify which part of the paper discusses this contribution or where the authors should provide additional evidence or arguments. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its suggestion for improvement but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s primary contribution is an incremental advancement in efficiency over the TACTiS approach, suggesting that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s contribution, suggesting that the primary contribution appears to be an incremental advancement in efficiency over the TACTiS approach. It acknowledges the need for more substantial evidence or arguments to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on how the authors might strengthen their argument or what kind of evidence or arguments would be sufficient. While it points out an area for improvement, it lacks actionable advice or detailed suggestions, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities is incremental and does not provide a clear direction for improvement. However, the comment lacks explicit guidance on how the authors could address these concerns or what specific changes could be made to enhance the novelty or impact of their work. Without concrete suggestions or actionable steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, it does not specify which datasets or parts of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the paper are considered incremental or how the authors could address these concerns. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited due to its focus on a topic that has been explored by many previous works. It implies that adding topic entities seems incremental and does not provide a clear direction for improvement. However, the comment lacks specific suggestions or actionable feedback on how the authors could address these concerns or enhance the novelty of their work. Without detailed guidance or constructive advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a discussion on this topic, but it does not specify what aspects of the discussion should be included or how it should be structured. As a result, the action is implicit and somewhat vague, leaving the authors with a general idea of what needs to be done but without concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO, allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspects of the theoretical guarantee are missing or how the authors should address this issue. The comment is specific in identifying the lack of discussion but lacks detailed guidance on how to improve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks discussion, specifically the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a relevant point that could enhance the paper\"s theoretical foundation and provide additional insights to readers. However, the comment does not offer suggestions or guidance on how the authors might address this gap in the discussion. While it highlights an important area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate quantitative measures or what specific metrics should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to include quantitative measures but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a quantitative measure to evaluate the generated VCEs, and notes that evaluation is mainly performed with visual inspection. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative measure to evaluate the generated VCEs, noting that evaluation is mainly performed with visual inspection. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by noting the lack of quantitative measures to evaluate the generated VCEs. It highlights that the evaluation is mainly performed with visual inspection, which is a relevant point for the authors to consider. However, the comment does not provide detailed guidance on how to incorporate quantitative measures or what specific metrics should be used. While it points out a weakness, it lacks actionable suggestions or examples that would help the authors address the issue effectively. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method only provides marginal improvements over baselines, with most improvements within the error bar range. It also notes that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the performance of their method. The action is implicit and vague, as the authors are left to infer that they need to improve the performance of their method, but without specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method compared to baselines, suggesting that the improvements are marginal and within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, indicating that the performance differences are not significant. However, the comment does not specify which part of the paper discusses these claims or where the performance comparisons are presented, making it weakly grounded. The comment is specific in its critique of the performance improvements and the error range, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method provides only marginal improvements over baselines, with most improvements within the error bar range. The reviewer questions the significance of these improvements, suggesting that the error range is high, indicating that the performance differences between some methods are not very significant. This claim is 3 as it provides a logical reasoning for questioning the significance of the improvements, but it lacks specific examples or detailed analysis to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that the method provides only marginal improvements over baselines, with most improvements within the error bar range. It questions the significance of these improvements, suggesting that the error range is high, indicating that the performance differences between some methods are not very significant. This feedback is 3 as it points out a potential weakness in the paper\"s claims about performance improvements. However, it lacks specific suggestions or guidance on how the authors might address this issue or improve the presentation of their results. While it highlights an area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights issues with the generated videos, specifically noting significant artifacts and questioning the action recognition performance compared to stateoftheart methods. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it guide the authors on how to address the issues or improve the quality of the videos. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the generated videos, specifically mentioning artifacts and the action recognition performance on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment does provide some specificity by questioning the action recognition performance compared to stateoftheart methods, which suggests that the authors should address this aspect. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generated videos have significant artifacts and questions the action recognition performance compared to stateoftheart methods. However, it does not provide specific examples or detailed reasoning to support these claims. The mention of artifacts and action recognition performance is vague, and the comparison to stateoftheart methods is not substantiated with specific references or detailed analysis. This lack of supporting evidence or detailed reasoning makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant issue with the generated videos, noting that they have significant artifacts and questioning the action recognition performance compared to stateoftheart methods. However, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address these issues or improve the quality of their videos. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the proposed evaluation set more diverse and representative than the previous method and how to select representative images. However, it does not provide any explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should provide more details or examples, but it does not specify what those details or examples should be. As a result, the action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of diversity and representation in the proposed evaluation set, specifically mentioning the need for clarity on how to make the set more diverse and representative than the previous method and how to select representative images. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where the evaluation set is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what needs to be clarified regarding diversity and representation, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed evaluation set is unclear in terms of diversity and representation, and how to select representative images. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without such evidence or justification, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed evaluation set, specifically the lack of clarity on how to make it more diverse and representative than the previous method and how to select representative images. This is an important point that could significantly impact the validity and applicability of the evaluation results. However, the comment does not provide specific suggestions or examples on how the authors might address these issues, such as recommending specific criteria or methods for selecting diverse and representative images. While it highlights a significant area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but does not fully support the authors in resolving it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also suggests providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These actions are clear and concrete, as they specify exactly what needs to be added to the paper. The authors know exactly how to apply these suggestions to improve the clarity and comprehensibility of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the background section, such as a brief overview of the original DPO algorithm, to clarify the RL context and distinguish the modifications proposed in the methods section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This claim is 3 as it logically suggests that a background section would enhance the clarity and comprehensibility of the paper. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This suggestion is valuable as it helps the authors establish the context and foundation for their work, making it easier for readers to understand the subsequent sections. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. This additional information would enhance the clarity and comprehensibility of the paper. Overall, the comment is 5 as it offers specific and constructive guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method to accommodate continuous language addition. The comment lacks actionable guidance or specific steps for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a potential limitation of the proposed method, specifically the issue of handling continuous addition of new languages due to the limited model capacity. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the method, but without explicit references to sections or details, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may encounter a limitation due to the limited model capacity when users continuously add new languages. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically that it may not be able to handle continuous addition of new languages due to its limited model capacity. This is a relevant concern that could impact the practicality and scalability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the method to accommodate continuous language addition. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). While it does not explicitly instruct the authors to make any changes or provide guidance on how to address this question, it implies that the authors should consider the relevance of the term in the context of their work. The action is implicit but clear, as the authors can infer that they need to evaluate the relevance of the term and potentially revise their work accordingly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), providing a clear direction for the authors to consider the context and implications of this term in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" to the work of DoshiVelez and Kim (2017), which is cited in the paper. This question prompts the authors to consider the context and implications of the term in their work, potentially leading to a deeper understanding and clarification of their ideas. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the paper. While it points out a relevant reference, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, it does not provide specific guidance on which datasets to include or how to conduct the additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment points out that the experiments are limited to MNIST and a single realworld dataset, but it does not specify which part of the paper this limitation is discussed in. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. However, it is specific in identifying the issue of limited datasets being used for experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it affects the validity or applicability of the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment points out a limitation in the experiments, specifically that they are limited to MNIST and a single realworld dataset. This feedback highlights an area where the authors could potentially expand their work to include a more diverse set of datasets, which could enhance the generalizability and applicability of their results. However, the comment does not provide specific suggestions or guidance on which datasets to include or how to conduct the additional experiments. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should provide more information about the parameters and their impact on efficiency, but it lacks concrete steps or examples to follow. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the number of parameters does not change when the kernel height/width remains the same, and it suggests that more details are expected regarding the efficiency improvements. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the number of parameters in the S2D structure and suggests that more details are expected regarding the efficiency improvements. The reviewer provides a logical reasoning by explaining that if the kernel height/width remains the same, the depth will increase, resulting in more parameters. However, the comment lacks specific examples or references to support the claim about the number of parameters or the efficiency improvements. While the reasoning is somewhat clear, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the S2D structure regarding the number of parameters and suggests that more details are expected regarding the efficiency improvements. It provides a logical explanation of how the depth of the structure could increase with the same kernel height/width, resulting in more parameters. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional details should be included. While it points out a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or differentiate their method from [10]. The comment lacks actionable details, such as recommending specific modifications or discussions to be included in the paper. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"approach in [10],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the approach in [10] cannot use the additional information, such as scoring causal predictions and interventional data. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the similarity between the proposed method and an existing approach in [10], suggesting that the latter could also incorporate scoring causal predictions and interventional data. It questions why [10] cannot use these side information. While the comment identifies a potential issue with the novelty of the proposed method, it lacks specific guidance or suggestions on how the authors might address this concern or differentiate their work from [10]. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results from the Atari game are limited to a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or improve the interpretability of their results. There is no guidance on whether they should expand the experiment to include more games or baselines, or how they might present their findings more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the Atari game result is limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the interpretation of the Atari game results, specifically noting that the results are limited to a single game and a single baseline. This feedback highlights an area where the authors could improve the clarity and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending additional experiments or analyses. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This implies that the model may not be incentivized to use fewer factors, leading to increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to implement a sparsity constraint. The authors are left to infer that they need to consider this aspect, but without concrete steps or examples, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"factorized model with an IBP prior,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of a sparsity constraint in the number of factors used by subsequent tasks, which is a critical aspect of the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to increased computation with more tasks. The comment provides a logical reasoning by explaining that a factorized model with an IBP prior would have a sparsity constraint, but the proposed method does not. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may need to infer the importance of the sparsity constraint and how it relates to the proposed method, which could be clarified with additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This is a critical observation, as it highlights a potential limitation in the model\"s ability to incentivize using fewer factors, which could lead to increased computation with more tasks. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or implement a sparsity constraint. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the authors should reiterate that the GPC\"s superior performance is due to the bandit feedback and not the form of the cost function. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be addressed in the paper. The comment is 5 as it offers a specific guidance on how to improve the draft by addressing the issue of comparison with the benchmark.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the authors\" commentary on the GPC (benchmark) and BPC (their method), suggesting that the GPC is performing better due to bandit feedback and not the form of the cost function. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study does not favor the authors, specifically noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). The reviewer suggests that this is due to the bandit feedback and not the form of the cost function. The comment provides a logical reasoning by pointing out the potential cause of the GPC\"s superior performance. However, it lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable explanation but could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) is performing better than BPC (their method). It suggests that the GPC\"s superior performance is due to bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to address the issue by reiterating the reasons behind the GPC\"s performance. By doing so, the authors can improve the clarity and completeness of their analysis. However, the comment could be more helpful if it offered additional guidance on how to present this information or what specific aspects of the analysis should be emphasized. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep at the time, to provide context. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim. While it implies that the authors should provide more detailed information or examples, it lacks concrete guidance on what specific aspects to address or how to present the information. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks.\" It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting that quantifying and clarifying the claim could be beneficial. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be helpful. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but it does not offer specific examples or detailed reasoning to fully substantiate the claim. The comment is 3, as it provides a logical connection to the original work but lacks detailed evidence or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" could be beneficial. It references the use of ReLUs in the AlexNet paper, which was considered deep and used convolution with pooling rather than ReLUs for the convolutional layers. This reference provides some context for the claim, but the comment lacks specific guidance on how to quantify or clarify the claim. While it points out a potential area for improvement, it does not offer detailed suggestions or examples on how to address the issue. Therefore, the comment is 3, as it identifies a potential weakness but lacks depth and actionable advice for the authors to improve their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It implies that the authors should provide more information about the calculation method or clarify the discrepancy between the reported perplexities and the better BLEU scores. While the comment does not explicitly instruct the authors to provide this information, it clearly points out a potential issue that needs to be addressed. Therefore, the comment is 4, as it provides a clear direction for the authors to improve their draft by explaining the perplexity calculation method or addressing the discrepancy.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and suggests that this high perplexity contradicts better BLEU scores. The comment further asks how the perplexity was calculated, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reported perplexities in Figure 1, suggesting that they are high and contradict better BLEU scores. However, it does not provide any specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reported perplexities in Figure 1, which are over 30, and questions how they were calculated. It suggests that this high perplexity contradicts better BLEU scores, which is an important observation that could impact the interpretation of the results. The comment is 3 as it prompts the authors to clarify the calculation method and potentially address the discrepancy between the reported perplexities and the BLEU scores. However, it could be more helpful if it provided specific suggestions on how to address this issue or explained why the perplexity is considered high. Overall, the comment offers a valuable point for improvement but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the evaluation should include experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, specifying exactly what additional experiments are needed to improve the draft. The comment is specific and concrete, giving the authors a clear path to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for additional experiments, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation should include experiments on distributed deployment and a larger model. However, it does not provide any supporting evidence, reasoning, or examples to justify why these experiments are necessary or how they would improve the evaluation. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation should include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies a potential area for improvement in the evaluation section. However, it lacks specific guidance on how to implement these experiments or what aspects of the evaluation would benefit from this addition. While it points out a potential gap in the evaluation, the comment could be more helpful if it provided more detailed suggestions or examples of how to conduct these experiments. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors need to elaborate on the importance of rooted patterns and how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback provides clear and concrete actions for the authors to take, such as elaborating on the importance of rooted patterns or discussing nonrooted patterns in the supplementary material. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of \"rooted patterns\" and how they are defined, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of elaboration on why rooted patterns are important and how they are chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors do not elaborate on the importance of rooted patterns or how they choose the roots. It suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, that the discussion should be moved to the supplementary material. The comment provides a logical reasoning for the need to clarify these aspects, but it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors need to provide more detail or clarification. It points out that the concept of rooted patterns is defined in a similar way to orbit counting in GSN, but it does not elaborate on why rooted patterns are important or how they are chosen. The comment suggests that a brief discussion is expected or, if nonrooted patterns are sufficient, it might be better to discuss this case in the supplementary material. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and completeness of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on the importance of rooted patterns or how to choose the roots. Overall, the comment is 4 as it directs the authors to a critical area needing further explanation and provides a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more explanations on the consistency between training and inference, specifically mentioning lines 9597 and 308310. While the comment implies that the authors should elaborate on the smoothness of neural models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more explanations. However, the comment does provide a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue, which is the lack of explanation regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it overly emphasizes the consistency between training and inference due to the smoothness of neural models. It suggests that the authors should provide more explanations on this topic, which is a clear and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on what kind of explanations would be beneficial. Despite this, the feedback is 4 as it directs the authors to a critical area that needs further elaboration."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It asks for clarification on whether the proposed model improves with larger word embedding and LSTM parameters. While the comment implies that the authors should provide evidence or experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional experiments or evidence to substantiate their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about superior performance with fewer parameters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have tested the model with standard parameter settings in the baseline model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. The reviewer requests evidence or experiments to support the claim, indicating a need for further clarification. However, the comment lacks specific examples or references to support the claim or to substantiate the suggestion for additional experiments. This makes the claim 3, as it provides a logical basis for questioning the claim but requires more detailed evidence or reasoning to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the authors\" claim of superior performance with fewer parameters, suggesting that it might be due to standard parameter settings in the baseline model. It questions whether the proposed model actually improves with larger word embedding and LSTM parameters, which is a relevant point for the authors to address. The comment provides a clear direction for the authors to substantiate their claim by suggesting additional experiments or evidence to support their findings. However, it could be more helpful if it offered specific suggestions on how to conduct these experiments or what specific metrics to use. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to address."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure the availability of the environment or a good OPE method. The action is implicit and somewhat vague, as the authors can infer that they need to consider these factors but are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or where the finetuning is mentioned, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these hyperparameters are introduced, the comment lacks full grounding. It is specific about the issue of finetuning and the dependence on the environment or OPE method, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two additional hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim remains 1, as it does not provide sufficient justification for the authors to make improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of two additional hyperparameters, k and \u03b7, and notes that they require finetuning, which depends on the availability of the environment or a good OPE method. This feedback is 3 as it points out a potential problem that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to ensure the availability of the environment or a good OPE method. Without actionable advice or detailed explanation, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a discrepancy in the authors\" approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the comment identifies an issue and provides a suggestion for improvement, it does not offer specific guidance on how to implement this suggestion or what specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the LN model and the GLM, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy in the application of regularization, suggesting that the authors should try to reproduce the main features of previous models to make the comparison fair. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors apply regularization to both LN models and GLMs, which is not consistent with the GLM by Pillow et al. The reviewer suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. However, the comment lacks specific examples or references to support the claim that the GLM by Pillow et al. did not crop the image. Without detailed evidence or references, the claim is 3, as it requires the authors to infer the basis of the comparison and the specific features that need to be reproduced. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the authors\" approach to regularization, noting that they apply regularization to both LN models and GLMs, while the GLM by Pillow et al. did not crop the image but used L1 regularization for the filters and a lowrank approximation to the spatial filter. The comment suggests that to make the comparison fair, the authors should try to reproduce the main features of previous models. While the feedback highlights an important issue, it lacks specific guidance on how to address the discrepancy or what specific features should be reproduced. The authors are left with a general direction but no detailed steps to follow, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the paper should include failure cases and related discussions. While it implies that the authors should add this content, it does not provide specific guidance on how to structure or present these cases or discussions. The action is implicit and somewhat vague, as the authors need to infer that they should include these elements but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include failure cases and related discussions. However, it does not specify which part of the paper should include these elements, such as specific sections or experiments. This makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment lacks specificity regarding what kind of failure cases or discussions should be included, leaving the authors with a general suggestion without detailed guidance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including failure cases and related discussions would be beneficial. However, it does not provide any reasoning, examples, or references to support why this addition would be valuable or how it would enhance the paper. Without specific justification or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the paper should include failure cases and related discussions, which could provide valuable insights into the robustness and limitations of the work. However, it lacks specificity and does not offer guidance on how to structure or present these cases or discussions. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not provide actionable steps for the authors to take."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that an ablation study on the necessity of the base layer GNN encoding would be helpful. This provides a clear and direct action for the authors to take, which is to conduct an ablation study to understand the role of the base layer GNN encoding in the proposed method. The comment is specific in its request, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"base layer GNN encoding\" in the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the necessity of the base layer GNN encoding and the need for an ablation study. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to understand its role. However, the comment does not provide specific reasoning or evidence to support why the base layer GNN encoding is unnecessary or how an ablation study would benefit the paper. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the suggestion without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the necessity of the base layer GNN encoding in the proposed method. It suggests conducting an ablation study to understand the role of this layer and its impact on the overall performance. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to explore and potentially improve their method. By addressing this point, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it included specific guidance on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"equation (10)\" and \"equation (11),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent use of \u03b4 in equations (10) and (11) and suggests introducing \u03b4 when (11) is discussed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \u03b4 is not used in equation (10) but is used in equation (11). This is a factual observation that does not require verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of \u03b4 in equations (10) and (11), noting that \u03b4 is not used in equation (10) but is used in equation (11). It suggests introducing \u03b4 when (11) is discussed to improve clarity. This feedback is clear and actionable, as it provides a concrete suggestion for improving the draft by ensuring consistency in the use of mathematical symbols. However, the comment could be more helpful if it explained why this inconsistency is problematic or how it affects the understanding of the equations. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly add the upper bounds of counting homomorphisms and potentially elaborate on empirical runtimes. This is a clear and concrete action for the authors to take, as it provides a specific direction for improvement. The comment also suggests that the authors should elaborate on empirical runtimes, which adds another actionable point. Therefore, the comment is 5, as it provides clear guidance on how to enhance the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss the computational complexity of counting homomorphisms, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a specific example of a brief statement made in the paper. The reviewer suggests that the paper should explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes. While the comment identifies a specific issue with the discussion of computational complexity, it lacks detailed reasoning or references to support the claim that these additions would be beneficial. The suggestion is 3, as it provides a logical basis for improvement but requires more detailed justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper, namely the discussion of computational complexity in counting homomorphisms. It points out that the paper lacks explicit bounds and potentially elaboration on empirical runtimes, which are crucial for understanding the practical implications of the work. The comment provides a clear and actionable suggestion for the authors to enhance their discussion by explicitly adding these elements. This feedback is valuable as it guides the authors to improve the clarity and depth of their analysis, making it more comprehensive and informative for readers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a typographical error in the first \"f\" in \"we fixed the form of\" and an extra period in a sentence. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. The comment provides clear and concrete actions for the authors to correct the typographical errors and offers a specific question for further clarification. The action is explicit and the authors know exactly what to do to address the errors and the question, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 108\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the typographical errors, such as the incorrect \"f\" in \"we fixed the form of\" and the extra period in a sentence, and it poses a question about the baseline MCL with deep learning. The comment provides clear guidance on what needs to be corrected and offers a specific question for further clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and a question about the baseline MCL with deep learning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific typographical errors in the manuscript, which are important to correct for clarity and professionalism. It also poses a question about the baseline MCL with deep learning, asking how the authors ensure that each network has converged to reasonable results. This question is relevant and could prompt the authors to provide more detailed explanations or evidence regarding their methodology. However, the comment could be more helpful if it provided suggestions on how to address the issue of early learning cutoff or how to ensure that each network has converged to reasonable results. Overall, the comment is actionable and provides valuable insights, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the inference time of their pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed of their method to previous topdown and bottomup pose estimation methods. While the comment implies that the authors should conduct this study, it does not provide explicit instructions on how to do so or what specific aspects to focus on. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests studying the inference time of the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It also recommends comparing the inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper should include this analysis or where the inference time is currently discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific about the need for an inference time comparison but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. The reviewer provides a logical reasoning by stating that since the method is direct, it should be compared to previous topdown and bottomup pose estimation methods in terms of inference speed. This claim is 3 as it provides a logical basis for the suggestion, but it could be strengthened with specific references or examples to support the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the study of inference time for the pose estimation method, which is a direct method that does not require detection or keypoint grouping. It suggests that this comparison could provide valuable insights into the performance of the method. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct the inference time study or what aspects to focus on. The authors are given a clear direction but are not provided with detailed instructions on how to implement the suggestion. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully guide the authors on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the proof in Theorem A.3, specifically regarding the input x having two indices when it is a vector. It also points out a potential error in the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors can infer that they need to clarify the input x and correct the equation, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential error in the proof regarding the input x having two indices when it is a vector, and it questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual observations and questions about the proof in Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the proof of Theorem A.3, pointing out that the input x is a vector, not a matrix, and questioning the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d. This feedback is clear and actionable, as it directs the authors to correct the input type and the equation, which could improve the accuracy and clarity of the proof. However, the comment could be more helpful if it provided additional context or explanation on why this correction is necessary or how it affects the overall understanding of the theorem. Overall, the comment is 4 as it guides the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the use of words like \"somewhat\" and \"good generative ability\" in section 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It suggests that the authors should address this issue by providing more detailed information on how they ensure the correctness of the pluggedin entities and relationships. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the effectiveness of beam search. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the use of words like \"somewhat\" and \"good generative ability\" in the description, and it raises concerns about the effectiveness of beam search in ensuring the correctness of the results. The comment further asks how the authors ensure the correctness of the pluggedin entities and relationships, and it suggests that the authors should provide more detailed information on this aspect. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the effectiveness of beam search in ensuring the correctness of the results, questioning the use of words like \"somewhat\" and \"good generative ability\" in the description. It suggests that only 77% of the result lists contain the ground truth logical forms, and it asks how the authors ensure the correctness of the pluggedin entities and relationships. The comment is 3 as it provides a logical basis for the concern, but it lacks specific examples or references to support the claim that beam search is ineffective. The authors would need to further explore the issue to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in sections 4.3 and 4.4, questioning the effectiveness of beam search in ensuring the correctness of the results. It raises concerns about the use of words like \"somewhat\" and \"good generative ability\" and suggests that only 77% of the result lists contain the ground truth logical forms. The comment also asks how the authors ensure the correctness of the pluggedin entities and relationships, and it suggests that the authors should provide more detailed information on this aspect. This feedback is clear and actionable, as it prompts the authors to reconsider the language used in their description and to provide more detailed information on the effectiveness of beam search. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or what additional information to include. Overall, the comment is 4 as it guides the authors toward improving the clarity and robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment critiques the claim about evolutional dropout and its limitations in addressing internal covariate shift. It suggests that the authors should explicitly discuss these limitations, particularly regarding batch normalization. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to discuss these limitations or what aspects should be emphasized. The action is explicit but somewhat vague, as the authors know they need to address the limitations but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and its limitations in addressing internal covariate shift. It also specifies the issue with batch normalization, which standardizes the variance and centers the activation. This provides clear guidance on what needs to be addressed in the paper. However, the comment could be more specific by suggesting how to discuss these limitations or what aspects of batch normalization should be emphasized. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the claim about evolutional dropout addressing internal covariate shift is limited, as it can only increase the variance of some lowvariance units. The reviewer supports this claim by comparing it to batch normalization, which standardizes the variance and centers the activation. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the claim about evolutional dropout addressing internal covariate shift. It suggests that the claim is limited because it can only increase the variance of some lowvariance units, and it contrasts this with batch normalization, which standardizes the variance and centers the activation. The comment provides a clear and actionable suggestion for the authors to explicitly discuss these limitations in their paper. However, it could be more helpful if it offered specific examples or guidance on how to discuss these limitations or what aspects of batch normalization should be emphasized. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment does not provide explicit guidance on how the authors should further improve their work or what specific aspects of the framework should be refined. It lacks actionable details, such as suggestions for additional experiments or modifications to the framework. As a result, the authors are left without clear direction on how to enhance their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of FedPCL, which relies heavily on pretrained models, and how the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models. This provides clear guidance on what needs to be improved or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL is sensitive to the selection of pretrained models, which limits its applications to more wide areas. The comment supports this claim by referencing Table 4, which shows the model accuracy is affected by the choice of pretrained models. However, the comment does not provide further details or examples to substantiate the claim or suggest improvements. While the reference to Table 4 provides some support, the lack of additional context or explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the limitations of FedPCL due to its reliance on pretrained models and suggests that the authors have adequately addressed these limitations by developing a lightweight federated learning framework and integrating pretrained models. However, the comment lacks specific suggestions or guidance on how the authors could further improve their work or what aspects of the framework should be refined. It does not provide actionable feedback or detailed insights into potential enhancements, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include tentative attention maps in the qualitative figures to provide a more comprehensive understanding of the attention mechanism. While the comment implies that the authors should add these maps, it does not explicitly instruct them to do so. The action is concrete, as it specifies what additional information should be included, but it is somewhat vague because it does not provide detailed guidance on how to present these maps. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that it relates to the visualization or discussion of the attention mechanism. However, it does not explicitly mention a specific section or figure where these maps should be included, making it weakly grounded. The comment is specific in suggesting what additional information should be included, such as the retrieved and final attentions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including tentative attention maps in the qualitative figures would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be valuable or how it would enhance the understanding of the attention mechanism. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that including tentative attention maps in the qualitative figures would enhance the understanding of the attention mechanism. This feedback is 3 as it identifies a potential area for improvement by recommending the inclusion of additional visual information. However, the comment lacks depth and does not provide specific guidance on how to present these maps or why they are important. Without further explanation or examples, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the author to add more description about the contribution of the paper. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment provides a specific suggestion for enhancing the paper\"s clarity by adding more details about the contribution. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this additional description should be added to, nor does it provide any guidance on what specific aspects of the contribution should be elaborated on. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need additional description. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any reasoning, examples, or references to support why this additional description is necessary or how it would enhance the paper. Without specific guidance or evidence, the claim is not verifiable, as it lacks the necessary support to help the authors understand and address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors should add more description about the contribution of the paper. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the contribution should be elaborated on or how this additional description would enhance the paper. Without detailed suggestions or examples, the authors may find it challenging to understand and implement the feedback effectively. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides several explicit suggestions for improving the paper. First, it recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models. This action is clear and concrete, as it specifies where the information should be placed and how it should be organized. Second, it suggests referencing tricks like normalization or feature scaling in a separate section, which is also a clear and concrete action. Finally, it mentions that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, providing a specific area for improvement. Overall, the comment is 5 as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections, \"2.3\" and \"2.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the two types of attention for deep VAEs in a separate section and referencing tricks like normalization or feature scaling in a separate section. The comment also suggests reorganizing the description of the layerwise attention mechanism to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides several suggestions for improvement, including describing the two types of attention for deep VAEs in a separate section, referencing tricks like normalization or feature scaling, and reorganizing the description of the layerwise attention mechanism. These suggestions are based on logical reasoning and common practices in the field, but they do not include specific examples or references to support the claims. While the suggestions are clear, they lack detailed justification or evidence to fully substantiate the claims. Therefore, the comment is 3, as it provides a direction for improvement but lacks the depth and evidence needed for full verifiability.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It recommends describing the two types of attention for deep VAEs in a separate section, followed by the generative and inference models, which can help clarify the contributions of the paper. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section, which can improve the organization and accessibility of the paper. Finally, it points out that the description of the layerwise attention mechanism is scattered across sections 2.3 and 2.4, suggesting a reorganization to improve clarity. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and organization of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the understanding of Figure 5 or the labels being incorrect. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific steps to take to improve the figure or labels. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as Figure 5, is being addressed. It lacks specificity because it does not provide details on what is unclear or incorrect about the figure or labels. Without explicit references or detailed feedback, the authors cannot effectively identify the issues or make improvements. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment claims that either the reviewer does not understand Figure 5 or the labels are incorrect. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential issue with the clarity or accuracy of Figure 5 or the labels used in the figure. However, it does not provide any specific guidance or suggestions on how to address this issue, such as suggesting alternative labels or clarifying the figure\"s purpose. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the paper and suggests that it is reasonable to assume that full annotation is available for datasets of scale ~100k images. It also notes that even if this is not the case, having an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. While the comment implies that the authors should include supervised baselines, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the paper, specifically mentioning that most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. It suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. However, the comment does not specify which part of the paper should include this baseline, such as the experimental section or the discussion. While the authors can infer that it relates to the experimental results, the comment lacks full grounding. It is specific about the need for a supervised baseline but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of supervised baselines is a significant issue, as most experiments are conducted on datasets of scale ~100k images, which implies that full annotation should be available. The reviewer suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This claim is 3 as it provides a logical reasoning for the inclusion of supervised baselines, but it lacks specific examples or references to support the assertion that full annotation is typically available for datasets of this scale. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which are crucial for understanding the performance of selfsupervised methods. It logically argues that since most experiments are conducted on datasets of scale ~100k images, it is reasonable to assume that full annotation is available. The comment suggests that including an informative baseline would be beneficial to show the performance of selfsupervised methods compared to a fully supervised pretrained network. This feedback is clear and actionable, providing the authors with a specific direction to enhance their experimental design and analysis. However, it could be more helpful if it included examples of suitable supervised baselines or detailed guidance on how to implement them. Overall, the comment is 4 as it effectively highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. It also notes that the benchmarks used are outdated and likely saturated. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue of minimal performance differences or how to update the benchmarks. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of performance differences between methods, noting that they are minimal across evaluations and often less than 1 percentage point. It also mentions that the benchmarks used are outdated and likely saturated, referencing specific works. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the issue of minimal performance differences and the need to update the benchmarks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point, which may be due to random variation. The reviewer supports this claim by referencing the outdated and likely saturated benchmarks used. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides some evidence, it could be strengthened with more detailed analysis or references to specific studies that support the claim. Therefore, the comment is 3, as it provides some evidence but could be more fully substantiated with additional details or references.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with most differences being less than 1 percentage point. This observation suggests that the methods may be overfitting or that the benchmarks are saturated. The comment also points out that the benchmarks used are outdated, which could impact the relevance and applicability of the results. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. Providing more detailed advice or examples on how to update the benchmarks or improve the performance evaluation would make the comment more helpful. Therefore, the comment is 3, as it identifies a significant issue but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. While the comment implies that the authors should evaluate their method on different domains and include BEAR in the baselines, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the method\"s effectiveness and the need to evaluate it on different domains. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics. It also questions the absence of BEAR from baselines and suggests that the method may not have much benefit. However, the comment lacks specific examples or references to support these claims or questions. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the method\"s effectiveness on Hopper, which has deterministic dynamics, and suggests evaluating it on other domains with nondeterministic dynamics to assess its empirical efficacy. This feedback is valuable as it prompts the authors to consider broader applicability and validate their method in different contexts. Additionally, the comment questions the absence of BEAR from baselines and suggests that the method may not have much benefit without this comparison. While the comment identifies areas for improvement, it could be more helpful if it provided specific guidance on how to conduct these evaluations or what specific domains to consider. Overall, the comment is 4 as it encourages the authors to expand their evaluation and enhance the robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. While the action is explicit, it lacks concrete guidance on how to present this justification or what specific aspects should be addressed. The authors are left to infer that they need to provide theoretical reasoning, but without detailed instructions on how to do so, the comment remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not specify which part of the paper this justification should be provided in, nor does it provide details on what aspects of the results need justification. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its request for theoretical justification, it lacks grounding as it does not specify where in the paper this should be provided. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. However, it does not provide any specific reasoning or evidence to support this claim. Without detailed explanation or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide theoretical justification for why cotraining and weight averaging can improve results. This is a valid point as these techniques are important for performance, and theoretical justification can help the authors better understand and articulate their contributions. However, the comment lacks specific guidance on how to present this justification or what aspects of the results should be emphasized. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a need for theoretical justification but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. While the comment provides a clear and explicit action\u2014changing \"X\" to a multiset\u2014it does not offer detailed guidance on how to implement this change or what specific considerations should be taken into account. The action is concrete, but the lack of additional context or explanation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the change from a set to a multiset in the context of representing a graph with repeated vertex or edge labels. This provides clear guidance on what needs to be corrected or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. The comment provides a logical reasoning based on the need to include multiplicities to ensure an honest representation of the graph. However, it lacks specific examples or references to support the claim, making it 3. The authors may need to further explore the rationale behind the suggestion, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It points out that in Section 4, \"X\" should be a multiset instead of a set, as it is necessary to include the multiplicities of the labels in the graph to accurately represent a graph with repeated vertex or edge labels. This feedback is clear and constructive, as it directly addresses a potential issue with the accuracy of the representation. However, the comment could be more helpful if it included additional context or explanation on why this change is necessary or how it would impact the overall understanding of the paper. Despite this, the comment is 4 as it guides the authors on how to improve the clarity and accuracy of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors\" derivation for falling into classical learning theorybased bounds, which are not considered realistic without Bayesian considerations. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the derivation. The comment lacks actionable details, such as suggesting alternative methods or approaches to incorporate Bayesian considerations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the authors\" derivation for falling into classical learning theorybased bounds, which are not considered realistic without Bayesian considerations. However, it does not specify which part of the paper this critique pertains to, such as a particular section or equation. The authors can infer that it relates to the derivation or theoretical aspects of the paper, but this inference is not direct. The comment is specific in its critique of the classical learning theorybased bounds and the need for Bayesian considerations, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" derivation falls into classical learning theorybased bounds, which are not considered realistic without Bayesian considerations. The reviewer supports this claim by mentioning BayesianPAC based bounds as an example of a more realistic approach. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general idea of the issue, it does not offer enough evidence or detailed explanation to fully verify the claim. Therefore, the comment is 3, as it provides a logical basis but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment critiques the authors\" derivation for falling into classical learning theorybased bounds, which are not considered realistic without Bayesian considerations. It suggests that the authors should consider BayesianPAC based bounds as a more realistic approach. While the comment identifies a potential weakness in the derivation, it lacks specific guidance on how the authors might incorporate Bayesian considerations or what specific aspects of the derivation need to be revised. The feedback is 3 as it points out a potential issue but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or offer specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details but may not be entirely sure of the exact content or structure of these details. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be added to, nor does it provide specific guidance on what aspects of the method should be elaborated on. While the authors might have an idea of where these details could be added, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are necessary or how they would enhance the understanding of the method. Without such justification, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment identifies areas for improvement, it lacks specific guidance or examples on how to present these details or what aspects of the method should be elaborated on. The authors are given a general direction but are not provided with actionable steps or detailed suggestions to enhance their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer suggests that the method might struggle to detect inconsistencies in responses due to the variety of individuals being discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the method\"s detection capabilities. The action is implicit and somewhat vague, as the authors can infer that they need to consider this issue but are not given detailed instructions on how to address it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific example of a prompt like \"introduce a sports celebrity to me,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed method, namely that it might struggle to detect hallucinations in openended responses due to the variety of individuals being discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" The reviewer provides a logical reasoning by explaining that the variety of individuals discussed in the responses could make it challenging to identify shared information for consistency checking. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be improved with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of a prompt like \"introduce a sports celebrity to me.\" This feedback highlights a specific challenge that the method might face in detecting inconsistencies in responses due to the variety of individuals being discussed. While the comment points out a potential weakness, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method\"s detection capabilities. The feedback is 3 as it directs the authors\" attention to a specific area for improvement, but it could be more beneficial with additional actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. While the comment does not explicitly instruct the authors to conduct these experiments, it provides a clear direction for action. The authors know that they need to verify the conclusion, but the comment could be more explicit in suggesting specific experiments or methods to conduct these tests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests verifying the conclusion about label noise and model size on MNIST and CNN, which implies that the authors should conduct additional experiments to test the theoretical findings in a realworld context. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need to verify the conclusion, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in their relation to realworld deep learning models. It provides a specific suggestion to verify the conclusion about label noise and model size on MNIST and CNN. This claim is 3 as it logically suggests that verifying these findings in realworld contexts could enhance the paper\"s credibility. However, the comment lacks detailed reasoning or references to support the claim, such as explaining why these specific models are relevant or how the verification process would benefit the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical findings and their relation to realworld deep learning models. It suggests that the authors verify the conclusion about label noise and model size on MNIST and CNN, which could provide a valuable contribution to the paper. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen the paper\"s claims. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the findings should be verified. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the paper\"s organization, writing, and content clarity. It suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, it questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and questions the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment provides some guidance on potential areas for improvement, it does not explicitly instruct the authors on how to implement these changes. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"writing\" and \"content clarity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the weaknesses, such as the need for a table to compare different CoT prompting methods across different dimensions and questions about the selection criteria in section 4.2. The comment is specific in detailing what needs to be addressed, such as the assumption about the frequenterror cluster and the selection criteria. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is wellorganized and the writing is good, but it also identifies areas for improvement. The reviewer suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. Additionally, the reviewer questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps are not included. While the comment identifies potential areas for improvement, it lacks specific examples or references to support the claims. The reasoning is 3, as it provides a logical basis for the critique but requires more detailed evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides both positive and constructive feedback. It acknowledges that the paper is wellorganized and the writing is good, which is a positive observation. However, it also identifies areas for improvement, such as suggesting the addition of a table to compare different CoT prompting methods across different dimensions. This feedback is actionable and can help the authors enhance the clarity and comprehensiveness of their paper. Additionally, the comment questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and the selection criteria in section 4.2, which are important areas for clarification and potential improvement. Overall, the comment is 4 as it provides clear and actionable suggestions for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the probability distribution p(y|Hf(tn)) should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. It also mentions that this assumption is made in the ELBOs later in the paper. This comment provides a clear and direct action for the authors to take, ensuring that the probability distribution is chosen as Gaussian. The explicit nature of the suggestion and the concrete detail on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the probability distribution \"p(y|Hf(tn))\" and the assumption of Gaussian distribution, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the choice of probability distribution and its implications for Kalman Filtering, Smoothing, and CVI. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian, as otherwise, Kalman Filtering and Smoothing, and CVI cannot be performed. The comment provides a logical reasoning by stating that this assumption is made in the ELBOs later in the paper, which supports the claim. However, the comment lacks specific references or detailed explanations to fully substantiate the claim, such as why this assumption is necessary or how it affects the analysis. Therefore, the comment is 3, as it provides a logical basis but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of probability distribution, noting that the probability distribution \"p(y|Hf(tn))\" should be chosen as Gaussian to enable Kalman Filtering, Smoothing, and CVI. This is a clear and actionable point that the authors can address to improve the clarity and feasibility of their analysis. However, the comment could be more helpful if it provided additional context or examples to explain why this choice is important or how it affects the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It suggests that the lack of reporting cosine similarities for such large weight decay strengths and the ending of plots at a weight decay strength where cosine similarities are still close to optimal is convenient. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The authors are left to infer that they should report cosine similarities for larger weight decay strengths or adjust the plotting range to show the full range of cosine similarities. While the comment highlights an area for improvement, it lacks concrete instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of suboptimally weight decay across all layers, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of reporting cosine similarities for large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of suboptimally weight decay across all layers is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. The reviewer supports this claim by pointing out that cosine similarities for such large weight decay strengths are not reported and that the plots end at a weight decay strength where cosine similarities are still close to optimal. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have observed similar effects. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the application of suboptimally weight decay across all layers, which is expected to result in large training losses and suboptimal cosine similarities, especially for large weight decay parameters. It points out that the lack of reporting cosine similarities for such large weight decay strengths and the convenient ending of plots at a weight decay strength where cosine similarities are still close to optimal. This feedback is clear and actionable, as it highlights a potential weakness in the paper that the authors can address by either reporting cosine similarities for larger weight decay strengths or adjusting the plotting range to show the full range of cosine similarities. By providing this guidance, the comment helps the authors improve the clarity and completeness of their results. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. It suggests that this omission could lead to incorrect conclusions by casual readers. The reviewer implies that the authors should fix this issue, but does not provide specific guidance on how to do so. The comment is explicit in identifying the problem but lacks concrete details on how to address it. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of not explaining that the results are for unsupervised random forests, which is a critical omission that could lead to incorrect conclusions. The comment provides a clear direction for the authors to address this issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This omission could lead to incorrect conclusions by casual readers. The reviewer suggests that this is a serious issue and implies that it should be addressed before publication. However, the comment does not provide specific examples or references to support the claim that this omission is a significant problem. While the claim is logical and somewhat supported by the mention of unsupervised random forests, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a serious omission in the paper, specifically that the results are for unsupervised random forests, which is not explained in the title, abstract, introduction, or discussion sections. This is a critical issue that could lead to incorrect conclusions by casual readers. The reviewer suggests that the authors should fix this oversight, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how to address this issue, such as suggesting where in the paper the explanation should be added or how to clarify the methodology. Despite this, the comment is 4 as it highlights a significant gap in the paper that needs to be addressed."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a lack of qualitative experiments to demonstrate the validity of the conditional independence model and suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. It also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics. The comment provides specific actions for the authors to take, such as providing experimental results, visualization, and schematic diagrams. These are explicit and concrete suggestions, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of qualitative experiments to demonstrate the validity of the conditional independence model, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD, as well as the need for a correctness test and comparative experiments with other metrics. The suggestion to use a toy dataset to demonstrate the separability of inlier and outlier features is also clear. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The reviewer also recommends using a toy dataset to demonstrate the separability of inlier and outlier features. The comment is 4 as it provides logical reasoning and suggests specific actions for the authors to take. However, it could be strengthened by providing more detailed examples or references to similar studies that have successfully demonstrated the benefits of such approaches. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides actionable suggestions for improvement, such as providing illustrative experimental results to demonstrate the potential benefits of minimizing HSICcondi over HSIC_HOOD. The comment also recommends using a toy dataset to demonstrate the separability of inlier and outlier features, which is a valuable suggestion for clarifying the model\"s assumptions. Additionally, it points out the absence of a correctness test and comparative experiments with other metrics, which are important for validation. The feedback is clear and provides specific guidance on how the authors can enhance their experimental design and analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the computational complexity of the proposed method compared to other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a computational complexity comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"online version of the algorithm\" and the issue of training multiple iterations/epochs with large models and datasets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for a comparison of the computational complexity with other methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the proposed method requires more computation than other methods and suggests a comparison of computational complexity. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or comparisons to other methods, making it difficult for the authors to understand the basis of the claim. As a result, the claim is 1.", "helpfulness_rationale": "The review comment raises a valid question about the computational complexity of the proposed method compared to other methods. It prompts the authors to provide a comparison, which is an important aspect of the paper\"s evaluation. However, the comment lacks depth and does not offer specific guidance on how to conduct the comparison or what aspects to focus on. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a gap but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides a clear direction for further analysis, it does not explicitly instruct the authors to conduct this study. The action is implicit but concrete, as it specifies what aspects of the analysis should be explored. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. However, it does not explicitly mention which part of the paper this analysis should be integrated into, making it weakly grounded. The comment is specific in detailing what aspects of the analysis should be explored, such as the roles between \"winners\" and \"cooperators\" and the potential impact of cost on collective return. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that studying the impact of the cost of incentivization on performance would be beneficial. It provides a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The reviewer also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. While the comment provides logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the suggestion but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a systematic analysis of the impact of the cost of incentivization on performance. It offers a specific example of what such an analysis could entail, including examining the reward incentives and collective return for various values of \u03b1. The comment also speculates on the potential impact of the cost on the roles between \"winners\" and \"cooperators,\" suggesting that a lower cost could lead to less distinct roles and a lower collective return. This feedback is highly valuable as it guides the authors to a specific area for further exploration and analysis, which could significantly enhance the paper. However, the comment could be more helpful if it provided additional details or examples on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 5 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It points out a specific example from line 486 where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment provides a clear and explicit action for the authors to take, which is to conduct significance testing to support their claims. This guidance is concrete and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issue by pointing out the lack of significance testing to support claims about the differences between methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors make significant claims about the differences between methods without conducting significance testing. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer suggests that without proper testing, it is difficult to determine whether these differences are significant. The comment is 4 as it provides a logical reasoning and a specific example to support the claim. However, it could be strengthened by referencing external works or studies that demonstrate the importance of significance testing in similar contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a specific example from line 486, where the authors claim that the conversational ability of ChatGPT and GPT4 significantly boosts translation quality and discourse awareness. The reviewer points out that without proper testing, it is difficult to determine whether these differences are significant. This feedback is 5 as it directs the authors to a specific area where their claims are not supported by evidence, providing them with a clear and actionable step to improve their draft. By addressing this issue, the authors can strengthen the credibility and robustness of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to revise the approach description in Section 3, which is currently difficult to follow. It suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be revised and how to do it. The comment is 5 as it gives specific guidance on how to improve the draft, making it easy for the authors to apply the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be revised, namely the approach description, and suggests using the additional page of the cameraready version to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be addressed and how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach description in Section 3 is difficult to follow and suggests revising it. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests using the additional page of the cameraready version to extend the approach description, but this suggestion is not accompanied by a detailed explanation of why this is necessary or how it would improve the clarity of the approach. Without additional context or evidence, the claim remains 3, as the authors may find it challenging to understand the basis of the critique and how to address it effectively.", "helpfulness_rationale": "The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It suggests revising the approach description and provides a clear and actionable suggestion to extend it using the additional page of the cameraready version. This feedback is valuable as it directs the authors to a specific area needing improvement and offers a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to improve the approach description or suggested specific changes to make it more accessible. Overall, the comment is 4 as it effectively points out a weakness and offers a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. While the comment highlights these gaps, it does not provide explicit guidance on how to address them. The authors are left to infer that they should include more detailed interpretive insights and comparisons with other methods. The action is implicit and somewhat vague, as it lacks specific suggestions on how to improve the interpretive insights or which methods to compare with. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods that do not rely on gyrostructures. This provides clear guidance on what needs to be improved in the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights and that the paper lacks comparison with other stateoftheart methods that do not rely on gyrostructures. The comment suggests that this omission makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. While the comment identifies specific gaps in the discussion, it does not provide detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the importance of these comparisons and the need for interpretive insights. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies two significant issues with the experimental section of the paper. First, it points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. This feedback is valuable as it highlights an area where the authors need to provide more detailed analysis and explanation to support their claims. Second, it notes the absence of comparison with other stateoftheart methods that do not rely on gyrostructures, which makes it unclear whether the proposed approach actually outperforms simpler or more commonly used techniques in manifoldbased learning. This feedback is also valuable as it prompts the authors to broaden their comparisons and provide a more comprehensive evaluation of their method. However, the comment could be more helpful if it suggested specific methods or approaches to include in the comparisons. Overall, the comment is 4 as it identifies important areas for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. While the comment implies that additional analysis is needed, it does not specify what kind of evidence or analysis is required or how it should be presented. The authors are left to infer that they need to provide more detailed information, but the comment lacks concrete guidance on what exactly is needed. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in its request for additional evidence or analysis, but it lacks full grounding as it does not explicitly mention the sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without such evidence or examples, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of evidence or analysis supporting the training effectiveness property of the dataset or other key properties that explain the importance and potential use cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to strengthen their claims. However, the comment could be more helpful if it suggested specific types of evidence or analysis that would be beneficial, such as comparisons with other datasets or detailed performance metrics. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 5 is difficult to comprehend and recommends providing more details about the two baselines presented. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation, and suggests extending CATER to other languages in the future. While the comment provides a clear action for the authors to take, it does not specify which details should be added or how to extend CATER to other languages. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as its difficulty in comprehension and the need for more details about the baselines presented. The comment suggests extending CATER to other languages, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to comprehend and suggests that more details about the baselines presented are needed. It also points out that the authors only study CATER for Englishcentric datasets, which is a limitation. The reviewer suggests extending CATER to other languages, which is a logical suggestion based on the widespread use of translation APIs. However, the comment lacks specific examples or references to support the claim about the difficulty of comprehension or the need for more details about the baselines. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and suggesting that more details about the baselines presented should be included. It also points out a limitation in the study, noting that the authors only focus on CATER for Englishcentric datasets, despite the widespread use of translation APIs for multiple languages. The comment provides a clear and actionable suggestion for improvement by recommending that the authors extend CATER to other languages in the future. This feedback is valuable as it directs the authors to enhance the comprehensibility and scope of their work, making it 4. However, it could be more helpful if it included specific guidance on how to extend CATER to other languages or what additional details should be included in the figure. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the literature review, specifically regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment implies that the authors should make these improvements, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added (an explicit and comparative analysis of related work), but it is somewhat vague in terms of how to execute this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and \"GFlowNet for sequence generation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved: the clarity of the main contribution and the distinction from existing work. The comment provides a clear direction for the authors to enhance the literature review by suggesting a more explicit and comparative analysis of related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear, particularly regarding the main contribution of the proposed method and its distinction from existing work. The reviewer suggests that the paper should provide a more explicit and comparative analysis of related work. While the comment identifies a potential issue, it lacks specific examples or references to existing work that could clarify the distinction. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the literature review, specifically the lack of clarity regarding the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work, which is crucial for effectively communicating the novelty and significance of the proposed method. This feedback is clear and actionable, as it directs the authors to enhance the literature review section to better support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct a more comprehensive analysis of related work. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how to implement this suggestion or what specific changes should be made to the section. The action is implicit and vague, as the authors are left to infer that they should remove the section but without clear instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of section 3.2 is problematic or how it relates to the distribution. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or how it affects the paper\"s content or clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that section 3.2 can be eliminated, as readers are assumed to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any reasoning or explanation for why this section is unnecessary or how it might detract from the paper\"s overall clarity or contribution. Without additional context or suggestions for improvement, the comment lacks depth and does not offer actionable guidance for the authors to enhance their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It highlights the need for proper ablation studies to verify this claim. While the comment identifies a specific concern and suggests a potential solution (ablation studies), it does not provide explicit instructions on how to conduct these studies or what specific aspects to focus on. The action is clear but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. It points out the need for proper ablation studies to verify this claim. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the claim and the need for ablation studies, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the improvements in teacher performance are due to distillation, suggesting that they might be due to regularization effects instead. The reviewer provides a logical reasoning by pointing out that the finetuning without earlystopping could lead to high variances, which would affect the validity of the claim. However, the comment lacks specific examples or references to support the argument, making it 3. The authors would need to conduct their own analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claim that the improvements in teacher performance are due to distillation. It suggests that the improvements might be due to regularization effects instead, given the lack of earlystopping and the high variances in finetuning. The comment highlights the need for proper ablation studies to verify this claim, which is a crucial point for the authors to consider. However, the comment could be more helpful by providing specific guidance on how to conduct these studies or what aspects to focus on. Overall, the comment is 3 as it points out a potential weakness and suggests a direction for improvement, but it lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two specific actions for the authors to take: (i) to include performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, to enhance the credibility of the framework, and (ii) to include morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These are explicit actions that the authors can directly implement to improve their draft. The second point is a minor suggestion, but it is still clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of performance on word similarity and sentence translation tasks and the inclusion of morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. This provides clear guidance on how to enhance the robustness and effectiveness of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that adding performance on word similarity and sentence translation tasks would enhance the credibility of the framework, similar to the MUSE paper and others. It also recommends including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments. These suggestions are based on common practices in the field and are logical, but the comment lacks specific examples or references to support the claim fully. The authors might need to infer the benefits of these additions themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific and actionable suggestions for improving the experiments section of the paper. First, it recommends adding performance on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would enhance the credibility and effectiveness of the framework. This is a clear and concrete suggestion that the authors can easily implement to strengthen their work. Second, it suggests including morphologically rich languages like Finnish, Hebrew, etc., and lowresource languages in the experiments, which would further diversify the evaluation and provide more comprehensive results. While the second point is a minor suggestion, it is still actionable and could help the authors expand their experiments. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes should be made to include the 1shot setting. The comment lacks actionable details, such as recommending specific experiments or modifications to the paper, making it 1.", "grounding_specificity_rationale": "The comment addresses the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its inquiry about the 1shot setting and the inclusion of related works like RALE, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. However, it does not provide any supporting evidence, reasoning, or references to justify why this omission is problematic or how it affects the paper\"s conclusions. The claim is based on a logical observation but lacks detailed justification or examples, making it 3. The authors would need to infer the importance of addressing this issue themselves, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid point about the use of node importance in the 1shot scenario and notes that the experiment part does not include this setting. It also questions why related works like RALE have included this setting but the paper does not. This feedback is 3 as it identifies a potential gap in the paper\"s experimental setup and suggests that the authors should consider including the 1shot setting. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the 1shot setting should be considered. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. While the comment implies that additional discussions are needed, it does not provide specific guidance on what aspects of these discussions should be included or how to structure them. The authors are left to infer that they need to expand on the existing discussions, but without concrete instructions on what to focus on or how to implement these changes, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be added to, nor does it provide details on what aspects of the LLMs\" struggles should be addressed. Without explicit references to sections or specific issues, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without specific examples or detailed explanations, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that there should be more discussions about why LLMs struggle at finegrained hard constraints and how to address these problems. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of the LLMs\" struggles should be addressed or how to structure these discussions. The comment is 3 as it points out a gap in the paper, but it does not offer actionable advice or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of insight into the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more detailed explanations or justifications for this approach. However, the comment does not explicitly instruct the authors to do so or offer specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more context but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio, it lacks insights into why this approach is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of insight into the rationale behind the need for selfsupervised learning on this kind of data. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results suggest the proposed approach is valuable for selfsupervised learning on 360 video data with spatial audio but lacks insights into why this approach is needed. The comment provides a logical reasoning by pointing out the absence of detailed explanations for the rationale behind the approach. However, it does not provide specific examples or references to support the claim, making it 3. The authors may need to infer the need for more detailed explanations themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the rationale behind the need for selfsupervised learning on 360 video data with spatial audio. It highlights that while the experimental results suggest the approach\"s value, the paper lacks insights into why this approach is necessary. This feedback is 3 as it points out an area where the authors could provide more context or explanation to strengthen their work. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how other works have addressed similar questions. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the link between IP and the terms/equations should be explained more explicitly and prominently. It also requests that labels be included for subfigures in Figures 3 and 4, rather than just being mentioned in the captions. While the comment provides a clear action for the authors to take, it does not specify how to implement this improvement or what specific changes are needed to make the link more explicit. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for labels on subfigures and the clarification of the link between IP and the terms/equations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the link between IP and the terms/equations could be explained more explicitly and prominently. However, it does not provide any specific examples or reasoning to support this claim. The suggestion to include labels for subfigures in Figures 3 and 4 is also mentioned, but without further explanation or justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the link between IP and the terms/equations could be explained more explicitly and prominently. It also provides a clear and actionable suggestion to include labels for subfigures in Figures 3 and 4, rather than just mentioning them in the captions. This feedback is valuable as it directs the authors to enhance the clarity and accessibility of their figures, which can significantly improve the readability and comprehension of their work. However, the comment could be more helpful if it included additional guidance on how to effectively explain the link or how to label the subfigures. Overall, the comment is 4 as it provides clear and actionable suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to average their results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific guidance on how to enhance the robustness and reliability of their results, making it 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the results are presented. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that can help the authors improve the robustness and reliability of their results. By suggesting a specific method for evaluating statistical significance, the comment provides a concrete step for the authors to take in enhancing the quality of their work. However, the comment could be more helpful if it explained why averaging over multiple runs is necessary or how it would impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, it does not provide explicit guidance on what specific analysis should be conducted or how to address this gap. The comment implies that the authors should include analysis on the projection head, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of analysis on the \"projection head,\" which is a critical component of the SimCLR approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only covers the SimCLR case and lacks analysis on the projection head, which is considered important. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why the projection head is crucial or how it relates to the SimCLR case. Without this additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, noting that it only covers the SimCLR case and lacks analysis on the projection head, which is considered important. This feedback is valuable as it highlights a gap in the paper that could be addressed to enhance its comprehensiveness and relevance. However, the comment does not provide specific suggestions or guidance on how to incorporate analysis on the projection head or what aspects of this analysis would be most relevant. While it points out an important area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the observations and conclusions should be highlighted in the paper, particularly in the experimental section. This implies that the authors should make a conscious effort to emphasize these aspects in their draft to improve clarity and understanding. However, the comment does not provide specific guidance on how to highlight these observations or what aspects should be emphasized. While the action is implied, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the observations and conclusions are hidden in the experimental section, which is a specific critique. However, it does not explicitly mention which part of the experimental section is problematic, making it weakly grounded. The comment does specify what needs to be addressed, which is highlighting the observations and conclusions to improve understanding of the tradeoffs of annotation effort and training performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the observations and conclusions are hidden in the experimental section, implying that they are not clearly highlighted or explained. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these aspects would be beneficial for understanding the tradeoffs of annotation effort and corresponding training performance. This feedback is clear and actionable, as it provides a concrete suggestion for improving the paper by emphasizing the importance of the observations and conclusions. However, the comment could be more helpful if it offered specific guidance on how to highlight these sections or what aspects should be emphasized. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is explicit, as it clearly instructs the authors to perform additional experiments to support their claims. The action is concrete, as it specifies the exact type of experiment (ablation) and the context (Section 3.4), providing a clear direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. However, it does not provide any specific examples or references to support the claim that these modifications are necessary or beneficial. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors conduct ablation experiments to validate the model performance using the modifications mentioned in Section 3.4. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s validation and demonstrating the effectiveness of the model. By addressing this point, the authors can strengthen their claims and provide more robust evidence to support their work. However, the comment could be more helpful if it explained why these modifications are important or how they might impact the model\"s performance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Remark 1\" and \"Zhang et. al.\" (presumably references in the paper), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the KDE requiring more data when the classifier space is beyond binary and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the KDE requiring more data when the classifier space is beyond binary, and questions whether it is possible to show the comparison of performance on datasets with a decision space beyond binary. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the KDE requiring more data when the classifier space is beyond binary, which is relevant to the methodology and results sections. It raises a question about the comparison of performance on datasets with a decision space beyond binary, suggesting that this could be an important aspect to consider. However, the comment lacks specific guidance or suggestions on how to address this issue or what specific datasets should be considered. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an area for further exploration but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. While these questions imply that the authors should investigate these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explore the impact of capacity on FID and consider potential artifacts in the pipeline, but the comment lacks specific details or suggestions on how to conduct these investigations. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for information about the impact of capacity and artifacts, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The questions themselves are not claims but rather requests for clarification or additional information. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could be valuable for the authors to explore: how the capacity of the SR model affects the FID and whether there are unexpected artifacts due to the proposed method being pipelined. These questions highlight potential areas for further investigation and analysis, which could enhance the understanding and robustness of the paper. However, the comment lacks specific guidance or suggestions on how to address these questions or what specific aspects to focus on. While it points out potential areas for improvement, it does not provide detailed or actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that the purpose of Proposition B.1 might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the purpose of Proposition B.1 and include a proof, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by pointing out that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. The comment further clarifies that the authors\" \"proof\" is missing, which adds specificity to the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also notes the absence of a proof, which is a critical issue. However, the comment lacks specific examples or references to support the claim that the purpose is unclear or that the proof is missing. This makes the claim 3, as the authors would need to infer the basis of the reviewer\"s critique and potentially conduct additional research to address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the purpose might be to illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. The reviewer also points out that the authors\" \"proof\" is missing, which is a critical oversight. This feedback is 3 as it highlights specific areas that need attention, but it could be more beneficial if it provided suggestions on how to address these issues or improve the clarity of the paper. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, which is to conduct these additional experiments. The comment is specific about the types of experiments that are missing, giving the authors a concrete understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing the types of experiments that are missing, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide specific examples or detailed reasoning to support why these experiments are necessary or how they would enhance the paper. Without such evidence or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of additional necessary experiments such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly points out areas where the paper could be strengthened by including these experiments. However, the comment could be more helpful if it provided specific suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern about the use of approximations in the paper, specifically mentioning lines 107110. It suggests that the authors should expand on the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set only in those lines. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (107110) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the possible vulnerability of the approximations used and suggesting that the authors should expand on this to reassure readers that it is not a real concern. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of approximations in the paper leaves \"loose ends\" and suggests that the possible vulnerability of these approximations needs to be expanded to reassure readers. The reviewer provides a specific example of the lines where these issues are discussed (107110) and mentions the assumption of attacks being in the feasible set. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the approximations are vulnerable or that the assumption is problematic. While the reference to specific lines provides some context, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of approximations in the paper, specifically mentioning lines 107110. It points out that the possible vulnerability of these approximations, such as the assumption of attacks being in the feasible set, needs to be expanded to reassure readers that it is not a real concern. This feedback is clear and actionable, as it directs the authors to provide additional context or explanation to address the concern. However, the comment could be more helpful if it suggested specific ways to expand on this vulnerability or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses a subjective opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific guidance or suggestions on how the authors might address this perception or improve the contribution of their work. There is no explicit or implicit action for the authors to take, such as suggesting alternative approaches or improvements to the model. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the contribution of the paper and the approach of the proposed model, but it does not specify which part of the paper this perception is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution or approach are considered incremental or limited. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the reviewer\"s opinion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses an opinion that the contribution of the paper appears limited and the proposed model incremental in its approach. However, it does not provide any specific reasoning or examples to support this claim or offer suggestions for improvement. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of what aspects of their work need attention or how to enhance its impact. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct a more careful analysis of the model\"s performance, particularly on \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis, it does not specify exactly how to do so or what additional details should be included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It also recommends providing more details about the evaluation procedures, which could be helpful. However, the comment does not specify which part of the paper discusses the model\"s performance or the evaluation procedures, making it weakly grounded. The suggestion to provide more details is specific, but without clear grounding, the authors may struggle to identify where to make improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, including some \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It suggests that more careful analysis is needed, particularly for these \"old\" benchmarks. The comment also recommends providing more details about the evaluation procedures, which could be helpful. However, the comment lacks specific examples or references to support the claim about the model\"s performance on \"old\" benchmarks. Additionally, it does not provide detailed guidance on how to conduct a more careful analysis or what specific details about the evaluation procedures should be included. This makes the claim 3, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks that might have been indirectly seen by the model through the data curation process. It suggests that more careful analysis is needed, particularly for these benchmarks. Additionally, it recommends providing more details about the evaluation procedures, which could be helpful for understanding the model\"s performance. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct a more careful analysis or what details about the evaluation procedures should be included. This limits the comment\"s usefulness, as it provides a general direction but does not offer actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy in the experimental part of the paper, specifically noting that the different metrics used for different OPE methods are not consistent across the figures. It explicitly asks the authors to provide comments on the differences between the two sets of evaluation methods. This request is clear and concrete, as it specifies the issue and suggests a specific action for the authors to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the differences between the two sets of evaluation methods in the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental part of the paper verifies different metrics for different OPE methods but notes a discrepancy in the figures. The reviewer suggests that the authors should provide comments on the differences between the two sets of evaluation methods. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the discrepancy and address it themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental part of the paper, noting that the different metrics used for different OPE methods are inconsistent across the figures. It suggests that the authors should provide comments on the differences between the two sets of evaluation methods. This feedback is clear and actionable, as it points out a specific area for improvement and provides a direct request for clarification. By addressing this issue, the authors can enhance the clarity and coherence of their experimental results. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the experimental results, noting that the proposed method does not show any advantage without prior information, but only when using prior knowledge. It suggests that this comparison is unfair because the proposed method requires two separate representation models to be learned for each dataset. The reviewer implies that this additional complexity and cost should be considered. While the comment identifies an issue with the experimental setup, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should consider the extra complexity and cost of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the comparison with the SOTA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed method only shows an advantage when using prior knowledge, suggesting that the comparison is unfair due to the additional complexity and cost of learning two separate representation models. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not show any advantage without prior information but only when using prior knowledge. The reviewer supports this claim by explaining that the method essentially requires two separate representation models, which adds complexity and cost. This reasoning is logical and based on the experimental results, making the claim 4. However, the comment could be strengthened by providing specific examples or references to the additional complexity and cost, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not show any advantage without prior information but only when using prior knowledge. It highlights that this comparison is unfair because the proposed method essentially requires two separate representation models to be learned for each dataset, which adds complexity and cost. This feedback is valuable as it points out a potential weakness in the experimental setup and suggests that the authors consider the additional complexity and cost of their method. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or how to design a more fair comparison. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include collaborative games in their experiments to explore how the evaluated methods behave in both collaborative and competitive settings. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to implement this suggestion or what specific collaborative games should be included. The authors are left to infer the details of how to incorporate collaborative games into their experiments, which could be improved with more concrete instructions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, it does not specify which part of the paper this issue pertains to, such as the sections where the experiments are described or the methodology section. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in the experiments and recommends including them to explore the behavior of the evaluated methods in both collaborative and competitive settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or necessary. Without such information, the authors may find it challenging to understand the basis of the suggestion and how it could enhance their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting the absence of collaborative games in the experiments. It suggests that including such games would be interesting and could provide valuable insights into the behavior of the evaluated methods in both collaborative and competitive settings. This feedback is clear and actionable, as it directs the authors to consider adding a new aspect to their experiments that could enhance the depth and relevance of their work. However, the comment could be more helpful if it provided specific examples of collaborative games or detailed guidance on how to incorporate them into the existing experimental design. Overall, the comment is 4 as it points out a meaningful area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific settings to include or suggesting ways to improve the figures. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of experimental settings for these figures, making them difficult to be convincing. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the absence of experimental settings for figures 1 to 9. This is a critical observation that could impact the credibility and persuasiveness of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the figures. While it points out a problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the rationale behind the work, specifically regarding the observation that current parameter isolation methods hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment identifies a specific area for clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rationale behind the work, specifically the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this rationale is based on, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the proposed method and its potential impact on task knowledge acquisition. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rationale behind the work is based on the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. The reviewer suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the rationale behind the work, specifically regarding the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests that the authors should clarify how their proposed method avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage the sparsity exhibited by activation channels in deep networks. While the comment highlights an important area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential gap in the rationale, but it could be more beneficial with additional details or examples on how to improve the clarity of the explanation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the adhoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. It also points out that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. While the comment identifies areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific statistics to use. The authors are left to infer that they should explore alternative statistics and provide a more robust theoretical justification for their approach. Therefore, the comment is 3, as it highlights areas for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the regularization term, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the adhoc nature of the regularization term and suggests alternative statistics that could be used to replace the mean and standard deviation. The comment provides a clear direction for improvement by suggesting the use of the median, which is not sensitive to outlier values. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the adhoc nature of the regularization term and suggests that the lack of theoretical support is a weakness. It provides a logical reasoning by suggesting that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment lacks specific examples or references to support the claim that the median is a better choice. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the adhoc nature of the regularization term and the lack of theoretical support. It suggests that the authors should explore alternative statistics, such as the median, to replace the mean and standard deviation in the regularization. This feedback is clear and actionable, as it provides specific suggestions for improving the theoretical foundation of the paper. However, the comment could be more helpful if it included examples or references to support the use of the median or other statistics. Overall, the comment is 4 as it guides the authors toward a more robust theoretical justification for their approach."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It clearly states the action needed, which is to integrate benchmark comparisons against stateoftheart fairness algorithms. This provides a concrete and specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the integration of benchmark comparisons against stateoftheart fairness algorithms to enhance the paper. This provides clear guidance on how to improve the experimental section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This claim is 3 as it logically suggests that comparisons with existing fairness algorithms would strengthen the paper, but it lacks specific examples or references to existing work that could be used for comparison. The authors would need to infer the specific fairness algorithms to include and how they would enhance the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting the absence of comparisons with existing fairness algorithms. It suggests that integrating benchmark comparisons against stateoftheart fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\"s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. This feedback is clear and actionable, offering a concrete suggestion for improvement that could significantly impact the paper\"s impact and credibility. However, it could be more helpful if it provided specific examples of existing fairness algorithms that should be compared. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of their proposed method and to include the iteration cost of all related methods, including baseline methods. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and direct, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the iteration cost should be discussed, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the iteration cost of the proposed method and the iteration cost of related methods, including baseline methods. This provides clear guidance on what the authors need to include in their discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the iteration cost is a critical aspect to discuss. The authors are left to infer the importance of this discussion themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method and compare it to the iteration cost of related methods, including baseline methods. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including a detailed discussion on computational efficiency. By addressing this point, the authors can improve the comprehensiveness and clarity of their work. However, the comment could be more helpful if it included specific examples or references to similar studies that have addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It explicitly instructs them to report average results over multiple runs, which is a clear and actionable step. It also suggests discussing the decision boundaries in the toy dataset, which is another actionable point. Additionally, it asks for clarification on what information is in Fig. 9, which is a specific request for more detail. Each of these points is directly actionable, providing the authors with clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experimental section\" and specific sections within it, such as \"Sec. 3.1\" and \"Sec. 3.3.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be addressed, such as reporting average results over multiple runs, discussing the decision boundaries in the toy dataset, and clarifying the information in Fig. 9. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple requests for clarification or additional information, rather than making subjective claims or judgments. It does not contain any opinions, suggestions, or critiques that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the experimental section of the paper. It explicitly instructs the authors to report average results over multiple runs, which is a clear and important step to ensure reproducibility and robustness. Additionally, it suggests discussing the decision boundaries in the toy dataset, which could provide valuable insights into the method\"s behavior. Finally, it asks for clarification on the information in Fig. 9, which could help the authors better present their findings. These suggestions are clear and actionable, offering the authors specific ways to enhance the clarity and robustness of their experimental results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the dimensionality problem or suggestions for potential solutions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed model, specifically that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the model\"s dimensionality, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This is a relevant observation that could impact the applicability and scalability of the model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate its impact on the model. Without actionable advice or additional context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the model. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the use of supervised pretraining and its potential impact on downstream tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prediction of homolumo gap\" and the \"QM9 in downstream experiments,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the TransformerM model performs poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that supervised pretraining based on the prediction of homolumo gap may lead to negative transfer, as evidenced by TransformerM\"s poor performance on most tasks except for homo, lumo, and gap. The reviewer provides an example from downstream experiments on QM9, which supports the claim. However, the comment could be strengthened by providing more detailed analysis or references to similar studies that have observed similar negative transfer effects. As it stands, the claim is 4 due to the example provided, but it could be further substantiated with additional evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of supervised pretraining based on the prediction of homolumo gap, suggesting that it may lead to negative transfer. It provides an example of TransformerM performing poorly on most tasks except for homo, lumo, and gap, which contradicts the paper\"s description of a generalpurpose neural network model. This feedback is 3 as it highlights a potential weakness in the paper\"s claims and suggests that the authors should reconsider their approach. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue or mitigate negative transfer. Overall, the comment is 3 as it points out a potential problem but lacks detailed guidance on how to resolve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" statement on lines 8082 regarding the center correlation not being insightful for discriminating model defenses, but then using it in figure 4 A&B. The reviewer questions why the metric was considered useful in one place but not another, or what the authors meant by their statement. This comment implies that the authors should clarify their reasoning or provide additional context to explain this inconsistency. However, it does not explicitly instruct the authors to do so, leaving the action implicit. The comment is 3 as it points out a potential inconsistency that the authors need to address, but it lacks concrete guidance on how to do so.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (8082) and figures (A&B), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" reasoning for using the center correlation metric in figure 4 A&B, despite claiming it is not insightful for discriminating model defenses. This provides clear guidance on what needs to be addressed, namely the inconsistency in the authors\" reasoning or the clarification of their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" statement about the center correlation not being insightful for discriminating model defenses, as it is used in figure 4 A&B. The reviewer is seeking clarification on why the metric is considered useful in one place but not another, or what the authors meant by their statement. This is a request for clarification rather than a subjective claim or opinion, making it a factual observation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" reasoning regarding the center correlation metric. It points out that the authors claim it is not insightful for discriminating model defenses but then use it in figure 4 A&B. This feedback is valuable as it prompts the authors to clarify their reasoning or provide additional context to explain this inconsistency. By addressing this issue, the authors can improve the coherence and credibility of their work. However, the comment could be more helpful if it suggested specific ways to clarify the authors\" statement or provided examples of how the center correlation could be used effectively in figure 4. Overall, the comment is 4 as it directs the authors to an important area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"distributional generalization\" may be too strong to accurately represent the empirical phenomenon presented. It points out that the total variation between the test and train distributions of the network\"s outputs might not be zero, and that this conclusion is difficult to draw from a few test functions where the outputs match. However, the comment does not provide explicit guidance on what term or phrasing would be more appropriate or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative terms or phrasing to better represent the phenomenon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"distributional generalization,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it might be too strong to capture the empirical phenomenon presented and suggesting that the total variation between the test and train distributions of the network\"s outputs might not be zero. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the appropriateness of the term \"distributional generalization\" to describe the phenomenon presented, suggesting that it might be too strong. The reviewer provides a logical reasoning by explaining that the term implies a total variation between the test and train distributions of the network\"s outputs, which might not be the case. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"distributional generalization\" used to describe the phenomenon presented in the paper. It points out that the term might be too strong and suggests that the total variation between the test and train distributions of the network\"s outputs might not be zero, which could be a misleading conclusion. The comment provides a clear and actionable suggestion for the authors to reconsider the term and its implications, which could help improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered specific alternative terms or phrasing to use instead. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong\" and points out that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their draft. It lacks guidance on how to address the issues raised or suggestions for enhancing the theoretical contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the theoretical contribution of the paper, specifically mentioning that it is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment does not specify which part of the paper this critique is based on, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issues with the theoretical contribution, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical contribution is \"ok but not particularly strong\" and that it is a weak, unpractical bound. It also notes that the proof does not provide significant mathematical novelty. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the theoretical contribution as \"ok but not particularly strong,\" indicating that it is a weak and unpractical bound. It also notes that the proof lacks significant mathematical novelty. While the comment identifies a potential weakness in the theoretical contribution, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the paper. Without actionable feedback or detailed advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. While the comment provides explicit actions to take, such as including ablation and using the same setup as in the DEN paper, it does not specify how to implement these actions. The authors are left with a clear understanding of what needs to be done but may need to infer the exact steps to follow. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation 2.1. Ablations 2.1.1\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental evaluation, such as the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. Additionally, it points out the need for a more comprehensive comparison with the DEN paper, including using the same setup. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation for the \"picking\" step and that the comparison on CIFAR is not convincing. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper. The comment provides some logical reasoning by pointing out the need for ablation and a more comprehensive comparison, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a basis for the critique but requires further elaboration to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several issues with the experimental evaluation, including the lack of ablation for the \"picking\" step and the inadequacy of the comparison on CIFAR. It suggests that the authors should include ablation for this step and provide a more comprehensive comparison with the CIFAR dataset, including using the same setup as in the DEN paper to ensure fairness and correctness. This feedback is clear and actionable, as it provides specific guidance on how to improve the experimental evaluation section. However, it could be more helpful if it included examples of what ablation should entail or how to set up the comparison with the DEN paper. Overall, the comment is 4 as it directs the authors to make significant improvements in their experimental evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use \"above/below diagonal\" instead of \"above/below 45 degree\" to make the plot easier to interpret. While the comment provides a specific suggestion for clarity, it does not offer detailed guidance on how to implement this change or why it is necessary. The action is explicit but somewhat vague, as the authors know they need to make the change but may not be entirely sure of the exact implementation or rationale behind it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plot\" and suggests a specific change to \"above/below diagonal\" instead of \"above/below 45 degree.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the plot labels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that \"above/below diagonal\" is easier to interpret than \"above/below 45 degree,\" which is described as a local property. The reviewer provides a logical reasoning that \"above/below diagonal\" is clearer because it refers to a visual aspect, while \"above/below 45 degree\" is more ambiguous. However, the comment lacks specific examples or references to support the claim that \"above/below diagonal\" is more interpretable. This makes the claim 3, as the authors may find it challenging to fully understand and address the issue without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to improve the clarity of the plot by using \"above/below diagonal\" instead of \"above/below 45 degree.\" This feedback is actionable and offers a clear and concise way for the authors to enhance the interpretability of their plot, which is a valuable contribution. However, the comment could be more helpful if it explained why \"above/below diagonal\" is more intuitive or provided examples of how this change might improve the plot. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for enhancing the clarity of the plot."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer implies that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment does not provide explicit guidance on how to clarify this point or what specific changes should be made to improve the clarity. While the action is implied, it is not directly stated, and the authors are left to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the phrasing and suggesting that the authors might be trying to convey that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the phrasing in lines L240 and L428, specifically asking for clarification on what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. However, the comment lacks specific examples or references to support this interpretation, making it 3. The authors would need to infer the intended meaning and potentially revise the phrasing to align with the reviewer\"s suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the phrasing in lines L240 and L428, questioning what is meant by \"is sufficient.\" The reviewer provides a logical interpretation of what the authors might be trying to convey, suggesting that the sum of the \"optimistic\" hopedfor rewards is close to the expected actual rewards. This feedback is 3 as it points out a potential area for clarification and improvement in the draft. However, it lacks specific suggestions or guidance on how to clarify the phrasing or what changes to make to enhance the clarity. While it provides some insight, the comment could be more actionable with additional details. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of clarity regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It specifically questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior. The reviewer does not provide explicit guidance on how the authors should address this issue, but the implication is that they should provide a clearer explanation of the relationship between their work and prior taskoptimized approaches. The comment is 3 as it identifies a gap in understanding but lacks concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scientific insight provided by the model and formalism over prior taskoptimized approaches. The comment highlights a lack of clarity regarding the relationship between the model and nonlinear RNN models that exhibit emergent behavior. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scientific insight provided by the model and formalism over prior taskoptimized approaches. It claims that the model is not shown to be a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a critical point for understanding the contribution of the work. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide additional evidence or reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the scientific insight provided by the model and formalism over prior taskoptimized approaches. It questions whether the model is a prototype approximation to nonlinear RNN models that exhibit emergent behavior, which is a crucial aspect of understanding the contribution of the work. The comment highlights a lack of clarity regarding the relationship between the model and prior taskoptimized approaches, suggesting that the authors need to provide a clearer explanation of their work. While the comment identifies an important area for improvement, it could be more helpful if it offered specific suggestions or examples of how the authors might address this issue. Overall, the comment is 3 as it points out a critical weakness but lacks detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the texts in legends and axis labels larger, similar to the text size. It also clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. These actions are direct and concrete, providing clear guidance on how to improve the draft. The authors know exactly what changes to make, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, and the beginning of page 6, where Proposition (1) is discussed. It also provides specific suggestions for improvement, such as increasing the font size of captions and legends in Figures 2 and 3, and clarifying the confusion between Proposition (1) and Equation 1. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the texts in legends and axis labels should be larger, similar to the text size, and that there is confusion between Proposition (1) and Equation 1. The comment provides a specific suggestion to clarify the confusion by increasing the font size of captions and legends in Figures 2 and 3. This is a logical suggestion based on the need for clarity in the presentation of information. However, the comment lacks specific examples or references to support the claim that larger font sizes would improve clarity. Therefore, the comment is 3, as it provides a logical basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the clarity and readability of the paper. It points out that the texts in legends and axis labels should be larger, similar to the text size, which is a clear and straightforward suggestion. Additionally, it clarifies the confusion between Proposition (1) and Equation 1 and suggests increasing the font size of captions and legends in Figures 2 and 3. This feedback is 5 as it directly addresses issues that can enhance the readability and comprehensibility of the paper, empowering the authors to make significant improvements to their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments. It specifies that this comparison should be made at a particular step of the sampling trajectory, referring to Figure 2 in Journey TRAK. This provides a clear and concrete action for the authors to take, as they are given specific steps to follow in order to enhance their experimental analysis. The comment is 5 as it provides a direct and specific guidance on how to improve the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the counterfactual experiments and suggests a comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely a comparison against Journey TRAK at a particular step of the sampling trajectory, as shown in Figure 2. This provides clear guidance on what the authors should include in their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison against Journey TRAK should be included in the counterfactual experiments. It references Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This claim is 3 as it provides a specific example from an external source to support the suggestion. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the counterfactual experiments. It recommends including a comparison against Journey TRAK, which is an external work, at a particular step of the sampling trajectory. This suggestion is based on a specific observation from Figure 2 in Journey TRAK, which shows a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. By suggesting this comparison, the reviewer offers a clear and constructive way for the authors to enhance their experimental analysis. However, the comment could be more helpful if it provided additional context or justification for why this comparison is important or how it might impact the overall understanding of the results. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It points out that Table 3 shows ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). The reviewer suggests that the placement of adaptive convolutions is important, but no analysis or comments are provided on this aspect of the technique. While the comment identifies a potential issue, it does not offer specific guidance on how the authors should address this issue or what kind of analysis or comments would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should include analysis or comments on the placement of adaptive convolutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table3\" and \"ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of adaptive convolutions and suggests that the placement of adaptive convolutions is important, but it does not provide further details or suggestions on how to address this issue. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that replacing normal convolutions with adaptive convolutions does not always lead to better performance, based on the experimental results in Table 3. The reviewer provides a specific example, ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer), to support this claim. This provides a clear and concrete example, making the claim 4. However, the comment could be strengthened by providing additional analysis or references to similar studies that support this observation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of adaptive convolutions in the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions does not always lead to better performance. It provides a specific example from Table 3, where ACNNv3 (all adaptive convolutions) performed worse than ACNNv2 (adaptive convolutions only in the last layer). This observation highlights the importance of the placement of adaptive convolutions, which is a valuable insight for the authors. However, the comment lacks detailed analysis or suggestions on how the authors might address this issue or what aspects of the technique should be analyzed further. While it points out a potential area for improvement, it does not provide actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should consider the implications of the tradeoff and possibly explore ways to mitigate it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"ancestral graphs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It questions how much information of a DAG is encoded in its corresponding ancestral graph. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the reduction in search space results in a loss of information. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential tradeoff between computational time reduction and the loss of information due to the reduction of the search space to ancestral graphs. It raises a question about how much information of a DAG is encoded in its corresponding ancestral graph, which is a relevant concern for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important aspect of the paper, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not provide explicit guidance on how to achieve this improvement or what specific aspects of the theoretical discussions should be addressed. The action is implied and somewhat vague, as the authors are left to infer that they should include sample complexity results but without detailed instructions on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the theoretical discussions needs improvement or where these results should be included. The authors can infer that it relates to the theoretical sections, but the comment lacks full grounding as it does not explicitly mention a specific section or line. The suggestion is specific in terms of what is expected, but the lack of grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could benefit from improvements, specifically mentioning the need for sample complexitytype results related to not returning NSF. The reviewer provides a specific expectation, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This suggestion is based on a logical expectation of what could be included in the theoretical discussions, but it lacks specific examples or references to support the claim. Therefore, the comment is 3, as it provides a clear direction but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could benefit from additional analysis or results related to sample complexity. It provides a clear and actionable suggestion by asking for specific results, such as \"given confidence levels, what is the sufficient amount of training data points that would not return NSF.\" This feedback is valuable as it guides the authors to enhance their theoretical discussions and provide more depth to their analysis. However, the comment could be more helpful if it offered examples or references to similar studies that have explored these topics, which would further empower the authors to implement the suggested improvements. Overall, the comment is 4 as it provides a clear direction for enhancing the theoretical discussions."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the description of the VAD is puzzling and suggests that the authors should clarify what they mean by \"discarding TF bins with a magnitude of less than epsilon.\" It also notes that this approach is not consistent with a VAD, which is supposed to look for speech presence and is unlikely to be defined over frequency. The comment implies that the authors should reconsider their definition and approach to VAD. While the action is implicit, it is clear and concrete, as it provides a specific direction for the authors to take in revising their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic with the VAD description, namely that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The comment further explains that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the authors are discarding TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer argues that a VAD should look for speech presence and is unlikely to be defined over frequency, which is a common understanding in the field. The comment provides a logical reasoning and references common knowledge about VADs, making it 4. However, it could be strengthened by providing specific references or examples to support the claim about VADs and their definition. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the description of the VAD, noting that it discards TF bins with a magnitude of less than epsilon, which is not consistent with a VAD. The reviewer points out that a VAD should look for speech presence and is unlikely to be defined over frequency, providing a clear understanding of what a VAD should entail. This feedback is valuable as it highlights a critical misunderstanding in the paper that could impact its validity and clarity. However, the comment could be more helpful if it offered suggestions on how to clarify or correct the VAD description, such as providing examples of how a VAD should operate or recommending specific changes to the paper. Overall, the comment is 4 as it identifies a critical issue and points out a potential misconception, but it could be more actionable with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including a brief discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. It provides a specific example of what could be discussed, namely the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is explicit and provides concrete guidance on what the authors should add to their discussion. The action is clear and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"discussion\" and \"Section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the empirical motivation for a timevarying Q ^ t and S t , and provides an example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer provides a specific example of what could be discussed, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by referencing specific studies or examples to support the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the draft. It highlights the need for a discussion on the empirical motivation for a timevarying Q ^ t and S t , as opposed to a fixed one. The reviewer offers a specific example of what could be explored, such as the effect on the volatility of \u03b1 t and the average lengths of the predictive intervals when Q ^ t and S t vary with time. This feedback is valuable as it guides the authors to include a relevant and potentially insightful discussion in their paper. However, the comment could be more helpful if it provided additional context or references to similar studies that have explored this topic. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. It also mentions that the literature has shown that regression methods do not significantly influence the results. The reviewer suggests that the authors clarify this issue and provides a potential solution by suggesting that direct regression to the center point is sufficient. However, the comment does not explicitly instruct the authors to clarify this point or provide specific guidance on how to address the issue. While the action is implied, it is not as clear as it could be, leaving the authors with a vague understanding of what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer provides a detailed explanation of the potential confusion regarding the methods and suggests that the authors clarify this issue. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the definitions in Table 1, specifically questioning the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer cites the literature to support their claim that regression methods do not significantly influence the results. However, the comment lacks specific references to the literature or detailed explanations of the differences between the methods. This makes it 3, as the authors would need to conduct further research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions and differences between various regression methods mentioned in the paper, specifically in Table 1. It highlights a potential confusion regarding the differences between anchorbased regression, regression in RepPoints, and oneshot regression in RetinaNet. The reviewer suggests that the authors clarify this issue to strengthen the motivations and foundations of their work. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the methods and their implications. However, the comment could be more helpful if it offered specific suggestions on how to clarify the definitions or provided examples of how the methods differ. Overall, the comment is 4 as it identifies a critical area for clarification and guidance, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. It also mentions that the experiments lack something to hang on to. However, it does not provide specific guidance on how to improve the clarity or intuition of the paper. The authors are left without actionable steps to take to address these issues. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not specify which parts of the paper are particularly challenging or where the lack of intuition is most apparent. Without specific references to sections, figures, or experiments, the authors cannot confidently determine which parts need attention. Additionally, the comment does not provide specific guidance on how to improve the clarity or intuition of the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not easy to follow and lacks a clear intuition for how the pieces fit together. However, it does not provide specific examples or detailed reasoning to support this claim. The comment suggests that the experiments lack something to hang on to, but it does not specify what this \"something\" is or how it could be improved. Without concrete evidence or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, stating that it is not easy to follow and lacks a clear intuition for how the pieces fit together. It also notes that the experiments lack something to hang on to, which further contributes to the lack of clarity. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or intuition of the paper. While it highlights areas for improvement, the feedback is incomplete and lacks actionable steps, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. The reviewer explicitly requests KID/FID metrics for the teacher network, providing a clear and concrete action for the authors to take. This guidance is explicit and specific, leaving no ambiguity about what needs to be done to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"student and refinement networks\" and the \"teacher network,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the fairness of the comparison and requests KID/FID metrics for the teacher network. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the fairness of the comparison between the student and refinement networks, suggesting that the teacher network\"s performance may be improved by training them simultaneously. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between the student and refinement networks, suggesting that training them simultaneously may improve the performance of the teacher network. It explicitly requests KID/FID metrics for the teacher network, which is a clear and actionable request that can help the authors evaluate and improve their work. However, the comment could be more helpful if it provided additional context or examples of how these metrics could be used to assess the fairness of the comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a concrete action to take, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the refined region vector, specifically questioning whether the attention weight is scaled before being used in the calculation. The reviewer suggests that having a scaling variable before the attention weight might help. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding a scaling variable before the attention weight. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the refined region vector and suggests that having a scaling variable before the attention weight might help. The comment provides a clear direction for improvement by asking whether the refined vector scales only the most important regions before global pooling. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. The reviewer suggests that having a scaling variable before the attention weight might help. However, the comment lacks specific reasoning or evidence to support why this change would be beneficial or how it would affect the results. Without detailed explanation or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the refined region vector, specifically the scaling factor applied to the attention weight before global pooling. It suggests that having a scaling variable before the attention weight might help. This feedback is 3 as it prompts the authors to consider a potential improvement in their methodology. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this change or why it might be beneficial. To be more helpful, the comment could offer suggestions on how to test or evaluate the impact of this change. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the LLM\"s ability to accurately recover the formal goal predicate or how to handle ambiguities in human language. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of goal misspecification and the impact on the LLM\"s performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the LLM not accurately recovering the formal goal predicate, especially when faced with ambiguities in human language. This is a critical observation that could impact the performance and reliability of the LLM. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific recommendations or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a potential problem but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to take, it lacks specific guidance on how to conduct the analysis or what specific aspects of the analysis should be focused on. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"IGEV\" and \"SOTA methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. Additionally, it raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. This provides clear guidance on what the authors need to address to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the improvement of the method over SOTA methods like IGEV is small, and questions whether there is no multipeak distribution problem in iterative optimization schemes similar to IGEV. The reviewer provides a suggestion to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This claim is 3 as it logically questions the improvement over IGEV and suggests a potential explanation through analysis. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to analyze the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved on IGEV. This feedback is valuable as it guides the authors to conduct a specific analysis that could help them understand and address the issue. Additionally, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV, prompting the authors to consider potential limitations or areas for improvement. Overall, the comment is 4 as it offers clear and actionable guidance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide modelspecific insights by investigating how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It also recommends presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. While the comment provides a clear action to take, it does not specify how to conduct this investigation or what specific aspects of the models should be analyzed. The authors are given a general direction but may need to infer the details of how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ModelSpecific Insights\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the investigation into how specific models behave differently when ReGuide is applied and the presentation of differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper focuses on generic findings across models and recommends a deeper investigation into how specific models behave differently when ReGuide is applied. The reviewer provides a specific example of GPT4o and InternVL2, suggesting that differences in false positive rates (FPR) should be presented for a better comparison. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s analysis, but it lacks detailed evidence or references to support the claim that these specific models behave differently. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending a deeper investigation into how specific models, such as GPT4o and InternVL2, behave differently when ReGuide is applied. It suggests presenting differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This feedback is valuable as it directs the authors to a specific area where their analysis could be more nuanced and detailed, offering a clear path for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct this investigation or what specific aspects of the models should be analyzed. Overall, the comment is 4 as it identifies a meaningful area for enhancement and offers actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify whether the Fourier modes are real or complex numbers. This is an explicit request for clarification, providing a clear action for the authors to take. The comment is specific in detailing what needs to be clarified, making it 5. Authors know exactly what needs to be done to improve their draft, ensuring that the action is concrete. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not specify which part of the paper this clarification pertains to, such as a specific section or figure where this information is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper that needs clarification. Therefore, this comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests clarifying whether the Fourier modes are real or complex numbers. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would impact the understanding of the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests clarifying whether the Fourier modes are real or complex numbers, which is a specific and actionable piece of feedback. By addressing this point, the authors can improve the clarity and precision of their explanation, ensuring that readers can better understand the nature of the Fourier modes. However, the comment could be more helpful if it provided additional context or examples to guide the authors on how to effectively clarify this point. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure. This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed to be included in the paper. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to supplement the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure, allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. The comment is also specific because it clearly specifies what needs to be added to the paper, namely the supplementation of the result comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the result comparison of \"Iteratively greedy Search\" versus \"random search\" on the model structure should be supplemented. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the overall understanding of the results. Despite this, the feedback is 4 as it points out a specific area for improvement, which the authors can address to strengthen their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include results using the GCPG model without pretrained initializations to clarify the contribution of the task formulation and pretrained language models. This is a clear and direct action for the authors to take, as it provides a specific step to address the issue of attribution. The comment is specific in detailing what additional results are needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for results using the GCPG model without pretrained initializations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of the contribution of the task formulation and pretrained language models. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks ablations, specifically the results without pretrained language models. The reviewer claims that it is unclear how much performance gain is due to the task formulation and how much is because of pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a logical request to clarify the contribution of the task formulation. However, the comment does not provide specific examples or references to support the claim that the current results are unclear. This makes the claim 3, as the authors would need to make a logical inference to understand the basis of the suggestion.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of ablations to clarify the contribution of the task formulation and pretrained language models. It suggests using the GCPG model without pretrained initializations to provide a clearer understanding of the performance gains. This feedback is clear and actionable, as it directs the authors to include additional results that can help clarify their findings. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these ablations or why the GCPG model is particularly relevant. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that it is difficult to understand what the axes are for Figure 1. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the axes should be labeled more clearly or if additional explanations are needed. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve the clarity of the figure. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding the axes in Figure 1. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand what the axes are for Figure 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is 3 as it points out a clear area for improvement in the paper, which is the labeling and explanation of the axes. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or offer alternative ways to present the data. While it highlights an important issue, it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider presenting results on ImageNet to enhance the convincingness of their proposed method. While the comment implies that the authors should include these results, it does not provide specific guidance on how to conduct the experiments or what aspects of the results should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include results on ImageNet to improve the paper\"s credibility. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. However, it does not specify which part of the paper should include these results or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making this comment weakly grounded. The suggestion is specific in terms of what could be added to enhance the paper\"s credibility, but without clear grounding, it is difficult for the authors to effectively address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing for the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to justify why this would be beneficial or how it would enhance the credibility of the work. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that results on ImageNet could be more convincing for the proposed method. While it provides a general direction for improvement, it lacks specific guidance or examples on how to achieve this or what aspects of the results on ImageNet would be most impactful. The feedback is 3 as it points out a potential area for enhancement, but it does not offer detailed advice or actionable steps for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which may require additional computational costs. This implies that the authors should include direct runtime comparisons to demonstrate the efficiency of their proposed approach. The comment is clear and provides a specific action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for direct runtime comparisons with existing methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of implicit differentiation and its potential impact on runtime efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that direct runtime comparisons with existing methods are missing and that the proposed approach is based on implicit differentiation, which may require additional computational costs. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach. While the reasoning is logical and the claim is based on a common understanding of implicit differentiation and its computational implications, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a clear rationale but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper, noting the absence of direct runtime comparisons with existing methods. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach, which is based on implicit differentiation. This feedback is clear and actionable, as it directs the authors to include these comparisons to strengthen their claims about the efficiency of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or suggested potential methods for doing so. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states that the proposed framework is a simple combination of metalearning and federated learning and does not see any technical contribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the framework need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not specify which part of the paper discusses this framework, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the framework are considered unoriginal or lacking in technical contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed framework is a simple combination of metalearning and federated learning, lacking any technical contribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment critiques the proposed framework for being a simple combination of metalearning and federated learning, indicating a lack of technical contribution. However, it does not provide any specific examples or suggestions for improvement, nor does it explain why the combination is considered unoriginal or insufficient. Without actionable feedback or detailed reasoning, the authors are left without a clear understanding of how to address the critique or enhance their framework. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the insufficiency of the contribution and suggests that the authors should further explore how to leverage the connection between complementary and model robustness to improve model robustness. While the comment implies that more insightful findings or solutions should be included, it does not provide specific guidance on what these findings or solutions should be. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to be more comprehensive. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the contribution of the paper, specifically the connection between complementary and model robustness. It suggests that the authors should explore how to leverage this connection to improve model robustness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing, which is the exploration of how to leverage the connection for model robustness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution is insufficient and suggests that the authors should explore how to leverage the connection between complementary and model robustness to improve model robustness. The comment provides a logical reasoning by pointing out that the conclusion about the relationship between complementary and robustness is intuitive and could be easily obtained. However, the comment lacks specific examples or references to support the claim that the contribution is insufficient or to suggest how to leverage the connection. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern about the contribution of the paper, noting that the study of the connection between complementary and model robustness is insufficient. It suggests that the authors should explore how to leverage this connection to improve model robustness. While the comment highlights a potential area for improvement, it lacks specific guidance or examples on how the authors might address this issue. The feedback is 3 as it points out a gap in the paper, but it could be more beneficial with additional suggestions or detailed advice on how to enhance the contribution. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that the authors should focus on what the differences in representation are between clusters rather than on which clusters are \"best.\" However, it does not provide explicit guidance on how to implement this change or what specific aspects of the representation differences should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should prioritize the differences in representation over the selection of \"best\" clusters. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the focus on which clusters are \"best\" is an odd choice given the motivation of the paper. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where this focus is discussed. Without explicit references to sections or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the representation differences should be prioritized over the selection of \"best\" clusters. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, suggesting that this is an odd choice given the paper\"s motivation. However, the comment does not provide specific reasoning or evidence to support why this choice is problematic or how it affects the paper\"s goals. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential inconsistency in the paper\"s focus on which clusters are considered \"best\" rather than the differences in representation between them. This observation highlights a potential mismatch between the paper\"s motivation and its emphasis on cluster selection. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to better align the focus with the paper\"s goals. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly identifies a specific error in the caption for Figure 7, noting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to correct the caption. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption for Figure 7, from \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what the authors need to address to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current caption is incorrect or how the correction would improve the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific error in the caption for Figure 7, noting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This is a clear and actionable piece of feedback that the authors can easily address to improve the accuracy and clarity of their paper. However, the comment does not provide additional context or explanation about why this correction is necessary or how it might impact the overall understanding of the paper. While it is helpful in pointing out a specific error, it could be more beneficial if it included more detailed guidance or suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include case studies and error studies to highlight the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits of such an approach. While the comment explicitly states the need for case studies and error studies, it does not provide specific guidance on how to implement them or what aspects to focus on. The action is clear but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Elementlevel Graph Pretraining\" and the \"complex structure\" mentioned in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of case studies and error studies to highlight the effectiveness of each proposed component. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that case studies and error studies could be beneficial in demonstrating the effectiveness of each proposed component. It provides an example of a case study from \"Graph pretraining for AMR parsing and generation\" to illustrate the potential benefits. However, the comment lacks specific examples or detailed reasoning to fully substantiate why case studies and error studies are necessary or how they would enhance the paper. While it provides a logical argument, the lack of detailed evidence or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of each proposed component. It highlights the importance of such studies by referencing an example from \"Graph pretraining for AMR parsing and generation,\" which illustrates the potential benefits of including these analyses. This feedback is valuable as it offers a concrete way for the authors to enhance the persuasiveness and credibility of their work. However, the comment could be more helpful if it provided specific guidance on how to design and conduct these studies, such as what aspects to focus on or how to present the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer requests clarification on the rationale for considering these factors as separate evaluations. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their evaluation criteria. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The comment is specific in its critique of the evaluation criteria and provides a logical explanation of how they might be entangled. However, it does not explicitly mention which part of the paper discusses these evaluation criteria, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific examples or references to support the claim that these factors are already considered within the framework. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation for considering explicitness(E) and size(S) as additional evaluation criteria in the traditional DCI framework. It suggests that these factors may already be considered within the framework, such as evaluating disentanglement using a fixed capacity of probing and the latent size. The reviewer provides a logical explanation of how these factors might be entangled, suggesting that changing the capacity of probing or the latent size would affect the DCI evaluation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify their motivation for considering these factors as separate evaluations. While it identifies a potential weakness in the paper, the feedback does not provide actionable steps for improvement, making it 3. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is concrete, as it specifies the need for clarification and provides a direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies what needs to be clarified: the standard deviation after multiple experiments and the improvement brought by SoRA compared to the baseline. The comment provides guidance on how to address this issue by suggesting the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the improvement brought by the SoRA method is limited due to random fluctuations, suggesting that the standard deviation after multiple experiments is not provided. The comment provides a logical reasoning by pointing out that the improvement may be due to random fluctuations, but it lacks specific examples or references to support this claim. The authors are left to infer the significance of the standard deviation and its impact on the results, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section of the paper, noting the absence of standard deviation after multiple experiments. It also points out that the improvement brought by the SoRA method is limited, which may be due to random fluctuations. The comment provides clear and actionable feedback by suggesting that the authors clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This guidance is valuable as it helps the authors understand the significance of their results and how to present them more effectively. However, the comment could be more helpful if it offered suggestions on how to address the issue of limited improvement or how to better present the results. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. While the comment provides explicit actions for the authors to take, such as increasing font size and ensuring proper placement, it does not offer detailed guidance on how to address these issues. The authors are left to infer the specific steps needed to improve the organization and layout of their paper. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Figure 1,\" \"Figure 2,\" \"Table 2,\" and \"page 6,\" allowing the authors to accurately identify the areas being addressed. It also specifies the issues with the layout, such as the font size and placement of figures and tables, and the formatting of the top two lines on page 6. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and that the layout is rushed, providing specific examples such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. These examples are detailed and provide clear justification for the claim, making the comment 4. However, the comment could be strengthened by providing additional context or references to similar issues in other papers, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the organization and layout of the paper. It identifies issues such as the font size of annotations in Figures 1 and 2, the placement of Table 2, and the formatting of the top two lines on page 6. By pointing out these specific problems, the comment empowers the authors to make improvements that enhance the clarity and professionalism of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as providing examples of better formatting or offering alternative layout options. Overall, the comment is 4 as it provides clear guidance for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not provide specific guidance on how to assess or improve the practicality and safety of these interventions. The comment lacks concrete steps or examples on how to conduct this assessment or what aspects to focus on. As a result, the authors are left without clear direction on how to address this concern. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments where these interventions are discussed. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its suggestion to consider practicality and safety, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that while the types of interventions included in the paper are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that while the types of interventions included are reasonable computationally, it is important to consider their practicality and safety for querying in the real world. This feedback is 3 as it highlights an area that the authors should address to ensure their work is applicable and relevant in practical settings. However, the comment lacks specific guidance or suggestions on how to assess or improve the practicality and safety of these interventions. Without detailed advice or examples, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations or definitions, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"upper faces\" of the convex hull, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for better explanation of the dual subdivision and projection process, as well as the issue with the variable \"p\" not being explicitly defined. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the meaning of \"upper faces\" of the convex hull and the dual subdivision and projection process. It also points out the lack of explicit definition for the variable \"p,\" which has been used extensively throughout the paper. These are factual observations that do not contain subjective claims or opinions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several areas of confusion or lack of clarity in the paper, including the meaning of \"upper faces\" of the convex hull, the dual subdivision and projection process, and the variable \"p\" that is not explicitly defined. These are important issues that could impact the understanding and interpretation of the paper. The comment suggests that these areas need to be explained better, which is a clear and actionable piece of feedback. However, it could be more helpful if it provided specific suggestions on how to clarify these concepts or offered examples of how they might be explained. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific changes they could make to support the integration of images and their augmentations. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the idea are questionable or how it could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses skepticism about the idea that images and their augmentations need to be treated separately. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s skepticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses skepticism about the idea that images and their augmentations need to be treated separately, suggesting that they can be interchangeable. However, it does not provide any specific reasoning or evidence to support this claim or offer suggestions for how the authors might address this concern. Without actionable feedback or detailed guidance, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate their proposed method separately from baseline detection or parsing techniques to better support their claim of performance gain. This feedback provides a clear and explicit action for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. The suggestion is concrete, as it specifies the need for separate evaluations and provides a rationale for why this is important. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"generative shape model\" and the \"word parsing model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that it is unclear which component contributes to the performance gain and recommends evaluating the method separately from baseline detection or parsing techniques. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain, and suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. The comment provides a logical reasoning by suggesting that the proposed approach follows a detectionparsing paradigm, which implies that evaluating separately would be beneficial. However, the comment lacks specific examples or references to support the claim, such as mentioning which baseline techniques should be used or providing data to substantiate the claim. This makes the claim 3, as it provides a reasonable argument but lacks detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, noting that it is unclear which component contributes to the performance gain. It suggests that evaluating the method separately from baseline detection or parsing techniques would better support the claim. This feedback is actionable as it provides a clear direction for the authors to take, which is to conduct separate evaluations of their method and baseline techniques. By doing so, the authors can better understand the impact of their method and provide stronger evidence to support their claims. However, the comment could be more helpful if it included specific suggestions on which baseline techniques to use or how to structure the evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could be more interesting if it did not involve manual disentangling and instead demonstrated everything being learned. While the comment implies that the authors should reconsider their approach, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their methodology and potentially revise the paper to include more automated disentangling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the manual disentangling process and suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. The comment suggests that the paper could be more interesting if it demonstrated everything being learned without manual intervention. However, the comment lacks specific examples or references to support the claim that manual disentangling is not necessary or beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a logical suggestion but lacks the necessary support to fully substantiate it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the manual disentangling process in the paper, questioning why the semantic segmentation network is the first module in the pipeline and suggesting that the paper could be more interesting if it demonstrated everything being learned without manual intervention. This feedback is 3 as it prompts the authors to consider whether their approach is the most effective or if there are alternative methods that could be explored. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or methods for automating the disentangling process. While it identifies a potential area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of connection between the theoretical analysis and the proposed method, specifically regarding the use of selfattention mechanisms in the context of graph neural networks (GNNs). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to strengthen the connection between the theoretical analysis and the proposed method, or how to enhance the generalization for distant nodes. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical analysis and the proposed method, specifically mentioning the derivation of PACBayesian bounds for GNNs in the transductive setting and the interplay between training and testing sets. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing the lack of a strong connection between the theoretical analysis and the proposed method, as well as the use of selfattention mechanisms in the context of GNNs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical analysis does not have a strong connection to the proposed method, which seems to simply adopt the selfattention mechanism from transformers. The reviewer questions how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a gap in the connection between the theoretical analysis and the proposed method, specifically regarding the use of selfattention mechanisms in the context of graph neural networks (GNNs). It points out that the proposed method seems to simply adopt the idea of selfattention from transformers and apply it to graphs, without explaining how it enhances generalization for distant nodes. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might strengthen the connection between the theoretical analysis and the proposed method. This limits the comment\"s usefulness in helping the authors improve their draft. Therefore, the comment is 3, as it provides insight into a potential weakness but does not offer actionable advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the method is not clear about its behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific actions they should take to clarify the behavior. The comment lacks guidance on whether the authors should provide additional analysis, simulations, or explanations to address this concern. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Lipschitz Hessian assumption,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the method\"s behavior without the Lipschitz Hessian assumption. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that the method\"s behavior is not clear without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific aspects of the method need clarification. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some of the pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"equation (12)\" and \"the presentation of these methods,\" which provides some grounding by referencing specific parts of the paper. However, it does not specify which parts of the presentation are vague or unclear, making it weakly grounded. The comment is specific in identifying the issue of using existing methods and the vagueness in the presentation, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some pieces in the paper are using existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some pieces rely on existing methods, such as equation (12), and that the presentation of these methods is vague. This feedback is 3 as it points out a potential weakness in the paper\"s originality and clarity. However, the comment lacks specific suggestions or guidance on how to improve the presentation or clarify the use of existing methods. Without actionable advice or detailed feedback, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While the comment implies that the authors should provide explanations for these choices, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for these decisions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the main rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. This provides clear guidance on what aspects of the experimental setup need clarification or explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the experimental setup, specifically regarding the rationales for having a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the rationales behind certain decisions in the experimental setup, specifically regarding the use of a separate timbre encoder module and the input of outputs from the content encoder rather than the timbre encoder. While it identifies areas that need clarification, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is 3 as it points out potential areas for improvement, but it could be more beneficial if it offered more detailed advice or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include the results for all four datasets in Table 4, which provides a clear and direct action for the authors to take. The comment is specific in identifying the missing information and offers a concrete step to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included in the table, namely the results for all four datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and concrete step to improve their draft. By addressing this issue, the authors can enhance the comprehensiveness and accuracy of their results, which is valuable guidance for improving the paper. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific guidance or suggestions on how to improve it. There is no explicit or implicit action for the authors to take, such as suggesting ways to clarify or organize the content. Without any actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not specify which parts of the paper are affected. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or presentation are jumbled, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing or presentation is \"jumbled at times,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the critique or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment mentions that the writing or presentation is jumbled at times, but it does not provide any specific examples or guidance on how to improve the clarity or organization of the paper. Without actionable feedback or suggestions, the authors are left without a clear understanding of what aspects of their writing need attention or how to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment does not explicitly instruct the authors to perform a computational complexity analysis or provide guidance on how to address the power demand concern, it implies that the authors should consider these aspects. The action is implicit but concrete, as it points to specific areas that need attention. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where computational complexity is discussed. While the authors might have an idea of where this information is discussed, the comment lacks full grounding. It is specific in its inquiry about computational complexity and power demand, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. However, the comment lacks specific examples or references to support the claim about computational complexity or power demand. Without detailed evidence or comparisons, the claim is not 5, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a question about the total computational complexity of the method compared to other methods, specifically mentioning emerging convolutions. It also speculates about the potential power demand on a mobile device if the Woodbury flow were to be used. While the comment identifies a potential area for improvement by suggesting a comparison with other methods, it lacks specific guidance or suggestions on how to address the computational complexity or power demand concerns. The feedback is 3 as it points out a relevant area for consideration, but it could be more beneficial with additional details or suggestions on how to improve the draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It explicitly states that these heads are active at the S2 token but do not primarily attend to it, referencing Section 3 of Wang et al., 2023. This provides a clear and concrete action for the authors to correct the statement in their draft. The comment is explicit and provides specific guidance on how to revise the text, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific section of the paper, \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the incorrect claim about the attention of these heads and references Section 3 of Wang et al., 2023 to support its assertion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"In the base IOI circuit, the Induction, Duplicate Token, and Previous Token heads primarily attend to the S2 token\" is incorrect, citing Section 3 of Wang et al., 2023. This claim is supported by a specific reference to the external work, which provides a clear and verifiable basis for the assertion. The reviewer logically explains the correct behavior of these heads, making the claim 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies an incorrect statement in the paper regarding the attention of the Induction, Duplicate Token, and Previous Token heads in the base IOI circuit. It points out that these heads are active at the S2 token but do not primarily attend to it, which is a critical correction for the authors to make. The comment is clear and actionable, providing the authors with specific guidance on how to correct their draft. By addressing this issue, the authors can improve the accuracy and clarity of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not provide any specific guidance or suggestions on how the authors could improve the contribution or make it more novel. The comment lacks actionable details, such as recommending new approaches or improvements to the pipeline. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, it does not specify which part of the paper this assessment is based on, such as the methodology, results, or discussion sections. Without explicit references to specific sections, the authors cannot confidently determine which parts need attention or improvement. The comment is specific in its critique of the contribution being incremental, but it lacks grounding as it does not point to a particular part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the work is incremental and that the proposed pipeline is not particularly impressive or novel. It implies that the pipeline is a collection of tricks to improve defense evaluation, which could be seen as a negative critique. However, the comment lacks specificity and does not provide any actionable feedback or suggestions for improvement. It does not offer guidance on how the authors could enhance the novelty or impact of their work, nor does it provide constructive feedback on how to address the critique. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, it does not provide explicit guidance on how to develop a distributed version or what specific aspects need to be considered. The action is implied, as the authors can infer that they need to develop a distributed version, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the scalability of the method, suggesting that it is not scalable without a distributed version. However, it does not specify which part of the paper discusses the method or where the scalability issue is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the scalability issue but lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is not scalable and suggests that a distributed version is needed to accommodate realworld datasets. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the scalability of the method, suggesting that a distributed version is needed to accommodate realworld datasets. This is a relevant observation that could impact the practicality and applicability of the method. However, the comment lacks specific guidance or suggestions on how to develop a distributed version or what aspects of the method need to be adapted for scalability. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the eta_ri term is not clearly explained as a noncentral chisquared distribution. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to clarify this point. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"eta_ri term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the eta_ri term being a noncentral chisquared distribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the eta_ri term being a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this term should be considered unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the eta_ri term being a noncentral chisquared distribution. This is a clear and actionable point that the authors can address to improve the understanding and clarity of their work. However, the comment could be more helpful if it provided additional context or examples to help the authors better understand the implications of this clarification. Overall, the comment is 3 as it points out a specific area for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment provides explicit feedback on the vagueness of certain RNNs and suggests that the reinforcement learning/agent analogy is out of place. It also points to specific lines in the paper where generalization capabilities are better illustrated. While the comment identifies areas for improvement, it does not provide concrete guidance on how to address the vagueness or suggest specific changes to the analogy or examples. The authors are left with a general idea of what needs to be improved but without detailed instructions on how to implement these improvements. Therefore, the comment is 3, as it provides a direction but lacks specificity in execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, \"L15\" and \"L1618,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the vagueness of certain RNNs and the reinforcement learning/agent analogy, providing clear guidance on what needs to be addressed. The comment is specific in detailing the problem with the vagueness and suggesting that the examples later in the paper better illustrate generalization capabilities. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the vagueness of certain RNNs and the reinforcement learning/agent analogy are out of place in the context of the paper. The reviewer provides a specific reference to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. However, the comment lacks detailed reasoning or specific examples from the literature to fully substantiate the claim. While the reference provides some support, the comment could be strengthened by further elaboration on why the analogy is inappropriate or how it could be improved. Therefore, the comment is 3, as it provides a starting point but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment provides specific feedback on the vagueness of certain RNNs and the reinforcement learning/agent analogy in the paper. It suggests that the examples later in the paper better illustrate generalization capabilities, which is a valuable point for the authors to consider. However, the comment could be more helpful by offering suggestions on how to address the vagueness or provide examples of how the analogy could be improved. While it identifies areas for improvement, the feedback lacks depth and specific guidance, making it 3 but not comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion, and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide more detailed analysis or justification for the proposed algorithm, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.5\" and \"the third figure,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of difference in terms of StableDiffusion and the need for further discussion, as well as the absence of mathematical or theoretical justification for the proposed Algorithm.1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion and that there is a lack of mathematical or theoretical justification for the proposed Algorithm.1. The comment provides some logical reasoning by pointing out the lack of difference in StableDiffusion, but it lacks specific examples or references to support the claim. The absence of detailed evidence or examples makes it 3, as the authors would need to infer the significance of the observation and the need for justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the proposed sensitivelayer selection against randomized selection does not make a significant difference in terms of StableDiffusion. It also points out the lack of mathematical or theoretical justification for the proposed Algorithm.1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their analysis. The feedback is 3 as it directs the authors to areas needing further exploration and justification, but it could be more actionable with specific recommendations or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. This is a clear and direct action for the authors to take, as it provides a specific guidance on how to improve the presentation of their data. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of triples as tuples instead of sets. This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuples instead of sets to better illustrate their tuplelike structure. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the triples denoted as $(e_1, r, e_2)$ be presented as tuples instead of sets. This feedback is clear and directly addresses a potential issue with the presentation of the data, which could enhance the readability and understanding of the paper. By following this suggestion, the authors can improve the clarity and precision of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of speed analysis in the experiments, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that the improvement on inference speed would be more interesting than reducing FLOPs. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include speed analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of speed analysis and the comparison of inference speed between the proposed network and prior work. It specifies the issue by pointing out the absence of such comparisons, which allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly articulates the need for comparisons of inference speed and why this would be more interesting than reducing FLOPs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of speed analysis is a significant issue, as it suggests that the experiments have focused on comparing GFLOPs of different segmentation networks but not on inference speed. The reviewer argues that the improvement in inference speed would be more interesting than reducing FLOPs. This claim is 3 as it provides a logical reasoning for why the authors should focus on inference speed, but it lacks specific examples or references to support the claim. The authors might need to infer the importance of inference speed themselves, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of speed analysis in the experiments. It points out that while the experiments compare GFLOPs of different segmentation networks, there is no comparison of inference speed between the proposed network and prior work. The reviewer suggests that the improvement in inference speed would be more interesting than reducing FLOPs, providing a clear and actionable suggestion for the authors to include speed analysis in their experiments. This feedback is 4 as it directs the authors to a critical area for improvement, but it could be more helpful if it included specific guidance on how to conduct the speed analysis or what aspects to focus on. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). The reviewer notes that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. While the comment identifies a potential issue, it does not provide explicit guidance on how to address this scalability problem or suggest specific actions to improve the scalability of the quantization. The authors are left to infer that they need to address this issue, but without concrete steps, the comment remains 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of scalability in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the problem of quantization being a bottleneck for the method, which is crucial for the authors to understand and address. The comment is specific because it clearly outlines the issue with scalability and the impact on the method\"s purpose. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It also notes that even with clustering before, the cost of quantization is high in terms of both N (number of data) and M (dimension). The reviewer further explains that the paper aims to speed up VI by achieving fast convergence, which is crucial for big data/big model settings. However, the reviewer suggests that the quantization is a bottleneck for this, making the method lose its purpose. The claim is supported by logical reasoning and references to the paper, providing a clear understanding of the issue and its implications. Therefore, the comment is 5, aligning with a score of 5.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, which is mentioned in the paper. It points out that even with clustering before, the cost of quantization is high in terms of both the number of data (N) and the dimension (M). This is a significant concern, as it affects the speed of VI and the method\"s applicability to big data/big model settings. The reviewer highlights that the paper aims to speed up VI by achieving fast convergence, which is crucial for these settings. However, the comment notes that the quantization is a bottleneck for this, making the method lose its purpose. This feedback is valuable as it highlights a critical weakness in the paper that the authors need to address to improve its impact and applicability. The comment is 3 as it provides a clear direction for improvement, but it could be more helpful if it offered specific suggestions on how to improve the scalability of the quantization. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their methodology against existing methods, such as contrastive decoding, and to address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. The comment provides clear and concrete actions for the authors to take, including specific comparisons to make and issues to address. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Contrastive Response Tuning\" and \"core methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is comparing the effectiveness of the method against existing methods like contrastive decoding and addressing issues mentioned above. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to existing methods or issues that need to be addressed. This makes the claim 3, as the authors would need to infer the specific methods and issues to be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address issues mentioned above. It also suggests that if the work does not compare effectively, it should aim for a more applicationoriented venue. This feedback is specific and constructive, guiding the authors on how to enhance the rigor and relevance of their work. However, the comment could be more helpful if it provided examples of specific issues or comparisons to consider. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. It also points out that the validation experiments are not comprehensive and that the time complexity and efficiency of the computation are not clearly analyzed. Additionally, it suggests that the authors should further elucidate the technical contribution rather than the form of the attack. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer what changes are needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. The comment also lacks specificity in terms of what needs to be addressed regarding the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the effectiveness and problem of the algorithm, suggesting that it requires access to the entire training dataset and questioning how it would operate effectively when the dataset is not fully perceptible. It also critiques the validation experiments as not comprehensive and points out that the time complexity and efficiency of the computation are not clearly analyzed. The reviewer expects the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the effectiveness and problem of the algorithm, the validation experiments, and the technical contribution. It points out that the algorithm requires access to the entire training dataset and questions how it would operate effectively when the dataset is not fully perceptible. Additionally, it critiques the validation experiments as not comprehensive and suggests that the time complexity and efficiency of the computation are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution rather than the form of the attack. While the feedback provides clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 3 as it highlights important areas for improvement, but it lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a statement in the paper that claims that every kernel can be described by a feature space parameterized by a neural network, which is not true. The reviewer suggests that the limitation of representing infinitedimensional RKHSs with neural networks should be made more clear. While the comment identifies a specific issue with the claim, it does not provide explicit guidance on how to address it or what specific changes should be made to clarify the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation, but it lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.\" This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of feature spaces and neural networks. The comment is also specific because it clearly specifies what needs to be addressed, namely the limitation of representing infinitedimensional RKHSs with neural networks. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim that every kernel can be described by a feature space parameterized by a neural network, pointing out a limitation with RBF kernels and their infinitedimensional representation. The reviewer provides a logical reasoning by referencing the fact that RKHS is famously infinitedimensional, making it impossible to represent with a neural network of finite width. This logical reasoning supports the claim, making it 4. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that every kernel can be described by a feature space parameterized by a neural network. It points out a limitation with RBF kernels, which are famously infinitedimensional, making it impossible to represent them with a neural network of finite width. The reviewer suggests that the limitation should be made more clear, providing a clear and actionable suggestion for improvement. This feedback is valuable as it highlights a critical aspect of the paper that needs clarification, guiding the authors to enhance the accuracy and completeness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. It suggests that the authors should conduct a thorough literature review to identify other works that use this property. While the comment explicitly states the need for a literature review, it does not provide specific guidance on how to conduct it or what aspects to focus on. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of originality in the proposed method and the need for a thorough literature review to identify other works that use the same property. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature, as the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known. The reviewer supports this claim by referencing specific works, such as the original denoising score matching objective and scoreinterpolation, which have used this property. This provides a clear and robust justification for the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known in the literature. It provides specific examples of existing works that use this property, such as the original denoising score matching objective and scoreinterpolation. This feedback is valuable as it highlights a potential gap in originality and suggests a thorough literature review to address it. However, the comment could be more helpful if it offered guidance on how to conduct the literature review or what specific aspects to focus on. Overall, the comment is 4 as it provides actionable feedback on a critical aspect of the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and somewhat vague, as the authors can infer that they need to clarify or improve the handling of autoregressive decoding during the generation phase, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It mentions the use of long token dimensions during training and questions whether the benefits of inference are still maintained. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the handling of autoregressive decoding and the potential impact on inference benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the linear attention mechanism handles autoregressive decoding, specifically during the generation phase. It suggests that the use of long token dimensions during training might limit the benefits of inference. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the handling of autoregressive decoding in the linear attention mechanism, specifically during the generation phase. It highlights a potential issue with the use of long token dimensions during training and questions whether the benefits of inference are still maintained. This is a valuable observation that could prompt the authors to reconsider their approach and potentially improve the robustness of their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their method. While it points out a critical area for consideration, it could be more helpful with additional details or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a weakness in the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. It suggests that the authors should provide a gradient comparison between KL and PCC to substantiate this claim. This feedback is clear and concrete, as it specifies exactly what needs to be done to address the issue. The authors know exactly how to apply this suggestion to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the assumption that PCC is more relaxed than KL divergence due to its invariance to scale and shift. The comment provides a logical reasoning for why this assumption is not convincing and suggests a gradient comparison between KL and PCC to substantiate the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is more relaxed than KL divergence due to its invariance to scale and shift. The reviewer provides a logical reasoning by explaining that the constraint strength of a loss function is defined by its gradient distribution, using KL divergence and MSE loss as examples. The reviewer suggests that a gradient comparison between KL and PCC is necessary to substantiate the claim. This reasoning is based on a clear understanding of the concepts and their implications, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the gradient comparison argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a key assumption in the paper regarding the relative relaxation of the Pearson correlation coefficient (PCC) compared to KL divergence due to its invariance to scale and shift. It challenges this assumption by pointing out that the constraint strength of a loss function is defined by its gradient distribution, using KL divergence and MSE loss as examples. The reviewer suggests that a gradient comparison between KL and PCC is necessary to substantiate the claim. This feedback is clear and actionable, as it provides a specific direction for the authors to address the assumption and strengthen their argument. By addressing this point, the authors can significantly improve the clarity and robustness of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment implies that the authors should provide additional analysis or discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the reproducibility of GPI with noise added and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. The comment also mentions the suitability of the approach for pattern separation tasks and suggests discussing this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. However, the comment lacks specific examples or references to support the claim about the fit of GPI with behavioral data or the suitability of the approach for pattern separation tasks. The suggestion for discussion is somewhat vague, as it does not provide detailed guidance on what aspects of the discussion should be included. Therefore, the comment is 3, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several pertinent questions about the reproducibility of GPI with noise added in Fig. 4 and suggests that there might be other measures to show that GPI cannot have as good a fit with behavioral data. It also mentions that the approach seems suitable for pattern separation tasks and suggests discussing this aspect. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or what specific measures could be taken to demonstrate the fit of GPI with behavioral data. The feedback is 3 as it points out areas for further exploration and discussion, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should compare the \"small learning rate for attention parameters\" benchmark with the proposed approach. This is an explicit action that the authors can directly take, as it provides a clear direction for further exploration and comparison. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, but it does not specify which part of the paper this suggestion pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to compare the two, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be valuable or how it would contribute to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the \"small learning rate for attention parameters\" benchmark with the proposed approach, which could provide valuable insights into the performance of the proposed method. This feedback is actionable and offers a specific direction for further exploration and analysis, potentially enhancing the robustness and generalizability of the work. However, the comment lacks depth and does not explain why this comparison is important or how it might impact the paper\"s conclusions. To be more helpful, the comment could provide additional context or suggestions on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is 3 as it identifies a potential area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. While the comment identifies an issue, it does not provide explicit guidance on how to address it or what specific experiments should be conducted. The authors are left to infer that they need to clarify this point and potentially conduct additional experiments, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the resolution of a debate left open in the paper. The comment questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the resolution of a debate left open in the paper and suggests that the distribution cannot be considered a factor in the results. It also questions whether experiments disentangle changes in distribution from the removal of information. While the comment raises valid points, it lacks specific examples or references to support the claim that the distribution is a significant factor. The reasoning is 3, as it highlights a potential issue but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the paper regarding the resolution of a debate left open in the previous work. It questions why the distribution cannot be considered a factor in the results and suggests that experiments should disentangle changes in distribution from the removal of information. This feedback is 3 as it points out a potential weakness in the paper that could be clarified or addressed. However, the comment lacks specific suggestions or guidance on how to resolve this issue or what experiments might be needed. While it highlights an area for improvement, it does not provide actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. The reviewer suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback provides a clear and explicit action for the authors to take, which is to reproduce the results using the same setting as the other methods. The suggestion is concrete and specific, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of AdamW with cosine lr for training and the comparison of methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison, suggesting that directly comparing results is unfair due to the different training settings. This provides clear guidance on what needs to be addressed to ensure fair comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that directly comparing results is unfair due to the different training settings used by the proposed method compared to the other methods. The reviewer suggests that reproducing the results using the same setting as the other methods would be more fair. This claim is 3 as it logically points out a potential issue with the comparison, but it lacks specific examples or references to support the argument. The authors would need to infer the specific training settings used by the other methods and determine how to reproduce their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the other methods only use Adam with a fixed lr. It suggests that directly comparing the results is unfair and recommends reproducing the results using the same setting as the other methods, which have their code released. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion to improve the fairness and validity of their comparison. By addressing this issue, the authors can enhance the credibility and reliability of their results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not specify which part of the paper this curiosity pertains to, such as a specific section, table, or figure where this combination is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for information, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The comment raises a curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it identifies an area of interest, it lacks specificity and actionable guidance for the authors. It does not provide details on what aspects of the SOTA method or adaptive metric should be explored or how the performance should be evaluated. Without concrete suggestions or examples, the comment does not offer meaningful assistance to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are terrible, providing specific issues with the plot quality. It mentions that the plots are too small, colors are hard to distinguish, axis labels are poorly labeled, and labels are visually similar. The reviewer also points out that these issues are the main presentation of the experimental results, which should be clearer. This feedback is clear and provides concrete actions for the authors to take, such as improving plot size, color contrast, and label clarity. The comment is 5 as it directly instructs the authors on how to enhance the clarity and quality of their plots, ensuring that they are more effective in communicating their results.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"plots\" and provides specific issues with them, such as their size, color contrast, and label clarity. It also mentions the \"main presentation of the experimental results,\" which further reinforces the grounding. The comment is specific because it details the problems with the plots, such as the small size, hardtodistinguish colors, and unclear labeling. This provides clear guidance on what needs to be addressed to improve the clarity and quality of the plots. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are terrible, with specific issues such as small size, hardtodistinguish colors, unclear axis labels, and visually similar labels. The reviewer provides logical reasoning by explaining the importance of clear plots as the main presentation of experimental results, which supports the claim. However, the comment could be strengthened by providing examples or references to similar studies with better plot quality, which would further substantiate the claim. Overall, the comment is 4, as it provides a clear rationale for the critique but lacks detailed examples or references. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues with the plots, such as their small size, hardtodistinguish colors, unclear axis labels, and visually similar labels. By pointing out these problems, the reviewer highlights areas where the authors can improve the clarity and effectiveness of their plots, which is crucial for effectively communicating their findings. The comment is clear and direct, offering a clear path for the authors to enhance the quality of their work. Therefore, it deserves a score of 5, indicating that it is 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvement, nor does it offer guidance on how to address the issue of low performance gains. As a result, the comment lacks actionability, leaving the authors without any direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the performance gains of the paper, specifically mentioning that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, it does not specify which metrics or parts of the paper this analysis is based on, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its critique of the performance gains, but it lacks grounding as it does not reference specific sections or metrics. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with most of the metrics showing a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the performance gains of the paper, noting that most of the metrics show a difference of less than 1% between the baseline (without caption and warmup) and the best approach (with caption and warmup). This is a clear and actionable observation that can guide the authors in understanding the limitations of their work. However, the comment could be more helpful if it provided suggestions on how to improve the performance gains or addressed potential sources of variability in the results. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a series of questions about the impact of the information about incorrect and corrected phrases and the type of mistake on the feedback network. It also asks about the performance without and with each of these two types of information and the performance with just natural language feedback. While the questions imply that the authors should analyze and present this information, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this analysis and present the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"information about incorrect phrase / corrected phrase and the information about the type of the mistake,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the impact of this information on the feedback network and the performance without and with each of these two types of information. Additionally, it asks about the performance with just natural language feedback. This level of detail provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point poses a series of questions about the impact of certain types of information on the feedback network. It does not make any subjective claims or judgments that require verification. The questions are factual and seek clarification, making them purely descriptive and not requiring verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a series of questions about the impact of certain types of information on the feedback network, specifically asking about the performance without and with each of two types of information and the performance with just natural language feedback. This is a thoughtful and insightful question that could prompt the authors to conduct additional analyses and provide more detailed information about the effectiveness of their feedback network. However, the comment does not offer specific suggestions or guidance on how to conduct these analyses or what specific aspects to focus on. While it points out a potential area for improvement, it lacks actionable advice, making it 3 but not fully comprehensive. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with Table 1, noting that it does not show standard deviations. It suggests that this omission would make the submission stronger if the experiments were more extensive. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to include standard deviations. The action is implied, as the authors can infer that they need to include standard deviations in Table 1, but it remains vague due to the lack of concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of standard deviations in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations, which would make the submission stronger if the experiments were more extensive. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this omission is significant or how it affects the overall strength of the submission. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not show standard deviations. This is a clear and actionable point that could significantly improve the paper by including this information. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific method for including standard deviations or explaining why this information is important. Despite this, the comment still offers valuable feedback that could guide the authors in enhancing their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. However, it does not provide explicit guidance or suggestions on how the authors should address this question or improve their draft. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific tables (1, 2, and 3) and the comparison with a different neural network in [14]. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it raises a question about the performance boost due to additional parameters and suggests that a better Unary baseline might affect the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. The comment references a different work ([14]) for comparison, which provides some basis for the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to conduct additional analysis or experiments to fully address the question raised. Therefore, the comment is 3, as it provides a starting point for further exploration but requires more detailed evidence or reasoning to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the performance boost due to additional parameters, specifically questioning whether there is still a performance boost if a better Unary baseline is used. It references a different work ([14]) for comparison and suggests that a better Unary baseline might affect the results. This feedback is 3 as it prompts the authors to consider the robustness of their results and the potential impact of different baselines. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the draft. To be more helpful, the comment could provide actionable steps or examples of how to conduct additional analyses or experiments to substantiate the claims. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit suggestions for improving the structure of the paper and highlights specific areas that require more attention, such as the IEM in Figure 3 and the visualization of Figure 7. It also suggests focusing on the IEM in Figure 3, which is considered the main figure in the paper. The comment is clear and provides concrete actions for the authors to take, such as reorganizing the structure of the paper and improving the visualization of specific figures. This level of detail and specificity makes the comment 5, as the authors know exactly what changes to make to improve the clarity and impact of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the introduction, method, and experiments, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be improved, such as the structure of the paper and the focus on the IEM in Figure 3. Additionally, it provides specific suggestions for improvement, like improving the visualization of Figure 7 and focusing on the IEM in Figure 3. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests improvements to the structure, specifically recommending a change from introduction>method>experiments. It also mentions that the IEM in Figure 3 is the main figure in the paper and suggests focusing on it. Additionally, it provides a suggestion to improve the visualization of Figure 7. While the comment provides some logical reasoning by suggesting a structure change, it lacks specific examples or references to support the claim that the paper is hard to follow. The suggestion to focus on the IEM in Figure 3 is 3, as it provides a direction for improvement but lacks detailed justification. The recommendation to improve the visualization of Figure 7 is also 3, as it points out an area for enhancement but does not provide specific guidance on how to achieve this. Overall, the comment is 3, as it provides some direction but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the structure and organization of the paper, suggesting improvements such as reorganizing the introduction, method, and experiments sections. It also highlights the importance of the IEM in Figure 3, which is considered the main figure in the paper, and suggests focusing on it. Additionally, the comment suggests improving the visualization of Figure 7 and Figure 3, which could enhance the clarity and impact of the paper. These suggestions are clear and provide the authors with a clear path for improving the structure and presentation of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the visualization or provided examples of how other papers have structured their papers effectively. Overall, the comment is 4 as it provides actionable feedback that can significantly improve the clarity and impact of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback implies that the authors should expand their discussion of related work to include a comparison with their own work. While the action is implicit, it is clear that the authors need to include a more detailed discussion of related work, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this discussion should be included in, such as the introduction, literature review, or results section. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a more detailed discussion of related work, but without explicit references to sections or elements, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This claim is 3 as it provides a logical reasoning for expanding the discussion of related work. However, it lacks specific examples or references to support the claim that the current discussion is insufficient. The authors would need to infer the specific aspects of the related work that should be discussed and the differences to the presented work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, including not only describing the related works but also discussing the differences to the presented work. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their literature review and comparison with existing work. By addressing this suggestion, the authors can improve the comprehensiveness and depth of their discussion, which could strengthen the paper\"s foundation and credibility. However, the comment could be more helpful if it provided examples of specific related works or aspects to focus on. Overall, the comment is 4 as it offers a concrete direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include attacks on other architectures and classification tasks beyond neural networks and image classification. While the comment implies that the authors should consider conducting experiments on these additional tasks, it does not provide specific guidance on how to implement these changes or what specific architectures or tasks should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which parts of the paper these experiments should be added to or which specific architectures or tasks should be considered. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment is not specific about what aspects of the experiments should be expanded or how they should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends expanding them to include attacks on other architectures and classification tasks. However, the comment does not provide any supporting evidence, examples, or references to justify why this expansion is necessary or beneficial. Without additional context or reasoning, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests expanding the experiments to include attacks on other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement in the paper, which could enhance its scope and relevance. However, the comment lacks specific guidance on which architectures or tasks should be considered, how to implement these changes, or what potential benefits this expansion might offer. While it points out a direction for improvement, the lack of detailed suggestions limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment requests information about the final used learning rates for the deep models, particularly for CIFAR10 and CIFAR100. It highlights the concern that the authors only tested four different learning rates and suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. While the comment explicitly states what information is missing and why it is important, it does not provide specific guidance on how to address this issue or what additional testing might be needed. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"deep models\" and \"CIFAR10 and CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014the final used learning rates for the deep models\u2014and why it is important for the authors to include this information. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the authors\" experimental setup, specifically mentioning that they only tested four different learning rates for the deep models, particularly CIFAR10 and CIFAR100. The reviewer suggests that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. This claim is 3 as it logically points out a potential issue with the experimental setup, but it lacks specific examples or references to support the claim fully. The authors would need to conduct additional testing or analysis to verify the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the authors only tested four different learning rates for the deep models, particularly CIFAR10 and CIFAR100. It highlights the potential problem that if the optimal learning rate for the baseline was outside the tested interval, it could affect the results. This feedback is clear and actionable, as it prompts the authors to consider testing a broader range of learning rates to ensure the robustness and generalizability of their findings. However, the comment could be more helpful if it provided suggestions on how to conduct this additional testing or what specific learning rates should be tested. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses skepticism about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explain their choice. The comment lacks concrete steps or detailed advice on how to improve the draft, leaving the authors uncertain about what specific actions to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the transformer\"s lack of locality bias, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate the argument, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of using a transformer without locality bias, suggesting that the limited speed of information propagation might lead to more impact from nearby nodes. However, it does not provide specific guidance or suggestions on how the authors might address this concern or explain why the transformer\"s lack of locality bias is not a concern in their context. The comment lacks actionable feedback or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the output from the algorithm depends on the order in which the data is processed and suggests that this should be clarified. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to clarify this point. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the order of data processing. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the output from the algorithm depends on the order in which the data is processed and recommends clarifying this point. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the algorithm\"s dependence on data order, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output from the algorithm depends on the order in which the data is processed, suggesting that this should be clarified. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, suggesting that it depends on the order in which the data is processed. This is a clear and actionable point that the authors should address to improve the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify this aspect or offered examples of how other studies have addressed similar issues. Despite this, the feedback is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to mitigate the potential impact. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the potential impact of their mitigation strategies on performance. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and questions their impact on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. However, the comment does not specify which part of the paper discusses these mitigation strategies, making it weakly grounded. The comment is specific in its concern about the potential impact on performance, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. It also points out that if the mitigation strategies significantly impair the model\"s utility, it could deter their adoption. However, the comment lacks specific examples or references to support the claim about the potential impact on performance. Without detailed evidence or examples, the claim is 3, as it provides a logical argument but lacks the necessary substantiation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies, suggesting that their impact on overall performance is unclear. It raises a concern about the tradeoff between reducing a particular behavior and maintaining high performance, and points out that significant impairment of the model\"s utility could deter adoption. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or what specific mitigation strategies might be more effective. The feedback is 3 as it prompts the authors to consider the potential impact of their mitigation strategies on performance, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the reason for using 6fold crossvalidation in the experiments. It points out that other papers in the field did not use crossvalidation, which raises questions about its necessity. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to clarify the rationale behind the crossvalidation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear explanation for the use of crossvalidation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of 6fold crossvalidation and the comparison with other papers that did not use it. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity regarding the reason for using 6fold crossvalidation. It suggests that the authors should provide a clear explanation for this choice, which is a concrete action for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reason for using 6fold crossvalidation is unclear because other papers in the field did not use it. However, the comment does not provide specific examples of these papers or explain why the use of crossvalidation is necessary or beneficial. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to make a significant effort to understand and address the issue, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the reason for using 6fold crossvalidation. It points out that other papers in the field did not use this method, which raises questions about its necessity. This feedback is valuable as it highlights an area where the authors need to provide a clearer explanation or justification for their methodology. However, the comment could be more helpful if it suggested ways to address this issue, such as by comparing the results with and without crossvalidation or by explaining the rationale behind the choice. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide explicit instructions on how to do so. The action is clear but somewhat vague, as the authors know they need to conduct additional experiments but may not be entirely sure of the specifics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are needed to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one setup out of three and there is no consistent trend in the results. The comment suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This claim is 3 as it provides a logical reasoning for the need for additional experiments, but it lacks specific examples or references to support the claim. The authors might need to conduct additional experiments themselves to fully understand the issue and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. This feedback is clear and actionable, as it points out a critical weakness in the paper\"s results and provides a concrete direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these additional experiments or what aspects of the analysis should be expanded. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors clarify the impact of the heuristic components, specifically the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. While the comment implies that the authors should provide more information about these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the heuristic components. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NonAmbiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the impact of the heuristic components, particularly the filtering template. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects, specifically mentioning the NonAmbiguous Query Generation procedure. The reviewer suggests that the authors should clarify the impact of these heuristic components, such as the sophisticated filtering template. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that these heuristic components are problematic or unclear. The reasoning is 3, as it points out a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper presents an effective engineering method for ReC but notes that the framework incorporates combinatorial and heuristic aspects. It suggests that the authors clarify the impact of these heuristic components, particularly the NonAmbiguous Query Generation procedure, which relies on a sophisticated filtering template. This feedback is clear and actionable, as it directs the authors to provide more information about the heuristic components and their impact on the framework. By addressing this point, the authors can enhance the clarity and comprehensiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the feasibility of training the proposed method without using camera information, specifically mentioning Line 223 and the \"knowledge of CAD model correspondences.\" It raises concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to provide more information or clarification regarding the use of camera information and ray marching. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of training the proposed method without using camera information, particularly regarding the \"knowledge of CAD model correspondences.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the feasibility of training the proposed method without using camera information, specifically mentioning \"Line 223\" and the \"knowledge of CAD model correspondences.\" The comment raises logical concerns about how ray marching can be performed without knowing the viewpoint and the origin of the ray. However, the comment lacks specific examples or references to support the claim that camera information is necessary for training. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the feasibility of training the proposed method without using camera information, specifically questioning the \"knowledge of CAD model correspondences\" mentioned in Line 223. It highlights the importance of camera information for ray marching and understanding the origin of the ray. While the comment identifies a potential weakness in the methodology, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a potential problem but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically mentioning the need for a detailed comparison of time complexity and competitiveness with prior art. While the comment implies that the authors should include such a comparison, it does not provide explicit instructions on how to conduct it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact details of what is expected. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, nor does it provide details on what aspects of the comparison should be addressed. The authors can infer that it relates to the discussion or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a particular comparison to be made. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. However, the comment does not provide specific examples or references to prior work that should be compared, nor does it explain why this comparison is necessary or how it would enhance the paper. Without detailed guidance or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, particularly regarding time complexity and competitiveness. This feedback is 3 as it identifies an area where the paper could be strengthened by providing a more comprehensive comparison with existing work. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on, leaving the authors with a general direction but without detailed steps to follow. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper discusses ODA as a method for solving the MOIP problem but does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not provide specific guidance on how the authors should address this issue or what additional details should be included to clarify the improvement. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the discussion of ODA as a method for solving the MOIP problem and points out that the paper does not clearly explain how the presented method improves performance and computation speed over ODA. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of clarity regarding the improvement over ODA. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it does not clearly explain how the presented method improves performance and computation speed over ODA, which is a method for solving the MOIP problem. This feedback is 3 as it points out a gap in the paper\"s explanation, but it lacks specific suggestions or guidance on how the authors might address this issue. While it highlights an area for improvement, the comment could be more helpful by providing examples or additional details on what aspects of the methodology need clarification. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where the lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or labels to make the figures more selfexplanatory. However, the comment does not explicitly instruct the authors to add these explanations or labels, leaving the action somewhat implicit. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the figure, specifically the lines \"No adapt\" and \"Finetune\" being covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure\"s clarity. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. However, the comment does not provide specific examples or detailed reasoning to support why these figures are not selfexplanatory. Without additional context or explanation, the authors may find it challenging to understand the issue and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with some figures, particularly Figure 4, where lines \"No adapt\" and \"Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it points out a specific area where the figures could be improved to enhance their selfexplanatory nature. By addressing this issue, the authors can enhance the clarity and accessibility of their figures, which is crucial for effectively communicating their research findings. However, the comment could be more helpful if it provided suggestions on how to improve the figures, such as adding labels or descriptions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the importance of the sampling process for obtaining different initializations x_0 and notes that it has not been evaluated carefully on the proposed benchmarks. However, it does not provide explicit guidance on how the authors should evaluate this aspect or what specific experiments should be conducted. The comment implies that the authors should conduct additional experiments to evaluate the sampling process, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sampling process for obtaining different initializations x_0, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the sampling process has not been evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sampling process for obtaining different initializations x_0 is important for convergence to the optimum and that it has not been evaluated carefully on the proposed benchmarks. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the sampling process used to obtain different initializations x_0, which is crucial for convergence to the optimum. It points out that this aspect has not been evaluated carefully on the proposed benchmarks, except for a limited comparison in Table 1 of the supplementary material. This feedback is valuable as it highlights a potential weakness in the paper that could impact its results and conclusions. However, the comment could be more helpful if it provided suggestions on how to evaluate this aspect or what specific experiments could be conducted to address it. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to implement it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies areas for clarification and potential issues, it does not provide explicit instructions or concrete suggestions on how the authors should address these concerns. The authors are left to infer that they need to provide a more detailed explanation or discussion of these aspects, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it highlights areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific papers, \"[9]\" and \"16,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the logic behind the comparisons, the computational cost, and its relevance in a practical scenario. The comment provides clear guidance on what needs to be addressed, namely the rationale behind the comparisons and the significance of the computational cost. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. The reviewer questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The comment also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. While the comment identifies potential issues and questions, it lacks specific examples or references to support the claims. The authors are left to infer the basis of the reviewer\"s concerns, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several pertinent questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with references [9] and [16]. It questions why the authors compare the proposed method with [9] first and then [16], and why they only compare the computational cost with [9]. The reviewer also questions whether the computational cost is a significant contribution to the paper and whether it is relevant in practical scenarios. These questions highlight areas where the authors need to provide more detailed explanations or justifications. However, the comment does not offer specific suggestions or guidance on how the authors might address these issues or improve the paper. While it identifies important areas for clarification, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. While the comment explicitly states the need for additional experiments, it does not provide specific guidance on which datasets to use or how to conduct these experiments. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental results, but this inference is not direct. The comment is specific in suggesting additional experiments and encouraging experiments on the full dataset, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to justify why additional experiments are necessary or how they would improve the evaluation. The claim is based on a general suggestion, but without specific examples or detailed justification, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages experiments on the full dataset instead of those in the lowresource regime. This feedback is clear and actionable, as it directly instructs the authors to expand their experimental scope and improve the comprehensiveness of their evaluation. However, the comment could be more helpful if it provided specific suggestions on which datasets to include or how to conduct these experiments. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions that the dataset transformation and experimental setup feel cumbersome and unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to improve clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the tasks and experimental setup. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of clarity in the paper regarding the generic argument task and the random argument task, specifically questioning how they prove the authors\" claims. It also mentions the cumbersomeness of the dataset transformation and experimental setup. However, the comment does not specify which sections or parts of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be clarified, but without explicit references to sections or figures, the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generic argument task and the random argument task are unclear in proving the authors\" claims. It also mentions that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of specific examples or references makes the claim 3, as the authors would need to infer the exact issues and potential solutions based on the general description provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the paper, specifically regarding the generic argument task and the random argument task. It points out that the authors\" claims are not clearly supported by these tasks, which could lead to confusion for readers. Additionally, it highlights the cumbersomeness and lack of clarity in the dataset transformation and experimental setup. While the comment provides some insight into areas that need improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to clarify the tasks and experimental setup, but without detailed advice, the feedback is 3. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline references. The comment is clear and concrete, as it specifies exactly what needs to be added and how it should be presented. This provides the authors with a direct and specific action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the idea of jointly discovering, hallucinating, and adapting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The comment provides a clear direction for the authors to include this analysis for a fair comparison with the baseline references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of discussion regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the impact of additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide an analysis for a fair comparison with the baseline references. This feedback is clear and actionable, as it points out a critical area that needs attention and suggests a specific improvement to enhance the paper\"s comprehensiveness and rigor. However, the comment could be more helpful if it provided examples or guidance on how to conduct this analysis or what specific aspects to consider. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, it does not provide specific guidance on how the authors should address this issue or what theoretical evidence should be presented. The comment implies that the authors should provide more detailed analysis or theoretical justification, but it does not offer concrete steps or examples of what this might entail. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of the correlation between dataset size and the Frobenius norm and singular values, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of theoretical evidence for the correlation and the need for more detailed analysis across different model architectures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming and lacks theoretical evidence. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. It highlights the need for more detailed analysis and theoretical justification to support this correlation. While the comment points out a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional evidence might be needed. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. It also questions the authors\" conclusion in L114 about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment implies that the authors should consider these issues and potentially address them in their paper. However, it does not provide explicit instructions or concrete steps for how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should consider these points and potentially revise their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises concerns about the use of AutoAugment as a stronger augmentation strategy, questioning the potential for information leaking and the implications for SSL algorithms. The comment also specifies the need to consider the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. The reviewer questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment is 3 as it provides a logical reasoning for the potential issue with AutoAugment and raises questions about the authors\" conclusion. However, it lacks specific examples or references to support the claim about information leaking or the potential impact on SSL algorithms. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the use of AutoAugment as a stronger augmentation strategy, suggesting that information leaking is likely due to its policy being obtained through supervised training on ImageNet. It also questions the authors\" conclusion about the pretraining dataset matching the target dataset in terms of object or scene centricity, and whether this could be a setback for SSL algorithms. The comment provides a clear and actionable suggestion for the authors to consider these issues and potentially address them in their paper. By highlighting these potential weaknesses and implications, the comment offers valuable insights that could help the authors improve their draft. However, it could be more helpful if it provided specific examples or references to support the claims about information leaking or the impact on SSL algorithms. Overall, the comment is 4 as it guides the authors toward a deeper understanding and potential resolution of these issues."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it would be interesting but not necessary to explore how the model works with tabular data, which is another form of multimodal data. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider tabular data but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring how the model works with tabular data, which is another form of multimodal data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this could be discussed. The authors can infer that it relates to the model\"s applicability to different forms of data, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting an additional exploration of tabular data, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that exploring how the model works with tabular data, which is another form of multimodal data, would be interesting but not necessary. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this exploration would be beneficial or how it would impact the paper\"s findings. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting but not necessary to explore how the model works with tabular data, which is another form of multimodal data. This feedback is 3 as it identifies a potential area for further exploration or discussion. However, it lacks specific guidance or suggestions on how to implement this exploration or what aspects of tabular data should be considered. While it points out a potential area for improvement, the comment could be more actionable with additional details or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include more analysis on the multilingual alignment of entity representations, specifically recommending visualizations or case studies for different types of languages. It also expresses interest in whether entities from lowresourced languages are well aligned with highresourced ones. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific visualizations or case studies should be included. The action is concrete but somewhat vague in terms of execution, as the authors need to determine the specific aspects of multilingual alignment to focus on and how to present the results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the languageagnostic characters of entity representations, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more analysis on the multilingual alignment of entity representations and the suggestion for visualizations or case studies for different types of languages. The comment also raises an interest in the alignment of entities from lowresourced languages with highresourced ones. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks analysis on the alignment of entity representations, specifically for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. While the comment identifies a potential gap in the analysis, it does not provide specific examples or references to support the claim that the current analysis is insufficient. The suggestion for visualizations or case studies is a logical one, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of analysis on the alignment of entity representations, particularly for multilingual alignment. It suggests that adding more analysis and visualizations or case studies for different languages would be beneficial. Additionally, it raises an interest in the alignment of entities from lowresourced languages with highresourced ones. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis and presentation. However, it could be more helpful if it included specific examples or suggestions on how to implement these improvements. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This explicit suggestion provides a clear action for the authors to take, which is to include additional details on using attention in an appendix. The comment is concrete, as it specifies the exact addition needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, it does not specify which part of the paper discusses attention or where additional details would be most relevant. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs attention. While the suggestion is specific in terms of what additional information is needed, the comment lacks grounding, making it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why additional details on attention are necessary or how they would enhance the paper. Without such justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be useful, specifically mentioning the possibility of including them in an appendix. This feedback is 3 as it identifies a potential area for improvement by suggesting an additional appendix to provide more detailed information on the use of attention. However, the comment lacks specific guidance on what aspects of attention should be covered or how the additional appendix should be structured. While it points out a potential area for improvement, it does not offer detailed suggestions or examples to help the authors fully address the issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. While it identifies specific issues, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to check for duplicates and ensure the correct publication venues and years are included. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions the references list, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of duplicates and missing publication venues/years, providing clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or publication years of many of the papers are missing. However, it does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact nature of the issues. Without specific examples or references, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the references list, noting that it contains duplicates and that the publication venues and/or publication years of many of the papers are missing. This feedback is clear and actionable, as it directs the authors to review and correct the references list to ensure accuracy and completeness. However, the comment could be more helpful if it provided suggestions on how to identify and correct duplicates or how to locate missing publication details. Overall, the comment is 4 as it highlights a critical aspect of the paper that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. It suggests that the authors should analyze and compare their theoretical results to those of other comparable methods. This feedback provides a clear and concrete action for the authors to take, which is to clarify the error bound and compare their results with others in the field. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound in Theorem 1 and the need for analysis and comparison with other comparable methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically mentioning the lack of clarity regarding the error bound. The comment suggests that the authors should analyze and compare their theoretical results with those of other comparable methods. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim about the clarity of the error bound or the need for comparison. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and that the authors need to analyze and compare their results with other comparable methods. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the authors clarify the error bound and compare their results. However, the comment could be more helpful if it offered specific guidance on how to analyze and compare the results, or provided examples of other methods to consider. Overall, the comment is 4 as it points out a critical area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks and points out that the pseudocode of the proposed method is missing. It also references external works that may be relevant to understanding the performance difference. However, the comment does not provide explicit instructions or suggestions on how the authors should address this issue or what specific aspects of the pseudocode should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include the missing pseudocode and explore the performance difference between explicit and implicit methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"locomotion tasks\" and the \"proposed method,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance difference between explicit and implicit methods and points out the missing pseudocode of the proposed method. Additionally, it references external works that could be relevant to understanding the performance difference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, and it mentions the missing pseudocode of the proposed method. The reviewer references external works by S\u00f8ren Asmussen and Peter W Glynn and P. Florence et al. to support the claim that explicit methods are better suited for locomotion tasks. However, the comment does not provide detailed reasoning or examples from these references to fully substantiate the claim. While the references offer some support, the comment lacks a comprehensive explanation or analysis of the performance difference, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the performance of explicit methods compared to implicit methods on locomotion tasks, which is an important aspect of the paper. It also points out the missing pseudocode of the proposed method, which is a significant oversight. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the pseudocode should be included. While it identifies a significant gap in the paper, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. It also mentions the method R3F and suggests that the authors should use it to maintain the generalization ability of the model. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific aspects of the R3F method should be applied. The action is implicit and somewhat vague, as the authors need to infer that they should explore the R3F method to maintain generalization. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of lowresource language pairs to finetune the multilingual model and mentions the method R3F to maintain generalization ability. However, it does not specify which part of the paper this discussion pertains to, such as a specific section or experiment. The mention of \"lowresource language translations\" and \"R3F\" provides some context, but the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the insignificance of the improvement and suggests using R3F, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of lowresource language pairs to finetune the multilingual model is insignificant in practical terms, despite an improvement of 0.8. The reviewer supports this claim by referencing the method R3F, which is used to maintain generalization ability. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a reference to a relevant work, the explanation is not comprehensive enough to fully support the claim. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of lowresource language pairs to finetune the multilingual model, suggesting that the improvement of 0.8 is insignificant in practical terms. It also mentions the method R3F as a potential solution to maintain generalization ability. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the R3F method should be applied. While it points out a potential weakness, it does not provide actionable steps for the authors to address it. Therefore, the comment is 3, as it highlights an area for improvement but does not offer detailed guidance for implementation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specific reason for the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. While the comment implies that the authors should address this issue by providing a rationale or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of Gaussian noise. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss their model\"s ability to work well for various image noise types, allowing the authors to accurately identify the relevant section. It is also specific because it questions the choice of Gaussian noise in the experiments and asks for a rationale or explanation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of Gaussian noise in the experiments, suggesting that there might be a particular reason for this choice. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of Gaussian noise in the experiments, noting that the paper claims the model works well for various image noise types. This is an important point as it highlights a potential limitation in the scope of the experiments. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the model or noise types should be explored. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and concrete action for the authors to take, as it provides a specific direction for improving the draft. The comment is specific in detailing what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the performance of existing PU learning methods as the dimensionality of the data increases. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the visualization of this effect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors visualize the effect of increasing dimensionality on the performance of existing PU learning methods. This is a clear and actionable suggestion that can significantly enhance the paper\"s research motivation and credibility. By visualizing the effect, the authors can provide a concrete demonstration of their claim, which is crucial for the paper\"s impact. However, the comment could be more helpful if it provided additional guidance on how to effectively visualize this effect or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While the comment implies that the authors should consider moving this information to the supplementary materials, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider moving the information to the supplementary materials. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The suggestion is specific, as it clearly identifies a potential improvement by recommending the inclusion of supplementary materials. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is the case. The comment lacks specificity and does not offer a detailed explanation or references to support the claim. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the empirical version of the objective (3) might be better suited for the supplementary materials. While it provides a specific suggestion for improvement, it lacks depth and does not explain why this change would be beneficial or how it would enhance the paper. The comment does not offer detailed guidance or examples on how to implement this suggestion, leaving the authors with a general idea but without actionable steps to improve their draft. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies that the results are needlessly convoluted and suggests that a related idea of speakerlistener communication from a teachability perspective was studied in [1]. It also mentions that the differences in figures seem too small and suggests checking that useful communication is actually happening. The reviewer provides a specific reference to [1] and [2] to support their suggestions. While the comment does not explicitly instruct the authors to follow these references, the explicit mention of them provides a clear direction for the authors to explore related literature and potentially improve their results. The action is concrete, as it specifies the need for a more straightforward explanation and suggests specific references to guide the authors in their analysis. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the need for a more straightforward explanation of the results, specifically mentioning that the description is needlessly convoluted. It suggests exploring a related idea of speakerlistener communication from a teachability perspective, referencing [1] and [2]. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections. The comment is specific in suggesting the need for a more straightforward explanation and references relevant literature to support the suggestion. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the results are needlessly convoluted and suggests exploring a related idea of speakerlistener communication from a teachability perspective. The reviewer provides references to [1] and [2] to support the claim. However, the comment lacks detailed reasoning or explanation of why the results are convoluted or how the suggested references could improve the clarity. While the references provide some context, the comment could be strengthened by offering more specific examples or explanations of the issues. Therefore, the comment is 3, as it provides some support but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the results section, noting that the description is needlessly convoluted. It suggests exploring a related idea of speakerlistener communication from a teachability perspective, referencing [1] and [2]. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement this suggestion or what aspects of the results need to be simplified. The references are helpful, but the comment could be more actionable with additional details on how to address the issue. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the approximation error should be mathematically characterized, which provides a clear and direct action for the authors to take. The comment is specific in detailing what needs to be done, namely, providing a mathematical characterization of the approximation error. This guidance is concrete, as it specifies the exact improvement needed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the approximation error, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a mathematical characterization of the approximation error. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approximation error is ambiguous and suggests providing a mathematical characterization. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current definition is unclear or how a mathematical characterization would improve clarity. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the approximation error definition, noting that it is ambiguous without additional context. It suggests providing a mathematical characterization to clarify the concept. This feedback is clear and actionable, as it directs the authors to make a specific improvement to enhance the clarity and precision of their work. However, the comment could be more helpful if it included examples or additional guidance on how to mathematically characterize the approximation error. Overall, the comment is 4 as it effectively points out a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific line (ln. 180182) where Corollar 10 is discussed, and it highlights a potential issue with the claim that uncertainty sampling moves in descent directions of the expected 01 loss. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific changes should be made to the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 180182,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made in this section, namely that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 01 loss, which does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific line in the paper where a claim is made about the effectiveness of uncertainty sampling. It points out that the claim is based on Corollar 10, which only shows that uncertainty sampling moves in descent directions of the expected 01 loss. The comment highlights a potential issue with the claim, noting that this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is 3 as it prompts the authors to reconsider the basis of their claim and potentially revise it to provide a more robust justification. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context or references to support the claim. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. While the comment identifies a specific issue with the model dynamics, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit and somewhat vague, as the authors can infer that they need to consider ways to improve the dynamics and complexity of the model. However, without concrete suggestions or examples, the comment lacks clarity and is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed model\" and the \"evolution model,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the model dynamics, noting that the model produces only one node changing cluster per time step and that the evolution model is simplistic, with no other edges changing except those associated with the 1 node changing cluster. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step on average due to the reassignment probability being 1/n, resulting in slow dynamics. It also notes that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. The comment provides logical reasoning by explaining the consequences of the reassignment probability and the simplicity of the evolution model. However, it lacks specific examples or references to support the claim that this is a significant issue or how it affects the overall performance of the model. Therefore, the comment is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, as the model can only change one node at a time. Additionally, the comment points out that the evolution model is simplistic, as it only changes edges associated with the 1 node changing cluster. This feedback is 3 as it highlights a potential limitation in the model\"s dynamics and complexity, which the authors could address to improve their draft. However, the comment could be more helpful by suggesting ways to address these issues or providing examples of alternative models or approaches that could be considered. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there are missing details about the division to train and test sets, including numbers and the method of division (random or other considerations). It clearly instructs the authors to add these details, providing a direct action for improvement. The comment is specific and provides concrete guidance on what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division to train and test sets, including numbers and the method of division. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be added, such as details about the division method and numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division to train and test sets, including numbers and the method of division. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper is lacking, namely the details about the division to train and test sets, including numbers and the method of division. It clearly states that these details should be added to improve the clarity and transparency of the paper. This feedback is actionable and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to present these details or provided examples of how similar studies have addressed this issue. Overall, the comment is 4 as it effectively points out a gap in the paper and provides a clear path for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for how to address the human labor issue or how to improve scalability. The comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of human labor in building text descriptions and the scalability of the framework with longtext inputs. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the need for human labor and the scalability issue, but it lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that building text descriptions for each task still requires human labor and that the optimal textual format for policy learning varies from task to task and model to model. The reviewer also mentions the scalability issue with longtext inputs. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies two main issues: the need for human labor in building text descriptions and the potential scalability issue with longtext inputs. It acknowledges the complexity of determining the optimal textual format for policy learning, which varies across tasks and models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their framework. While it highlights important areas for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out potential weaknesses but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance improvement of the proposed methods is not significant, as evidenced by the figure 3, and recommends using tables to show the key improvements more intuitively and in detail. While the comment provides a clear action\u2014using tables to present the key improvements\u2014it does not specify which tables should be used or how to present them. The authors are left to infer the details of implementing this suggestion, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods seems not so significant, with the biggest improvement in the bank dataset being around 0.02. Additionally, it suggests using tables to show the key improvements more intuitively and in detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance improvement of the proposed methods is not significant, based on the figure 3, and suggests using tables to show the key improvements more intuitively and in detail. The comment provides a logical reasoning by pointing out the lack of significant performance improvement and the potential for more detailed presentation using tables. However, it does not provide specific data or references to support the claim about the performance improvement or the suggestion for using tables. This makes the claim 3, as the authors would need to make a concerted effort to verify the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance improvement of the proposed methods seems not to be significant, as evidenced by figure 3. It suggests using tables to present the key improvements more intuitively and in detail. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of results. By recommending the use of tables, the reviewer offers a method for the authors to enhance the clarity and comprehensiveness of their findings. However, the comment could be more helpful if it provided specific guidance on which tables to use or how to present the key improvements. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the experimental validation, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed information about the optimization strategy and consider related works, but the comment lacks specific instructions on how to implement these improvements. Therefore, the comment is 3, as it identifies areas for improvement but does not offer concrete steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental validation\" and \"shallow networks\" being considered, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental validation, such as the lack of description of the optimization strategy and the consideration of layer redundancy in the context of network pruning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, specifically mentioning the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, such as the consideration of layer redundancy in the context of network pruning. The reviewer provides a reference to a specific paper that discusses this issue, which adds some level of verification to the claim. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the experimental validation section, including the use of shallow networks (2 or 3 layers) and the lack of description of the optimization strategy. It also points out a minor issue with positioning with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how to address them. The reference to a specific paper on network pruning could be more helpful if it included suggestions on how to incorporate this work into the paper. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance or actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not provide any guidance on how the authors might prove these results or what specific theoretical aspects should be explored. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical evidence but without clear direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the lack of theoretical results, but it is 1 as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the work does not prove any new theoretical results despite the use of a specific type of loss in a particular setting. However, it lacks depth and does not provide any specific suggestions or guidance on how the authors might address this issue or what theoretical results could be explored. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors can provide more evidence to either prove or disprove it. While the comment implies that the authors should provide evidence to support or refute the hypothesis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence to substantiate the hypothesis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. However, it does not specify which part of the paper this hypothesis pertains to, making it weakly grounded. The comment is specific in suggesting that the human test results might support the hypothesis but questions whether the authors can provide more evidence to prove or disprove it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a hypothesis about the two parts of the paper, proposing that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion for additional evidence is a clear indication of what the authors could do to improve the draft, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a hypothesis about the two parts of the paper, suggesting that the trivial part is simple and consistent with the training set, while the impossible part is characterized by ambiguous labels, atypical object pose, or position. The reviewer acknowledges that the human test results might support this hypothesis but questions whether the authors could provide more evidence to either prove or disprove it. This feedback is 3 as it identifies a potential area for further exploration and provides a direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions on how to test or substantiate the hypothesis, such as recommending specific experiments or analyses. Overall, the comment provides some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the testing of the bAbI model, specifically asking about the testing of other tasks beyond Task 1. While it implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional testing details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"bAbI\" and \"Task 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the testing of the bAbI model, particularly in relation to Task 1, and suggests that other tasks should be tested as well. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking about the testing of the bAbI model on other tasks beyond Task 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the testing of the bAbI model, specifically asking about the testing of other tasks beyond Task 1. This is a valuable point as it highlights a potential limitation in the paper\"s evaluation, which could impact the generalizability of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies an area for improvement, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the authors should improve Section 3.2 by providing more illustrations and examples. This feedback is clear and direct, giving the authors a specific action to take to enhance the clarity and comprehensibility of their draft. The comment provides a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more illustrations and examples to improve the clarity of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to follow Section 3.2, implying that the content is unclear or lacks clarity. However, the comment does not provide specific examples or detailed reasoning to support this claim. It suggests that the authors might improve the section by adding more illustrations and examples, but this is not a fully developed argument. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the need for improvement themselves.", "helpfulness_rationale": "The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It suggests that the authors might improve the section by providing more illustrations and examples, which could enhance its clarity and comprehensibility. While the comment highlights a potential area for improvement, it lacks detailed guidance or specific examples of what kind of illustrations or examples would be beneficial. This limits the comment\"s helpfulness, as it provides a general direction but does not fully support the authors in making the necessary improvements. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is limited, suggesting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific guidance or suggestions on how the authors could improve their technical contribution or what aspects of the typical model could be leveraged to enhance their work. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is limited and does not provide a specific part of the paper where this issue is addressed. It mentions the crossdomain recommendation setting, but without further context or detailed explanation, the authors may struggle to identify the exact section or aspect of the paper that needs attention. The comment lacks specificity in detailing what is considered typical or how the technical contribution could be improved. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited and does not provide a significant extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technical contribution of the paper is limited, specifically noting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any specific examples or suggestions for how the authors could enhance their technical contribution or what aspects of the typical model could be leveraged to improve their work. Without actionable feedback or detailed guidance, the authors are left without a clear path forward to address the critique. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. While the comment implies that the authors should add these baselines, it does not provide explicit instructions on how to implement this suggestion or what specific baselines to include. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests adding fullysupervised baselines for small models in Table 1 to understand the gap between full supervision and SSL for these models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting the addition of fullysupervised baselines but lacks grounding as it does not explicitly mention the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would contribute to the understanding of the gap. Without such justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests adding fullysupervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. This is a clear and actionable suggestion that could provide valuable insights into the performance of the models under different conditions. However, the comment could be more helpful if it explained why this addition is necessary or how it would impact the understanding of the gap. Despite this, the suggestion is still valuable and provides a clear direction for improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically asking about the time required to calculate the hypervolume of different regions in each step of LaMOO. It also mentions that the computation of hypervolume could be timeconsuming, especially for problems with many objectives. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete suggestions on how to improve the time complexity or optimize the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should address the time complexity issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of time complexity in the algorithm, particularly the repeated calculation of hypervolume for promising region selection, which could be timeconsuming for problems with many objectives. The comment also raises a question about the practicality of LaMOO for such problems. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. The comment suggests that this could make LaMOO impractical for such problems. However, the comment lacks specific examples or references to support the claim that the time complexity is a significant issue. While it identifies a potential concern, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the time complexity of the proposed algorithm, specifically questioning whether the repeated calculation of hypervolume for promising region selection in LaMOO could be timeconsuming, especially for problems with many objectives. This is an important consideration for the practicality of the algorithm, as it could limit its applicability to certain types of problems. The comment prompts the authors to address this issue and consider ways to optimize the algorithm for efficiency. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the time complexity or offered guidance on potential optimization techniques. Overall, the comment is 3 as it identifies a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the dataset used in the experiments is small but suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. While the comment implies that the authors should consider running experiments on larger datasets, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider running experiments on larger datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of the dataset being small, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to include results on larger datasets like ImageNet, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dataset used in the experiments is small and suggests that results on larger datasets like ImageNet would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why larger datasets are necessary or how they would impact the paper\"s conclusions. Without additional context or examples, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the issue of using small datasets in the experiments and suggests that results on larger datasets like ImageNet would be more convincing. However, it also states that this is a minor issue and does not affect the overall quality of the paper. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address the issue of dataset size. The feedback is 3 as it points out a potential weakness but lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, as well as the generic and vague title. It suggests being honest and direct in the critique and provides a specific example of what \"brittle convergence properties\" means. Additionally, it mentions that DeepRL methods are widely adopted and suggests considering the landscape 10 years ago. While the comment provides some guidance on what aspects to address, it lacks concrete details on how to implement these suggestions. The authors are given a general direction but may need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues, including the limitations of evolutionary methods, the generic and vague title, and the need for more detailed discussion on leveraging state, reactiveness, and learning during an episode. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting that the title is too generic and vague and that the authors should be more precise in their critique. It also asks for clarification on the term \"brittle convergence properties\" and mentions the widespread adoption of DeepRL methods. Overall, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point makes several claims, including that the paper discusses limitations of evolutionary methods, the title is too generic and vague, and that DeepRL methods are widely adopted. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The mention of \"brittle convergence properties\" is not explained, and the suggestion to be more precise in critiques is not accompanied by examples or detailed guidance. As a result, the claims are not 5, as they lack the necessary evidence or explanation to substantiate them. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas for improvement, including the need to discuss leveraging state, reactiveness, and learning during an episode, which could enhance the paper\"s depth and relevance. It also points out that the title is too generic and vague, suggesting that the authors should be more precise in their critique. Additionally, the reviewer questions the term \"brittle convergence properties\" and notes that DeepRL methods are widely adopted, suggesting that the authors should consider the landscape 10 years ago. While the comment provides some actionable feedback, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how similar works have tackled these topics. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image, and how the edges are handled in areas where depth discontinuities occur. While the questions are explicit, they do not provide specific guidance on how the authors should address these issues. The authors know they need to provide more information about the synthesis process, but the comment lacks concrete details on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks about how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas with depth discontinuities. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, making it fully grounded. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. While the questions are valid, they do not provide specific examples or references to support the claim that these aspects are unclear or lacking in the paper. The comment lacks detailed reasoning or evidence to substantiate the need for clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack and the forward model used to generate a defocused image. It specifically asks for clarification on how the defocus map and an image are used to synthesize the defocused image and how edges are handled in areas where depth discontinuities occur. These questions highlight potential gaps in the explanation of the methodology, which could be crucial for readers to understand and replicate the work. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional details or examples. While it identifies areas for improvement, the feedback lacks depth and actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper claims a unique contribution regarding the number of points and apriori knowledge needed for its algorithm, but it suggests that empirical justification would be beneficial. However, it does not provide specific guidance on how to conduct this empirical justification or what kind of evidence would be sufficient. The action is implicit and somewhat vague, as the authors can infer that they need to provide empirical evidence but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper lacks empirical justification for the claim about the number of points and apriori knowledge needed for the algorithm. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is unique because it does not require as many points or apriori knowledge about dimensions of subspaces. However, the comment suggests that empirical justification would be beneficial. While the claim is logical, it lacks specific examples or references to support the assertion that empirical justification is necessary. The reasoning is 3, as it provides a general idea of what could be improved, but it does not offer detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by suggesting empirical justification for the claim about the algorithm\"s unique contribution. It points out that the paper lacks empirical evidence to support the claim that the algorithm does not require as many points or apriori knowledge about dimensions of subspaces. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the credibility and robustness of their claims. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the empirical justification. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. While the comment identifies issues with novelty and similarity, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should improve the novelty and differentiate their approach from existing work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"specific components of the approach,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with novelty, noting that the weak predictors used are not novel and that the sampling strategy is similar to epsilongreedy and BRPNAS. The comment provides specific examples of the predictors and the similarity to BRPNAS, allowing the authors to understand the issues clearly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the specific components of the approach are not novel, as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. The reviewer also notes that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, the reviewer states that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. The claim is supported by specific references to external works, such as [2,3,7] and [5], which provide a basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or additional references to further substantiate the claim. Overall, the claim is 4, as it is supported by specific references and logical reasoning.", "helpfulness_rationale": "The review comment identifies a significant issue with the novelty of the approach, noting that the specific components are not novel as they use MLP, Regression Tree, or Random Forest, which have been used for NAS performance prediction before. It also points out that the sampling strategy is similar to epsilongreedy and the same as that in BRPNAS. Additionally, it highlights that the results of the proposed WeakNAS are almost the same as BRPNAS, as shown in Table 2 in Appendix C. This feedback is 3 as it provides clear and actionable information about the lack of novelty in the approach. However, it could be more helpful if it offered suggestions on how to differentiate the approach or improve its novelty. Overall, the comment identifies a critical area for improvement but lacks depth and specific guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015) and suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and provides a concrete action for the authors to take, which is to include a discussion on the comparison with RMED. The comment is specific about what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed S1DBED algorithm\" and \"RMED (Komiyama et al. 2015),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion on the comparison with RMED. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed S1DBED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the proposed S1DBED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is 3 as it points out a specific area where the paper could be improved by addressing the comparison with an existing work. However, the comment could be more helpful if it provided suggestions on how to conduct this discussion or what aspects to focus on. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify what aspects of the previous work should be discussed or how the authors should incorporate this discussion into their paper. The comment lacks explicit guidance on how to address this issue, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this discussion is missing from, nor does it provide details on what aspects of previous work should be included. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is specific in identifying the need for a comprehensive discussion of previous work but lacks grounding as it does not pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or how they should be discussed. Without specific references or examples, the claim lacks verifiability, as it does not provide a clear basis for the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not provided a comprehensive discussion of previous work on the topic. This is a critical observation that could significantly impact the paper\"s credibility and relevance. However, the comment lacks specific guidance on what aspects of previous work should be discussed or how the authors might incorporate this discussion into their paper. Without actionable suggestions or examples, the authors are left with a general understanding of the issue but without clear direction on how to address it. Therefore, the comment is 3, as it points out a significant weakness but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and suggests that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and a flow chart. However, the comment does provide specific questions about the process, which can guide the authors in understanding what information is missing and how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.4.3\" and \"equation (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. The comment also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, suggesting that more details and a flow chart would be helpful. It also asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment identifies areas for clarification and potential improvements, it does not provide specific evidence or references to support the need for these changes. The authors are left to infer the importance of these details, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the clarity of the paper regarding the OT sample selection process, specifically questioning whether it runs iteratively or only once. It suggests that more details and a flow chart would be beneficial for readers to understand the process. Additionally, it asks about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity and comprehensibility of the paper. By addressing these points, the authors can significantly enhance the readability and understanding of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix, asking why these methods are not included in the experiments and how they compare to ConBO. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include experiments with continuous tasks and consider including entropy methods in the experiments. The action is concrete but somewhat vague, as it lacks detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on how KG handles the continuous task setting, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of experiments with continuous tasks and questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix. The comment further asks how these methods compare to ConBO, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. While the comment identifies a potential gap in the experimental setup, it lacks specific examples or references to support the claim that these methods should be included in the experiments. The reasoning is 3, as it highlights a potential issue but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the absence of experiments with continuous tasks, despite the authors discussing how KG handles continuous tasks. It also questions the inclusion of entropy methods for conditional optimization in Section 7 of the appendix and asks how these methods compare to ConBO. This feedback is clear and actionable, as it prompts the authors to address the omission of continuous tasks in their experiments and to consider including entropy methods for conditional optimization. By providing specific questions and suggestions, the comment empowers the authors to enhance their draft and improve the comprehensiveness of their experimental setup. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a comparison of GCG with other LLMs could be included, as it demonstrated the transferability of its approach. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs. While the comment implies that the authors should include this comparison and address the jailbreaking issue, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GCG\" and \"their approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a comparison with other LLMs and the issue of low jailbreaking percentages for certain LLMs. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a comparison with other LLMs could be included, as it demonstrated the transferability of the GCG approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Additionally, the mention of the jailbreaking percentage being low for certain LLMs is a factual observation but lacks context or explanation. Therefore, the claim is 3, as it requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a comparison with other LLMs, which could demonstrate the transferability of the GCG approach. This feedback is actionable and provides a clear direction for the authors to enhance their draft. Additionally, it points out a minor issue with the jailbreaking percentage for certain LLMs, which could be addressed to improve the paper. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the comparison or how to address the jailbreaking issue. Overall, the comment is 4 as it offers valuable insights for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the authors\" explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. While it acknowledges the novelty of the approach, it explicitly requests a more detailed explanation to better understand the difference. This feedback is clear and provides a specific action for the authors to take, which is to provide a more detailed explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of unsupervised feature selection from a diffusion perspective, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for a more detailed explanation of the difference between similarity and exit times in nature. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. The reviewer acknowledges the novelty of the approach but expresses difficulty in understanding the distinction. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the explanation is unclear. Without additional context or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the explanation of the difference between similarity and exit times in the context of unsupervised feature selection from a diffusion perspective. It acknowledges the novelty of the approach but expresses a need for a more detailed explanation to better understand the distinction. This feedback is clear and actionable, as it prompts the authors to provide a more comprehensive explanation to clarify the concept. However, the comment could be more helpful if it offered suggestions on how to present this explanation or what specific aspects should be emphasized. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. While it implies that the authors should address this limitation, it does not provide explicit instructions or suggestions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a response to the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the limitations of the framework, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the framework is limited in this way. Without such information, the authors may find it challenging to address the question or understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the limitations of the unified framework in terms of its applicability to general POMDP formulations, specifically those with continuous or infinite spaces. This is a relevant point that could help the authors identify potential areas for improvement or expansion in their work. However, the comment lacks specific guidance or suggestions on how to address this limitation or what specific aspects of the framework might need improvement. While it points out an important area for consideration, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the calculation of precision/recall/F1score for a 4class classification of breast density and suggests providing AUC results for breast cancer detection. While the comment implies that the authors should include these details in their paper, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these details. However, the comment provides concrete examples of what is missing, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the calculation of precision/recall/F1score for a 4class classification of breast density and the reporting of AUC results for breast cancer detection. It also specifies the need for sensitivity and specificity at different operating points for model performance comparisons. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions about the calculation of precision/recall/F1score and the reporting of AUC results. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the calculation and reporting of results for a 4class classification of breast density and breast cancer detection. It suggests that providing AUC results with sensitivity and specificity at different operating points could be more informative for comparisons. This feedback is clear and actionable, as it directs the authors to include specific details that could enhance the clarity and comprehensiveness of their results. However, the comment could be more helpful if it provided examples of how these additional results could be presented or discussed. Overall, the comment is 4 as it guides the authors toward improving the clarity and comprehensiveness of their results section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is wellstudied in the community, provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner and that the authors\" dataset can be considered extra data to learn from. While the comment implies that the authors should consider using the Kialo dataset, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should use the Kialo dataset rather than being directly told to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community. It also notes that the Kialo dataset provides pairs of short claims and their counters, and that it is cleaner than the dataset created by the authors. However, the comment does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The suggestion to use the Kialo dataset is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the creation of the dataset is optional and that the Kialo dataset, which is wellstudied in the community, provides pairs of short claims and their counters. The reviewer claims that the Kialo dataset is cleaner than the one created by the authors and can be considered extra data to learn from. However, the comment lacks specific examples or references to support the claim that the Kialo dataset is cleaner or that it provides a better dataset for learning. The suggestion is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the creation of the dataset is optional and provides a specific example by mentioning the Kialo dataset, which is wellstudied in the community and provides pairs of short claims and their counters. The reviewer notes that the Kialo dataset is cleaner than the one created by the authors and can be considered extra data to learn from. This feedback is 3 as it points out an alternative dataset that could be used for learning purposes. However, the comment lacks depth and does not provide specific guidance on how the authors might incorporate the Kialo dataset into their work or why it might be beneficial. While it offers a suggestion, it could be more helpful with additional details or suggestions for implementation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the use of Transformer in the paper, noting that it is no longer novel in the field and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement in the ablation study, suggesting that it is limited (<1%). However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific modifications should be made to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the novelty and impact of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Transformer\" and \"crosslayer,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the modification does not bring much insight and that the selfcross attention improvement is limited. Additionally, it provides specific examples from the ablation study (table 4 and 5) to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of Transformer in the paper is not novel and that the authors\" modification (crosslayer) does not bring significant insight. The reviewer supports this claim by referencing the widespread adoption of Transformer in NLP and vision tasks, which suggests that the modification is not innovative. Additionally, the reviewer points out that the selfcross attention improvement is limited (<1%) and questions whether this should be considered significant. The comment is 4 as it provides logical reasoning and references to common practices in the field, but it could be strengthened with specific examples or references to studies that demonstrate the limited impact of the proposed modification. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment provides a critical analysis of the paper\"s contribution, specifically regarding the use of Transformer and the authors\" modification (crosslayer). It points out that the Transformer is no longer novel in the field and that the modification does not bring significant insight. The reviewer also questions the significance of the selfcross attention improvement, suggesting that it is limited and not a significant improvement over other methods. This feedback is 3 as it identifies a potential weakness in the paper\"s contribution and suggests that the authors should reconsider the novelty and impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what aspects of the paper could be improved. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, it does not provide specific guidance on how to implement these changes or what aspects of the experiments should be improved. The comment implies that the authors should address the weaknesses mentioned, but it lacks concrete details on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the limited number of tasks and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically the limited number of tasks, and suggests that the authors should include at least 10 tasks and sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the robustness and comprehensiveness of the experiments. However, the comment could be more helpful if it explained why the current number of tasks is insufficient or how sequential results would benefit the analysis. Despite this, the feedback is 4 as it points out a critical area for improvement and offers a concrete suggestion for enhancing the paper. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional tasks should be included in the experiments. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments, specifically mentioning \"sentence similarity tasks and open domain QA tasks.\" This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited and suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. The comment provides a logical reasoning by pointing out that these tasks are common in the NLP field and could enhance the scope of the experiments. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the experiments. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing a specific direction for the authors to expand their experiments and enhance the scope of their work. By addressing this suggestion, the authors can improve the comprehensiveness and relevance of their evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include the prompt in the appendix or supplement, providing a clear action for the authors to take. Additionally, it suggests that the abstract might be difficult to understand and recommends rephrasing it. However, the comment does not provide specific guidance on how to rephrase the abstract or what changes to make to the Figure 2. While the action is clear, the lack of detailed instructions on how to implement the rephrasing and yaxis labeling makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the prompt and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as including the prompt in the appendix or supplement and clarifying the purpose of Figure 2. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the prompt should be included in the appendix or supplement, providing a clear and actionable suggestion for improvement. However, the comment does not provide any supporting evidence or reasoning to justify why this is necessary or how it would enhance the paper. Additionally, the comment mentions issues with the abstract and Figure 2, but without specific examples or detailed explanations, it lacks verifiability. Therefore, the comment is considered 2, as it provides a direction for improvement but lacks sufficient evidence or reasoning to fully support the claim.", "helpfulness_rationale": "The review comment provides two main pieces of feedback. First, it suggests that the prompt should be included in the appendix or supplement, which is a clear and actionable suggestion for improving the paper. This feedback is specific and can help the authors ensure that their work is accessible and understandable. Second, it points out issues with the abstract and Figure 2, suggesting that they might be difficult to understand and recommending rephrasing. While these comments are 3, they do not provide detailed guidance on how to improve the clarity or accessibility of the abstract or Figure 2. Overall, the comment is 4 as it identifies areas for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. While the comment raises a valid point, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their motivation. The authors are left to infer that they need to provide a clearer explanation or justification for their choice, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this analysis is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be clarified or improved regarding the motivation for analyzing only the last convolutional layer. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the motivation for analyzing only the last convolutional layer, specifically asking why numerosity would not appear in earlier layers. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation for analyzing only the last convolutional layer, specifically questioning why numerosity would not appear in earlier layers. This is an important point that could impact the clarity and justification of the paper\"s analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a clearer explanation. While it identifies a potential weakness, it does not offer actionable steps or examples for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment points out that the parameter S remains a problem, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps the authors should consider to improve the parameter setting. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the issue of setting the parameter S, but it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspect of the parameter S setting is problematic or how it could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The comment states that \"How to set the parameter S remains a problem,\" but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the parameter S, indicating that it remains a problem. However, it lacks any further explanation or guidance on how to address this issue or what aspects of the parameter setting are problematic. Without actionable advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is not helpful, as it does not provide the authors with any meaningful insights or direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider conducting a human evaluation, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The authors are left to infer that they should consider conducting a human evaluation, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper discusses the evaluation metrics or the caption generation process, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include human evaluation, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback highlights a potential weakness in the paper\"s evaluation methodology and provides a clear direction for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects of the caption generation process should be evaluated by humans. While it identifies an area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the claim in the introduction that \"these shape constraints do not require tuning a free parameter\" and the fact that the choice of employing a convex or concave constraint, and an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this discrepancy. The action is implicit, as the authors can infer that they need to clarify or correct the statement in the introduction, but it is vague because it lacks specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" pointing out that the choice of convex or concave constraints and increasing/decreasing constraints can be considered hyperparameters that need to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the claim in the introduction that \"these shape constraints do not require tuning a free parameter,\" by pointing out that the choice of convex or concave constraints, and increasing/decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This is a logical observation based on the definition of hyperparameters, which are often tuned to optimize model performance. However, the comment does not provide specific examples or references to support the claim that these constraints should be considered hyperparameters. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the introduction regarding the claim that \"these shape constraints do not require tuning a free parameter.\" It points out that the choice of convex or concave constraints, and increasing/decreasing constraints, can be considered hyperparameters that need to be chosen or tuned. This feedback is valuable as it highlights a potential inconsistency in the paper that the authors should address to ensure clarity and accuracy. However, the comment could be more helpful if it provided specific suggestions on how to clarify this point in the introduction or offered guidance on how to present the hyperparameters in a more accurate manner. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It highlights a specific assumption, Assumption 4.1, which indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This provides a clear and concrete action for the authors to take, which is to review and potentially revise the convergence proof to enhance its novelty and rigor. The comment is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 4.1\" and \"Modification 1 in Appendix C,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical proof for convergence, noting that it lacks novelty and rigor due to the trivial adaptation from previous theorems. The comment provides a clear rationale for why the proof is not substantial, which helps the authors understand the need for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence appears trivial and lacks novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer suggests that the convergence proof can be trivially adapted from previous theorems with straightforward modifications, as outlined in Modification 1 in Appendix C. This reasoning is based on logical deduction from the assumptions and the provided modifications, making the claim 4. However, the comment could be strengthened by referencing specific theorems or examples to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, stating that it appears trivial and lacks novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, which can be trivially adapted from previous theorems with straightforward modifications. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting the lack of novelty and rigor in the proof, the comment offers a constructive suggestion for improvement. However, it could be more helpful if it provided additional guidance on how to enhance the rigor or novelty of the proof. Overall, the comment is 4 as it directs the authors to a critical area needing attention and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, which is to mention this fact clearly in their paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental setup borrowed from [2], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, namely that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup borrowed from [2] is only semireal because it involves artificially created multinode seed cascades by merging singlenode seed cascades. This claim is 3 as it provides a logical reasoning for the classification, based on the description of the experimental setup. However, the comment lacks specific examples or references to [2] to fully substantiate the claim. Providing more detailed evidence or references would strengthen the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This is a clear and actionable point that the authors should address to ensure the validity and credibility of their results. By mentioning this issue clearly, the authors can improve the transparency and accuracy of their experimental setup. However, the comment could be more helpful if it provided suggestions on how to clarify this point in the paper or offered guidance on how to address the issue. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two main issues: the limited scope of datasets and models used in the study and the lack of assessment of other important biases and datasets. It also points out the absence of assessments on stateoftheart generative models like GPT. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should expand their dataset and model selection and include assessments on additional biases and models like GPT. However, the comment lacks concrete suggestions on how to implement these changes or what specific datasets or models should be considered. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the study, specifically mentioning the bias benchmarks and the absence of assessments on stateoftheart generative models like GPT. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the dataset and model selection and the need for additional assessments. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the datasets and models used in the study are limited and that the bias benchmarks only assess gender, race, and religion. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific limitations, it lacks detailed justification or examples to fully substantiate the claim. The authors would need to infer the importance of these omissions and the potential impact on the study\"s conclusions. Therefore, the comment is 3, as it provides some basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant limitation in the study, noting that the datasets and models used are limited and that the bias benchmarks only assess gender, race, and religion. It also points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the study could be expanded to include a broader range of biases and models, which would enhance its scope and relevance. However, the comment could be more helpful if it provided specific suggestions on which datasets or models to consider or how to incorporate assessments of generative models like GPT. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a contradiction between two statements regarding the multienv model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to clarify the contradiction or what aspects of the statements are problematic. However, the authors can infer that they need to provide a clear explanation or resolution to the contradiction, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statements about the multienv model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of contradiction between the two statements regarding the model\"s performance and knowledge sharing. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contradiction between two statements regarding the multienv model: one stating a performance loss and another claiming knowledge sharing leads to outperformance. The reviewer requests clarification, indicating that the authors need to address this contradiction. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim of contradiction. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a contradiction in the paper regarding the performance of the multienv model. It points out that the model is stated to have an inevitable performance loss but also outperforms the singleenv model due to knowledge sharing. This contradiction highlights a potential inconsistency in the paper that needs clarification. The comment is 3 as it prompts the authors to clarify this contradiction, which could be an important aspect of their work. However, it could be more helpful if it provided suggestions on how to address the contradiction or offered additional context to better understand the implications. Overall, the comment is 3 as it directs the authors to a critical area needing clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or a citation to the metrics. This feedback is explicit, as it clearly states what the authors need to do to improve their draft: either provide an explanation or a citation to the metrics used. The action is concrete, as it specifies exactly what the authors need to do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the metrics,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: an explanation or a citation to the metrics used in the paper. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that an explanation or citation to the metrics would be beneficial. However, the comment does not provide specific examples or detailed reasoning to support why the current description is insufficient or how an explanation or citation would improve the paper. Without additional context or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the lack of an explanation or citation for the metrics used. This is a critical feedback as it highlights an area where the authors could enhance the clarity and transparency of their work. By suggesting that an explanation or citation would be beneficial, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of how the metrics are used or why they are important, which would guide the authors in addressing the issue more effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies issues with Figure 3, including the unclear workflow and captions, as well as the confusing representation of communication modes on the left side. This provides clear and direct guidance on what needs to be improved, namely the clarity and comprehensibility of the figure. The authors are given specific actions to take, such as revising the captions and the representation of communication modes, to enhance the figure\"s understandability. The feedback is concrete and provides concrete steps for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow and captions and the confusing representation of communication modes on the left side. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as the representation of communication modes on the left side. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks specific references or examples to clarify the issues, making it difficult for the authors to address the feedback effectively. Therefore, the claim is considered 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and the representation of communication modes on the left side is confusing. This feedback is actionable as it provides the authors with a clear understanding of what needs to be improved in the figure. By addressing these issues, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of how similar figures have been effectively presented. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"learned [MASK] embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this term or what steps they should take to address the issue. The comment lacks actionable details, such as recommending specific terminology or clarification methods. As a result, the authors are left without a clear understanding of what is expected of them to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the term \"learned [MASK] embedding.\" This provides clear guidance on what the authors need to address to improve the clarity of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"learned [MASK] embedding\" is unclear in the SSL pretraining stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or examples to explain why this term is unclear or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. This is a clear and actionable point that can help the authors clarify their terminology and improve the clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to better explain or define this term, or if it offered examples of how it might be used in the context of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area needing clarification, which can help them improve the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the reported results are partially derivative, as they extend to hypernetworks results that have already been presented in the literature for standard networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific changes should be made to improve the originality of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in identifying the issue of derivative results, but without clear grounding, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the reported results are partially derivative, as they extend to hypernetworks of results already presented in the literature for standard networks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the originality of the reported results, suggesting that they are partially derivative as they extend to hypernetworks of results already presented in the literature for standard networks. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the originality of their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks motivation for the applications of the fast label aggregation algorithms in a streaming setting. It highlights that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting specific ways to motivate the problem or providing examples of streaming applications that could benefit from such algorithms. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger motivation for the problem and consider dynamic datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the objective of the paper, which is to design fast label aggregation algorithms for a streaming setting. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of motivation for the problem and the use of static datasets in the empirical analysis, which are crucial for the paper\"s usefulness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting. It notes that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. However, the comment does not provide specific examples or references to support this claim, nor does it offer suggestions on how to address the issue. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the objective of designing fast label aggregation algorithms for a streaming setting is not adequately motivated. It points out that all the datasets used in the empirical analysis are static, which is a concern for the paper\"s usefulness. The comment highlights the need for a stronger motivation for the problem, suggesting that the paper would be more valuable if it addressed applications in a streaming setting. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or suggestions on how to motivate the problem or what aspects of streaming applications should be considered. Overall, the comment is 3 as it guides the authors toward a meaningful enhancement of their draft, but it could be more actionable with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. It also mentions that additional relevant CoT baselines for incontext learning of large language models are missing in Table 2 and 3. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the scope and include relevant CoT baselines, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and 3\" and \"Question A,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the underspecification of the scope and the missing CoT baselines for incontext learning of large language models. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the scope of the study is underspecified and suggests that the work focuses on injecting a CoTbased approach to smallscale language models. The reviewer provides some support by mentioning that additional relevant CoT baselines for incontext learning of large language models are missing in Table 2 and 3, referencing \"Question A.\" However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it points out a potential issue, the lack of detailed evidence or examples makes it 3, as the authors would need to further explore the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the scope of the study, noting that it appears to focus on injecting a CoTbased approach to smallscale language models. It also points out that additional relevant CoT baselines for incontext learning of large language models are missing in Table 2 and 3, referencing \"Question A.\" This feedback is clear and actionable, as it directs the authors to clarify the scope of their work and provide relevant baselines. By addressing these points, the authors can improve the comprehensiveness and accuracy of their study. However, the comment could be more helpful if it provided specific guidance on how to present these additional baselines or how to better define the scope of the study. Overall, the comment is 4 as it effectively highlights areas for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment explicitly states that Figure 3 is difficult to read, providing a clear action for the authors to take. However, it does not specify what aspects of the figure are challenging to read or how the authors might improve the figure to make it more readable. While the action is explicit, the lack of concrete details on how to address the issue makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, stating that it is difficult to read anything on the figure. This provides clear guidance on what needs to be addressed to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment claims that \"Figure 3 is very hard to read anything on the figure.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 3, stating that it is difficult to read anything on the figure. This feedback is clear and actionable, as it directs the authors to address a specific visual aspect of their work that may impact the readability and comprehension of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as recommending adjustments to the figure size, font, or color scheme. Overall, the comment is 3 as it points out a clear issue but lacks detailed guidance on how to resolve it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific aspects of the connection should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the connection between the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While it identifies a potential area for further exploration or discussion, it does not provide any actionable feedback or suggestions for the authors to address this question or enhance their draft. The comment lacks depth and specificity, leaving the authors without clear guidance on how to proceed. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about whether the GAT is trained with the whole model and suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment implies that the authors should review the text for clarity, it does not provide specific guidance on how to achieve this or what aspects of the text need to be revised. The action is implicit and somewhat vague, as the authors can infer that they need to review the text but may not be entirely sure of the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"245,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the training of the GAT and suggests that the text needs to be reviewed for clarity. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the training of the GAT with the whole model, which is a relevant point for clarity. It also suggests that the text needs to be reviewed by an English native speaker to improve clarity. While the comment identifies a potential issue with the clarity of the text, it lacks specific guidance on how to address these concerns. The authors are given a general direction to improve the clarity but are not provided with detailed suggestions or examples of what specific changes might be needed. Therefore, the comment is 3, as it points out an area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. While the comment provides a specific action to take regarding the parameter `lambda`, it does not offer guidance on how to address the issue with the SGD learning rate or what the justification should be. The action is explicit but lacks concrete details on how to implement the change or justify the choice of `lambda`. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of `n^2/(2*s^2)` being replaced with an arbitrary parameter `lambda` and questions the justification behind using an SGD learning rate of ~0.1. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these concerns or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and the use of an SGD learning rate of ~0.1. It points out that the justification for these choices is unclear, which is a valid concern. However, the comment does not provide detailed guidance or suggestions on how the authors might address these issues or improve the clarity of their explanations. While it highlights areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This guidance is clear and specific, giving the authors a direct action to take. The comment also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the importance of error analysis and its role in evaluating model performance and identifying potential issues. It also encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This provides clear guidance on what needs to be addressed, making the comment fully grounded. The comment is specific because it details the importance of error analysis and its role in guiding subsequent improvements and expansions of the ERC research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This claim is 3 as it logically supports the importance of error analysis in the context of model evaluation and improvement. However, the comment lacks specific examples or references to substantiate the claim fully. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It highlights the importance of error analysis in evaluating model performance and identifying potential issues, and encourages the authors to conduct such analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their draft by incorporating error analysis, which can aid in guiding subsequent improvements and expansions of the ERC research. However, the comment could be more helpful if it included specific examples or suggestions on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. While the comment provides a general direction for analysis and potential improvements, it does not offer specific guidance on how to conduct this analysis or what aspects to focus on. The authors are left to infer the details of how to implement these suggestions, making the action implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment does not specify which part of the paper should include this analysis or discussion, nor does it provide detailed guidance on what aspects of the domain gap should be addressed. While the authors might have an idea of where to focus their analysis, the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests analyzing the domain gap and discussing the gap between datasets. It also mentions the potential value of the approach if it can finetune a pretrained model on synthetic data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the domain gap or the value of the approach. Without such evidence or examples, the authors may find it challenging to understand and address the suggestions. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to analyze the domain gap and discuss the gap between datasets. It highlights the potential value of the approach if it can finetune a pretrained model on synthetic data. This feedback is valuable as it directs the authors to consider an important aspect of their work that could enhance its impact and relevance. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis or what aspects of the domain gap should be considered. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the scalability of the model, specifically noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should consider scalability and performance tradeoffs. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and the issue of scalability, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the performance degradation as the maximum number of identities grows, and suggests that the capacity should be set to a small number, like 10. The comment further questions whether the authors have considered how to scale up without compromising performance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the performance of the model degrades as the maximum number of identities grows, suggesting that the capacity should be set to a small number, like 10. The reviewer provides a specific example from Table 3 (a) to support this claim. However, the comment lacks detailed reasoning or references to explain why this specific capacity threshold is necessary or how it affects performance. While the claim is based on a specific observation, it could be strengthened with more detailed justification or examples. Therefore, the comment is 3, as it provides some support but lacks full clarity and depth.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the model, noting that performance degrades as the maximum number of identities grows. It suggests that the capacity should be set to a small number, like 10, to address this issue. The comment also raises a valid question about how to scale up without compromising performance, which is an important consideration for realworld applications. While the comment provides a clear and actionable suggestion, it could be more helpful if it offered additional insights or examples on how to achieve this scalability without sacrificing performance. Overall, the comment is 4 as it directs the authors to consider a critical aspect of their model\"s scalability and performance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors claim their work as preliminary but question the NLPspecific aspects of their approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be revised to better align with an NLPspecific focus. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim made by the authors regarding their work being preliminary and discusses the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of NLPspecific aspects in the approach, but without explicit references to sections or details, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the reviewer\"s concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the claim made by the authors that their work is preliminary, specifically regarding the application of LLP to NLP tasks. It points out that the approach does not appear to have any NLPspecific aspects, which is a valid observation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their approach to better align with an NLPspecific focus. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that at least one NCEbased method should be included for comparison. It provides a specific reference to a study that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This guidance is clear and concrete, as it specifies the exact action the authors need to take by including a specific method for comparison. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including at least one NCEbased method for comparison, referencing a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular method for comparison, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This reference provides a logical basis for the claim, as it supports the suggestion with a specific example. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced study to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment suggests that at least one NCEbased method should be included for comparison. It references a specific study [1] that demonstrates the possibility of learning EBM on natural images with a strong noise distribution. This feedback is 3 as it provides a clear direction for the authors to consider adding a relevant method for comparison. However, the comment could be more helpful if it explained why this particular method is important or how it relates to the current work. Additionally, it could offer suggestions on how to integrate the new method into the existing study. While the feedback provides a starting point, it lacks depth and specificity, making it 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment section could be improved by conducting significance tests on the human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a clear direction for improvement, it does not specify how to conduct these tests or which recent LLMs should be compared. The authors are given an explicit action to take, which is to conduct significance tests and comparisons, but the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the experiment section, specifically recommending the inclusion of significance tests on human evaluation results and comparisons with recent LLMs. However, it does not specify which part of the experiment section needs improvement or which specific LLMs should be compared. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting improvements, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment section could be improved by conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these changes would significantly enhance the experiment section. The absence of detailed justification or evidence makes the claim 3, as the authors would need to make a significant effort to understand and implement the suggested improvements.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiment section, suggesting that conducting significance tests on human evaluation results and comparing the proposed method with recent LLMs would enhance the quality of the work. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the rigor and comprehensiveness of their experiment section. However, the comment could be more helpful if it included specific examples of recent LLMs or detailed guidance on how to conduct the significance tests. Overall, the comment is 4 as it effectively points out a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to discuss a previous work on joint error for UDA, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. It also suggests that the authors should illustrate the relationship between this work and their proposed method, and explain why their method is better. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what steps to take to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the joint error for UDA and references a specific work, \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment,\" from ICML2019. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the relationship between the proposed method and the previous work, and why the proposed method is better. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" claim about the lack of research on joint error for UDA is incorrect, as it has already been studied in previous works like \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The reviewer supports this claim by referencing the specific work, providing a clear and direct reference to substantiate the claim. This makes the comment 4, as it offers a specific example to support the claim, but it could be further strengthened by providing additional details or analysis on why the proposed method is better than the existing work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the lack of research on joint error for UDA. It challenges this claim by pointing out that the problem of arbitrarily increased joint error has already been studied in previous works, specifically mentioning \"Domain Adaptation with AsymmetricallyRelaxed Distribution Alignment\" from ICML2019. The comment suggests that the authors should discuss this work and its relationship to their proposed method, and explain why their method is better. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the existing literature and justifying the novelty of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the fairness of the comparison with SOTA methods, noting that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superiority of the proposed method may be due to the largerscale datasets. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors can infer that they should consider the impact of dataset size on performance and potentially adjust the comparison with SOTA methods. However, the comment lacks concrete steps or suggestions on how to conduct this adjustment or what specific aspects of the comparison should be revised. Therefore, the comment is 3, as it points out an issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with SOTA methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance of the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets. This provides clear guidance on what needs to be addressed, namely the fairness of the comparison with SOTA methods. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison with SOTA methods may be unfair due to the difference in dataset size. The reviewer provides a logical reasoning by pointing out that the superiority of the proposed method may be due to the largerscale datasets. However, the comment lacks specific examples or references to support the claim that the dataset size significantly impacts the accuracy. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. The authors would need to further explore the impact of dataset size on performance to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the paper\"s performance against SOTA methods. It points out that the paper is based on a newly collected 209M dataset, while existing methods use smaller datasets, such as GEM with only 20M unlabeled data. This observation highlights a potential bias in the comparison, as the larger dataset may contribute to the superiority of the proposed method. The comment suggests that the superiority may be due to the largerscale datasets, which is a relevant consideration for the authors to address. However, the comment could be more helpful by providing specific suggestions on how to adjust the comparison or how to account for the dataset size difference. Overall, the comment is 3 as it identifies a relevant concern but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It also notes the absence of a discussion on the research gap, such as why existing methods cannot be applied. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the research gap should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide a justification for the need of a new curriculum learning method and address the research gap, but the comment does not offer detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the need for designing a new curriculum learning method for text graphs is not justified and that the research gap, such as why existing methods cannot be applied, is not discussed. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, as existing methods cannot be applied. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that while several curriculum learning methods have been discussed in Section 1, the need for designing a new method for text graphs is not justified. It points out the absence of a discussion on the research gap, such as why existing methods cannot be applied. This feedback is 3 as it highlights a potential gap in the paper that the authors should address to strengthen their argument. However, the comment could be more helpful if it provided suggestions on how to address this gap or what specific aspects of the research gap should be discussed. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This is an explicit and concrete action that the authors can take to improve their draft. The comment clearly specifies what needs to be done and how it can be done, making it 5.", "grounding_specificity_rationale": "The comment suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular approach to address the domain adaptation problem, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using powerful pretrained language models like BERT and XLNet as the base encoder for all methods and comparing the efficacy of the transfer parts instead of using the simplest ngram features. This claim is 3 as it provides a logical reasoning for the suggestion, based on the common use of these models in domain adaptation tasks in the NLP field. However, the comment lacks specific examples or references to support the claim fully, such as studies or experiments that demonstrate the effectiveness of these models in domain adaptation. This makes the claim 3, as it provides a reasonable basis but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to use powerful pretrained language models like BERT and XLNet as the base encoder for all methods and compare the efficacy of the transfer parts instead of using the simplest ngram features. This feedback is clear and constructive, as it offers a concrete way to improve the methodology and enhance the results. By following this advice, the authors can potentially improve the robustness and generalizability of their approach. However, the comment could be more helpful if it included additional context or examples to further explain the rationale behind the suggestion. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis or provide additional experiments to clarify the contribution of each module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology and results sections where the method and its performance are discussed. The comment is specific in detailing what needs to be addressed, namely the need for more detailed analysis or additional experiments to clarify the contribution of each module. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point questions whether the main performance gain of the proposed method is due to a specific module or the increased number of parameters. It suggests that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the current study is insufficient. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that it comprises several complicated modules and has more parameters than the baselines. It questions whether the main performance gain is due to a specific module or the increased number of parameters, and points out that the current version of the ablation study does not provide definitive answers to these questions. This feedback is 3 as it highlights an area where the authors could improve their analysis and provide more detailed explanations of the method\"s performance. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what additional analyses could be conducted. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explanation in the paper regarding the two quantities mentioned in lines 196197. It explicitly asks for more clarification on why the two quantities are different and how they capture the difference in learning settings. This feedback provides a clear and direct action for the authors to take, which is to provide additional explanation in these lines. The comment is specific and concrete, giving the authors a clear idea of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l 1967,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation regarding the two quantities and their relationship to learning settings. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the explanation provided in lines 196197, asking for more clarification on why the two quantities are different and how they capture the difference in learning settings. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this explanation is necessary or how it would impact the paper\"s understanding. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires more explanation, specifically the two quantities mentioned in lines 196197. It asks for clarification on why the two quantities are different and how they capture the difference in learning settings. While the comment highlights a potential gap in the paper\"s explanation, it does not provide detailed guidance or suggestions on how to address this issue. The authors are given a clear direction to improve their draft, but the comment could be more helpful with additional context or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and direct request, providing the authors with a specific action to take. The comment is specific in detailing what needs to be discussed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to discuss the sensitivity of fixed tuning parameters in the model, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the strengths and weaknesses of these parameters. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a relevant and important aspect to consider, as it could impact the robustness and generalizability of the model. However, the comment lacks specific guidance or examples on how to approach this discussion or what aspects to focus on. While it identifies a potential area for improvement, it does not provide detailed instructions or suggestions for the authors to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed framework should be tested with different policy gradient approaches and provides a specific question about the number of random seeds used for learning the policies (DDPO and IPPG). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment results. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its request for information about the random seeds used, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not provide any supporting evidence, reasoning, or references to justify why these changes would be beneficial or necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests testing the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments. However, the comment lacks depth and does not provide specific guidance on how to implement these changes or what specific aspects of the framework would benefit from testing with different policy gradient approaches. While it points out a potential area for enhancement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. While it implies that the authors should expand their analysis, it does not provide specific guidance on which datasets or tasks to include or how to conduct the additional evaluations. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to enhance their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not specify which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the need for additional datasets and tasks, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from evaluating on more datasets and tasks to strengthen the results and conclusions. However, it does not provide any specific reasoning or evidence to support why this would be beneficial or how it would impact the paper\"s conclusions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s evaluation, noting that it is based on only one dataset and one task. It suggests that expanding the analysis to more datasets and tasks would strengthen the results and conclusions. This feedback is 3 as it points out an area for improvement, but it lacks specific guidance on which datasets or tasks to consider or how to conduct the additional evaluations. While it highlights a potential weakness, the comment does not provide actionable steps for the authors to address it. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific areas where the writing could be improved, such as the definition of \"relevant\" auxiliary model weights in 2.1. It provides explicit guidance on what needs to be clarified, namely the interpretation of the current definition. This feedback is clear and concrete, as it directly instructs the authors on what part of the writing needs improvement and how to clarify it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely the interpretation of the \"relevant\" auxiliary model weights in the definition. This provides clear guidance on what aspect of the writing needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the writing in specific sections, such as definition 2.1. It suggests that the definition is difficult to interpret and provides examples of areas that could be improved. However, the comment does not provide specific reasoning or examples to support why the writing is unclear or how it could be clarified. Without additional context or detailed explanation, the claim remains 3, as it lacks the necessary evidence or justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the writing could be improved, providing clear and actionable feedback. It points out that the definitions in the paper, such as \"relevant\" auxiliary model weights in definition 2.1, are difficult to interpret. By highlighting these areas, the comment offers a concrete way for the authors to enhance the clarity and accessibility of their writing. However, the comment could be more helpful if it provided suggestions on how to clarify these definitions or examples to improve understanding. Overall, the feedback is 4 as it directs the authors to specific areas needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the robustness of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It suggests that the use of ULiRA [1] is recommended. However, the comment does not provide explicit instructions on how to address this concern or implement the suggested use of ULiRA. While the authors can infer that they should consider using ULiRA, the comment lacks concrete guidance on how to integrate it into their work. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and raises concerns about the robustness of MIA testing for privacy guarantees. It also suggests using ULiRA [1] as a recommendation. However, the comment does not specify which part of the paper discusses the use of MIA testing or where the recommendation for ULiRA should be integrated. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issue with MIA testing and the recommendation for ULiRA, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness is not robust enough for privacy guarantees. It suggests that the use of ULiRA [1] is recommended. The comment provides a logical reasoning by pointing out the potential limitations of MIA testing and the need for a more robust approach. However, it lacks specific examples or references to support the claim about the robustness of MIA testing or the effectiveness of ULiRA. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness. It raises a valid concern about the robustness of MIA testing for privacy guarantees, which is an important consideration for the paper\"s contributions. The comment suggests using ULiRA [1] as a more robust alternative, providing a clear and actionable suggestion for improvement. However, the comment could be more helpful if it explained why MIA testing is not robust or how ULiRA might address these concerns. Overall, the comment provides valuable insight into a potential weakness and offers a constructive suggestion for improvement, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit instructions or concrete guidance on how to address this issue. The authors are left to infer that they should consider presenting their considerations in this context, but without specific details on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests presenting them in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting that the considerations should be applicable to kernel regression and that they could be presented in the language of kernel interpolation/smoothing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression. It suggests that these considerations should also be applicable to kernel interpolation/smoothing. However, the comment lacks any supporting evidence, reasoning, or references to justify why this is the case or how it would be relevant to the paper. Without additional context or explanation, the claim remains 1, as it does not provide sufficient justification for the authors to address the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression, suggesting that they should also be applicable to kernel interpolation/smoothing. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or present the considerations in the context of kernel interpolation/smoothing. The comment is 3 as it points out a potential gap in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. It explicitly asks if it is possible to conduct such a comparison. The comment provides a clear and direct action for the authors to take, which is to conduct a quantitative comparison on the final outputs. This guidance is explicit and concrete, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the quantitative evaluation results, noting that they only reflect middle outputs and suggesting a comparison with final outputs. The comment further questions whether a quantitative comparison on the final outputs is possible, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quantitative evaluation results in Figure 3 only reflect middle outputs and suggests that a quantitative comparison on the final outputs would be more convincing. The comment provides a logical reasoning by pointing out that the current evaluation does not fully demonstrate ModelAngelo\"s superiority to competitors. However, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to make a significant effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results in Figure 3, noting that they only reflect middle outputs rather than the final outputs. It suggests that a quantitative comparison on the final outputs would be more convincing in demonstrating ModelAngelo\"s superiority to competitors. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or provided examples of how it might be done. Overall, the comment is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that the authors should provide more details in the paper and/or supplementary information to clarify the procedures and include error bars or pvalues when making statistical inferences. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should add more details and clarify the figures. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2\" and \"simulation or experimentbased evidence,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the explanations being qualitative, the lack of detailed procedures, and the confusion with figures like \"sample count.\" The comment provides clear guidance on what needs to be addressed, such as adding more details and including error bars or pvalues when making statistical inferences. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations in the paper are qualitative and that the procedures are described minimally or not at all, with some figures being confusing. The reviewer suggests that adding more details and clarifying the procedures would be beneficial. The comment also mentions the absence of error bars or pvalues when statistical inferences are made. While the comment identifies specific issues, it lacks detailed examples or references to support the claim that the explanations are qualitative or that the procedures are unclear. This makes the claim 3, as the authors would need to make a concerted effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of detailed explanations, minimal or absent simulation procedures, and confusing figures. It suggests that the authors should provide more details and clarity in the paper and/or supplementary information to enhance the understanding of the experiments. Additionally, it points out the absence of error bars or pvalues when statistical inferences are made. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their explanations and figures. However, the comment could be more helpful if it provided specific examples of what additional details or clarifications would be beneficial. Overall, the comment is 4 as it guides the authors toward improving the quality and comprehensiveness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add supportive references for claims that may be inspired by existing studies. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. The comment is clear and concrete, as it specifies which parts of the paper need references and provides a specific example of where these references should be added. This gives the authors a direct action to take to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5564,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to add supportive references for claims inspired by existing studies. The comment provides a detailed example of the factors that need references, such as order sensitivity, complexity, diversity, and style sensitivity. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some claims may be inspired by existing studies and suggests that it is critical to add supportive references. The reviewer provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. However, the comment lacks detailed reasoning or specific references to existing studies that support the claims. While it highlights a potential issue, the lack of detailed evidence or examples makes the claim 3. The authors would need to further investigate and provide references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that some claims may be inspired by existing studies and suggesting that supportive references are necessary. It provides a specific example by referencing lines 5564, where the authors discuss factors affecting the performance of chainofthought prompting. This feedback is clear and actionable, as it directs the authors to include references to support their claims. However, the comment could be more helpful if it suggested specific references or examples of existing studies that address these factors. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance the credibility and robustness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback implies that the authors should include this information in their paper to enhance its clarity and usefulness to the community. However, the comment does not provide specific guidance on how to present these settings or what aspects should be included. While the action is implied, it is not as clear as it could be, leaving the authors with a general idea of what needs to be done but without detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include these settings, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment lacks specific examples or references to these works, making it difficult for the authors to understand the exact nature of the suggestion. Without detailed justification or examples, the claim is not 5, as it relies on general knowledge of the field. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the clarity and usefulness of their work. By including these settings, the authors can help the community better understand the advances in their area and facilitate a single review of various approaches. However, the comment could be more helpful if it provided examples of how these settings were used in prior work or suggested specific ways to present them in the paper. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out an unclear aspect of the paper regarding the presentation of specific examples of biases and prediction shifts, noting that while the bias can happen, the general applicability of these situations is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or detailed advice on how to improve the clarity or applicability of these examples. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the general applicability of the examples presented. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper presents specific examples of biases and prediction shifts but lacks clarity on their general applicability. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the presentation of examples of biases and prediction shifts in the paper. It points out that while the paper presents these examples, it does not clarify their general applicability or relevance. This feedback is 3 as it highlights a potential weakness in the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as by offering examples of how these biases might apply in broader contexts or by recommending ways to enhance the explanation of their significance. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that adding a few more datasets would be beneficial, particularly in terms of crosstask transferability. While the comment implies that the authors should consider adding more datasets, it does not provide specific guidance on which datasets to include or how to incorporate them into the analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on crosstask transferability. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need to be revised. The comment is specific in suggesting the addition of datasets, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would impact the analysis. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that adding a few more datasets, particularly concerning crosstask transferability, would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets to include or how they would enhance the analysis. The feedback is 3 as it points out a potential gap in the paper, but it does not offer actionable steps for the authors to address this suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the tasks are somewhat standard and implies that the authors could have included more unique tasks to showcase the diversity of images/plots. It provides a specific example of interleaved imagetext tasks, such as question answering from images, as a potential area for improvement. While the comment does not explicitly instruct the authors to implement these tasks, it clearly outlines a direction for enhancing the paper by suggesting a specific area for innovation. The action is implicit but concrete, as the authors can infer the need to explore unique tasks and understand the potential benefits of doing so. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also mentions the potential for unique tasks that could showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the tasks or experiments described. The comment is specific in suggesting a potential area for improvement, which is to include more unique tasks. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks are somewhat standard, such as figure captioning and matching figures/subfigures to appropriate captions. It also implies that the authors could have included more unique tasks to showcase the diversity of images/plots, such as interleaved imagetext tasks like question answering from images. The comment provides a logical reasoning for why the tasks might be considered standard and suggests a potential area for improvement. However, it lacks specific examples or references to support the claim that unique tasks could have been included. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the tasks are somewhat standard and could benefit from more unique tasks to showcase the diversity of images/plots. It suggests specific areas for improvement, such as interleaved imagetext tasks like question answering from images. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their work by incorporating more innovative tasks. However, the comment could be more helpful if it offered examples or detailed guidance on how to implement these tasks. Overall, the comment is 4 as it provides a clear path for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether there is any additional novel effort in the section on 3D Gaussians generation, specifically mentioning the previous work by Luciddreamer. This request is clear and provides a direct action for the authors to take, which is to address the issue by either explaining the novelty or providing evidence of additional effort. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1 for 3D Gaussians generation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether there is any additional novel effort in this section. This provides clear guidance on what the authors need to clarify or improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation is merely a repetition of previous work, specifically mentioning \"Luciddreamer.\" However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the section on 3D Gaussians generation, specifically questioning whether there is any additional novel effort beyond the previous work by Luciddreamer. This feedback is 3 as it prompts the authors to clarify whether their work builds upon existing efforts or introduces new contributions. However, the comment lacks specific guidance on how the authors might address this issue or what additional efforts could be highlighted. While it points out a potential weakness, it does not provide actionable suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude and that the nonnegative constraint on the distribution is dropped, requiring further approximation. Additionally, it questions the assumption that the loss function belongs to the RKHS. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the tractability and assumptions of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the crude upper bound in the theorem and the assumption that the loss function belongs to the RKHS. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that MMD DRO does not enjoy a tractable exact equivalent reformulation, which is a severe drawback. The reviewer supports this claim by pointing out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and that further approximation is still needed even for a simple kernel ridge regression problem. Additionally, the reviewer questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. The comment provides logical reasoning and specific examples to support the claim, making it 4. However, it could be strengthened by providing more detailed examples or references to similar works that have addressed this issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the tractability of MMD DRO compared to other methods like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, as it drops the nonnegative constraint on the distribution, and that further approximation is still needed even for a simple kernel ridge regression problem. Additionally, it questions the assumption that the loss function belongs to the RKHS, which is already pointed out by the authors. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it alerts the authors to potential weaknesses in their methodology, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide explicit instructions, they imply that the authors should address these issues in their paper. The action is implicit but concrete, as it points to specific areas that need clarification or elaboration. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it specifically references the \"nonvanishing duality gap\" and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the comment does not explicitly mention a specific section or line in the paper, the authors can infer that it relates to the theoretical aspects of the framework or the application to nonconvex losses. The comment is specific in its inquiry about the relevance and potential use of the framework, making it weakly grounded but specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. The reviewer also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not present claims, they imply that the authors should provide more detailed explanations or justifications for the relevance of their framework. However, the comment lacks specific examples or references to support these questions, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the relevance of the framework to nonconvex losses and nonnorm type defenses, and it seeks clarification on the implications of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints. It also asks about the potential use of statistics, such as covariance, to design better defenses in binary classification. While the questions themselves do not provide specific suggestions for improvement, they prompt the authors to consider and address these important aspects of their work. The feedback is 3 as it encourages the authors to clarify and strengthen their theoretical foundations and applications. However, it could be more helpful if it offered specific guidance or examples on how to address these questions. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. While the comment implies that the authors should consider this approach, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it would impact the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests an experiment involving sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This is a clear and actionable suggestion that could potentially improve the paper by providing additional insights into the performance of the baselines. However, the comment lacks depth and does not explain why this approach might be beneficial or how it could be implemented effectively. While it provides a specific direction for improvement, it could be more helpful with additional guidance or rationale. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several areas where the paper lacks detail, specifically regarding the techniques used and the reproducibility of the results. It highlights the importance of understanding the sparsification process, the landmark generation, and the number of landmarks used. Additionally, it questions how to achieve shape invariance. While the comment provides a clear list of specific questions that need to be addressed, it does not offer explicit guidance on how to implement these improvements. The authors are left with a clear understanding of what needs to be added but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the techniques and the reproducibility of the results. It provides detailed questions about the sparsification process, landmark generation, and number of landmarks used, as well as how to achieve shape invariance. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be clarified or improved in each area. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper regarding the techniques used and the reproducibility of the results. It highlights specific areas that are unclear, such as the sparsification process, landmark generation, and number of landmarks used. The reviewer also questions how to achieve shape invariance. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support the claims. This makes the comment 3, as it points out areas that need clarification but lacks the depth and evidence needed for full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper lacks detail and clarity, particularly regarding the techniques used and the reproducibility of the results. It highlights specific questions that need to be addressed, such as the sparsification process, landmark generation, and number of landmarks used. The comment also questions how to achieve shape invariance and provides a detailed list of questions that, if answered, could significantly improve the clarity and reproducibility of the paper. This level of detail and specificity offers the authors clear guidance on what needs to be addressed to improve their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to reorganize the Appendix H section, which is difficult to follow. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific about the issue of difficulty in following the section, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the Appendix H section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is that it is difficult to follow. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Appendix H section is difficult to follow. However, it does not provide any specific examples or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is clear and actionable, as it directs the authors to reorganize the section to improve its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to reorganize the section or what specific changes might improve its readability. Overall, the comment is 3 as it points out a clear area for improvement but lacks detailed guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer suggests that more technical details, such as the number of units in the RNN implementation, are missing. This feedback implies that the authors should include these details in the main text or supplementary material to improve reproducibility. While the action is implicit, it is clear and concrete, as it specifies the exact details that need to be added to improve reproducibility. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the supplementary material, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with reproducibility, such as the lack of technical details like the number of units in the RNN implementation. This provides clear guidance on what needs to be addressed to improve reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, as it lacks technical details necessary for reproduction. The reviewer provides a specific example of the lack of details about the RNN implementation, such as the number of units. This claim is 3 as it highlights a gap in the paper\"s reproducibility, but it could be strengthened by providing more detailed examples or references to similar works that require such technical details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the paper, noting that while the pseudocode is provided in the supplementary material, it does not provide enough detail for actual reproduction. The reviewer highlights specific areas that are missing, such as technical details about the RNN implementation, which are necessary for reproducing the work. This feedback is clear and actionable, as it points out specific gaps that the authors need to address to improve the reproducibility of their work. However, the comment could be more helpful if it suggested ways to address these gaps or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars or more random trials to potentially reduce random fluctuations in the results. While the comment implies that the authors should consider adding these elements, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add error bars or more trials to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with the inclusion of error bars or more random trials to potentially reduce random fluctuations in the results. However, the comment does not provide any specific reasoning or evidence to support why error bars or more trials would be beneficial. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in Figure 1, suggesting that the inclusion of error bars or more random trials could strengthen the figure by potentially reducing random fluctuations in the results. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the figure\"s robustness and clarity. However, the comment could be more helpful if it explained why error bars or additional trials are beneficial or how they might impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. It also references external works that discuss contextaware robust finetuning, finetuning impact on foundation models, and robust finetuning of zeroshot models. While the comment provides explicit actions, it does not specify how to implement these suggestions or what specific details should be included in the introduction or Figure 1. The authors are given clear guidance on what needs to be added but lack detailed instructions on how to execute these actions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"related work section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a brief introduction to energy models in the related work section and the lack of clarity regarding the correspondence between different learning rates and steps in Figure 1. The comment also provides references to external works that could be relevant to the contextaware robust finetuning discussed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and clarifies the correspondence between different learning rates and steps in Figure 1. The reviewer references external works to support their claim, such as \"Contextaware robust finetuning,\" \"Finetuning can cripple your foundation model; preserving features may be the solution,\" and \"Robust finetuning of zeroshot models.\" These references provide a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples of how these references relate to the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. It also points out a lack of clarity in Figure 1, specifically regarding the correspondence between different learning rates and steps. The reviewer references external works that could be relevant to the contextaware robust finetuning discussed in the paper, which adds depth to the feedback. This guidance is clear and constructive, empowering the authors to enhance their draft by addressing these specific issues. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of premature evictions. The comment lacks concrete details or suggestions on how to improve the approach or validate its effectiveness. As a result, the authors are left without clear direction on how to apply this feedback to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the utilitybased approach used in FIITED, specifically the potential biases introduced by basing eviction decisions solely on utility scores. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue of temporary high utility scores leading to premature evictions, providing a clear direction for the authors to consider. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that basing eviction decisions purely on utility scores might introduce biases, specifically mentioning the risk of premature evictions due to temporary high utility scores for recent chunks. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim. The reasoning is logical but could be strengthened with additional evidence or detailed explanation. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the utilitybased approach used in FIITED, specifically the risk of biases due to temporary high utility scores for recent chunks. This is a valuable observation that could lead to premature evictions of other valuable chunks. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of biases. While it points out a relevant concern, it does not provide actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is not central to the paper and provides little valuable information. It suggests that the focus on DNNs is not relevant to the paper\"s core focus on detecting drift types and magnitude. The comment implies that the authors should reconsider the content and relevance of this paragraph, but it does not provide specific guidance on how to revise it or what alternative content could be included. The action is implicit and somewhat vague, as the authors need to infer the exact changes required to improve the draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is problematic: the lack of mention of drift in the introduction, which is central to the paper\"s focus. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is not central to the paper and provides little valuable information. This claim is 3 as it logically argues that the introduction of DNNs is not directly relevant to the paper\"s focus on detecting drift types and magnitude. However, the comment lacks specific examples or references to support the claim, making it 3. The authors may need to infer the relevance of the DNN introduction themselves, which could lead to some confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the paper\"s core focus. This feedback is clear and actionable, as it suggests that the authors should reconsider the relevance and content of this paragraph to ensure it aligns with the paper\"s central theme. By addressing this issue, the authors can improve the clarity and focus of their introduction, making the paper more effective for its intended audience. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the paper lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to include quantitative experiments and comparisons, as well as detailed explanations of the algorithms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific steps for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology and the experimental section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of quantitative experiments and comparisons with other algorithms, as well as the need for more detailed explanations of the presented ones. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the performance of the different parts of the framework and their contribution to the final result. It suggests that the lack of quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones, makes it unclear what the exact performance of the framework and its individual parts are compared to other solutions. The comment provides a logical reasoning for the need for more detailed information, but it does not include specific examples or references to support the claim. This makes the claim 3, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of clarity regarding the performance of the different parts of the framework and their contribution to the final result. It points out that while the framework yields promising visual stimuli results, it lacks quantitative experiments and comparisons with other algorithms, as well as detailed explanations of the presented ones. This feedback is valuable as it highlights a critical area for improvement in the paper, specifically the need for more comprehensive and detailed experimental results. However, the comment could be more helpful if it provided specific suggestions on how to address these gaps, such as which experiments to conduct or how to present the results more effectively. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they should consider to improve the clarity of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or table. The authors cannot confidently determine the exact part of the paper being addressed, making this comment weakly grounded. The comment is specific in its concern about the model\"s ability to generate novel knowledge or testable hypotheses, but without clear grounding, it lacks actionable guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the clarity of whether the model can generate novel knowledge or testable hypotheses about neuron data. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their work. Without actionable feedback or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, similar to Theorem 1. This implies that the authors should consider simplifying the content of Theorem 2 to make it more accessible to a broader audience. However, the comment does not provide specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While the action is implied, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not specify which part of the paper contains Theorem 2 or where the simplified version should be placed. The authors can infer that it relates to the section containing the theorem, but this inference is not direct. The comment is specific in suggesting a potential simplification but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. However, it does not provide any supporting evidence, reasoning, or examples to justify why this simplification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests simplifying Theorem 2 to make it more accessible to the general audience, similar to Theorem 1. This feedback is 3 as it identifies a potential area for improvement in making the paper more understandable and engaging for a broader audience. However, the comment lacks specific guidance on how to achieve this simplification or what aspects of Theorem 2 are particularly challenging for the general reader. While it points out a potential issue, it does not provide detailed suggestions or examples to help the authors effectively address the problem. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of their model. While the comment implies that the authors should conduct additional experiments, it does not provide specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and determine how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by using a larger image resolution, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests conducting experiments using a larger image resolution, specifically 224*224, to explore the performance of the model. This is a valuable suggestion as it could provide insights into how the model would perform with different image resolutions. However, the comment lacks depth and does not explain why this change would be beneficial or how it might impact the results. Additionally, it does not offer specific guidance on how to implement this suggestion or what aspects of the model might be affected by the change in resolution. While the comment identifies a potential area for improvement, it could be more helpful with additional context and detailed suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the calculation of the keypoint mask averaged feature vector, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the calculation of the keypoint mask averaged feature vector. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the calculation of the keypoint mask averaged feature vector, specifically asking whether it is calculated by multiplying each feature map elementwise by H_psi. While this question may be relevant to the authors, it does not provide any guidance or suggestions for improvement. It lacks actionable feedback or context that would help the authors understand how to address the issue or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use styles (e.g., dashed lines) or add color to make it easier to distinguish between the different curves in Figure 2. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve the figure. The suggestion is specific and actionable, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the difficulty in distinguishing between the different curves and suggests using styles or adding color to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish and recommends using styles (e.g., dashed lines) or adding color to improve clarity. However, the comment does not provide any specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested changes would improve it. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. The authors would need to make a significant effort to understand and implement the suggested changes, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on Figure 2, noting that the different curves are difficult to distinguish and suggesting ways to improve clarity. It recommends using styles (e.g., dashed lines) or adding color, which are clear and concrete suggestions that can help the authors enhance the figure\"s readability and understanding. This feedback is valuable as it directly addresses a visual aspect of the paper, providing the authors with a clear path to improve the presentation of their results. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly recommends that the authors tone down the introduction and not refer to the task as \"language learning.\" It suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is 5 as it gives a direct and specific direction for improvement, ensuring that the authors know exactly how to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction\" and the \"claims made in the introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the overstatement of the task as \"language learning\" and the evaluation on question answering, suggesting that it is more accurately described as a feedbackdriven QA in the form of a dialog. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are far from what has been achieved by the tasks and models, and suggests that the authors should tone down the introduction and not refer to it as \"language learning.\" The reviewer provides a logical reasoning by pointing out that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support the claim that the task is significantly different from language learning. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are far from what has been achieved by the tasks and models. It suggests that the authors should tone down the introduction and not refer to it as \"language learning,\" as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific and constructive suggestion for improving the introduction. By addressing this issue, the authors can enhance the clarity and accuracy of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or provide a convincing analytical or empirical argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the central contribution of the paper, specifically the use of ODEs to model weight evolution, and questions the accuracy of neural ODEs while recomputing activations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of inaccuracy in neural ODEs and the need for a convincing analytical or empirical argument. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the central contribution of the paper, which is modeling weight evolution using ODEs, is based on a problem of neural ODEs exhibiting inaccuracy while recomputing activations. The reviewer questions the accuracy of this issue and suggests that a previous paper first reported it. However, the comment lacks specific references or detailed evidence to support the claim that the issue is inaccurate or that it has been previously reported. This makes the claim 3, as the authors would need to conduct further research to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s central contribution, which is the use of ODEs to model weight evolution. It questions the accuracy of neural ODEs while recomputing activations, suggesting that this issue has been previously reported. The comment highlights a gap in the paper\"s analysis or evidence, noting that the current paper does not provide a convincing analytical or empirical argument to support its claim. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it points out a potential weakness, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While the comment implies that the authors should add this information, it does not explicitly instruct them to do so or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include this detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or table. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting what needs to be added, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not provide any supporting evidence, reasoning, or examples to justify why this mention is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. While it identifies a potential area for clarification, it lacks specificity and does not provide guidance on how to effectively mention this aspect in the paper. The comment is 3 as it points out a potential gap in the explanation, but it does not offer detailed suggestions or examples on how to address it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment implies that the authors should focus on proving lower bounds for round complexity, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on this aspect of the work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the results and methodology sections where the lower bound results are discussed. The comment is specific in detailing what is problematic about the paper\"s approach, but it lacks grounding as it does not specify which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. The comment provides a logical reasoning for why the lower bound results are not as significant as they might seem, but it lacks specific examples or references to support this claim. While the reasoning is somewhat valid, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that proving lower bounds for round complexity is a significant part of the work involved in proving results for batched ranking problems. However, it also points out that the paper exploits an easy reduction from the problem of collaborative ranking, which makes the lower bound results a straightforward corollary of the collaborative ranking results. This feedback highlights a potential oversight in the paper\"s approach and suggests that the authors should focus on proving lower bounds for round complexity to strengthen their results. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how other papers have successfully tackled this challenge. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. While the comment implies that the authors should consider using more advanced prompting techniques, it does not provide specific guidance on how to implement this suggestion or what specific prompts might be effective. The action is implicit and somewhat vague, as the authors need to infer the need for more advanced prompting techniques and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the prompting technique used in the study, suggesting that it is basic and fails to leverage the full potentials of LLMs. It recommends using carefully curated prompts to generate better systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique, making it weakly grounded. The suggestion to use carefully curated prompts is specific, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potentials of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or reasoning makes the claim 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the study, namely the use of a basic prompting technique that fails to leverage the full potential of LLMs. It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights an important area for improvement, it lacks specific guidance on how to implement this suggestion or what criteria should be used to curate prompts. This limits the comment\"s usefulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial but acknowledges the potential issue of compute. It also thanks the authors for their response and provides a positive assessment of how well the concerns were addressed. However, the comment does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to manage the compute issue. The action is implicit and somewhat vague, as the authors can infer that they should consider conducting additional experiments but are not given specific steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on larger datasets, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting the need for additional experiments but lacks detailed guidance on how to implement them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting additional experiments on larger datasets but acknowledges the potential issue of compute. It thanks the authors for their response and provides a positive assessment of how well the concerns were addressed. However, the comment lacks specific reasoning or evidence to support the claim about maintaining probabilities at large batch sizes. The suggestion is 3 as it provides a logical basis for the concern but does not offer detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, which could provide valuable insights into the model\"s performance and robustness. However, it acknowledges the potential issue of compute and notes that maintaining probabilities might become an issue at large batch sizes. While the comment identifies a potential area for improvement, it does not offer specific guidance or suggestions on how to address the compute issue or how to design the additional experiments. The feedback is 3 as it points out a potential area for improvement but lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the performance of the model on REC and RES is behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance or suggestions for potential improvements. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the performance of the model on REC and RES being behind more recent models, specifically mentioning GLaMM and UNINEXT as examples. This claim is supported by references to external works, which provides a basis for the comparison. However, the comment could be strengthened by providing more detailed analysis or specific metrics to support the claim further. As it stands, the claim is 4 due to the inclusion of references, but it could be more robust with additional evidence or explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights a significant issue with the performance of the model on REC and RES, comparing it to more recent models and providing specific examples like GLaMM and UNINEXT. This feedback is valuable as it identifies a clear area for improvement, allowing the authors to address the issue and potentially improve their results. However, the comment could be more helpful if it provided suggestions on how to improve the performance or offered guidance on potential strategies for catching up with more recent models. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area needing improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the term \"evidence\" might be too strong and recommends a more appropriate wording, such as \"Fig.\" This implies that the authors should revise the language in the paper to be more precise and accurate. However, the comment does not provide specific guidance on how to rephrase the term or what alternative wording would be more appropriate. While the action is implicit, it is clear that the authors need to adjust the language, but the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific figure (Fig. 5) and suggests that the term \"evidence\" might be too strong. However, it does not specify which part of the figure or the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting a more appropriate term, such as \"Fig.\" This provides some guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the term \"evidence\" might be too strong in describing the figure (Fig. 5) and recommends using a more appropriate term, such as \"Fig.\" This is a suggestion for clarification rather than a claim or opinion that requires verification. It does not present an argument or evidence to support the claim that \"evidence\" is inappropriate. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the language used in the paper, specifically suggesting that the term \"evidence\" might be too strong for the context of the figure being discussed. The reviewer provides a specific alternative, \"Fig.,\" which is a clear and actionable suggestion for the authors to consider. This feedback is valuable as it helps the authors improve the clarity and precision of their language, which can enhance the overall understanding and impact of their work. However, the comment could be more helpful if it explained why \"evidence\" might be inappropriate or provided additional context on the figure in question. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. While the comment identifies a specific area of concern, it does not provide explicit guidance on how the authors should address this issue or improve the novelty of their approach. The action is implicit and somewhat vague, as the authors can infer that they need to explore ways to enhance the innovation of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed video storyboarding approach\" and \"framewise SDSA,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of limited novelty, pointing out that the primary method relies on framewise SDSA, which is similar to ConsiStory. The comment further details the only notable difference, which is the mask source, using CLIPseg and OTSU segmentation instead of crossattention. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed video storyboarding approach lacks novelty, as it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer notes that the only notable difference is the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. This claim is 3 as it provides a specific comparison to ConsiStory, which is a wellknown approach, and highlights the difference in the mask source. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim of limited novelty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it relies heavily on framewise SDSA, which is similar to the approach used in ConsiStory. The reviewer highlights the only notable difference as the mask source, which uses CLIPseg and OTSU segmentation instead of crossattention. This feedback is 3 as it points out a specific area where the paper could be improved by exploring more innovative approaches or techniques. However, the comment lacks detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. To be more helpful, the comment could provide specific suggestions or examples of alternative methods that could be considered. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison, but it is not as concrete as it could be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, and proposes a comparison with previous approaches on fewshot classification in such datasets. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting a comparison with previous approaches and providing a potential dataset for testing, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this suggestion or how it could be tested. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the method being discussed is more relevant for images with multiple objects or cluttered scenes, which is a valuable observation. It also proposes an interesting comparison with previous approaches on fewshot classification in such datasets, which could provide valuable insights for the authors. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it points out a potential area for improvement, it does not offer detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so or specify how this explanation should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation of the bounds. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper discusses the bounds or where the explanation should be added. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the bounds are discussed, the comment lacks specificity in identifying the exact part of the paper that needs improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this additional explanation is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how to effectively explain the bounds or what aspects of the explanation should be included. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. This provides clear and direct guidance on what the authors should do, which is to clarify the implementation method and avoid unnecessary detail. The action is explicit and concrete, as it specifies the exact change needed in the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenAI\"s Triton\" and \"CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the implementation of kernels with OpenAI\"s Triton instead of CUDA and the suggestion that a fullpage explanation is unnecessary due to wellknown engineering improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is the case or why a fullpage explanation is not needed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered a valid critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a specific observation about the implementation of kernels with OpenAI\"s Triton, rather than CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. This feedback is 3 as it points out a potential oversight in the paper, but it lacks depth and does not offer suggestions on how to address the issue or improve the explanation. The comment could be more helpful if it provided additional context or guidance on how to present the information more effectively. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability. The reviewer also points out that the manipulation scenario might be challenging due to the complexity of the tasks. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the transferability and complexity of the tasks but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the work and the transferability of the policy, suggesting that the difficulty of the source and target tasks might limit the transferability. It also provides specific examples of the manipulation scenario, such as the 3prong task with clockwise and counterclockwise rotations, and the 4prong task, which could provide sufficient information about the target task. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the transferability and the complexity of the tasks, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While it provides some evidence and examples, it could be strengthened by offering more detailed explanations or references to support the argument. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the work and the transferability of the policy. It suggests that the difficulty of the source and target tasks might limit the transferability, and provides examples of the manipulation scenario to support this claim. The reviewer also points out that the policy transfer might be challenging due to the complexity of the tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or clarify their work. While it identifies potential weaknesses and areas for improvement, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is 3, as it highlights important areas for consideration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not provide specific guidance on how the authors should address this concern or what steps they should take to improve the results on larger backbones like SwinB or SwinL. The action is implicit and somewhat vague, as the authors can infer that they need to test the method on larger backbones but are not given clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method, noting that it achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. It also suggests that the proposed method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the relative gains and the potential impact of the global pooling structure on smaller backbones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method achieves only a small improvement of about 1% on most baselines, even with a smaller backbone like ResNet50. The reviewer suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. However, the comment lacks specific examples or references to support the claim about the relative gains or the potential impact of the global pooling structure on larger backbones like SwinB or SwinL. Without detailed evidence or comparisons, the claim is 3, as it provides a logical reasoning but lacks sufficient support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting that the relative gains are not very strong, even on a smaller backbone like ResNet50. It suggests that the method might be easier to improve on smaller backbones due to its global pooling structure. The comment raises a valid concern about the method\"s performance on larger backbones like SwinB or SwinL, which could be important for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method\"s performance on larger backbones. While it points out a potential weakness, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis of neural networks, specifically noting that the extension from linear models to wide fullyconnected neural networks is trivial with the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to reconsider their analysis of neural networks and possibly expand it to include more complex models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This provides clear guidance on what needs to be addressed in the analysis of neural networks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks is less significant due to the existing NTK theorem, which trivially extends from linear models to wide fullyconnected neural networks. The reviewer supports this claim by referencing specific sections (3.2, 3.3) where this analysis is discussed. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the existing NTK theorem makes the analysis trivial or how the work bypasses the core problem of overparametrized neural networks. While the reference to specific sections provides some context, the comment could be strengthened with additional justification or examples. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it highlights a potential weakness in the analysis of neural networks, which the authors could address to enhance the rigor and depth of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the analysis need improvement. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task (5, 6, and 4). It suggests that having such a small number might not be sufficient, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a specific suggestion to consider using more datasets to ensure rigor. However, the comment does not provide explicit guidance on how to select or acquire additional datasets, nor does it offer specific examples of datasets that could be used. While the action is implicit, it is clear that the authors need to consider expanding their dataset selection, but the lack of concrete details makes the comment 3.", "grounding_specificity_rationale": "The comment raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment is fully grounded as it explicitly mentions the number of datasets for each task, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it details the concern about the rigor of the evaluation and suggests that more datasets might be needed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The reviewer provides a logical reasoning by pointing out that having a limited number of datasets could impact the evaluation\"s thoroughness. However, the comment lacks specific examples or references to support the claim that some datasets are too large for all algorithms. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the rigor of the evaluation, given the limited number of datasets for each task. It suggests that having 5, 6, and 4 datasets for the tasks, respectively, might not be enough, particularly if some datasets are too large for all algorithms to be used. The comment provides a logical reasoning for the need to consider additional datasets to ensure a thorough evaluation. However, it lacks specific suggestions on how to address this issue or which datasets could be considered. While it identifies a potential weakness, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of results with larger models like ResNet101/152, which is a specific action for the authors to take. However, it does not provide guidance on how to conduct these experiments or what specific aspects to focus on. The comment implies that the authors should include results with larger models, but it lacks concrete details on how to implement this action. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the performance of ResNet models on imageNet classification, specifically mentioning ResNet50/34/18 and noting the absence of results with larger models like ResNet101/152. However, it does not specify which part of the paper discusses these results, making it weakly grounded. The comment is specific in identifying the issue of not including results with larger models, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results with larger models like ResNet101/152, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to previous studies or benchmarks, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of results with larger models like ResNet101/152. This is a clear and actionable observation that can guide the authors in expanding their experimental evaluation to include results with larger models. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the feedback is 3 as it highlights a gap in the paper but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the abstract and the introduction, specifically regarding the use of terms like \"relatively inexpensive\" and \"expensive to evaluate.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue, such as suggesting clarifications or rephrasing in the abstract or introduction. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, specifically mentioning a reference to Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach (Stroh et al., 2017). This provides full grounding as it explicitly mentions the specific part of the paper being addressed. The comment is also specific because it points out the confusion regarding the use of terms like \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of terms like \"relatively inexpensive\" and \"expensive to evaluate\" in the abstract and introduction, respectively. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these terms are confusing or misleading. Without additional context or examples, the claim remains 1, as it lacks the necessary information to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the abstract and introduction regarding the use of terms like \"relatively inexpensive\" and \"expensive to evaluate.\" This feedback is 3 as it points out a potential inconsistency in the language used, which could confuse readers. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending clarifications or rephrasing in the abstract or introduction. While it highlights an area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and questions whether it can solve sparsereward tasks as well as other methods (Qmix). However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable details, such as recommending specific experiments or analyses to conduct, or suggesting ways to improve the method\"s performance in sparsereward scenarios. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the method and the experiments, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the method addresses sparse reward problems and whether it can solve sparsereward tasks as well as other methods (Qmix). The comment provides a clear direction for improvement by asking for clarification on the method\"s performance in sparsereward scenarios. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the method\"s ability to address sparse reward problems and suggests that the experiments do not support this claim. The reviewer provides a logical reasoning by comparing the proposed method to dense reward signals and subtaskspecific rewards, which could be seen as a way to address sparse reward issues. However, the comment lacks specific examples or references to support the claim that the method does not address sparse reward problems effectively. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the method\"s ability to address sparse reward problems effectively, based on the experiments presented. It suggests that the proposed method requires subtaskspecific rewards, which is similar to dense reward signals, and questions whether it can solve sparsereward tasks as well as other methods (Qmix). The comment also includes minor comments that suggest specific areas for improvement. However, the feedback lacks detailed guidance or suggestions on how the authors might address these issues or improve their method. While it identifies potential weaknesses, the comment could be more helpful by providing actionable steps or examples to enhance the draft. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"curated AH36M dataset\" and the need for clarification on whether it is used for training. It also raises questions about whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about whether the curated AH36M dataset is used for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the fairness of the comparison. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of the curated AH36M dataset for training and whether other methods, such as HMR and SPIN, had access to the dataset during training for a fair comparison. This is an important consideration for ensuring the fairness and validity of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their methodology. While it identifies a potential area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment identifies two main issues: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific guidance on how to address these issues or what aspects of the proof or discussion are confusing. It lacks concrete details on how to improve the clarity or depth of the paper. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies specific issues with the proof of the main results, suggesting that there are confusing mistakes. However, it does not specify which part of the proof is confusing or where the mistakes are located. Additionally, it mentions the lack of a detailed discussion and comparison with previous work, but it does not specify which parts of the paper are missing this discussion. The comment also suggests that the paper lacks new insights, but it does not provide specific examples or details to support this claim. Overall, the comment is 1 and lacks specificity, making it difficult for the authors to understand and address the issues. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. Additionally, it suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The lack of specific examples or references makes the claim 1, as it does not provide sufficient evidence or justification to support the claims. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: confusion in the proof of the main results and the lack of a detailed discussion and comparison with previous work. It also suggests that the paper does not provide any new insights. However, the comment does not provide specific examples or detailed guidance on how to address these issues or what aspects of the proof or discussion are confusing. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses several issues related to the motivation, experimental results, and comparison of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The comment does provide some specificity by mentioning the addition of CAT and GAN, which could be used to guide the authors in identifying the relevant sections. Overall, the comment is weakly grounded because it does not specify the exact parts of the paper being addressed, but it is specific in identifying the issues. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point claims that the motivation for using an adversarial network is unclear and that the experimental results are unfair. It also suggests that the proposed model is equipped with newlyadded CAT and GAN, which is a larger model than others. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed explanations to substantiate the claims, making it difficult for the authors to understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity in the motivation for using an adversarial network, the unfairness of the experimental results, and the comparison with a larger model. It also points out the addition of CAT and GAN, which could be considered a significant change. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation or experimental results. While it highlights areas for improvement, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to compare their captioning experiment results to the official COOC leader board on the blind test set, which is a clear and concrete action. It also suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a specific example of [5,17] and mentioning that several other approaches have been proposed since then. This feedback is detailed and provides specific guidance on how to improve the paper by including comparisons to official test sets and other relevant works. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the captioning experiment, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the comparison to related work on the official COOC leader board on the blind test set. The comment provides a clear rationale for why this comparison is important and suggests specific examples of approaches that have been evaluated on the blind challenge set. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the captioning experiment should be compared to the official COOC leader board on the blind test set, which is a specific suggestion for improvement. The reviewer provides a reference to the COOC leaderboard and examples of approaches that have been evaluated on the blind challenge set, such as [5,17]. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would enhance the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the captioning experiment. It points out that the paper currently compares to related work only on some not official test set or dev set, which is not ideal for demonstrating the final results. The reviewer suggests that the paper should compare to the official COOC leader board on the blind test set, which is a widely recognized benchmark in the field. Additionally, the comment suggests that the paper should compare to other approaches that have been evaluated on the blind challenge set, providing a clear direction for improvement. This feedback is detailed and constructive, empowering the authors to enhance the credibility and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the reliability of the results or what specific steps to take to validate them. As a result, the authors are left without clear direction on how to improve the draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the MSE being significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. This observation raises concerns about the validity of the results and highlights a potential weakness in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their experimental results. Without actionable feedback or detailed analysis, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the novelty of their work. The comment lacks actionable details, such as recommending ways to differentiate the methodology or suggesting alternative approaches to enhance originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique is based on, such as specific sections or methods where the extension is evident. Without explicit references to sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or references to existing methods to substantiate this claim. Without detailed comparisons or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how the authors might differentiate their work or enhance its originality. Without actionable feedback or guidance, the authors are left without a clear understanding of how to address the critique or improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific techniques or approaches to incorporate adversarial loss or explaining why it is necessary. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out the absence of adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where this is discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the adversarial loss are missing or how it could be incorporated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is no adversarial loss to ensure that perturbed data is similar to authentic data. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, noting the absence of adversarial loss to ensure that perturbed data is similar to authentic data. This is a relevant point that could impact the validity and reliability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or incorporate adversarial loss. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific line (L248) where the term \"wrong\" is used and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is 5 as it offers a direct and specific suggestion for clarification, making it easy for the authors to implement the suggested changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"wrong\" and the use of terms like \"good\" and \"bad\" explanations. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the term \"wrong\" in a specific context and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This is a request for clarification rather than a claim or opinion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the term \"wrong\" in the paper and suggests that the authors clarify what is meant by \"good/bad/wrong\" explanations before using these concepts. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and coherence of the paper. By addressing this point, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered additional guidance on how to clarify these concepts or provided examples of how they might be clarified. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the limited comparison of performance with only a few methods and the lack of consistent superiority of the proposed method over others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. The reviewer is open to changing their rating based on feedback from the authors and comments from other reviewers. While the comment implies that the authors should provide additional analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific analysis required. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of performance comparison, specifically mentioning that the results are only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion for analysis is specific, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. However, the comment lacks specific examples or detailed reasoning to support why the results are inferior or how they violate the motivation. Without these details, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is 3, as it provides a general direction but lacks the necessary evidence or specificity to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance is only compared with a few methods and that the proposed method is not consistently better than others. It suggests that some analysis should be provided to address the issue of inferior results, as they violate the motivation. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their work. However, the comment could be more helpful if it provided examples of the analysis that should be conducted or suggested specific methods for evaluating the performance. Despite this, the feedback is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It explicitly states that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. This feedback provides a clear and concrete action for the authors to take, which is to include a comparison with the image classification result of MVF to demonstrate the superiority of their method. The comment is 5 as it directly instructs the authors on how to enhance their experimental setup to address the critique.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental demonstration of the contribution points\" and the \"experimental comparison between ELF (the author\"s method) and the baseline without Mid Vision Feedback (MVF),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the lack of a comparison with the image classification result of Mid Vision Feedback (MVF)\u2014and why this is important for proving the superiority of the schema searched by ELF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The comment provides a logical reasoning by pointing out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without MVF, which does not prove that the schema searched by ELF is better than the schema in MVF. However, the comment does not provide specific examples or references to support the claim that a comparison with the image classification result of MVF is necessary. This makes the claim 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It points out that the current experimental comparison only compares ELF (the author\"s method) with the baseline without Mid Vision Feedback (MVF), but not with the image classification result of Mid Vision Feedback (MVF). This feedback is clear and actionable, as it suggests that the authors should include a comparison with the image classification result of MVF to demonstrate the superiority of their method. By addressing this feedback, the authors can significantly enhance the experimental section of their paper, providing stronger evidence for their claims. Therefore, the comment is 5, as it offers a concrete and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should add more content on this topic. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information is discussed. The authors can infer that it relates to the dataset analysis or discussion, but the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but without explicit references, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these aspects are important or how they could be addressed. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that the authors should cover more on the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is clear and actionable, as it points out a gap in the paper that could enhance its depth and relevance. However, the comment could be more helpful if it provided examples or detailed suggestions on how to address this issue, such as which types of activities should be covered or how they could be integrated into the existing analysis. Overall, the comment is 4 as it directs the authors to a meaningful area for expansion and improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should use different notation to avoid confusion between the dimensionality of points and the dilation factor. This is a clear and direct action for the authors to take, as it provides a specific recommendation for improving the clarity of their paper. The comment is concrete, as it specifies the need for different notation, and it is also somewhat vague as it does not provide detailed guidance on what specific notation should be used. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"D\" to represent both dimensionality and dilation factor, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of different notation to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using \"D\" to represent both dimensionality and dilation factor can cause confusion. However, it does not provide any supporting evidence or examples to substantiate this claim. The comment lacks specific reasoning or references to justify why using different notation would be beneficial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, suggesting that using \"D\" to represent both dimensionality and dilation factor can cause confusion. This is a clear and actionable suggestion that can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided examples of alternative notations or explained why the current notation is problematic. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can enhance the overall quality of their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the concept of \"state\" and questions the equivalence of \"elements\" to \"states\" or \"actions\" in a specific context. While the comment identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more elaboration on the concept of state, but the comment lacks concrete suggestions on what specific aspects should be clarified or how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of \"state\" and its equivalence to \"elements\" or \"actions.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" and its equivalence to \"elements\" or \"actions.\" It suggests that more elaboration is needed. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the concept of state is unclear or how it should be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the concept of \"state\" and questions its equivalence to \"elements\" or \"actions.\" It points out that more elaboration is needed to clarify this concept, which is an important aspect of the paper. While the comment highlights a potential area for improvement, it does not provide specific suggestions or guidance on how to clarify the concept or what aspects need further explanation. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or table where the results are presented. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a comparison using the Jaccard index. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the support of the proposed solution with that of baseline methods, specifically mentioning the Jaccard index as a potential metric. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific method for evaluating the support of the proposed solution. However, the comment lacks depth and does not provide detailed guidance on how to implement this comparison or why it is important. Additionally, it does not address other aspects of the paper, such as clarity or coherence. While it points out a potential improvement, the feedback could be more comprehensive and actionable with additional explanation and context. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment does not provide explicit instructions or concrete steps for the authors to take to address this issue. While it implies that the authors should investigate and explain the reason behind the difference, it lacks detailed guidance on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not offer specific steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 5.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the tendency of a generator equipped with a standard RGCN as a discriminator to collapse after several iterations, while the proposed module does not. The comment suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, it does not provide specific suggestions on how to address this issue or what aspects of the proposed module should be explored. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a generator equipped with a standard RGCN as a discriminator tends to collapse after several iterations, while the proposed module does not. The reviewer suggests that understanding the reason behind this difference is essential to showcase the mechanism of the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors would need to further explore the issue to fully understand and address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific observation regarding the behavior of a generator equipped with a standard RGCN as a discriminator, noting that it tends to collapse after several iterations, while the proposed module does not. This observation is important as it highlights a potential difference between the proposed method and previous ones, which could be crucial to understanding the mechanism of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out an area for improvement, it does not offer actionable steps or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the originality of the paper, noting similarities to a previous study. It implies that the authors should address this issue by either explaining how their work differs from the previous study or demonstrating novel contributions. However, the comment does not provide specific guidance on how to do this, such as suggesting ways to differentiate the work or highlighting areas where novelty is present. The action is implicit and somewhat vague, as the authors need to infer that they should address the originality concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the originality of the paper, specifically mentioning a previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" This provides some grounding by referencing a specific work, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the paper are similar to the previous study or how the authors can address the originality concerns. The lack of specificity regarding the issues or suggestions for improvement makes it weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s originality is questionable due to similarities with a previous study. However, it does not provide specific examples or detailed comparisons to substantiate this claim. The mention of the previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning,\" serves as a reference but does not offer a comprehensive analysis or critique of the similarities. This lack of detailed evidence or reasoning makes the claim 3, as the authors would need to conduct their own analysis to fully understand the basis of the originality concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, noting similarities to a previous study, \"How Do Nonlinear Transformers Learn and Generalize in InContext Learning.\" It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address the originality concerns. The feedback is 3 as it points out a potential problem but does not provide actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any explicit or implicit suggestions on how the authors should clarify these comparisons or what specific aspects need to be addressed. There is no guidance on whether additional explanations or examples are needed, nor is there a recommendation for how to present the comparisons more clearly. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical comparisons to adaptive learning of GPRGNN, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the theoretical comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical comparisons to adaptive learning of GPRGNN. It points out that the comparisons are not clear, which is a critical issue for understanding the paper\"s contributions and implications. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these comparisons or what aspects need to be addressed. While it highlights an important area for improvement, the feedback is incomplete and does not fully support the authors in making the necessary changes. Therefore, the comment is 3, as it provides a direction for improvement but lacks actionable details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when performing other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the measurement. The action is implicit and somewhat vague, as the authors can infer that they need to consider alternative methods for measuring object hallucination, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. However, it does not specify which part of the paper this issue pertains to, such as a particular section or experiment where this measurement is used. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the methodology but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the sufficiency of using only yes/no responses to measure object hallucination. It highlights that a simple yes response does not necessarily indicate comprehension of the object in the image, as the model may still produce incorrect objects when undertaking other tasks. This claim is 3 as it provides a logical reasoning for why a simple yes/no response might not be sufficient. However, the comment could be strengthened by providing specific examples or references to studies that have demonstrated the limitations of such a measurement approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the sufficiency of using only yes/no responses to measure object hallucination, highlighting that a simple yes response does not necessarily indicate comprehension of the object in the image. It points out that the model may still produce incorrect objects when undertaking other tasks. This feedback is 3 as it identifies a potential limitation in the methodology and encourages the authors to consider alternative approaches for measuring object hallucination. However, the comment could be more helpful if it provided specific suggestions or examples of alternative methods that could be used. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and that the discussion requires improvement. It provides a specific action for the authors to take, which is to conduct experiments on more datasets and train the baseline models with the \"correct\" forecast horizon to put the results in a proper context. This feedback is explicit and provides concrete steps for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the verylongterm forecasting task being of limited practical significance and suggests that the discussion requires improvement. However, it does not specify which part of the paper discusses this task or the specific aspects that need improvement. The authors can infer that it relates to the discussion section, but the comment lacks full grounding as it does not explicitly mention the section. Additionally, while it suggests conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon, it does not provide detailed guidance on how to implement these improvements. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion requires improvement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the limited practical significance of the verylongterm forecasting task. It suggests that the discussion requires improvement by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon to put the results in context. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the discussion section of their paper. However, the comment could be more helpful if it elaborated on why the current discussion is insufficient or how the suggested improvements would enhance the paper\"s contribution. Overall, the comment is 4 as it guides the authors toward a meaningful revision of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. It suggests that this is a key difference between the work and VideoChatGPT and other works. The reviewer implies that the authors should include experiments and explanation to address this gap. While the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to conduct them, it clearly identifies an area for improvement and suggests a direction for the authors to take. Therefore, the comment is 3, as it provides a clear but implicit action for the authors to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Experiments  Ablation\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the inclusion of experiments and explanation regarding the different queries used in spatiotemporal representation, specifically spatial, temporal, and summary. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absence of experiments and explanation regarding the different queries used in spatiotemporal representation is a missing component. The reviewer suggests that this is a key difference between the work and VideoChatGPT and other works. However, the comment lacks specific examples or references to support the claim that these queries are crucial or how they contribute to the work\"s significance. Without detailed justification or evidence, the claim remains 3, as it provides a general suggestion but lacks the necessary depth to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of experiments and explanation regarding the different queries used in spatiotemporal representation. It highlights the importance of these queries as a key difference between the work and VideoChatGPT and other works. The comment suggests that the authors should include experiments and explanation to address this gap, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided specific examples of queries or detailed guidance on how to conduct these experiments. Overall, the comment is 4 as it points out a critical area for improvement and offers a clear direction for the authors to enhance their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not provide specific guidance on how the authors should address this issue or what aspects of the FRM should be elaborated upon. The comment implies that the authors should provide more details about the innovative aspects of their model, but it does not offer concrete steps or examples of what these details should include. As a result, the action is implicit and vague, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, it does not specify which part of the paper discusses the FRM, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the FRM should be elaborated upon or how the innovation could be detailed. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM, which is a combination of channel attention and spatial attention, lacks innovation and should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed FRM, which is a combination of channel attention and spatial attention, suggesting that it lacks innovation. However, it does not provide specific guidance or examples on how the authors could enhance the innovation or what aspects of the FRM should be detailed. The comment is vague and lacks actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the potential negative social impacts of their work, such as increased automation or dual use risks. While the comment does not explicitly instruct the authors to include these aspects in their paper, it provides a clear direction for improvement by highlighting areas that could be explored. The action is implicit but concrete, as it specifies the potential negative impacts that should be addressed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 379,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential negative social impacts of the work, such as increased automation or dual use risks. The comment provides a clear direction for improvement by suggesting that the authors should consider these aspects in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors state no negative social impacts of their work (line 379) and suggests that they should consider the potential negative impacts, such as increased automation or dual use risks. However, the comment lacks specific examples or references to support the claim that these potential negative impacts are significant or relevant to the work. Without detailed reasoning or evidence, the claim remains 3, as it provides a general direction for improvement but lacks the necessary justification to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the lack of consideration of negative social impacts, such as increased automation or dual use risks. While it acknowledges that the authors may not have intended to address these aspects, it provides a clear and actionable suggestion for improvement by encouraging the authors to consider these aspects in their work. This feedback is 3 as it points out a relevant area for exploration, but it could be more helpful if it offered specific examples or guidance on how to address these potential impacts. Overall, the comment provides a valuable direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific reorganization of the sections, proposing to move the first paragraph of Section 4 to Section 3 and placing the remainder of Section 4 before Section 3. This provides a clear and concrete action for the authors to take, as it offers a specific way to restructure the sections to improve clarity and coherence. The comment is explicit in its suggestion and provides a concrete implementation, making it 5.", "grounding_specificity_rationale": "The comment suggests reorganizing sections 3 and 4 to improve clarity and coherence. It explicitly mentions \"Section 3 and Section 4,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific because it suggests a specific reorganization, such as moving the first paragraph of Section 4 to Section 3 and placing the remainder before Section 3. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that sections 3 and 4 are redundant and proposes a specific reorganization to improve clarity and coherence. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the sections are redundant or how the suggested reorganization would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making changes. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential redundancy in sections 3 and 4, suggesting that reorganizing these sections could improve clarity and coherence. It provides a specific and actionable suggestion by proposing to move the first paragraph of section 4 to section 3 and placing the remainder before section 3. This feedback is clear and offers a concrete way for the authors to enhance the organization and flow of their paper, which could improve the overall readability and comprehensibility. However, the comment could be more helpful if it explained why the current organization is redundant or how the suggested reorganization would benefit the paper. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should provide more details to establish a connection between these concepts. However, the comment does not specify what kind of details are needed or how the authors should present them. While the action is implicit, it is vague because it lacks concrete guidance on how to address the issue of clarity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as the connection between these concepts and the zeroshot learning effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity between the concepts of \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that this lack of clarity is due to poor clarity in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might clarify these concepts or improve the clarity of their writing. While it highlights an area for improvement, the feedback lacks actionable details, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct these analyses to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"strong empirical results\" of the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the potential contribution of finding out the reasons behind the empirical results through theoretical analyses or experiments. However, the comment lacks specificity regarding what kind of theoretical analyses or experiments would be needed to address the questions raised. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the paper could provide theoretical analyses or extensive experiments to understand why the simple greedy selection approach outperforms more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment raises valid questions about the empirical results, it lacks specific examples or references to support the claim that these analyses are missing from the paper. The suggestion is logical and relevant, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could provide theoretical analyses or extensive experiments to understand the reasons behind the empirical results. It points out that the simple greedy selection approach outperforms more principled acquisition functions and that deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment highlights a valuable area for exploration, it lacks specific guidance on how to conduct these analyses or what aspects to focus on. The authors are given a direction for improvement but are not provided with detailed steps or examples to follow. Therefore, the comment is 3, as it points out a potential area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for a citation regarding the kmax problem, which is a clear and direct action for the authors to take. The comment provides a specific request for additional information, ensuring that the authors know exactly what is expected of them. The action is concrete, as it specifies the need for a citation, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for a citation regarding the kmax problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a citation regarding the kmax problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for a citation regarding the kmax problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual request for additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where additional information or clarification is needed. By asking for a citation regarding the kmax problem, the reviewer prompts the authors to provide more context or references to support their claims. This feedback is actionable and can help the authors enhance the comprehensiveness and credibility of their work. However, the comment could be more helpful if it provided more detailed guidance on how to address the issue or suggested specific sources to consider. Overall, the comment is 3 as it directs the authors to a specific area for improvement but lacks depth and detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. This feedback implies that the authors should provide more detailed information about the estimation process and the model\"s reliability. However, the comment does not explicitly instruct the authors to include this information, nor does it provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors can infer that they need to add more details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and how reliable the model is expected to be. This provides clear guidance on what the authors need to include in their paper to improve it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no information on how the function for the optimal sequence length was estimated (Equation 1) and how reliable the model is expected to be. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the estimation process and reliability of the model for the optimal sequence length. It highlights the lack of information on how this function was estimated and how reliable the model is expected to be. This feedback is valuable as it points out a critical area that the authors need to address to ensure the robustness and credibility of their work. However, the comment could be more helpful if it provided specific suggestions on how to present this information or what aspects of the estimation process should be emphasized. Overall, the comment is 3 as it directs the authors to a crucial area for improvement, but it lacks detailed guidance on how to address it effectively."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the applicability or what specific steps to take to mitigate the assumptions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the assumptions about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the assumptions made and their impact on applicability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods is limited due to strong assumptions about the availability of camera parameters and object segmentation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods, specifically noting that strong assumptions are made about the availability of camera parameters (extrinsics and intrinsics) and object segmentation. This feedback highlights a potential weakness in the paper that could impact its relevance and practicality. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it points out a relevant concern, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a discrepancy in the language used in Figure L006, specifically noting that \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level.\" This feedback is clear and provides a direct action for the authors to take, which is to revise the language in the figure to be more accurate. The suggestion is concrete, as it specifies the exact change needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the language used in the figure and suggests a possible correction by adding \"on the subword level.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figure caption, \"thousands,\" is not accurate. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment suggests a possible correction by adding \"on the subword level,\" but without further explanation or examples, it lacks verifiability. The authors may find it challenging to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in Figure L006, noting that the term \"thousands\" is not accurate. It suggests a possible correction by adding \"on the subword level,\" which could improve the accuracy of the figure. This feedback is clear and actionable, as it provides a direct suggestion for the authors to consider when revising their draft. However, the comment could be more helpful if it explained why \"thousands\" is not accurate or how the suggested correction would improve the figure. Overall, the comment is 4 as it points out a specific issue and offers a potential solution, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It notes that several hyperparameters, such as regularization, are not explicitly mentioned and asks for clarification on why the yvalue in the latent path figures is always 0 at x=0. The reviewer also expresses interest in seeing further analysis on the model, specifically mentioning interpolations. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestions are somewhat vague, as they do not specify how to address the issues or what specific analyses should be conducted. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig 3\" and \"regularization,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues by questioning the yvalue at x=0 in the latent path figures and expressing interest in further analysis of the model. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model. While the comment identifies areas for clarification and potential improvements, it lacks specific examples or references to support the claim that these issues are problematic or require attention. The lack of detailed reasoning or evidence makes the claim 3, as the authors may find it challenging to fully understand and address the issues without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the absence of certain hyperparameters, such as regularization, and the yvalue at x=0 in the latent path figures. It also expresses interest in further analysis of the model, specifically mentioning interpolations. While the comment highlights important issues, it lacks specific guidance or suggestions on how to address these concerns or what additional analyses could be conducted. The feedback is 3 as it points out areas for improvement but does not provide detailed instructions or examples on how to implement these suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It specifically points out that the exact contributions need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix rather than the main sections. While the comment provides a clear indication of what needs to be addressed, it does not offer specific guidance on how to improve the clarity of the contributions or suggest ways to integrate the material into the main sections. The action is explicit but somewhat vague in terms of execution, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"deeprag algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of forward referencing, where material is introduced without proper explanation and is later explained in later sections. The comment further details the need for clearer contributions in the Introduction and the placement of supporting material in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. The reviewer provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned as being in the appendix rather than the main sections. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to similar issues in other works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is later explained in later sections. It provides specific examples, such as Figure 1 and the deeprag algorithm, which are mentioned as being in the appendix rather than the main sections. This feedback is clear and actionable, as it directs the authors to clarify the contributions in the Introduction and ensure that supporting material is integrated into the main sections. By addressing these points, the authors can significantly improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided suggestions on how to effectively integrate the material into the main sections or offered guidance on how to present the contributions in a more clear and concise manner. Overall, the comment is 4 as it identifies a critical area for improvement and provides actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effect of rounding core tensors on the full tensor error and asks if there is an error bound in terms of epsilon. While the comment identifies a potential area for clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The authors are left to infer that they need to provide more information about the theoretical effects of rounding and the error bound, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the rounding of core tensors, allowing the authors to accurately identify the relevant section. It is also specific because it raises a question about the effect on the full tensor error and asks for clarification on the error bound in terms of epsilon. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effects of rounding core tensors on the full tensor error and asks for clarification on the error bound in terms of epsilon. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors discuss the rounding of core tensors and raises a question about the effect on the full tensor error. It asks for clarification on the error bound in terms of epsilon. This feedback is 3 as it points out a potential gap in the explanation and provides a clear direction for the authors to address. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar issues have been addressed in related work. Overall, the comment is 3 as it directs the authors to a specific area needing clarification but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. While the comment implies that the authors should add results on the generative setting, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on the generative setting in Table 1. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Table 1 only shows results on the discriminative setting, which is not applicable in real applications. The reviewer suggests that the authors should include results on the generative setting as well. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Table 1 only shows results on the discriminative setting, which is not applicable in real applications. It suggests that the authors should include results on the generative setting as well. This feedback is clear and actionable, as it directs the authors to address a gap in their experimental evaluation. However, the comment could be more helpful if it provided additional context or examples on how to conduct the analysis on the generative setting. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what kind of evidence or examples would be sufficient or how the authors should present them. The comment lacks concrete guidance on how to implement this suggestion, leaving the authors uncertain about what specific actions to take. As a result, the comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or example that needs improvement. The comment is 1, as it does not specify where in the paper this issue is addressed. Additionally, it lacks specificity because it does not provide details on what kind of evidence or examples would be sufficient to convince the reader. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide more evidence or examples to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. While it identifies a potential weakness in the paper, it lacks specificity and does not provide guidance on what kind of evidence or examples would be sufficient to address this concern. The comment is 3 as it points out an area for improvement, but it does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive and detailed."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific steps to take to explore the effectiveness of the approach for other language families. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the effectiveness of the proposed approach for other language families, which is a clear and specific point. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of unknown effectiveness, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach for other language families remains unknown. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of concern regarding the effectiveness of the proposed approach for other language families. It highlights a gap in the paper that needs to be addressed, which is important for the authors to consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how to explore or demonstrate the effectiveness of the approach for other language families. While it points out a relevant issue, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. While it identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or examples of what kind of security analysis should be conducted. As a result, the authors are left without clear direction on how to improve their draft in this area. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of analysis on the security (protection of privacy) of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of security analysis, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper, noting that the authors have not analyzed the security (specifically, the protection of privacy) of the proposed framework. This is a critical oversight that could impact the validity and reliability of the work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending particular security analyses or methodologies to consider. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. This provides a clear and direct action for the authors to take, which is to explicitly mention the form of p in their draft. The comment also references the reviewer\"s previous comment, which adds context and clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the form of p is not explicitly stated and assumes it to be a Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as it is assumed to be a Gaussian distribution. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption is valid or necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the form of p is not explicitly stated near line 135, despite being assumed to be a Gaussian distribution. This feedback is clear and actionable, as it directs the authors to explicitly mention the form of p in their draft. By addressing this point, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is 4 as it guides the authors toward a specific improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. While it implies that the authors should expand on these differences, it does not explicitly instruct them to do so or provide specific guidance on how to approach this enhancement. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed descriptions of the differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not specify which parts of the related work section are lacking in detail or which works are not described adequately. Without explicit references to specific sections or works, the authors cannot confidently determine which parts need attention. The comment is 1 as it does not specify where in the paper the related work section is located, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the works mentioned. However, it does not provide specific examples or references to the works that are lacking in detail or clarity. Without these details, the authors may find it challenging to understand the exact areas that need improvement. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient evidence or examples to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the related work section, specifically suggesting that the differences between the works mentioned are not described enough. This feedback is 3 as it points out a specific area where the paper could be strengthened, but it lacks depth and does not provide detailed guidance on how to address this issue. The authors are given a general direction to enhance the related work section, but the comment could be more helpful with additional suggestions or examples on how to improve the descriptions of the differences. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain what type of understanding is gained by looking at the PPP maps. This is a clear and direct request for clarification, providing the authors with a specific action to take. The comment is concrete because it specifies the exact information that needs to be added, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors state the importance of reliable PPP metrics for understanding PPP effects in different tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks for an explanation of what type of understanding is gained by looking at the PPP maps, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the authors\" explanation regarding the understanding gained from looking at PPP maps. It suggests that while the importance of reliable PPP metrics is mentioned, the article lacks explicit explanation or understanding of this concept. The comment is 3 as it provides a logical basis for the claim by pointing out the absence of detailed explanation, but it does not offer specific examples or references to support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the understanding gained from looking at PPP maps. It points out that while the authors mention the importance of reliable PPP metrics, they do not provide an explicit explanation or understanding of this concept. The comment is clear and actionable, as it prompts the authors to clarify what type of understanding is gained by looking at the PPP maps. This feedback is valuable as it directs the authors to enhance the clarity and comprehensiveness of their explanation, which could improve the overall understanding and impact of their work. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This implies that the authors should include such comparisons to enhance the credibility of their work. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of comparisons with other stateoftheart methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not compared their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which affects the credibility of their work. However, the comment does not provide specific examples or references to these stateoftheart methods or explain how the absence of comparison affects the credibility. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided sufficient evidence for the credibility of their work. It points out the lack of comparison with stateoftheart methods for spanrelated tasks, such as SpanBERT, which is a relevant benchmark for evaluating the effectiveness of the proposed methods. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the credibility of their work. However, the comment could be more helpful if it provided examples of how these comparisons could be conducted or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. It also mentions that the connection between the text and the figure, as well as the equations, is difficult to understand. This provides clear and concrete actions for the authors to take, such as redrawing the figure and improving the explanations in the text. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2(b)\" and \"the forwardprediction model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, namely the lack of a clear schematic representation in Figure 2(b) and the difficulty in connecting the text and equations with the figure. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the details of the forwardprediction model are not well explained, particularly in Figure 2(b), and suggests that the figure should be redrawn to better represent the schematic. The reviewer provides a specific example of the figure not showing the schematic representation and notes the difficulty in connecting the text and equations with the figure. This provides a clear and concrete basis for the claim, making it 4. However, the comment could be strengthened by providing additional details or references to similar issues in other works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clear explanation and representation of the forwardprediction model in Figure 2(b). It points out that the figure does not provide a schematic representation of the model, making it difficult for readers to understand the concept. The comment suggests that the figure should be redrawn to better illustrate the model. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that can help the authors enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the explanation or suggested alternative ways to present the model. Overall, the comment is 4 as it directs the authors to a specific area needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The reviewer also questions the authors\" approach and suggests that they should provide a stronger baseline than RBI to prove the usefulness of FP. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide a stronger baseline or address the training issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training process for RBI, specifically noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. It suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\" approach and suggests that they should provide a stronger baseline than RBI to prove the usefulness of FP. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the training process or results sections. The comment is specific in identifying the issue with the training process and the need for a stronger baseline, but it lacks grounding as it does not explicitly mention the sections of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the training process for RBI only focuses on rewarded actions, which ignores rewardless actions that could provide useful supervision. The reviewer suggests that this could be a significant factor in the superiority of FP + RBI over RBI alone. The comment also questions the authors\" approach and suggests that they should provide a stronger baseline than RBI to prove the usefulness of FP. While the comment provides a logical reasoning for the potential impact of the training process, it lacks specific examples or references to support the claim about the superiority of FP + RBI. The suggestion to provide a stronger baseline is somewhat vague, as it does not specify what kind of baseline would be appropriate or how it should be evaluated. Therefore, the claim is 3, as it provides a logical argument but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that could provide useful supervision. This is a significant observation that could impact the performance and effectiveness of the model. The comment suggests that this could be a factor contributing to the superiority of FP + RBI over RBI alone. Additionally, it questions the authors\" approach and suggests that they should provide a stronger baseline than RBI to prove the usefulness of FP. While the comment highlights important areas for improvement, it lacks specific guidance on how to address these issues or what kind of baseline would be appropriate. The feedback is 3 as it points out potential weaknesses and areas for improvement, but it could be more comprehensive with additional details or suggestions. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer suggests that the only benefit is the reduction of gradient path by the slow RNN. While the comment identifies a potential issue with the statement, it does not provide explicit guidance on how the authors should address this misleading aspect. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the time scales involved and possibly revise the statement to be more accurate. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"multiscale statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, explaining that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The comment further suggests that the only benefit is the reduction of gradient path by the slow RNN. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. The reviewer supports this claim by explaining the distinction between physical and logical time scales and the potential benefit of reducing gradient path by the slow RNN. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. As it stands, the comment is 4, as it provides a logical explanation but lacks specific references or detailed evidence to fully support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential misleading aspect in the paper regarding the multiscale statement. It points out that the slow and fast RNN do not operate on different physical time scales but rather on the logical time scale when the stacks are sequentialized in the graph. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and understanding of the work. However, the comment could be more helpful if it provided specific suggestions on how the authors might clarify this aspect or rephrase the statement to be more accurate. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several issues with the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. While the comment highlights areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The suggestion to discuss the similarity and difference with reinforcement learning is a vague direction, and the comment lacks specific guidance on how to address these issues. The authors are left with a general idea of what needs to be improved but without clear steps on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses several issues, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides some specificity in suggesting a direction for the conclusion, it lacks full grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline methods are weak and not stateoftheart, and that there is no discussion of limitations. It suggests that the paper could benefit from a comparison with reinforcement learning. While the comment identifies specific areas for improvement, it lacks detailed evidence or references to support the claim about the baseline methods or the need for a discussion on limitations. The suggestion for a comparison with reinforcement learning is somewhat vague, as it does not provide specific guidance on how to conduct such a comparison. Therefore, the comment is 3, as it provides some basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the weakness of the baseline methods, the lack of discussion on limitations, and the need for a comparison with reinforcement learning. It suggests a direction for the conclusion by proposing a discussion on the similarity and difference with reinforcement learning, as well as the generalizability of the results to RL settings. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a general direction but may need to infer more detailed steps to take. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the distinction between the expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. While the comment implies that the authors should make this distinction clearer upfront, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction, but it is concrete in that it provides a clear direction for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the distinction between expected performance under observation noise and the objective function of interest, which is a stochastic noisy function. The comment provides a clear direction for improvement by suggesting that the distinction should be made clearer upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the expected performance under observation noise is typically used for evaluation because the decisionmaker is interested in the true objective function and the noise is assumed to be noise (misleading, not representative). The reviewer suggests that in the current paper, the decisionmaker does care about the noise, and the objective function of interest is the stochastic noisy function. The comment provides a logical reasoning for the distinction between the two scenarios, but it lacks specific examples or references to support the claim that the current paper\"s approach is misleading. Therefore, the claim is 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s approach to evaluation, noting that the expected performance under observation noise is typically used because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. However, in the current paper, the decisionmaker is interested in the stochastic noisy function, which is a different objective. The comment suggests that the distinction between these two should be clarified upfront to avoid misleading the reader. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to clarify this distinction or provided examples of how other papers have addressed similar issues. Overall, the comment is 4 as it highlights an important distinction that the authors should consider, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This implies that the authors should experiment with using VGAE with a vamp prior to compare the benefits of the generative model and inference. Additionally, the comment recommends keeping the generative model fixed and optimizing only the inference part, parameterizing it as either SIGVAE or VGAE to compare representations. While the suggestion is clear, it lacks specific guidance on how to implement this change or what specific parameters to adjust. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VGAE with a vamp prior\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the potential benefits of the generative model and inference, and suggests running VGAE with a vamp prior to better match the doubly stochastic construction. Additionally, it provides a minor suggestion to keep the generative model fixed and optimize only the inference part, which is a clear and actionable point. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work. This claim is 3 as it provides a logical reasoning for the suggestion, which is to test whether the benefits are from a better generative model or better inference. However, the comment lacks specific examples or references to support the claim, such as studies that have used VGAE with a vamp prior or detailed explanations of how this would impact the results. Therefore, the comment is rated as 3, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to improve the paper by running VGAE with a vamp prior to better match the doubly stochastic construction. This is a specific and meaningful recommendation that could help the authors better understand the impact of their generative model and inference on the results. Additionally, the comment suggests a minor point about optimizing only the inference part of the model and parameterizing it as either SIGVAE or VGAE to compare representations. While this suggestion is 3, it lacks depth and does not provide detailed guidance on how to implement these changes. Overall, the comment is 4 as it offers clear and actionable feedback on improving the paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to enhance the novelty or contribution of their work. The action is implicit and vague, as the authors are left to infer that they need to improve the novelty or contribution of their work, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance of the method, specifically mentioning Table 2, and acknowledges the novelty and contribution of the work. However, it does not specify which part of the paper discusses the novelty or contribution, making it weakly grounded. The comment does specify that the main contribution is a new network design inspired by prior work for sound source localization, which provides some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method\"s performance is good, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. However, the comment lacks specific examples or references to support the claim that the method is incremental or lacks novelty. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the good performance of the method, especially in Table 2, but questions the novelty and contribution of the method. It suggests that the main contribution is a new network design inspired by prior work for sound source localization. While the comment identifies a potential issue with the novelty and contribution of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the importance of longrange dependencies in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the importance of learning longrange dependencies for powerful predictors, particularly in the context of semantic segmentation. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. The reviewer acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The comment suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. However, the comment lacks specific examples or references to support the claim that learning longrange dependencies is not always necessary. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the importance of learning longrange dependencies for powerful predictors, specifically in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer suggests that the truth likely lies somewhere in between and points out the need for a discussion on this topic. This feedback is 3 as it prompts the authors to consider the importance of longrange dependencies in their work and to address the potential ambiguity in their claims. However, the comment could be more helpful if it provided specific suggestions on how to frame this discussion or what aspects of the topic should be explored. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the definition of $e_l$ in Equation (3) and points out that the results in Corollaries 1, 2, and 3, as well as Theorem 4, have exponential dependence on the diameter $M$ of the domain of data. It also notes that the dependence on $M$ affects the constant factor of the required feature size. The reviewer suggests that this may indicate a weakness in the proposed approaches or at least in the theoretical results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The feedback is 3 as it highlights a potential problem but lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (3)\" and \"Corollaries 1, 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the definition of $e_l$ and pointing out the exponential dependence on the diameter $M$ of the domain of data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the definition of $e_l$ in Equation (3) and questions the exponential dependence on the diameter $M$ of the domain of data in the theoretical results. It suggests that this dependence affects the constant factor of the required feature size, which could indicate a weakness in the proposed approaches. The reviewer provides a logical reasoning by pointing out that the performance is more quickly getting worse than standard random features, as shown in Figure 1. This observation is based on factual data and logical reasoning, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the performance degradation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the definition of $e_l$ in Equation (3) and pointing out the exponential dependence on the diameter $M$ of the domain of data in the theoretical results. It suggests that this dependence affects the constant factor of the required feature size, which could indicate a weakness in the proposed approaches. The reviewer provides a logical reasoning by noting that the performance is more quickly getting worse than standard random features, as shown in Figure 1. This observation highlights a potential issue with the theoretical results and suggests that the authors should address this concern. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the theoretical results need further clarification. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, another phenomenon observed in the context of very deep graph networks. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what specific steps to take to improve the modeling ability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the longrange modeling ability of DGNs, specifically mentioning oversquashing and vanishing/exploding gradients as potential causes. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the potential causes of poor performance, such as oversmoothing, which is observed in the context of very deep graph networks. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modeling ability of DGNs is due to oversquashing and vanishing/exploding gradients, but also suggests that it could be due to oversmoothing. The reviewer supports this claim by referencing a paper that discusses oversmoothing in the context of very deep graph networks. However, the comment lacks specific examples or detailed explanations of how oversmoothing affects the modeling ability, making it 3. The authors would need to further explore the issue and understand the implications of oversmoothing to fully address the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modeling ability of DGNs, suggesting that it could be due to oversmoothing, a phenomenon observed in the context of very deep graph networks. This feedback is 3 as it points out a potential cause of the poor performance, which the authors could investigate further. However, the comment lacks specific suggestions or guidance on how to address this issue or what experiments to conduct to verify the hypothesis. While it provides a direction for further exploration, it could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors have a demonstration or result related to their model collapsing less than other methods. It also asks about the specific observation of gradients becoming 0 and collapsing, mentioning line 159. While the comment implies that the authors should provide evidence or examples to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for evidence or results related to the model collapsing less than other methods, and it raises questions about the common occurrence of gradients becoming 0 and collapsing. This provides clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification, rather than making subjective claims or opinions. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods. It specifically mentions line 159, where the authors mention gradients becoming 0 and collapsing. This feedback is 3 as it prompts the authors to provide evidence or examples to support their claim, which could strengthen the paper\"s argument. However, the comment lacks depth and does not offer specific suggestions on how to address the issue or what kind of evidence would be beneficial. While it points out a potential area for improvement, it could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific guidance on how to clarify the formulation or what aspects are unclear. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the issue. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the problem formulation is unclear in the statement and introduction examples, but it does not specify which parts of the paper these issues are found in. The authors cannot confidently determine which sections or examples are being addressed, making it weakly grounded. The comment is specific in identifying the issue of unclear problem formulation, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the problem formulation is unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without specific references or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specificity and does not provide any guidance on how to improve the clarity or what aspects of the formulation are unclear. Without actionable suggestions or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. This suggestion is clear and concrete, as it specifies the exact types of experiments that should be conducted. The authors know exactly what needs to be done to address the comment, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\"s applicability and generalizability. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives to provide insights into the method\"s applicability and generalizability. This claim is 3 as it logically suggests that including experiments with different LLM families could enhance the paper\"s contribution. However, the comment lacks specific examples or references to support the claim, such as explaining why these particular models are relevant or how they would impact the results. This makes the claim 3, as it provides a logical basis but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\"s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly suggests a specific area for improvement that could enhance the paper\"s contribution. By addressing this suggestion, the authors can significantly strengthen their work. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific insights to focus on. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to consider for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method only works for generative models that can be finetuned as an in/outpainting model. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method are limited to finetuning or how this limitation could be addressed. Without clear guidance on what needs to be improved or expanded, the authors may find it challenging to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method only works for generative models that can be finetuned as an in/outpainting model. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the method, suggesting that it only works for generative models that can be finetuned as an in/outpainting model. While this observation highlights a potential weakness, it does not provide any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address this limitation or what aspects of the method might need reconsideration. Without specific advice or constructive feedback, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a perceived weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\"s imagined process. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to improve the connections. The comment lacks actionable details, such as suggesting ways to clarify or strengthen the connections, making it difficult for the authors to know exactly how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first part and the second part, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the perceived weakness in the connections between the curve finding and FGE, and it provides a rationale for this observation. However, the comment lacks specificity regarding what needs to be addressed or improved in these connections. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the connections between the curve finding and FGE are weak, suggesting a discrepancy between the title and the actual process described. The reviewer provides a rationale by explaining their understanding of the process, which is based on their interpretation of the title and the first part of the paper. However, the comment lacks specific examples or references to support the claim, making it 3. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the connections between the curve finding and FGE, suggesting that the process described in the first part does not align with the title or the author\"s imagined process. It highlights a discrepancy in the authors\" expectations and the actual content, which could lead to confusion or misunderstanding. However, the comment lacks specific suggestions or guidance on how to address this issue or improve the connections between the two parts. While it points out a potential problem, it does not provide actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it identifies a weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include results for linear scalarization + Concorde, which is a heuristicbased solver, in their experimental analysis. This is an explicit action that the authors can directly implement to improve their draft. The comment provides a clear rationale for why this inclusion is necessary, as it highlights the competitive nature of learningbased solvers compared to heuristicbased solvers and the fact that the SOTA heuristicsolver usually has the best performance for single objective TSP. However, the comment could be more concrete by specifying which section of the paper should include these results, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and \"Pareto front\" from Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results for linear scalarization + Concorde, a heuristicbased solver, for a better comparison. This provides clear guidance on how to improve the paper by including additional results. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are better than the heuristicbased solvers, based on experimental results. However, it does not provide specific details or references to support this claim, such as specific experimental settings, results, or comparisons. The mention of \"SOTA heuristicsolver\" (e.g., Concorde) suggests that the authors should include results for linear scalarization + Concorde for a better comparison. While the comment highlights a potential area for improvement, it lacks detailed evidence or references to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include results for linear scalarization + Concorde, a heuristicbased solver, in their experimental analysis. This feedback is actionable as it provides a clear and concrete suggestion for enhancing the comparison between learningbased and heuristicbased solvers. By including these results, the authors can better demonstrate the performance of their learningbased solver in the context of a competitive landscape. However, the comment could be more helpful if it explained why this inclusion is important or how it would impact the overall analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use generalized Voronoi graphs, semantic maps, or pose graphs for exploration. While the comment implies that the authors should provide a comparison or discussion of their method with these existing methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of their method in relation to these existing methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and \"generalized Voronoi graph or semantic maps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely a discussion of the proposed method in relation to existing methods that use similar concepts for exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. The reviewer supports this claim by referencing existing methods, such as graphbased SLAM, where loop closure is applied. This provides a logical basis for the claim, as it highlights the potential overlap with existing methods. However, the comment could be strengthened by providing more detailed examples or references to specific works that demonstrate these similarities. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks comprehensive evidence or references.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that some of the general ideas presented are already present in other methods, specifically mentioning the use of generalized Voronoi graphs, semantic maps, and pose graphs for exploration. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could enhance its originality and contribution. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific examples or references to these existing methods to guide the authors in their analysis. Overall, the comment is 4 as it highlights an area for improvement and provides a clear suggestion for enhancing the paper\"s originality and contribution."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving some experimental details and tasks back into the main text and moving some background information from Section 2 to the appendix. While the suggestion is clear, it does not provide specific guidance on which details should be moved or how to structure them. The authors are left to infer which details are crucial to include in the main text and which can be moved to the appendix. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, tasks, and other details being moved to the appendix, making it difficult to interpret the paper. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. However, the comment does not specify which details should be moved or where they should be placed, leaving the authors to infer the exact changes needed. While the authors can infer the general areas being addressed, the comment lacks specificity in terms of what needs to be addressed or how to implement the suggested changes. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental setup, tasks, and other details are moved to the appendix, making it difficult to interpret the paper. The reviewer proposes moving some of these details back into the main text and suggests moving some background information from Section 2 to the appendix. However, the comment lacks specific examples or detailed reasoning to support why these changes would improve the clarity or interpretability of the paper. The suggestion is based on a general observation without detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization and presentation of the experimental setup, tasks, and other details, which are currently relegated to the appendix. This makes it difficult for readers to interpret the paper effectively. The comment suggests a solution by proposing moving some of these details back into the main text and moving some background information from Section 2 to the appendix. While the suggestion is clear and actionable, it could be more helpful if it provided specific examples of which details should be moved or how to structure them. Overall, the comment is 4 as it points out a critical issue and offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that glosses should be provided in Figure 2, which is a clear and direct action for the authors to take. The comment specifies the exact part of the paper where the glosses are needed, making it 5. The authors know exactly what needs to be done to improve their draft, providing concrete guidance on how to implement the suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing glosses in Figure 2, which is a specific part of the paper. However, it does not explicitly mention which section or figure should include the glosses, leaving the authors to infer the relevant part. While the suggestion is specific in terms of what needs to be added, it lacks full grounding as it does not directly point to the exact section or figure. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests providing glosses in Figure 2, which is a request for clarification or additional information. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is a factual statement and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment suggests providing glosses in Figure 2, which is a specific and actionable piece of feedback. By suggesting that glosses be added, the reviewer helps the authors improve the clarity and accessibility of their figures, making it easier for readers to understand the content. This is a clear and constructive suggestion that can significantly enhance the paper\"s readability and usability. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This implies that the authors should include a reference to the work or clarify the context in which \"Memb\" is mentioned. However, the comment does not explicitly instruct the authors to add a reference or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a reference, but it is not explicitly stated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Memb,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of a reference to the stateoftheart \"Memb,\" which is a clear issue that needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the term \"Memb\" is mentioned as the previous stateoftheart but no reference is provided. This is a clear and actionable point, as it highlights a potential gap in the paper\"s literature review or citation. By addressing this issue, the authors can ensure that their work is properly contextualized and grounded in the existing literature. However, the comment could be more helpful if it provided suggestions on how to include the missing reference or what specific works should be cited. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any explicit or implicit suggestions for how the authors might address this question or improve their draft. The comment lacks actionable guidance or specific recommendations, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the choice of grouping for quantization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of pertensor and perchannel grouping and suggests considering finer grouping instead. This provides clear guidance on what aspect of the quantization method is being questioned and what alternative might be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. However, it does not provide any supporting evidence, reasoning, or references to justify why finer grouping might be preferable. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the choice of grouping for quantization, specifically questioning why pertensor and perchannel grouping is used instead of finer grouping. This is a valid point that could lead to a more efficient or accurate quantization process. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or explore alternative methods. While it identifies a potential area for improvement, it does not offer actionable advice or detailed reasoning, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It explicitly recommends conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact aspect to investigate and offers a specific direction for further analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the model evaluation or results section, but this inference is not direct. The comment is specific in suggesting a particular aspect to investigate, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is important or how it would benefit the study. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1, as it does not provide sufficient justification for the authors to act on it.", "helpfulness_rationale": "The review comment suggests studying the impact of the ratio of unseen classes on the performance of the model. It provides a specific direction for further analysis by recommending conducting experiments to explore how the performance varies with different ratios of unseen classes unlabeled examples. This feedback is actionable and constructive, as it offers a clear and specific area for the authors to investigate to improve their draft. However, the comment could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it identifies a meaningful area for improvement and offers a clear path for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. While the comment implies that the authors should provide an explanation or rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address this question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these architectures are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if the combination of these architectures is a reason for the improvements. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the choice of using GRU for the Pyramid and LSTM for the sequential part, questioning whether the combination of these architectures is a reason for the improvements. This is a valuable point as it prompts the authors to consider the rationale behind their choice and whether it is justified. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for improvement, it could be more helpful with additional context or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the definition of \"active vertices\" in a specific line of the paper. While it identifies a potential issue with the clarity of the definition, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the definition, but it lacks specific instructions or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \"active vertices\" and seeks clarification on how it is defined in this context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the definition of \"active vertices\" in a specific line of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of \"active vertices\" in a specific line of the paper, which is a clear and actionable point. By asking for clarification on the definition, the reviewer prompts the authors to provide more detailed explanations or definitions to ensure that their work is clear and understandable. This feedback is valuable as it helps the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested alternative ways to present the definition or provided examples to illustrate the concept. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a discrepancy between the paper\"s claims and the limitations it discusses. It points out that the theory is not mentioned as a limitation in the main text, despite being applicable to the used model. The reviewer suggests that the authors should address this issue by explicitly mentioning the theoretical limitation in the main text. Additionally, the comment notes that the vagueness of structural assumptions in the appendix makes it difficult to find the theoretical limitation. The reviewer also suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general, which could be a valuable addition to the paper. The feedback is explicit and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fact that their theory does not seem to be applicable to the used model\" and the \"vagueness of unspecified 'structural assumptions,\" that are only given in the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of the theoretical limitation not being mentioned in the main text and suggests that the authors should elaborate on the potential negative societal impact of graph neural networks in general. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not mention the theoretical limitation of its theory being applicable to the used model, despite the vagueness of structural assumptions in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and should elaborate on the potential negative societal impact of these networks. The comment provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about the current use of graph neural networks in industry. Additionally, the suggestion to elaborate on the potential negative impact is somewhat vague, as it does not provide detailed guidance on what aspects of the impact should be addressed. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks specific evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the theoretical limitation of the theory being applicable to the used model is not mentioned in the main text. This is a critical oversight, as it affects the validity and applicability of the paper\"s claims. The reviewer suggests that the authors should address this limitation by explicitly mentioning it in the main text, which would enhance the transparency and credibility of the work. Additionally, the comment points out the vagueness of structural assumptions in the appendix, making it difficult for readers to find the theoretical limitation. This feedback is valuable as it highlights a critical area for improvement in the paper. However, the comment could be more helpful if it provided specific guidance on how to address the vagueness of structural assumptions or how to elaborate on the potential negative societal impact of graph neural networks. Overall, the comment is 4 as it identifies a significant issue and offers actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \"epsilongreedy\" in the context of training, indicating that the authors need to provide more information about this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \"epsilongreedy\" in the context of training. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"epsilongreedy\" in the context of training, specifically asking whether it is used in addition to the proposed strategy. This question highlights a potential area of confusion or misunderstanding in the paper, which could be clarified to enhance the readers\" comprehension. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but not comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the method or what specific aspects need attention. The authors are left without any direction on how to address the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the combination are lacking or how the authors could improve it. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with a Gaussian distribution replaced by a Gaussian mixture distribution. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might improve their work or address the critique. The comment identifies a potential issue with the method\"s novelty but does not offer actionable advice or insights into how to enhance the paper. As a result, the feedback is not helpful, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to ensure that both heads are affected. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors should address this issue. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) are affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). This is a clear observation that could be relevant for the authors to address, as it highlights a potential imbalance in the paper\"s focus. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific changes could be made to ensure a more balanced presentation. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide explicit guidance on what specific part of the framework is vital or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the importance of the framework but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment does specify what needs to be addressed, which is the discussion on the framework and its role in using CLIP for weakly supervised learning. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific part of the framework for using CLIP to guide weakly supervised learning. It suggests that the discussion is necessary to distinguish the paper from other related work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the framework should be emphasized. The feedback is 3 as it points out a potential gap in the discussion, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment identifies areas for improvement, it does not provide explicit guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. The authors are left to infer that they need to address these issues, but the lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment critiques the analogy between HOI analysis and Harmonic analysis, noting that the link is weak. It also points out the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. However, the comment does not specify which part of the paper discusses the analogy or the basis for HOI analysis, making it weakly grounded. The comment is specific in detailing the issues with the analogy and the connection to Fourier analysis, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, and that the connection between the decomposition/integration steps and Fourier analysis is not close. The reviewer provides logical reasoning by pointing out the limited basis for HOI analysis, with only two elements (human and object), and the lack of a direct connection between the decomposition/integration steps and Fourier analysis. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the basis of the analogy and the connection to Fourier analysis to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is not strong. It also highlights the limited basis for HOI analysis, with only two elements (human and object), and questions the connection between the decomposition/integration steps introduced in the paper and Fourier analysis. While the comment points out areas for improvement, it lacks specific suggestions or guidance on how to strengthen the analogy or clarify the connection between the decomposition/integration steps and Fourier analysis. This limits the comment\"s usefulness in helping the authors improve their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. However, it also acknowledges that most existing ML accelerators use bitparallel fixedpoint numbers, which could restrict the implications of the proposed methodology. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or explore its implications further. The action is implicit and somewhat vague, as the authors can infer that they might need to consider the impact of this limitation on the applicability of their methodology. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the potential limitation of the proposed methodology, specifically regarding the performance gains of dynamic precision control during training on bitserial accelerators. It also mentions the use of bitparallel fixedpoint numbers by most existing ML accelerators, which could restrict the implications of the proposed methodology. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the applicability of the methodology to existing accelerators. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators, which is a specific observation about the applicability of the proposed methodology. However, the comment lacks supporting evidence or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the claim is considered 2, as it provides a logical reasoning but lacks sufficient evidence or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed methodology, noting that dynamic precision control during training might only show meaningful performance gains on bitserial accelerators. This is a relevant observation that could impact the applicability and generalizability of the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or explore its implications further. While it highlights an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and whether it generalizes well. While the comment implies that the authors should consider including additional focus distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the focus distance range. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the focus distance shown in the figure, suggesting that it should include other distances beyond those present in the training data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus distance shown in Figure 8, noting that it only includes 1m and 5m, which are both present in the training data. The reviewer asks whether the focus distance extends beyond these examples and whether it generalizes well. This claim is 3 as it raises a valid question about the scope and applicability of the results. However, it lacks specific examples or references to support the claim that other focus distances should be considered. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 8, noting that it only shows focus distances of 1m and 5m, which are both present in the training data. It raises a valid question about whether the focus distance extends beyond these examples and whether it generalizes well. This feedback is 3 as it prompts the authors to consider the broader applicability of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional focus distances or discussing the implications of this limitation. Overall, the comment is 3 as it points out a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their neural application. It provides an example from Gabbay & Hosehn (2018) to illustrate how style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a clear direction for the authors to consider broadening their definition of content and style, it does not offer specific guidance on how to implement this suggestion. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the authors\" neural application and provides a specific example from Gabbay & Hosehn (2018) to illustrate the broader definition of content and style. It also raises a question about the authors\" understanding of the term \"style\" in their model, which adds specificity to the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, providing an example from Gabbay & Hosehn (2018) where style is instancespecific and content includes information that can be transferred among groups. The comment also raises a question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. While the comment provides a logical reasoning for broadening the definition of content and style, it lacks specific examples or references to support the claim that the authors\" understanding is incorrect. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider broadening their definition of content and style, particularly in the context of their neural application. It offers an example from Gabbay & Hosehn (2018) to illustrate how style can be defined more broadly and how content includes information that can be transferred among groups. Additionally, the comment raises a pertinent question about the authors\" understanding of the term \"style\" in their model, given that it is not sequential and does not capture the temporal dynamic structure. This feedback is valuable as it prompts the authors to reconsider their terminology and potentially enhance the clarity and applicability of their work. However, the comment could be more helpful if it provided specific guidance on how to address the question about the temporal dynamic structure. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. It provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. While the comment identifies areas that need further explanation, it does not explicitly instruct the authors on how to improve the analysis or provide guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of vit quantification, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the analysis could be explained in depth, particularly regarding the information distortion and the quantization of MHSA. The comment provides specific examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, specifically addressing the information distortion and the quantization of MHSA. The reviewer provides examples of the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This provides a logical and detailed explanation of the issue, making the claim 4. However, the comment could be strengthened by referencing specific studies or literature that support the claims about information distortion and quantization. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, specifically addressing the information distortion and the quantization of MHSA. It highlights the variance difference in the proposed approach compared to existing methods, such as QBERT, Q8BERT, BinaryBERT, and FullyBinaryBert. This feedback is 5 as it identifies specific areas where the authors need to provide more depth and clarity in their analysis. By pointing out the limitations of the proposed approach and referencing existing works, the comment offers actionable guidance for the authors to improve their draft. However, it could be further enhanced by suggesting specific ways to address the issues or providing additional references to support the claims. Overall, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a main weakness of the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN, and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The action is implicit and somewhat vague, as the authors can infer that they need to include comparisons to STN and provide more detailed explanations of the Xtransformation. However, the comment lacks concrete steps or examples on how to implement these improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"spatial transformer networks (STN)\" and the \"proposed Xtransformation,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the technical novelty of the work, the lack of comparison to STN, and the absence of empirical or conceptual comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited due to its similarity to spatial transformer networks (STN) and the absence of comparisons to STN. The reviewer supports this claim by mentioning existing works that propose to apply STN in a local pixel neighborhood and by pointing out that PointNet uses a variant of STN in their network architecture. However, the comment lacks specific examples or references to these existing works, which would strengthen the verifiability of the claim. While the reasoning is logical and the comparison to STN is clear, the lack of detailed references or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of technical novelty with respect to spatial transformer networks (STN) and the absence of comparisons to STN. It points out that the proposed Xtransformation seems similar to STN and that existing works have applied STN in a local pixel neighborhood. Additionally, it notes the absence of empirical or conceptual comparisons to STN in the paper. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to enhance the novelty and relevance of their work. By addressing these points, the authors can significantly improve the originality and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a confusion regarding the reward in Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. It provides references to external works that may help clarify the issue, such as [1] and [2], which are articles on the topic of reinforcement learning. However, the comment does not explicitly instruct the authors to include these references or provide specific guidance on how to clarify the reward or network model. While the action is implied, it is not as direct as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of confusion regarding the reward and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. The references provided, such as [1] and [2], could be helpful in clarifying the issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of Eq. 12, specifically questioning where the reward comes from and whether one of the r_i is taken from Eq. 11. The reviewer suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment identifies a potential issue with the clarity of the equations, it lacks specific examples or detailed reasoning to fully substantiate the claim. The references provided could be helpful in understanding the context, but the comment itself does not provide enough evidence or detailed reasoning to fully verify the claim. Therefore, the comment is 3, as it highlights an area for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Eq. 12, noting that the reward source is not clearly explained and questioning whether one of the r_i is taken from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. While the comment highlights a potential area for improvement, it does not provide detailed guidance on how to address the issue or suggest specific ways to clarify the equations. The references provided could be helpful, but the comment itself lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It explicitly instructs them to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31 and to attach each theorem and corollary to its corresponding proof in the main paper. Additionally, it highlights the primary concerns of motivation, methodology soundness, and experiment persuasion, which the authors should address to improve the paper. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of incorrect labeling of \"Fig.7\" as \"Fig.12\" and suggests attaching each theorem and corollary to its corresponding proof to improve clarity. Additionally, it provides a general assessment of the paper\"s qualities, such as its novelty, clear theoretical guarantees, and convincing empirical results. This feedback is specific and provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the labeling of \"Fig.7\" in Supp. Page 31, suggesting it should be labeled as \"Fig.12.\" It also provides a general assessment of the paper\"s qualities, such as its novelty, clear theoretical guarantees, and convincing empirical results. However, the comment lacks specific examples or references to support the claim about the labeling or the need for attaching theorems and corollaries to their proofs. While the general assessment is 3, the lack of detailed evidence or examples makes the claim 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It explicitly instructs the authors to correct the labeling of \"Fig.7\" to \"Fig.12\" in Supp. Page 31, which is a clear and specific action. Additionally, it suggests attaching each theorem and corollary to its corresponding proof to enhance the reader\"s understanding of the paper. This feedback is valuable as it directly addresses issues related to clarity and organization in the paper. The comment also acknowledges the paper\"s strengths, such as its novelty, clear theoretical guarantees, and convincing empirical results, which is a positive aspect. Overall, the comment is 4 as it offers concrete steps for improvement while acknowledging the paper\"s strengths."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the definition and implementation of the action verbs and action frames in the paper. It explicitly asks for clarification on the selection of 50 classes and the choice of action verbs, as well as the process of picking action frames. While the questions are clear, they do not provide explicit guidance on how to address them. The authors can infer that they need to provide more detailed explanations or examples to answer these questions, but the comment lacks concrete steps for implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the definition and implementation of action verbs and action frames, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification on the definition and implementation of certain concepts. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the definition and implementation of action verbs and action frames in the paper. It specifically asks for clarification on the selection of 50 classes and the choice of action verbs, as well as the process of picking action frames. While the questions are clear and provide a direction for improvement, the comment lacks depth and does not offer specific suggestions or guidance on how to address these issues. The authors are given a general idea of what needs to be clarified, but the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a minor issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the spelling of \"Empiically\" on line 32, suggesting it should be corrected to \"Empirically.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, noting a misspelling in the text. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a minor but important issue with the spelling of \"Empiically\" on line 32 of page 1, suggesting it should be corrected to \"Empirically.\" This is a clear and actionable suggestion that can help improve the accuracy and professionalism of the paper. By addressing this issue, the authors can enhance the clarity and credibility of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. It also points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. The comment provides a clear direction for the authors to consider incorporating representation learning into the feature selection process in Section 4.2. This feedback is explicit and concrete, as it specifies the exact area that needs improvement and how to address it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue with the proposed invariant learning module, suggesting that it could be improved by considering representation learning. Additionally, it provides a rationale for the suggestion by discussing the current framework and its limitations. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed invariant learning module could be improved by considering representation learning, which is currently discussed in the appendix. The reviewer provides a logical reasoning by pointing out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4. However, the comment lacks specific examples or references to the appendix or Section 4 to fully substantiate the claim. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3, as it requires further elaboration to fully support the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the proposed invariant learning module, suggesting that it could be enhanced by considering representation learning. It points out that the framework seems not to be limited to rawlevel selection, as evidenced by the discussion in Section 4, and notes that representation learning is currently discussed in the appendix. This feedback is clear and actionable, as it provides a specific direction for the authors to consider incorporating representation learning into the feature selection process. By addressing this suggestion, the authors could significantly improve the robustness and generalizability of their approach. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the design of rewards as an example. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending specific steps to clarify the reward design or suggesting ways to improve the explanation. As a result, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the design of rewards, which is a clear and specific point. However, it does not explicitly mention which part of the paper discusses the rewards, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of understanding of how the rewards are designed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"some details are missing,\" specifically mentioning the design of rewards as an example. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, specifically the design of rewards. It highlights a gap in understanding that could impact the clarity and effectiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the reward design. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the generalizability of a model to different numbers of entities, specifically mentioning Figure 3 of INs as an example. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalizability or suggestions for modifications to the model or methodology. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 3 of INs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the generalizability of the model to different numbers of entities, providing a concrete example from Figure 3 of INs. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of entities is fixed and that it is unclear how to generalize a model to different numbers of entities, using Figure 3 of INs as an example. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the generalizability of the model to different numbers of entities, referencing Figure 3 of INs as an example. This is a clear and actionable point, as it highlights a potential limitation in the model\"s applicability. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as discussing potential methods for adapting the model to different entity counts or suggesting ways to improve its robustness. Despite this, the comment still offers valuable insight into a potential weakness in the paper, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required. It also mentions that the experimental design is good. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest improvements, offer guidance on how to address the weakness, or provide specific feedback on the execution effort or experimental design. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"double edge point,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, backed by good experimental design. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it also points out that the approach lacks novelty and that the execution effort may outweigh the novelty. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific examples or detailed reasoning to support this claim. While the comment provides some insight into the potential weaknesses, it lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to consider but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment acknowledges the incremental improvement to the KNN based MT approach and the large engineering and execution effort required, which is backed by a good experimental design. However, it points out that the approach lacks novelty and that the execution effort may outweigh the novelty. The comment suggests that the lack of code release after the revision process could be a weakness, but it does not provide specific suggestions or guidance on how to address this issue. While the comment identifies a potential weakness, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it provides insight into a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the runtime of Prithvi WxC should be discussed, given its large parameter count and its potential impact on the applicability of MLbased emulators for climate model parametrizations. This is a clear and direct action for the authors to take, as it provides a specific area for improvement and guidance on how to address it. The comment is concrete, as it specifies the need for runtime discussion and the potential limitation of the model due to its large parameter count. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Prithvi WxC\" model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the runtime of Prithvi WxC and its potential limitation as a result of its large parameter count. This provides clear guidance on what aspect of the paper needs attention and improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed due to its large parameter count, which could be a limitation for MLbased emulators of climate model parametrizations. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this runtime is important or how it affects the applicability of MLbased emulators. Without additional context or explanation, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the runtime of Prithvi WxC should be discussed, given its large parameter count. This is a clear and actionable suggestion that could help the authors address a potential limitation of their work. By discussing the runtime, the authors can provide additional context and insights into the practical applicability of their model. However, the comment could be more helpful if it included specific examples or references to similar studies that have discussed runtime limitations in similar contexts. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or complexity of the idea, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the novelty or straightforwardness are problematic, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the novelty of the idea is not enough, and that both the new metric and method are straightforward. However, it does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions for how the authors might enhance the novelty or complexity of their work. Without actionable feedback or guidance, the authors are left without a clear understanding of what improvements could be made to address the critique. Therefore, the comment is rated as 2, as it identifies a potential weakness but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance on how to address this issue or what changes should be made to improve the clarity of the contribution. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as specific sections, figures, or claims. Without explicit references to these elements, the authors cannot confidently determine where to address the issue. Additionally, the comment lacks specificity regarding what aspects of the framing contribute to the overselling and how it affects the clarity of the contribution. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific references or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed guidance on how the framing could be improved to better convey the actual contribution of the work. Without actionable suggestions or examples, the authors are left without a clear understanding of how to address this issue. Therefore, the comment is not helpful, as it lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. While the comment provides a clear direction for improvement, it does not specify which steps should be taken or how to implement the changes. The authors are given a general idea of what needs to be improved but are left to determine the exact details of execution. Therefore, the comment is 3, as it provides a clear direction but lacks concrete guidance on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where the model description is discussed. The authors can infer that it relates to the model description or methodology sections, but this inference is not direct. The comment is specific in suggesting improvements, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model description could be improved by presenting the generative process in separate steps for better understanding, and it recommends reducing the number of symbols and using a notation table. However, the comment does not provide specific examples or detailed reasoning to support why these changes would improve the understanding of the model. The suggestion is based on general logic but lacks the necessary evidence or examples to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a logical basis but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model description, suggesting that the generative process could be presented in separate steps for better understanding. It also recommends reducing the number of symbols and using a notation table, which could enhance the clarity of the model description. While the comment provides actionable suggestions, it lacks depth and does not explain why these changes would be beneficial or how they would impact the overall understanding of the model. The authors are given a clear direction for improvement but could benefit from more detailed guidance on how to implement these changes effectively. Therefore, the comment is 3, as it provides a starting point for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the quality of paraphrases generated for training data, specifically noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. However, it does not provide explicit guidance on how to address this issue or what specific steps the authors should take to improve the quality of the paraphrases. The comment lacks concrete details or suggestions on how to improve the paraphrasing process, leaving the authors uncertain about how to apply the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of generating paraphrases for training data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear paraphrases and its impact on the quality of the final training data. The comment provides a clear rationale for the concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paraphrases generated for training data are unclear and impact the quality of the final training data. This claim is 3 as it logically follows that if the paraphrases are not sufficiently different from the original sentences, the quality of the training data could suffer. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, which is not as straightforward as it could be. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the quality of paraphrases generated for training data, noting that the paraphrases need to be sufficiently different from the original sentences to ensure the model\"s reliance on them. This is a crucial point that could significantly impact the quality of the final training data and, in turn, the overall performance of the model. The comment provides a clear and actionable suggestion for improvement, which is to ensure that the paraphrases are sufficiently different from the original sentences. However, the comment could be more helpful if it offered specific examples or guidance on how to achieve this goal. Overall, the comment is 4 as it highlights an important area for improvement and provides a clear direction for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggests that another color or a larger font might help in highlighting the humanidentified rationales better. While the comment provides a clear and concrete suggestion for improving the figure, it does not explicitly instruct the authors on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the font or color to enhance readability. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This provides clear guidance on what needs to be addressed to improve the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales for more complicated NLP tasks like machine translation is not a simple problem, and that the paper is wellorganized and easy to follow. The comment suggests that Figure 2 is cluttered and that the \"bold\" text is hard to see, proposing a solution of using another color or a larger font to enhance readability. While the comment provides a logical reasoning for the issue with Figure 2, it lacks specific examples or references to support the claim about the complexity of identifying rationales for NLP tasks. The suggestion to improve the figure is 3, as it provides a clear direction for improvement but could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 2, noting that the \"bold\" text is hard to see and suggesting that another color or a larger font might help in highlighting the humanidentified rationales better. This feedback is clear and actionable, as it provides a concrete suggestion for improving the figure\"s readability. However, the comment could be more helpful if it explained why the current font or color is problematic or how the suggested changes would enhance the figure\"s effectiveness. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, which can significantly impact the clarity and accessibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should verify the effectiveness and universality of the FlippedQA framework beyond LLMbased models, specifically mentioning HiTeA and InternVideo as examples. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is clear but not directly stated, making the comment 3. The authors can infer that they need to conduct additional experiments to verify the effectiveness and universality of the framework, but the comment lacks concrete details on how to implement this action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the FlippedQA framework, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to verify the effectiveness and universality of the framework beyond LLMbased models. This provides clear guidance on what additional experiments or analysis are needed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FlippedQA framework is a general framework for various generative VideoQA models but is only applied to LLMbased models. The reviewer suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. While the comment provides a logical reasoning for the need to test the framework on a broader range of models, it lacks specific examples or references to support the claim that these other models would be ideal for testing. This makes the claim 3, as it provides a clear direction but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper, noting that the FlippedQA framework is only applied to LLMbased models. It suggests that verifying its effectiveness and universality to nonLLMbased models like HiTeA and InternVideo would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental scope and demonstrate the generalizability of their framework. By addressing this point, the authors can enhance the robustness and applicability of their work. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific guidance or suggestions on how to improve the writing. The comment lacks actionable details, such as recommending ways to simplify the language, clarify concepts, or structure the paper for better readability. As a result, the authors are left without a clear understanding of what changes to make to enhance the clarity and accessibility of their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not specify which parts of the paper are particularly challenging to understand or where the writing could be improved. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the writing could be improved, specifically mentioning that it took effort to understand the main idea and theoretical analysis of the paper. However, it does not provide any specific suggestions or guidance on how to improve the writing, such as identifying areas that are confusing or offering recommendations for clarity or structure. Without actionable feedback, the authors are left without a clear understanding of what changes to make to enhance the clarity and accessibility of their draft. Therefore, the comment is rated as 2, as it points out a potential issue but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address these concerns to improve the paper. However, it does not provide specific guidance on how to address these concerns or what aspects of the method should be improved. The mention of existing methods and references to ClopperPearson intervals and Gaussian elimination suggest that the authors should provide more detailed explanations or comparisons to these methods. However, the comment lacks concrete instructions or examples on how to enhance the theoretical novelty or address the concerns effectively. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"existing methods\" that it builds upon, such as ClopperPearson intervals and Gaussian elimination. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the concerns about the lack of theoretical novelty and the need for the authors to address these concerns. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges a willingness to improve their score if the authors address these concerns. However, the comment does not provide specific examples or detailed reasoning to support the claim about the lack of novelty. The references to ClopperPearson intervals and Gaussian elimination suggest that the reviewer is familiar with these methods, but this alone does not fully substantiate the claim. The comment could be strengthened by providing more detailed reasoning or examples to support the critique. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern about the novelty of the proposed method, noting that it primarily builds upon existing methods like ClopperPearson intervals and Gaussian elimination. While it acknowledges the authors\" willingness to improve their score, the comment lacks specific guidance on how to address the concerns about the lack of theoretical novelty. It does not provide suggestions on how to differentiate the method from existing approaches or what aspects of the method could be improved to demonstrate novelty. The references to existing methods and the general critique are helpful in pointing out a potential weakness, but the comment could be more actionable with specific suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks explicit or implicit actions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about whether the text input can be concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the concatenation of text elements, but without explicit references to sections or figures, the authors cannot confidently determine where to address this question. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about whether the text input can be concatenated by the four text elements of an object. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the concatenation of text elements, specifically asking whether the four text elements of an object can be concatenated. While this question highlights a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or context, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper should provide a stronger motivation for why the topic is important. However, it does not specify what kind of motivation is needed or how it should be presented. The authors are left to infer that they need to include a motivation section, but without concrete guidance on what aspects to focus on or how to structure it, the action remains vague. Therefore, this comment is 3, as it identifies a potential area for improvement but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not specify which part of the paper this issue pertains to, such as the introduction or the sections where the topic is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what kind of motivation is needed or how it should be presented. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from a stronger motivation for why the topic is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper could benefit from a stronger motivation for why the topic is important. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance on how to achieve this motivation or what aspects of the paper need to be revised. Without actionable advice or examples, the authors are left without a clear path forward. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made to the sentence. The action is implicit and vague, as the authors are left to infer that they need to revise the sentence but without detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in lines 1217, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the sentence is cumbersome and could be made clearer. This provides clear guidance on what the authors need to improve, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and could be made clearer. However, it does not provide any specific reasoning or examples to support this claim. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the abstract, specifically the sentence in lines 1217. It points out that the sentence is cumbersome and could be made clearer, providing a clear direction for improvement. However, the comment lacks depth and does not offer specific suggestions or examples on how to simplify the sentence or what aspects are confusing. While it highlights an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative comparisons that might be more fair. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their comparisons, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the domainspecific model being trained on Pix3D and the experiments being conducted on Pix3D, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model and zeroshot singleimage 3D reconstruction models are unfair due to the use of Pix3D as both the training and testing dataset. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparisons made between the domainspecific model and zeroshot singleimage 3D reconstruction models, suggesting that these comparisons are unfair due to the use of Pix3D as both the training and testing dataset. This feedback highlights a potential bias in the experimental setup that could impact the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or suggest alternative comparisons that might be more fair. While it points out a relevant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the claim that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance. It also points out that Table 5 shows a tradeoff between head and tail categories but notes that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. Additionally, the reviewer encourages the authors to continue this line of work for future submissions. While the comment provides explicit actions to take, such as investigating the tradeoffs and improving the baselines, it lacks specific guidance on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Decouple [Kang et al.],\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the comparison to Decouple [Kang et al.] and suggests exploring the tradeoff between head and tail categories for the baselines. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is worse than Decouple [Kang et al.] for overall performance, and it provides a specific example of this by referencing Table 5. Additionally, it suggests that similar tradeoffs have not been fully investigated for the baselines, specifically mentioning the potential for Decouple [Kang et al.] to improve tail accuracy while decreasing head accuracy. This claim is supported by logical reasoning and specific examples, making it 4. However, the comment could be strengthened by providing more detailed evidence or references to support the claim about the tradeoffs for the baselines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a tradeoff between head and tail categories, as shown in Table 5, but points out that similar tradeoffs have not been fully investigated for the baselines. The reviewer suggests that the authors should explore this further and potentially improve the baselines by changing hyperparameters. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their work. However, it could be more helpful if it included suggestions on how to conduct the additional investigations or what specific hyperparameters to consider. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on realistic noisy datasets like WebVision would provide more support for the C2D method. While the suggestion is clear, it lacks specific guidance on how to conduct these experiments or what specific aspects of the C2D method should be tested. The authors are left to infer that they should conduct additional experiments, but without detailed instructions on how to do so, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the suggestion is clear, it lacks grounding as it does not specify where in the paper it should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, the comment does not provide any specific reasoning or evidence to support why these experiments would be beneficial or how they would impact the methodology. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This is a clear and actionable suggestion that could enhance the robustness and generalizability of the method. However, the comment lacks specific guidance on which aspects of the C2D method should be tested or how these experiments should be designed. While it identifies a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but requires further elaboration to be fully beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the evaluation, noting that it is based on only four OCR QA datasets and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include additional datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" and \"4 OCR QA datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limited evaluation and the need for more scenarios like the LLaVA benchmark in ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited and relies on only four OCR QA datasets, which may be unreliable. It suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. The comment provides a logical reasoning by pointing out the potential limitations of the current evaluation and the need for more diverse scenarios. However, it lacks specific examples or references to the LLaVA benchmark or other datasets, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable argument but could be more fully supported with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it is based on only four OCR QA datasets and suggesting that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This feedback is clear and actionable, as it points out a specific area where the evaluation could be expanded and improved. By suggesting the inclusion of additional datasets, the comment provides the authors with a concrete direction for enhancing the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it explained why the LLaVA benchmark is particularly relevant or how it might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their evaluation section."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the tasks. It lacks actionable details, such as recommending specific changes or methods to simplify the tasks. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It also questions the interpretation of the models\" learning and whether simpler tasks would suffice. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the tasks and the need for proof that more complex tasks are necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. The reviewer expresses difficulty in solving these tasks and questions the interpretation of the models\" learning. However, the comment lacks specific examples or references to support the claim that these tasks are overly complex or confusing. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to be 5.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the interpretation of the models\" learning and whether simpler tasks would suffice. The comment also asks for proof that more complex tasks are necessary. While the feedback identifies potential issues with the tasks, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the tasks. The comment highlights areas for consideration but does not provide actionable steps for improvement, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation of weak supervision could be improved by addressing the realism of the evaluated tweets. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should improve the realism of the evaluation and generation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"weak supervision\" and the \"evaluated tweets,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the realism of the evaluated tweets and the generation process, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the realism of the evaluated tweets and the generation process, suggesting that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. The reviewer also points out that the authors\" embeddings are initialized by averaging artificial tweets, which further undermines the realism. These claims are based on logical reasoning and observations about the nature of the prompt and the generation process. However, the comment lacks specific examples or references to support the claim that the evaluation is unrealistic. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It points out that the prompt requires all structured elements for perspectives to be present in the generated tweets, which may not be realistic. Additionally, it questions the realism of the authors\" generation, suggesting that the authors\" embeddings are initialized by averaging artificial tweets. This feedback is valuable as it highlights areas where the evaluation could be improved, providing the authors with a clear direction for enhancing the realism and credibility of their results. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or what aspects of the evaluation should be revised. Overall, the comment is 4 as it identifies a critical area for improvement and provides a direction for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of essential visualization of intermediate processes and comparisons, which is a clear actionable point. However, it does not provide specific guidance on what visualizations or comparisons are missing or how they should be presented. The authors are left to infer that they need to include visualizations and comparisons, but without concrete details on what is expected, the comment remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of essential visualization of intermediate processes and comparisons, which is a specific issue that needs to be addressed. However, it does not specify which parts of the paper should include these visualizations or comparisons, making it difficult for the authors to pinpoint the exact sections that need improvement. While the comment is specific in identifying the issue, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it points out a critical area where the authors need to enhance their draft. However, the comment could be more helpful if it provided suggestions on what types of visualizations or comparisons would be beneficial or how they could be effectively integrated into the paper. Despite this, the comment still offers valuable insights that can guide the authors in improving their draft, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. However, it does not provide any guidance on how the authors should address this issue or what specific changes need to be made to ensure compliance with the stated condition. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Definition 1\" and \"expected counterfactual,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the expected counterfactual violates a condition stated in Definition 1. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the expected counterfactual, noting that it violates a condition stated in Definition 1. This is a clear and actionable point that the authors can address to improve the accuracy and validity of their work. However, the comment lacks depth and does not provide suggestions on how to resolve the issue or what specific changes need to be made. While it highlights a critical area for improvement, it could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The authors are left to infer that they might need to reconsider the importance of their result in light of the external work, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the iteration complexity in Theorem 3 is no longer dimensionfree, which is a clear concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the result is not surprising due to external work that suggests perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. However, the comment lacks specific references to the external work or detailed reasoning to support the claim that the result is not surprising. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is 3, as it provides some basis for the claim but requires more detailed evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the importance of the result, referencing external work that suggests that perturbed gradient descent can find secondorder stationary points with almostdimensionfree polynomial iteration complexity. The reviewer also points out that the iteration complexity in Theorem 3 is no longer dimensionfree, which could impact the significance of the result. While the comment identifies potential weaknesses in the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it highlights areas for consideration, but it could be more beneficial with additional advice or actionable steps for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action, providing the authors with a specific task to accomplish. The comment is specific in detailing where the results should be included, making it 5. Authors know exactly what needs to be done to address the feedback, ensuring they can effectively implement the suggested changes. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be included, namely \"keypoint detection results.\" This provides clear guidance on what the authors need to address in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that keypoint detection results should be included in the experiments section. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s content and clarity. However, the comment could be more helpful if it explained why this inclusion is important or how it would enhance the understanding of the results. Overall, the comment offers a clear direction for improvement but lacks depth and explanation, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This explicit action provides a clear direction for the authors to take, as it specifies a specific comparison to be made. The comment is concrete, as it directly instructs the authors on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison with existing models, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific comparison that could enhance the paper by comparing the proposed model with existing models that use answers as inputs, such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16). This feedback is actionable and provides a clear direction for the authors to improve their draft by including a comparison that could strengthen the paper\"s contribution. However, the comment could be more helpful if it explained why this comparison is important or how it would benefit the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. It also mentions minor problems, but does not provide further details or suggestions for improvement. The comment implies that the authors should clarify this aspect of their methodology, but it lacks explicit guidance on how to address the issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the grid search process but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"grid search of learning rate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking whether the grid search is performed on the validation set, providing clear guidance on what needs to be clarified. However, the comment does not provide specific suggestions or examples for improvement, leaving the authors to infer what changes might be necessary. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of a question asking about the grid search for learning rate, specifically whether it is performed on the validation set. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the grid search for learning rate, specifically asking whether it is performed on the validation set. This is a relevant point that could impact the robustness and generalizability of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or that the term \"discourse\" is being used inappropriately. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or adjust their terminology. The comment lacks concrete details or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the high number of discourse relations in the treebank, suggesting that it might be an artifact of the colloquial language or an inappropriate use of the term \"discourse.\" This is a relevant point that could prompt the authors to reconsider their terminology and potentially clarify their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential area for clarification, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. While the comment implies that the authors should consider this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to consider diversity but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. However, it does not provide any supporting evidence, reasoning, or references to justify why this diversity is important or how it might impact the results. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the diversity of the sample in terms of racial and economic backgrounds, and whether the results might generalize to other groups, including marginalized ones. This is a relevant and insightful point that could prompt the authors to consider the broader implications of their findings and how they might apply to diverse populations. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional analyses or discussions. While it highlights a potential area for improvement, it could be more helpful with more detailed advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality. However, the comment does not provide specific guidance on how to achieve this improvement or what aspects of the output need to be addressed. The authors are left to infer that they need to work on improving the quality, but without concrete suggestions or detailed feedback, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, comparing it to recent GAN works and suggesting that there is still room for improvement. However, it does not specify which part of the paper discusses the output quality, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the output quality and the need for improvement, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but not realistic, comparing it to recent GAN works that have achieved higher quality results. The reviewer suggests that there is still room for improvement in result quality. However, the comment lacks specific examples or references to recent GAN works that have achieved higher quality results, making it 3. The authors would need to infer the specific examples or references themselves to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the output quality of the paper, comparing it to recent GAN works that have achieved higher quality results. It suggests that there is still room for improvement in the result quality, given the current state of the field. However, the comment lacks specific suggestions or guidance on how the authors might improve the output quality or what aspects of the paper need attention. While it highlights an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their work. It lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Therefore, the comment is 3, as it identifies areas of concern but does not offer detailed instructions on how to address them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"soft labels is essentially on top of CRM and Cross entropy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the use of subpar hyperparameters and the results being impressive but potentially misleading due to the use of subpar hyperparameters. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the concerns or how to address them. The lack of detailed justification or evidence makes the claim 2, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the use of soft labels on top of CRM and Cross entropy, questioning why the authors did not extend the curve further. It also mentions that the results seem impressive but expresses concern about the use of subpar hyperparameters, suggesting that the authors may be using suboptimal parameters. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. The feedback is 3 as it points out areas of concern, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a good idea but is presented as an afterthought. It implies that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement these changes or what specific translations to include. The action is concrete but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of more evaluation on classifying unseen words and the addition of translations to Figure 6 for nonChinese speakers. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is presented as an afterthought and that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also suggests adding translations to Figure 6 for nonChinese speakers. While the comment provides a logical reasoning for the need to expand the evaluation, it lacks specific examples or references to support the claim that the current evaluation is insufficient. This makes the claim 3, as the authors would need to infer the need for additional evaluation and translations based on the comment alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the presentation of the simple/traditional experiment for unseen characters as an afterthought. It suggests that more evaluation in this direction, specifically on classifying unseen words, would be beneficial. The reviewer also provides a specific suggestion to add translations to Figure 6 for nonChinese speakers. This feedback is clear and actionable, as it directs the authors to expand their evaluation and improve the clarity of their results. However, the comment could be more helpful if it provided additional guidance on how to conduct the suggested evaluations or what specific translations to include. Overall, the comment is 4 as it offers valuable insights and suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the number of images provided in the VioT dataset is small, which may impact the validity of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of images, provide additional data, or justify the current number of images. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the VioT dataset, specifically mentioning the number of images provided in each of the four categories. This provides full grounding as it allows the authors to accurately identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what aspect of the dataset\"s size is problematic or how it affects the validity of the approach. Without specific guidance on how to address this issue, the authors may find it challenging to understand and implement the suggested improvements. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the number of images in the VioT dataset is small, which may impact the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and how it affects the validity of the approach. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the VioT dataset, noting that the number of images provided is small, which may impact the validity of the approach. However, it does not provide any specific suggestions or guidance on how the authors might address this issue, such as recommending an increase in the number of images or suggesting alternative datasets. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. While the suggestion is explicit, it lacks concrete guidance on how to conduct the study or what specific aspects to focus on. The authors are given a clear direction to consider conducting an ablation study, but the lack of detailed instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this analysis could be conducted. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this study would be beneficial or how it would contribute to the understanding of NER tasks. Without such justification, the claim remains 1, as it lacks the necessary information to support the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study of the number of layers versus performance (perf) to explore the impact of layer count on NER tasks. This is a clear and actionable suggestion that could provide valuable insights into the effectiveness of different layer configurations in NER tasks. However, the comment could be more helpful if it included specific guidance on which aspects of the performance to focus on or how to design the ablation study. Despite this, the feedback is 4 as it directs the authors to a specific area for further exploration and potential improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and they had to read the text multiple times. While the comment provides some guidance on what needs to be improved, it lacks concrete details on how to implement these changes. The authors are given a general idea of what needs to be addressed but are not provided with specific steps or examples of how to improve the explanations or figure captions. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Fig. 1 and 2\" and \"figure captions,\" allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issues with the paper, such as the difficulty in following the mathematical derivations and the lack of explanations in the figure captions. The comment suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is hard to follow and suggests that more intuitive explanations are needed for the mathematical derivations. It also mentions that figure captions are lacking and require additional explanations and legends. The reviewer provides specific examples, such as the need to explain the colors in Fig. 2, which adds a level of detail and specificity to the claim. However, the comment could be strengthened by providing more detailed reasoning or references to similar works that have successfully addressed similar issues. Overall, the claim is 4, as it is supported by specific examples and observations, but it could be further substantiated with additional evidence or references.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and provides examples of what could be improved, such as explaining the colors in Fig. 2. Additionally, the reviewer mentions that Fig. 1 and 2 did not contribute much to their understanding, and they had to read the text multiple times. This feedback is clear and actionable, as it points out specific areas where the paper could be improved to enhance its clarity and accessibility. However, the comment could be more helpful if it provided suggestions on how to improve the explanations or offered additional guidance on how to make the paper more intuitive. Overall, the comment is 4 as it identifies key areas for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the sensitivity of empirical results to hyperparameter choices, emphasizing the potential impact on the method\"s effectiveness. It explicitly states that resolving this issue is crucial and suggests that the authors should consider this point. However, the comment does not provide specific guidance on how to address this issue, such as recommending particular analyses or experiments to test hyperparameter sensitivity. While the action is implied, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"hyperparameter choices\" and the \"empirical results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of sensitivity to hyperparameter choices and the potential impact on the method\"s effectiveness. The comment highlights the importance of resolving this issue and suggests that it could affect the overall rating of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the sensitivity of empirical results to hyperparameter choices, suggesting that wrong choices could undermine the method\"s effectiveness. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the sensitivity of empirical results to hyperparameter choices. It highlights the potential impact of incorrect choices on the effectiveness of the method, which is a crucial consideration for the authors. The comment explicitly states that resolving this issue is crucial and suggests that it could affect the overall rating of the paper. While it does not provide specific suggestions on how to address this issue, it points out a significant area for improvement that the authors should consider. Therefore, the comment is 4, as it directs the authors\" attention to a critical aspect of their work that needs further exploration and resolution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of their method\"s novelty, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to further claim the novelty and contribution of their proposed method, as it is similar to existing attack methods on a surrogate model. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the novelty and contribution, as it highlights the need for a more detailed explanation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is similar to existing attack methods on a surrogate model, suggesting that the novelty and contribution of the proposed method are not adequately addressed. However, the comment does not provide specific examples or references to existing methods, making it difficult for the authors to understand the exact nature of the similarity. Without detailed comparisons or references, the claim lacks verifiability, as it relies on a general observation without specific evidence or reasoning. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it is similar to existing attack methods on a surrogate model. It suggests that the authors need to further claim the novelty and contribution of their method to differentiate it from existing work. While the comment highlights an important area for improvement, it lacks specific guidance on how the authors might effectively demonstrate the novelty and contribution of their method. The feedback is 3 as it points out a potential weakness but does not provide detailed suggestions for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides specific references to external works that could be used to improve the paper. While the comment identifies the issues, it does not offer explicit guidance on how to address them, such as suggesting font size changes or providing examples of how to include the gradient symbol. The references are helpful but do not fully replace the need for explicit instructions. Therefore, the comment is 3, as it provides some direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the text size in Table 1 and the missing gradient symbol in Algorithm 1. Additionally, it provides references to external works that could be used to improve the paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements and observations about the paper, such as the size of the text in Table 1 and the missing gradient symbol in Algorithm 1. It also provides references to external works, which could be used to support the claims. However, the comment does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the text in Table 1 is too small and hard to read, and the gradient symbol is missing in Algorithm 1. It also provides references to external works that could be used to improve the paper. While the comment highlights these issues, it lacks detailed guidance or suggestions on how to address them. The references are helpful but do not fully replace the need for actionable feedback. Therefore, the comment is 3, as it provides some insights but does not fully support the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their discussion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed discussion on computational aspects and address the practical limitations of their methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects and questions the practical usefulness of the proposed methods for high dimensions. It specifically mentions the appendix and the algorithm\"s requirement to solve several LPs in high dimensions, which is not easily calculable. The comment also points out that the experiments are performed on small datasets. However, it does not explicitly mention which part of the paper discusses computational aspects or where the appendix is located, making it weakly grounded. The comment is specific in detailing the issues with the computational aspects and the experiments, but without clear grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail and questions the practical usefulness of their proposed methods for high dimensions. The reviewer supports this claim by pointing out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This provides a logical reasoning for the claim, but it could be strengthened by referencing specific calculations or examples to illustrate the practical limitations. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion of computational aspects and the practical usefulness of the proposed methods for high dimensions. It points out that the algorithm requires solving several LPs in high dimensions, which is not easily calculable, and that the experiments are performed on small datasets. This feedback is valuable as it highlights a critical area for improvement in the paper, particularly regarding the scalability and practicality of the proposed methods. However, the comment could be more helpful if it provided specific suggestions on how the authors might address these issues, such as suggesting ways to simplify the computational aspects or discussing alternative methods for highdimensional datasets. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the ResNet in the experiments in section 7.1 shares parameters between the residual blocks. It suggests that if not, a potentially interesting baseline would be to compare it to a deeper ResNet with parameter sharing, which could be equivalent to an ODE net with a fixed timestep Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 7.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about whether the ResNet in the experiments shares parameters between the residual blocks and suggests a potential baseline comparison with a deeper ResNet with parameter sharing. This provides clear guidance on what needs to be addressed or explored in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the ResNet in the experiments shares parameters between the residual blocks. It suggests that if not, a deeper ResNet with parameter sharing could be a baseline comparison. The comment provides a logical reasoning by comparing the ResNet to an ODE net with a fixed timestep Euler integrator. However, it lacks specific examples or references to support the claim that parameter sharing would be equivalent to an ODE net. This makes the claim 3, as the authors would need to make a connection themselves based on the provided reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the ResNet in the experiments, asking whether it shares parameters between the residual blocks. This is a relevant point that could impact the validity and comparability of the experiments. The comment also suggests a potential baseline comparison with a deeper ResNet that shares parameters, which could provide a more accurate representation of the model\"s capabilities. While the comment identifies a potential area for improvement, it lacks detailed guidance or suggestions on how to implement this comparison or what specific aspects to focus on. Therefore, the comment is 3, as it points out a potential weakness but does not fully guide the authors on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a major issue with the motivation section, specifically regarding the crossencoder architecture. It notes that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the motivation section or what specific changes should be made to clarify the architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the motivation section, particularly regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment does not specify which part of the motivation section this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the crossencoder architecture, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture is not ignoring crossentity comparison but instead attends to all candidates at once, which may not be as finegrained as expected. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a major issue with the motivation section, specifically regarding the crossencoder architecture. It points out that the architecture is not ignoring crossentity comparison as previously stated but instead attends to all candidates at once, which may not be as finegrained as expected. This feedback is clear and actionable, as it highlights a critical misconception in the paper that the authors need to address to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided suggestions on how to clarify or adjust the motivation section to better align with the current understanding of the crossencoder architecture. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve their design choice. The comment lacks actionable details, such as recommending alternative approaches or suggesting ways to justify the decision. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or how it might impact the paper\"s results or analysis. Without detailed justification or examples, the claim remains 3, as the authors may find it challenging to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the design choice of trimming questions after the first 10, suggesting that it is an odd choice given the nature of the question model, which is a bag of words. This feedback highlights a potential issue with the methodology, prompting the authors to reconsider their approach. However, the comment lacks specific suggestions or guidance on how to address this issue or what alternative design choices might be considered. While it identifies a potential weakness, it does not provide actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work uses an outdated GNN model and method, which affects the performance of the framework. It also mentions that the baseline algorithms/methods are also outdated. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without actionable guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of an outdated GNN model and method, which affects the performance of the framework. However, it does not specify which part of the paper discusses the GNN model or the baseline algorithms/methods, making it difficult for the authors to pinpoint the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the GNN model or baseline algorithms/methods are outdated or how they could be improved. Without clear guidance on what needs to be addressed, the authors may find it challenging to make the necessary changes. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an outdated GNN model and method, which impacts the performance of the framework. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the use of outdated methods affects the performance. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the work, noting that it uses an outdated GNN model and method, which impacts the performance of the framework. This is a critical observation that could significantly affect the paper\"s credibility and relevance. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as suggesting modern alternatives or updating the methods. Without detailed feedback or constructive advice, the authors are left without a clear path forward to improve their draft. Therefore, the comment is 3, as it points out a critical weakness but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how the proposed method produces the type of explanation mentioned in Figure 1. It suggests that additional adhoc postanalysis might be required to extract shared motifs to explain a set of instances. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific steps the authors should take to improve the explanation. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to clarify the process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding how the proposed method produces the type of explanation mentioned in the figure. The comment suggests that additional adhoc postanalysis might be required to extract shared motifs, and it implies that this analysis might be easier with the proposed method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the explanation in Figure 1 is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. The reviewer provides a quote from Line 48 to support this claim, which suggests that the analysis might be easier with the proposed method but still requires additional effort. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the quote provides some context, it does not fully address the issue of clarity or the necessity of additional analysis. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 1, noting that the explanation provided is unclear and suggests that additional adhoc postanalysis might be required to extract shared motifs. It references Line 48 to provide context and implies that the proposed method might make this analysis easier but still requires additional effort. While the comment highlights a potential weakness in the explanation, it does not offer specific suggestions or guidance on how to address this issue or improve the clarity of the figure. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed guidance for the authors to enhance their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The comment provides two ways to strengthen the experiment: by either using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. While the comment provides some guidance on how to address the issue, it lacks specific instructions on how to implement these suggestions. The action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment that estimates the quality of uncertainty estimates, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the experiment, which relies on pseudo feature importance due to the unavailability of true feature importance. The comment provides specific guidance on how to strengthen the experiment by suggesting two ways: using a different method to estimate the true feature importance or providing a more detailed explanation of the perturbation value. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment relies on pseudo feature importance due to the unavailability of true feature importance. It suggests that the correctness of the pseudo feature importance is based on Proposition 3.2 and a large enough perturbation value. The reviewer provides a logical reasoning by explaining the potential issue with the experiment\"s reliance on pseudo feature importance and the need for a more detailed explanation of the perturbation value. However, the comment lacks specific references to external works or examples to fully substantiate the claim. This makes the claim 3, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the experiment estimates the quality of uncertainty estimates by comparing the true feature importance to a 95% credible interval. However, the true feature importance is not available, so the experiment relies on pseudo feature importance. The reviewer suggests two ways to strengthen the experiment: by using a different method to estimate the true feature importance or by providing a more detailed explanation of the perturbation value. This feedback is clear and actionable, as it offers specific suggestions for improving the experiment\"s reliability and credibility. By addressing these points, the authors can enhance the robustness and trustworthiness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific properties of Z should be considered or how to address the issue of nonconvexity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ln. 182184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the issue of nonconvexity and suggests that it may not be a problem if the function Z has certain properties. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. However, the comment lacks any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a specific line in the paper (ln. 182184) and suggests that nonconvexity may not be an issue for the SGD to converge if the function Z has certain properties. While this feedback highlights a potential issue, it lacks depth and does not provide specific guidance or examples of what properties of Z would be beneficial for convergence. The comment could be more helpful if it offered suggestions on how to explore or test these properties, or if it provided references to similar studies or literature. As it stands, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to compare models, clarify confusing sections, and correct the missing citations and unreferenced notation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"several sections\" and \"Line 99, section 3.1,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the lack of model comparison, confusing sections, missing citations, and unreferenced notation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors did not compare any models other than GPT2, which is a factual observation. It also mentions that several sections are confusing and points out specific missing citations and unreferenced notation. However, the comment lacks detailed reasoning or examples to support why these issues are problematic or how they impact the paper\"s overall quality. The absence of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is 3, as it provides some evidence but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of model comparison, confusing sections, missing citations, and unreferenced notation. It highlights specific sections and lines that need attention, providing clear and actionable feedback for the authors to improve their draft. By pointing out these issues, the comment helps the authors understand what needs to be addressed to enhance the clarity and completeness of their work. However, it could be more helpful if it offered suggestions on how to improve the confusing sections or provided examples of how to better compare models. Overall, the comment is 4 as it directs the authors\" attention to critical areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific lines in the SuppMat that should be moved from red to green. This provides clear and direct instructions for the authors to follow, ensuring they know exactly what changes to make. The action is concrete, as it specifies the exact lines and their corresponding SuppMat sections, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the SuppMat, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the exact lines that need to be moved from red to green, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the SuppMat, specifically mentioning lines that should be moved from red to green. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific lines in the SuppMat that should be moved from red to green, providing clear and actionable feedback. This guidance is valuable as it helps the authors ensure that their SuppMat is accurate and uptodate. However, the comment could be more helpful if it explained why these lines are important or how they contribute to the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to make a specific correction that can improve the clarity and accuracy of their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be included. The comment lacks concrete details on what changes the authors should make to enhance their draft. As a result, the authors are left without clear direction on how to address the suggestion. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should address. It also mentions that the paper is a short one, which implies that the suggestion is not a strong negative. However, without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to understand what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would enhance the paper. The comment lacks specificity and does not offer detailed guidance on what aspects of the analysis should be expanded or how to conduct it. As a result, the claim is 1, as it does not provide sufficient justification for the authors to understand and act upon the suggestion.", "helpfulness_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance on what aspects of the analysis should be expanded or how to conduct it. The comment acknowledges that the paper is a short one, which limits the scope of the analysis. While the suggestion is valid, the lack of actionable details makes it difficult for the authors to understand and implement the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of proper experimental settings and the absence of code. While it points out the importance of result reproducibility, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to include detailed experimental settings and provide the code, but the comment lacks concrete steps or examples on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental settings\" and the absence of \"code,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for proper experimental settings and the provision of code to ensure result reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly and that the result reproducibility is critical. It also notes the absence of code, which is a significant concern. However, the comment does not provide specific examples or detailed reasoning to support why the experimental settings are not mentioned or how the lack of code affects result reproducibility. This makes the claim 3, as the authors would need to infer the importance of these issues and potentially conduct additional research to fully understand the implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the experimental settings and the absence of code, which affects the reproducibility of results. It highlights the importance of providing detailed experimental settings and code to ensure the reliability of the findings. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending particular experimental settings or code sharing practices. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of a proper comparison against online learning approaches and reinforcement learning (RL). It suggests that the authors should clarify why online learning cannot be used and address the challenges of including retraining cost in the evaluation. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or what aspects of the comparison should be addressed. The authors are left with a general idea of what needs to be done but without detailed instructions on how to execute these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors mention that online learning formulation overlooks key practical considerations. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of a proper comparison against online learning approaches and reinforcement learning, and the challenges of including retraining cost in the evaluation. It provides a clear direction for improvement by asking questions about the reasons behind the limitations of online learning and how to address these challenges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of a proper comparison against online learning approaches and reinforcement learning, suggesting that the abstract and other parts of the paper overlook key practical considerations. The reviewer provides a logical reasoning by questioning why online learning cannot be used and highlights the importance of including retraining cost in the evaluation. However, the comment lacks specific examples or references to support the claim, such as detailed comparisons or studies that demonstrate the limitations of online learning. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that the abstract and other sections mention the limitations of online learning formulations but do not provide a proper comparison against online learning approaches or reinforcement learning. It suggests that the authors should clarify why online learning cannot be used and address the challenges of including retraining cost in the evaluation. The comment provides a clear and actionable suggestion for improvement, guiding the authors to address a critical aspect of their work that could enhance its impact and credibility. However, it could be more helpful if it offered specific examples or references to similar studies that have addressed these issues, which would provide the authors with a more detailed roadmap for improvement. Overall, the comment is 4 as it effectively points out a significant oversight and offers a clear direction for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite works related to metalearning and distinguish their approaches from those already cited. It also recommends linking the work on RL for architecture search and optimizers to continual learning. While the comment provides a clear direction for the authors to expand their literature review and improve the connection between their work and related literature, it does not specify which works should be cited or how to distinguish them. The action is explicit but lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the need to cite related works and to distinguish approaches, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that there is a deeper tie to metalearning and that the authors should cite related works and distinguish their approaches. It also mentions the work on RL for architecture search and optimizers, which should be linked to continual learning. While the comment provides a logical reasoning for the need to cite and distinguish related works, it lacks specific examples or references to support the claim about the deeper tie to metalearning. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to expand their literature review and distinguish their work from related approaches in the field of metalearning. It highlights the importance of citing and discussing related works, particularly those that focus on RL for architecture search and optimizers, as they are relevant to continual learning. This feedback is valuable as it guides the authors to strengthen their literature review and connection to existing research, which can enhance the comprehensiveness and originality of their work. However, the comment could be more helpful if it provided specific examples of related works or detailed guidance on how to distinguish the approaches. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. While the comment implies that the authors should consider these options, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not specify which part of the paper this issue pertains to, such as the methodology or results sections. While the authors might have an idea of where this feedback is relevant, it is not explicitly grounded. The comment is specific in suggesting alternative approaches to improve the diversity of teacher feedback, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. However, the comment does not provide any supporting evidence, examples, or references to justify why this diversity is important or how it would improve the paper. Without additional context or explanation, the claim remains 3, as the authors may find it challenging to understand the significance of this suggestion without further elaboration. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the diversity of teacher feedback, assuming it was autogenerated. It suggests considering using a Turked teacher feedback or generating different kinds of feedback to better represent reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment could be more helpful if it offered more detailed guidance on how to implement these suggestions or provided examples of how other studies have addressed this issue. Overall, the comment provides some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. While the comment implies that the authors should include a summary of the supplementary experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a summary of the supplementary experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the main text should be revised or where the summary should be placed. The authors can infer that it relates to the sections discussing the experiments or results, but this inference is not direct. The comment is specific in suggesting the need for a summary of the supplementary experiments, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the main text should make it more clear that there are additional experiments in the supplement and preferably summarize their results. This feedback is 3 as it identifies a potential gap in the paper\"s presentation, which could enhance the clarity and comprehensiveness of the main text. However, the comment lacks specific guidance on how to effectively summarize the supplementary experiments or what aspects of the results should be highlighted. While it points out an area for improvement, it does not provide detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a comprehensive comparison with the works mentioned, GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer provides specific references to these works, making it clear what needs to be done. Additionally, the comment mentions that the societal impact is shown on the last page of the manuscript, which is not relevant to the action being requested. Therefore, the action is explicit and concrete, as the authors know exactly what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, \"GFF[1]\" and \"EfficientFCN[2],\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a comprehensive comparison with these works, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer suggests a comprehensive comparison with these works. However, the comment does not provide specific examples or detailed reasoning to support why these references are important or how they could enhance the paper. While the references are mentioned, the lack of detailed justification or explanation makes the claim 3, as the authors would need to infer the significance of these references themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement fast semantic segmentation in the encodedecoder architecture. The reviewer suggests a comprehensive comparison with these works, which could enhance the paper\"s contribution and relevance. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript. While the comment highlights a critical area for improvement, it could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the slight improvement reported in Table 6 and Table 7 and the claim that experimental results prove the effectiveness of the proposed prompts. However, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to support their claim. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6 and Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the slight improvement reported in these tables and the claim about the effectiveness of the proposed prompts. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the slight improvement reported in Tables 6 and 7 does not support the claim that experimental results prove the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the slight improvement reported in Tables 6 and 7 and the claim that experimental results prove the effectiveness of the proposed prompts. This is a critical observation that could impact the validity of the authors\" claims. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental design to better support their claims. Without actionable feedback or specific advice, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it points out a potential problem but lacks depth and specificity in its critique."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". While the comment implies that these comparisons could provide valuable insights, it does not explicitly instruct the authors to conduct these comparisons or explain why they are necessary. The action is implicit and somewhat vague, as the authors need to infer the importance of these comparisons and how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper these comparisons should be included in, making it weakly grounded. The comment is specific in suggesting the need for these comparisons, as it clearly identifies the potential benefits of including them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the performance with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any justification or reasoning for why these comparisons are necessary or how they would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the relevance of these comparisons. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the performance of the paper with two specific works, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This feedback is 3 as it provides a clear direction for the authors to consider in terms of benchmarking their work against existing approaches. However, the comment lacks depth and does not explain why these comparisons are important or how they would enhance the paper. Additionally, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. While it provides a starting point, the feedback could be more comprehensive and actionable with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the analysis, specifically the alignment of features at different spatial locations to the same channel. It suggests that there could be many different designs for this analysis, such as experiments or analysis with different sampling intervals and sample sizes. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implied and somewhat vague, as the authors can infer that they need to explore different designs but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment does provide some specificity by suggesting different designs, such as experiments or analysis with different sampling intervals and sample sizes, but it lacks detailed guidance on how to implement these suggestions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of Cycle FC align features at different spatial locations to the same channel is insufficient. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes, is vague and lacks specific guidance on how to implement these changes. Without concrete evidence or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of Cycle FC align features at different spatial locations to the same channel, suggesting that the analysis is insufficient. It provides a specific suggestion to explore different designs, such as experiments or analysis with different sampling intervals and sample sizes. This feedback is 3 as it points out a potential area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it provided more detailed guidance on how to implement these changes or what specific aspects of the analysis should be addressed. Overall, the comment is 3 as it highlights an area for improvement but lacks depth and actionable steps."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of standard deviations in the paper, which raises concerns about the validity of the results. It suggests that the authors should include standard deviations to provide more transparency and confidence in their findings. While the comment explicitly states the action needed (displaying standard deviations), it does not provide specific guidance on how to present these deviations or what aspects to focus on. The action is clear but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of standard deviations in the paper, which raises concerns about the validity of the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where standard deviations should be displayed. This makes it difficult for the authors to pinpoint the exact location of the issue. While the comment is specific in identifying the absence of standard deviations, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of standard deviations in the paper raises concerns about the validity of the results. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to similar studies that have included standard deviations, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the absence of standard deviations. This is a critical observation that could impact the validity and reliability of the results. However, the comment does not provide specific guidance on how to address this issue or what aspects of the results might be affected by the lack of standard deviations. While it highlights a potential problem, it lacks actionable advice or suggestions for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide explicit guidance or suggestions on how to achieve this extension. The comment implies that the authors should consider broadening the scope of their work, but it lacks concrete steps or detailed advice on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the specificity of the setting, suggesting that the approach could be extended to more general settings. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the setting and its suggestion for broadening the scope, but without clear references to specific sections or elements, the authors may struggle to identify where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the setting and suggests that the approach could be extended to more general settings. However, it does not provide any supporting evidence, reasoning, or references to justify why the current setting is limiting or how it could be expanded. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid point about the specificity of the setting, suggesting that the approach could be extended to more general settings. It questions the limitations of the current setting and encourages the authors to explore broader applicability. However, the comment lacks specific guidance or suggestions on how to achieve this extension or what aspects of the setting might be limiting. While it identifies a potential area for improvement, it does not provide actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the feature extractor used for dimensionality of each region, specifically asking about the feature extractor used in line 201. This is an explicit question that directly asks for clarification, providing a clear action for the authors to take. However, it does not offer specific guidance on how to address the issue or what information should be included in the response. The action is explicit but somewhat vague in terms of detail, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the feature extractor used for dimensionality, providing clear guidance on what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the feature extractor used for dimensionality in line 201. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the feature extractor used for dimensionality in line 201. This is a clear and actionable request for clarification, as it prompts the authors to provide more information about their methodology. By addressing this question, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it implies that the authors should include these details, it does not explicitly instruct them to do so or provide specific guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should include these details but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not specify which part of the paper this information should be included in, nor does it provide details on what specific aspects of the computation, algorithm, or implementation should be highlighted. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that providing computation/algorithm/implementation details would be helpful for readers. However, it does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would enhance the paper. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that providing computation/algorithm/implementation details would be helpful for readers. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what details should be included or how they could be presented. Without further elaboration or examples, the authors may find it challenging to understand the exact nature of the feedback and how to address it. Therefore, the comment is 3, as it points out a potential area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the choice of p < 0.4 in Algorithm 1, indicating that the reviewer is seeking clarification or explanation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information they should include in their response. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation or justification for their choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the choice of p < 0.4 in Algorithm 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the choice of p < 0.4 in Algorithm 1, indicating a potential area for clarification or explanation in the paper. While it highlights a specific aspect that may need further elaboration, it does not provide any guidance or suggestions on how the authors might address this issue or what additional information could be included. The comment is 3 as it points out a potential gap in the explanation, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. It specifically mentions the need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This feedback provides clear and concrete actions for the authors to take, such as adding explanations or analysis for the figures. The comment is 5 as it directly instructs the authors on what needs to be done to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for Figures 1, 2, and 3. The comment provides detailed guidance on what needs to be clarified, such as the negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have presented Figures 1, 2, and 3 but have not provided explanations or analysis for them. The reviewer suggests that the authors need to clarify why there are negative numbers in Figure 1 and the implications of Figure 2 and Figure 3. This claim is 3 as it logically points out the need for additional analysis or explanation, but it lacks specific examples or references to support the claim. The authors would need to make a significant effort to understand the implications and provide the necessary analysis, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of explanations or analysis for Figures 1, 2, and 3. It points out that the figures contain negative numbers and suggests that the authors need to clarify these aspects. This feedback is clear and actionable, as it provides the authors with a direct and concrete task to address the issue. By addressing these points, the authors can improve the clarity and comprehensiveness of their figures, which can enhance the overall understanding and impact of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not provide specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. The comment lacks concrete details or suggestions on how to enhance the explanation, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is discussed, the comment lacks full grounding. It is specific in suggesting that the motivation needs clarification, but without explicit references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the motivation behind applying CMD in federated learning. It suggests that the motivation could benefit from a more explicit demonstration or explanation, which is a valid point. However, the comment lacks specific guidance on how to improve the clarity or what aspects of the motivation should be emphasized. Without actionable advice or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is 3 as it points out a potential area for improvement but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment implies that the authors should provide more analysis and comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more analysis and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of analysis regarding the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not specify which sections or parts of the paper should include this analysis or comparison, making it somewhat specific. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of data augmentation methods and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides a logical reasoning by suggesting that such comparisons would clarify the unique advantages of the method. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the claim, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of analysis regarding the effectiveness of data augmentation methods. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and comparison sections. However, the comment could be more helpful if it offered examples or guidance on how to conduct these comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear path for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. The action is concrete, as it specifies what the authors should do to improve their draft, but it is somewhat vague in its execution, as the authors need to determine the exact methodology and implementation of the ablation study. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing examples of alternative approaches, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. The comment provides a logical reasoning by suggesting alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, it lacks specific examples or references to support the claim that these alternative approaches would provide a clearer understanding of the net effect. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests conducting an ablation study to evaluate the net effect of each component in the learning process with MMD. It provides specific examples of alternative approaches, such as learning with typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a clear direction for the authors to improve their draft by conducting an ablation study to better understand the impact of each component. However, the comment could be more helpful if it provided additional guidance on how to conduct the ablation study or suggested specific metrics or analyses to focus on. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it does not explicitly instruct the authors to perform a specific action, it implies that the authors should consider this scenario and its implications for their model. The comment is 3 as it provides a direction for further exploration, but it lacks concrete guidance on how to implement this exploration or what specific aspects to focus on. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspect of the model\"s performance is being questioned or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it highlights an area of interest, it does not provide any guidance or suggestions for improvement. It lacks depth and actionable feedback, leaving the authors without a clear understanding of how to address the issue or enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It suggests that RLCD (or RLCDRescore) may not be able to scale to larger language models that are better at differentiating responses near the decision boundary. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what specific steps they should consider to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tab. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the shrinking advantage of RLCD over RLAIF as the model size increases, and it raises a question about whether RLCD can scale to larger language models. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of RLCD over RLAIF shrinks as the model size increases, and it questions whether RLCD can scale to larger language models. However, the comment lacks specific examples, data, or references to support this claim. Without additional evidence or detailed reasoning, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison between RLCD and RLAIF, noting that the advantage of RLCD over RLAIF shrinks as the model size increases. It raises a question about whether RLCD (or RLCDRescore) can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input, and questions whether there is a solution to address this issue. While the comment identifies a potential problem, it does not provide explicit guidance or suggestions on how the authors might address the scalability issue or improve the practical contribution of their paper. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed NC measure, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the method when applied to large datasets like ImageNet. However, it does not provide specific suggestions or examples on how to address the scalability issue, which would make the comment more actionable. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point questions the scalability of the proposed NC measure, suggesting that it may not be practical for large datasets like ImageNet. However, the comment lacks specific examples or evidence to support this claim, such as data or references to similar methods that have successfully addressed scalability issues. Without such details, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it provides a logical concern but lacks sufficient evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It raises a valid concern about the practicality of the method when applied to large datasets like ImageNet. However, the comment does not provide specific suggestions or examples on how to address the scalability issue or improve the practical contribution of the paper. While it highlights an important area for consideration, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to conduct a quantitative analysis on the computational gains, specifically mentioning GPU hours, memory usage, or training time. This provides a clear and concrete action for the authors to take, as it specifies the exact measurements that should be included in the analysis. The comment is specific and direct, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of quantitative analysis on computational gains, specifically referring to the claim of computational benefits from replacing the MAE model with a CNNbased data augmentation strategy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for quantitative analysis on GPU hours, memory usage, or training time to substantiate the computational gains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks specific measurements or comparisons to substantiate the computational benefits of replacing the MAE model with a CNNbased data augmentation strategy. The reviewer suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of the efficiency improvements in DQ V2. This claim is 3 as it logically suggests that quantitative analysis would strengthen the paper\"s claims, but it lacks specific examples or references to similar studies or benchmarks that could further substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of quantitative analysis on the computational gains claimed in the paper. It suggests that including measurements such as GPU hours, memory usage, or training time would provide stronger evidence to substantiate these claims. This feedback is clear and actionable, as it directs the authors to conduct a quantitative analysis that would enhance the credibility and robustness of their findings. However, the comment could be more helpful if it provided examples of how such an analysis might be conducted or what specific metrics should be considered. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not provide explicit guidance on how the authors should incorporate this consideration into their analysis or what specific changes should be made to account for this time. The action is implied and somewhat vague, as the authors can infer that they need to consider the time aspect but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to consider the time aspect when comparing methods, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the time for COLMAP and scenebyscene finetuning should be taken into account when comparing methods, which would render the method less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this time consideration is important or how it affects the efficiency of the method. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the efficiency of the method when comparing it to COLMAP and scenebyscene finetuning. It suggests that the time taken for these processes should be considered, which could impact the method\"s effectiveness for certain scenes. While the comment highlights an important aspect to consider, it lacks specific guidance or suggestions on how the authors should address this issue or what specific changes should be made to improve the efficiency of the method. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions about the \"filter manifold network\" (FMN) and its scalability with the number of filter parameters. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. Additionally, it questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they should address these questions, but the comment lacks specific guidance on how to do so. Therefore, the comment is 3, as it implies actions but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the scalability of the FMN with larger input and output channels, and it suggests experimenting with other architectures. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It asks if the authors experimented with other architectures for FMN and how adaptive convolutions scale with the number of filter parameters. The reviewer also questions whether FMN can scale well with larger input and output channels, which is common in many CNN architectures. While the comment identifies areas for improvement, it lacks specific examples or references to support the claims about scalability or the need for further analysis. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the discussion and analysis of the \"filter manifold network\" (FMN), which is the main part of the technique. It raises important questions about the scalability of the FMN with larger input and output channels, suggesting that the authors should experiment with other architectures and explore the impact of adaptive convolutions on the number of filter parameters. The comment also questions whether FMN can scale well in common CNN architectures with input and output channels ranging from 128 to 512. This feedback is clear and actionable, providing the authors with specific areas to address in their draft. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to important areas for improvement and enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform and suggesting that comparisons to UNets are necessary. While the comment identifies a potential issue with the model, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they should make comparisons to UNets, but the comment lacks specific instructions on how to conduct these comparisons or what aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"fractional transform\" and the \"UNet part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the contribution of the UNet part in the fractional Fourier domain and suggests comparisons to UNets, which are necessary to understand the performance boost. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the contribution of the UNet part in the CoNO model, suggesting that it is unclear whether the fractional transform or the UNet operation in the fractional Fourier domain is responsible for the claimed performance boost. The reviewer references external works, such as Raonic et al and Gupta et al, to support their claim that UNets have strong performance on regular gridded domains. This provides a logical basis for the claim, but the comment could be strengthened by providing more detailed comparisons or examples from the referenced works. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed CoNO model, questioning the contribution of the UNet part after the fractional transform. It suggests that the performance boost might be due to the fractional transform or the UNet operation in the fractional Fourier domain, which is comparable to pointwise multiplication as done in FNOs. The comment also references external works, such as Raonic et al and Gupta et al, to support the claim that UNets have strong performance on regular gridded domains. This feedback is 3 as it points out a potential weakness in the model and suggests a direction for further exploration. However, it could be more helpful if it provided specific suggestions on how to address this issue or what comparisons to UNets might reveal. Overall, the comment offers some guidance but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It also suggests that a comparison of computation complexity should be included in the experiment part. While the comment identifies a specific issue with the computational complexity, it does not provide explicit guidance on how to address it or suggest ways to reduce the computational burden. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison of computation complexity in the experiment part. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"the calculation of all the flipped previous layer output into the current layer,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically mentioning that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. The comment suggests that a comparison of computation complexity should be included in the experiment part. While the claim is based on logical reasoning and specific observations about the algorithm, it lacks detailed evidence or references to support the assertion that the PSA method requires more computation. This makes the claim 3, as the authors would need to further investigate and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the computational complexity of the proposed PSA method compared to baselines, noting that in Algorithm 1, the calculation of all flipped previous layer outputs into the current layer is required. It suggests that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to include a specific analysis of computational complexity to address the concern. However, the comment could be more helpful if it provided suggestions on how to optimize the computational complexity or offered examples of similar comparisons in related work. Overall, the comment is 4 as it effectively guides the authors on how to improve their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific feedback on the font size and suggests improvements, such as making the words in the grey box larger, increasing the size of V_mem, Th_i, and U_i^t, and using a larger font for the \"CTRL\" long form explanation. Additionally, it points out the lack of details comparison with other stateoftheart Transformer designs, suggesting a \"table\" manner to emphasize the data for readers. While the comment provides explicit actions and concrete details on how to implement these improvements, it could be more helpful if it offered suggestions on how to present the data comparison in a more effective way. Overall, the comment is 4 as it provides clear guidance on what needs to be addressed, but it could be more detailed in its suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures, such as \"fig 1\" and \"figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point makes several claims about the font size, the \"CTRL\" long form explanation, and the lack of details comparison with other stateoftheart Transformer designs. While the comment provides specific examples of issues with the figures, such as font size and the \"CTRL\" long form explanation, it lacks detailed reasoning or references to support why these issues are problematic or how they impact the paper\"s overall quality. The suggestion to use a \"table\" manner for data comparison is a logical suggestion, but it does not provide sufficient evidence or examples to fully substantiate the claim. Therefore, the comment is 3, as it provides some support but lacks detailed justification or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the figures, suggesting improvements such as increasing the font size of certain elements and using a \"table\" manner to emphasize data comparisons. It also points out the lack of details comparison with other stateoftheart Transformer designs, which is a critical area for improvement. By addressing these specific issues, the authors can significantly enhance the clarity and comprehensiveness of their figures and comparisons. However, the comment could be more helpful if it provided additional guidance on how to present the data comparison in a more effective way, such as suggesting specific metrics or visualizations. Overall, the comment is 4 as it identifies specific areas for improvement and offers actionable suggestions, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this concern or what specific steps to take to improve the results. As a result, the authors are left without any clear direction on how to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of reporting results after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It raises a concern about the early stages of training, where the model parameters might be garbage, and the planning component might hurt more than help. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the training process and the potential impact on the agent\"s behavior, but without clear grounding, the authors cannot confidently identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. The reviewer speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a logical observation but lacks specific examples or references to support the claim. The comment is 3 as it provides a reasonable basis for the concern but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results being reported after a significant amount of training has occurred, suggesting that the agent\"s behavior during learning is also important. It speculates that early in training, the model parameters might be garbage, and the planning component might hurt more than help. This is a thoughtprovoking observation that could prompt the authors to consider how their results might be affected by the training process. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their results. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an important aspect of the paper but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests that the authors rewrite the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct action for the authors to take, as it provides a specific line and page number for them to address. The comment also indicates that the current sentence is unclear, which further guides the authors on what changes are needed to improve the clarity. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and pages (\"P. 5, p. 3, l.\") where the issue is located, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarity of the sentence regarding the use of \"j\" to simulate errors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification and a specific suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence, requesting that the authors rewrite it to improve understanding. This feedback is clear and actionable, as it provides a direct and concrete suggestion for improvement. By addressing this issue, the authors can enhance the clarity and readability of their paper, which is valuable guidance for improving the draft. However, the comment could be more helpful if it included additional context or explanation about why the current sentence is unclear or how it could be rewritten to improve comprehension. Overall, the comment is 4, as it effectively directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. While the comment identifies a gap in the manuscript, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information on their approach but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"the documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the handling of documents as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what needs to be addressed in the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the approach taken for handling documents in DocRED, specifically asking whether the documents are considered as an entire sentence and how the model deals with concepts involving multiple entity mentions referring to the same entity. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is missing from the manuscript. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the manuscript that is missing information, specifically regarding the handling of documents in DocRED and how the model deals with concepts involving multiple entity mentions referring to the same entity. This is a clear and actionable point that can help the authors improve their draft by providing more detailed information on their approach. However, the comment could be more helpful if it offered suggestions on how to address this gap or provided examples of how similar approaches have been handled in the literature. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the perceived marginality or how to improve the contribution. As a result, the authors are left without any clear direction on how to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, it does not specify which part of the paper this assessment is based on, such as the methods or the stage where they are used. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need improvement or clarification. Additionally, the comment does not provide specific guidance on how to address the issue of marginality or what changes could be made to enhance the contribution. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal because the methods used in different stages are welldesigned and demonstrated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to specific methods or stages where the methods are welldesigned or demonstrated, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is marginal, as the methods used in different stages are welldesigned and demonstrated. It also implies that adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential issue with the perceived marginality of the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or improve their contribution. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed feedback for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. While the comment identifies a potential issue with the clarity of the main contribution, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the motivations for PBSD and its contribution to the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study\" and the \"DSCL part,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the clarity of the main contribution, particularly regarding the motivations for PBSD beyond improving the discriminative representation on tail classes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This claim is 3 as it highlights a potential inconsistency in the paper\"s focus, but it lacks specific examples or references to support the argument. The authors would need to further explore and clarify the motivations for PBSD to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the main contribution, noting that while the performance gain is mostly from PBSD, the paper is primarily motivated by supervised contrastive learning. The reviewer questions whether there are other motivations for PBSD besides improving the discriminative representation on tail classes. This feedback is 3 as it points out a potential inconsistency in the paper\"s focus, which could be clarified to enhance the coherence and impact of the contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as by providing additional context or examples. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. While the comment implies that the authors should consider including more details about these experiments in the main text, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they should provide more information but are not given specific guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it does not specify which part of the paper the Appendix is attached to, making it weakly grounded. The comment also mentions the Brusselator as an example of an additional experiment, but it does not specify which part of the Appendix this experiment is discussed in. This lack of specificity makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the inclusion of a comprehensive Appendix and appreciates the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This statement is a factual observation about the reviewer\"s experience and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment appreciates the inclusion of a comprehensive Appendix and acknowledges the additional detail it provides. However, it also notes that the reviewer did not have time to carefully read the additional experiments described in the Appendix, such as the Brusselator. This feedback highlights a potential limitation in the paper\"s presentation, as it suggests that the main text may not fully convey the significance or results of these experiments. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how to address this issue. Therefore, the comment is 3, as it points out a potential weakness but lacks actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer implies that the description could be misleading if the two methods are not the same. However, the comment does not provide explicit guidance on how the authors should clarify this distinction or what specific changes should be made to the description. While the action is implied, it is not concrete, as the authors are left to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\" claim of using active learning and asks for clarification on whether the \"active learning pipeline\" method is the same as traditional active learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim of using active learning in step 2, specifically asking whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. The reviewer provides a logical reasoning by pointing out that the description could be misleading if the two methods are not the same. However, the comment lacks specific examples or references to support the claim that the methods are different. This makes the claim 3, as the authors would need to make a concerted effort to understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the authors\" claim of using active learning in step 2, specifically questioning whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples to label. This is an important clarification that could impact the readers\" understanding of the methodology and its applicability. The comment prompts the authors to clarify this distinction, which is crucial for ensuring the accuracy and transparency of their work. However, the comment could be more helpful if it provided specific suggestions on how to clarify the distinction or examples of how the two methods differ. Despite this, the feedback is 4 as it directs the authors to an important area for clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the distribution should be clarified, how it should be clarified, or what specific aspects of the distribution are unclear. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the detailed distribution of the proposed dataset is unclear. However, it does not specify which part of the paper discusses the dataset or where the distribution should be clarified. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are unclear or how they could be clarified. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the detailed distribution of the proposed dataset. This is a relevant point that could impact the reproducibility and comparability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific ways to clarify the distribution or suggesting improvements to the methodology. Without actionable feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It proposes an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. While the comment implies that the authors should consider this alternative approach, it does not provide explicit instructions or concrete steps on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the proposed method in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. However, the comment does not specify which part of the paper discusses the method or the annotation requirements, making it weakly grounded. The suggestion to consider a selfsupervised approach is specific, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited in its application to supervised training due to the need for annotated labels for learning semantic tokens. It suggests an alternative approach using a selfsupervised pretraining approach without annotations. While the comment provides a logical reasoning for the limitation and suggests an alternative, it lacks specific examples or references to support the claim that a selfsupervised approach would be more appealing. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed method, specifically the requirement for annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests an alternative approach using a selfsupervised pretraining approach without annotations, which could be more appealing. This feedback is 3 as it points out a potential weakness in the methodology and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to implement the selfsupervised approach. Overall, the comment provides a valuable insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their LFF method by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should conduct experiments on these tasks, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their LFF method by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to demonstrate scalability by addressing more challenging tasks, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate the scalability of LFF by showing it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. The comment provides a logical reasoning that the scalability of LFF should be demonstrated on more complex tasks, but it lacks specific examples or references to support the claim that these tasks are indeed more challenging. This makes the claim 3, as the authors would need to infer the complexity of the suggested tasks and determine if they are appropriate for demonstrating scalability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of the LFF method, it is important to show that it can be applied to more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experimental setup and demonstrate the broader applicability of their method. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or what specific aspects of the LFF method should be emphasized in the new tasks. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the abstract should include a specific measurement, such as \"attain greater expressivity, as measured by the change in linear regions in output space after [citation], instead of just \"attain greater expressivity.\" Additionally, it recommends including learning curves for all experiments in an appendix. While the comment provides explicit actions, it does not specify which experiments should include learning curves or how to present them. The authors are given clear guidance on what to add to the abstract and an appendix, but the execution of these actions is not detailed. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be changed in the abstract, suggesting a specific measurement to include and recommending the inclusion of learning curves in an appendix. This level of detail provides clear direction for the authors to make improvements. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests changes to the abstract, specifically recommending a specific measurement to include and suggesting the inclusion of learning curves in an appendix. While the comment provides a logical reasoning for these changes, it lacks specific examples or references to support the claim that these changes would improve the paper. The suggestion is 3, as it provides a clear direction for improvement but could benefit from more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract section of the paper. It suggests a more precise measurement for expressivity, which is a clear and concrete suggestion that can help the authors improve the clarity and rigor of their abstract. Additionally, it recommends including learning curves for all experiments in an appendix, which is a valuable suggestion for providing additional insights and transparency. However, the comment could be more helpful if it explained why these changes would be beneficial or how they would enhance the paper\"s impact. Overall, the comment is 4 as it offers clear and actionable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the need for domain adaptation and the usefulness of the proposed method. It suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. While the comment implies that the authors should provide examples of how their method could be applied in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of practical applications. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results of mapping one RGB image to another RGB image with a different style, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the motivation and usefulness of the proposed method, suggesting that demonstrating its application on actual tasks involving domain adaptation would be beneficial. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the motivation and usefulness of the paper, suggesting that the proposed method is unclear in its application and does not demonstrate its utility on actual tasks involving domain adaptation. The comment provides a logical reasoning by pointing out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. However, the comment lacks specific examples or references to support the claim that demonstrating the methodology on actual tasks would be beneficial. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically questioning the motivation and usefulness of the proposed method. It points out that the method demonstrated is limited to mapping one RGB image to another with a different style, which does not necessarily justify the need for domain adaptation. The comment suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper\"s clarity and relevance. However, it could be more helpful if it included examples of such tasks or detailed guidance on how to implement them. Overall, the comment is 4 as it highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether the authors should consider other baselines or update their references to more recent works. As a result, the authors are left without a clear direction on how to address this issue. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works, \"MISA,\" \"M2FNet,\" and \"MMDFN,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but notes that MULT was proposed in 2019 and is therefore out of fashion. This claim is 3 as it provides a specific reference to MULT and its publication year, which supports the assertion that it is outdated. However, the comment lacks detailed reasoning or examples to fully substantiate why MULT is considered out of fashion or how it impacts the current work. Therefore, the comment is rated as 3, as it provides some support but could be strengthened with additional context or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but points out that MULT was proposed in 2019 and is therefore out of fashion. This feedback is 3 as it highlights an outdated reference that may not be relevant to the current state of research. However, the comment lacks specific suggestions on how the authors might address this issue, such as suggesting alternative baselines or updating the references to more recent works. While it provides some insight, it could be more actionable and comprehensive to fully assist the authors in improving their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a major issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks for all models and the omission of tensor completion results for fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the clarity and fairness of the comparisons. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It also provides specific guidance on how to address this issue by suggesting that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the value of the used ranks is omitted, making it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This claim is 3 as it provides a logical reasoning for the need for a fair comparison and suggests a method to achieve it. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental comparison, specifically the lack of clarity regarding the value of the used ranks and the omission of tensor completion results for fair comparison. It provides a clear and actionable suggestion by recommending that the authors compare the tensor completion results for all models with the same number of model parameters, which can be computed by adding the number of entries of all core tensors for each model. This feedback is valuable as it guides the authors on how to improve the clarity and fairness of their experimental comparison, making it 5. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" as ATA is reported to be better than FP according to the results in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include ATA in the comparison. The comment is specific and provides concrete guidance on how to improve the table, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"leave one out setting,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of ATA in the comparison under the leave one out setting. This provides clear guidance on how to improve the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 2, under the leave one out setting, the proposed method should be compared to \"ATA\" in addition to \"LFP\" because ATA is reported to be better than FP according to the results in Table 1. This claim is 3 as it provides a logical reasoning based on the results in Table 1, but it lacks specific examples or references to support the claim that ATA is indeed better than FP. The authors would need to make a judgment based on the provided information, which may not be as straightforward as the reviewer implies. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, noting that the proposed method is only compared to \"LFP\" under the leave one out setting, despite ATA being reported as better than FP according to the results in Table 1. The comment suggests that including ATA in the comparison would be more convincing. This feedback is clear and actionable, as it provides a specific suggestion for improving the table by adding ATA to the comparison. However, it could be more helpful if it explained why ATA is considered better or how this comparison would enhance the paper\"s conclusions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the normalization module, noting that it appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in the context of Fig. 4, where the chosen symbols overlap. Additionally, the reviewer points out minor issues with the text, such as overlapping symbols in Fig. 4 and a lack of clarity after equation (4). While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to standardize the pictograms or address the overlapping symbols issue. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"normalization module\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. Additionally, it provides specific feedback on the figures, particularly Fig. 4, where the chosen symbols overlap. The comment also mentions minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the normalization module appears different in two versions but is described as the same in the text. It suggests that a standardization of the pictograms is needed, particularly in Fig. 4, where the chosen symbols overlap. The reviewer also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4). However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the specific issues and how to address them, which could be challenging without additional context or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the normalization module, noting that it appears different in two versions but is described as the same in the text. This is a clear and actionable point that the authors can address to improve the consistency and clarity of their work. Additionally, the comment highlights the importance of standardizing the pictograms, particularly in Fig. 4, where the chosen symbols overlap. This feedback is valuable as it helps the authors ensure that their figures are clear and easy to understand. The comment also points out minor issues with the text, such as overlapping symbols and a lack of clarity after equation (4), which can be addressed to improve the overall readability. Overall, the comment is 4 as it provides clear and actionable suggestions for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the authors\" claims and the theoretical part of the paper. It questions whether the proposed algorithm is detailed enough to remove subdivision splines and whether it requires extra computation cost for space partitioning. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to clarify the algorithm\"s details and potential computational costs, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the observation and the goal of pruning, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detail in the theoretical part regarding the proposed algorithm for removing subdivision splines and the potential extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the observation of subdivision splines and the goal of pruning. It points out that the theoretical part lacks details on how the proposed algorithm would remove these splines, specifically questioning whether it would require extra computation cost. The comment is 3 as it highlights a potential gap in the paper\"s explanation, but it does not provide specific examples or references to support the claim. The authors would need to further explore the theoretical part to address this concern, making the comment 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the authors\" claims and the theoretical part of the paper. It points out that while the authors claim that only parts of subdivision splines are useful for decision boundaries, the theoretical part lacks details on how the proposed algorithm would remove these splines. The comment also raises a question about the potential extra computation cost for space partitioning. This feedback is 3 as it highlights a gap in the paper that the authors need to address, but it could be more beneficial if it provided specific suggestions on how to clarify the theoretical part or mitigate the computational cost. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that W1 and W2 are not defined, and it speculates that they might denote the Encoder and Decoder networks. It also mentions that W and V are not defined in the same context, providing specific references to the pages and equations where these terms are mentioned. This feedback is clear and directs the authors to define these terms, which is a concrete action for them to take. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1 and W2\" and \"W and V,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these terms are not defined, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"W1 and W2 are not defined\" and speculates that they might denote the Encoder and Decoder networks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that W1 and W2 are not defined and speculating that they might denote the Encoder and Decoder networks. It provides clear and actionable feedback by pointing out the lack of definitions for these terms and suggesting that the authors clarify their meaning. This feedback is valuable as it directs the authors to a specific area that needs attention and improvement, ensuring that the paper is more clear and accessible to readers. However, the comment could be more helpful if it offered additional guidance on how to define these terms or provided examples of how they might be used in the context of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. It suggests that a better comparison should be considered. While the comment implies that the authors should reconsider their comparison, it does not provide specific guidance on how to improve the comparison or what alternative baselines should be used. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with baselines, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the comparison, stating that it is unfair due to the lack of prior knowledge of users or language embedding computation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines, noting that the lack of prior knowledge of users or language embedding computation may unfairly skew the results. This is a valuable observation that could lead to a more robust and fair comparison. However, the comment does not provide specific suggestions on how to address this issue or what alternative baselines could be considered. While it highlights an important area for improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the outputside layers, Figure 4, and the Pixelshuffle operation. It asks for clarification on whether the pixelshuffle operation is used in the superresolution field and why the dimensionality remains the same after upsampling in Figure 2(b). Additionally, it points out the lack of discussion on potential negative societal impacts. While the comment identifies areas that need clarification and potential improvements, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify these points in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several specific issues, including the lack of clarity in the outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the use of pixelshuffle in the superresolution field and the dimensionality after upsampling in Figure 2(b). However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of Figure 4 and the presentation of Pixelshuffle details. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and observations about the paper, including the lack of clarity in the outputside layers, the unclear illustration of Figure 4, and the presentation of Pixelshuffle details. It also questions the use of pixelshuffle in the superresolution field and the dimensionality after upsampling in Figure 2(b). However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate these claims. The authors would need to make a significant effort to address these points, which makes the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper. It questions the lack of clarity in the outputside layers and the illustration of Figure 4, which could benefit from more detailed explanations. Additionally, it points out the need to clarify the Pixelshuffle operation and its potential use in the superresolution field. The comment also highlights the absence of a discussion on potential negative societal impacts, which is a critical aspect of the paper. While the feedback provides clear direction for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the comment is 4 as it guides the authors toward improving the clarity and completeness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or analysis regarding the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also asks whether this alternating process could help improve performance. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the behavior of negative chips and the potential impact of the alternating process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the behavior of negative chips generated from the lightweight RPN and whether they are fixed or updated while the RPN is trained. It also inquires whether this alternating process could help improve performance. This feedback is 3 as it prompts the authors to clarify their methodology and potentially explore avenues for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions or improve their work. Overall, the comment offers a starting point for the authors to consider, but it lacks depth and actionable guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. While the comment implies that the authors should conduct this evaluation, it does not provide specific guidance on how to implement this suggestion or what aspects of the evaluation should be prioritized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should evaluate their proposed approach on both new and old patients, which implies that it relates to the evaluation section of the paper. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in suggesting the need to evaluate the approach on both new and old patients, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should evaluate their proposed approach on both new and old patients. However, it does not provide any supporting evidence, reasoning, or references to justify why this evaluation is necessary or how it would impact the paper\"s conclusions. The claim is based on a logical assumption, but without further elaboration or examples, it lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should evaluate their proposed approach on both new and old patients, which is a relevant and actionable suggestion. It highlights the importance of considering both types of patients to ensure the robustness and generalizability of the approach. However, the comment could be more helpful if it provided specific guidance on how to conduct this evaluation, such as suggesting metrics or methods to compare the results. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights an issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use this dataset in their training. The reviewer questions whether 300WLP is used in all experiments or just some, and if it is used in all, it could provide an unfair advantage to the proposed method. This comment implies that the authors should clarify the experimental methodology and provide more details on the dataset usage. However, it does not explicitly instruct the authors to do so, leaving the action somewhat implicit. The authors can infer that they need to address this issue, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental methodology, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the claim that 300WLP is used to train the model, but later it is claimed that the same procedure is used as for baselines. The comment also questions whether 300WLP is used in all experiments or just some, and whether this could provide an unfair advantage to the proposed method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental methodology, specifically questioning the use of the 300WLP dataset for training. The reviewer points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. The comment suggests that if 300WLP is used in all experiments, it could provide an unfair advantage to the proposed method. This claim is 3 as it highlights a potential issue with the experimental setup, but it lacks specific examples or references to support the claim that 300WLP provides an unfair advantage. The authors would need to further investigate and substantiate this claim to fully address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental methodology, specifically regarding the use of the 300WLP dataset. It points out that the paper claims the same procedure is used as for baselines, but most baselines do not use the 300WLP dataset in their training. This raises a concern about whether the use of 300WLP provides an unfair advantage to the proposed method. The comment questions whether 300WLP is used in all experiments or just some, and if it is used in all, it suggests that this could be a significant factor in the results. This feedback is clear and actionable, as it prompts the authors to clarify their experimental methodology and address the potential bias introduced by the use of 300WLP. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what additional information should be included in the paper. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to enhance the transparency and fairness of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the technique should be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying potential issues with the novelty of the technique, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any evidence, examples, or references to support this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of this assertion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the technique behind the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. While it identifies a potential issue with the novelty of the algorithm, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve the novelty of their work. The comment is 3 as it points out a potential weakness, but it does not offer actionable advice or detailed feedback for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It also points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the formulation. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider their assumptions about the observations and their aggregation process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the integral in Equation (1)\" and references specific works, \"Law et al., NeurIPS\"18\" and \"4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to the bag observation model in [Law et al., NeurIPS\"18] or the spatial aggregation process in [4]. The reviewer provides references to these works, which supports the claim by referencing established models and processes. However, the comment lacks detailed explanation or analysis of how these references relate to the integral in Equation (1) or the authors\" formulation. While the references provide some context, the comment could be strengthened by explaining how the references support the claim or by offering a more detailed comparison. Therefore, the comment is 3, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" understanding of the integral in Equation (1) and its relation to the bag observation model or spatial aggregation process. It points out that the authors\" formulation assumes observations are obtained by averaging over the corresponding support, which may not be accurate. The comment provides a clear and actionable suggestion for the authors to reconsider their assumptions about the observations and their aggregation process. However, it could be more helpful if it offered specific guidance on how the authors might address this issue or what alternative aggregation methods might be considered. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to explore."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the paper lacks indepth analysis and suggests that the authors should provide an explanation for the training dynamics observed. This feedback is clear and provides a direct action for the authors to take, which is to include an analysis of the training dynamics. The comment is specific in its request for an explanation, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and specifically mentions that the authors found inverse scaling over compute, but does not provide further details on what this means or how it affects the paper. It implies that the authors should provide an explanation for this observation, but without explicit references to specific sections or elements of the paper, the authors may struggle to identify where this analysis should be included. Therefore, the comment is weakly grounded because it does not specify which part of the paper should be analyzed, but it is specific in its request for an explanation. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and implies that the authors should provide an explanation for the observed training dynamics. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that there is no indepth analysis of the training dynamics observed. It suggests that the authors should provide an explanation for the inverse scaling over compute, which would enhance the paper\"s solidity. While the comment highlights an important area for improvement, it lacks specific guidance on how to conduct this analysis or what aspects should be addressed. This limits the comment\"s helpfulness, as it points out a critical issue but does not provide detailed instructions on how to resolve it. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It also questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer implies that a formal definition would be beneficial for readers to understand the architecture. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide a formal definition, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"multihead attention,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multihead attention, and questions the purpose of a split arrow in Figure 2. The comment further specifies that a formal definition would be beneficial for readers to understand the architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the lack of mathematical definition for certain architectural details, specifically mentioning multihead attention. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer. The reviewer assumes that these are the inputs for the attention layer, namely query, keys, and values. The comment suggests that a formal definition would be beneficial for readers to understand the architecture. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that a formal definition is necessary. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the lack of mathematical definition for certain architectural details, such as multihead attention, in the paper. It questions the purpose of a split arrow in Figure 2 and asks for clarification on the inputs for the attention layer, specifically query, keys, and values. The reviewer assumes these to be the inputs and questions whether the same vectors are used for keys and values. The comment suggests that a formal definition of these concepts would be beneficial for readers to understand the architecture. While the comment highlights an important area for improvement, it does not provide specific suggestions or guidance on how to address this issue. The authors are left to infer that they need to provide a formal definition, but the feedback lacks detailed instructions or examples. Therefore, the comment is 3, as it points out a critical area for clarification but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. While the comment implies that the authors should modify their experimental setup, it does not provide explicit instructions on how to implement this change or what specific tasks to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or the discussion of the results. The authors can infer that it relates to the latter part, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks full grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the setting with a fixed policy is a subset of reinforcement learning and proposes that tasks could be made more complex to test the policy\"s adaptability. However, the comment lacks specific examples or references to support this claim or to justify why the current setting is insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the suggestion. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should consider tasks that are more complex than those with a fixed policy, which would allow them to compare their approach with a reinforcement learning algorithm baseline. This feedback is 3 as it identifies a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on which tasks to consider or how to implement this change. Additionally, it does not provide detailed reasoning or examples to support the claim that tasks need to be more complex. While the suggestion is 3, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the comprehensiveness of the experimental analyses and the method itself, noting that the focus is primarily on the presentation of results. It suggests that the authors should provide more detailed analyses of the method and its performance, particularly in light of the baseline\"s underperformance. While the comment implies that the authors should include more comprehensive analyses, it does not specify exactly what aspects need to be addressed or how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed analyses but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"majority of the experiments\" and the \"analyses of the method itself and the experimental outcomes,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analyses are not comprehensive enough, particularly in light of the baseline\"s underperformance. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments focus on the presentation of results and that the analyses of the method and experimental outcomes are not comprehensive enough. It suggests that the authors\" method underperforms the baseline in some instances, which raises questions about the extent to which the performance improvement can be attributed to the authors\" claim. The comment provides some logical reasoning by pointing out the potential limitations of the method and its claims, but it lacks specific examples or references to support the claim about the baseline performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or references to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the majority of the experiments focus on the presentation of results rather than comprehensive analyses of the method and experimental outcomes. It highlights the potential problem of attributing the performance improvement to the authors\" claim, given that the method underperforms the baseline in some instances. This feedback is valuable as it points out a critical area for improvement in the paper, particularly regarding the rigor and depth of the experimental analyses. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as which aspects of the method or results should be further explored or explained. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to broaden the scope of the paper or what specific aspects of multitask models should be explored. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this issue is related to, such as specific sections or examples where the focus on multitask models is discussed. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the multitask models are problematic or how they could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any specific guidance or suggestions on how the authors might broaden the scope of their work or address this limitation. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. It suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the current work. The reviewer provides a specific question about the Assumption 2 and the rate of QSGD in the stochastic regime, implying that the authors should consider these papers for further analysis. While the comment does not explicitly instruct the authors to include these papers, the action is implicit and concrete, as it clearly identifies the need for additional analysis and provides a specific direction for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"next section\" and the \"Literature review,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of relevant papers, [1] and [2], and suggests that VRMARINA and DASHAMVR could be relevant to the current work. The comment provides a clear direction for the authors to consider these papers and address the Assumption 2 and QSGD rate in the stochastic regime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning [1] and [2]. The reviewer provides a specific example of VRMARINA and DASHAMVR, which are mentioned in these papers, and suggests that they could be relevant to the current work. The reviewer also poses a question about the Assumption 2 and the rate of QSGD in the stochastic regime. This claim is 4 as it provides a logical reasoning and specific examples to support the suggestion that these papers should be considered. However, the comment could be strengthened by providing more detailed comparisons or references to the specific aspects of the papers that are relevant to the current work. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant oversight in the literature review, noting that several relevant papers are missing from the analysis. It specifically mentions [1] and [2], which are believed to be relevant to the current work. The reviewer suggests that VRMARINA and DASHAMVR, mentioned in these papers, could be relevant to the Assumption 2 and the rate of QSGD in the stochastic regime. This feedback is clear and actionable, as it provides the authors with specific papers to consider for further analysis and potential enhancement of their work. By addressing this feedback, the authors can significantly improve the comprehensiveness and rigor of their literature review. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the presentation of the paper is hard to follow for the reviewer. However, it does not provide any specific guidance or suggestions on how to improve the presentation or what aspects are particularly challenging to understand. Without concrete advice or examples, the authors are left without a clear understanding of what changes need to be made to enhance the clarity of their draft. As a result, the comment lacks actionability, leaving the authors without direction on how to address the issue. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not specify which part of the paper is particularly challenging or where the presentation lacks clarity. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. Additionally, the comment does not provide specific guidance on how to enhance the clarity of the presentation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation of the paper is hard to follow. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or justification, the authors are left without a clear understanding of what aspects of the presentation are problematic or how they could be improved. As a result, the claim is 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment states that the presentation of the paper is hard to follow, but it does not provide any specific details or suggestions on how to improve the clarity or organization of the paper. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the presentation need attention or how to enhance the readability. This lack of specificity and direction makes the comment 2, as it provides some insight but lacks depth and detail to be fully beneficial for the authors. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: whether the authors have any additional insights into modest performance gains on Clothing1M and how the algorithm performs on other realworld datasets like WebVision, evaluated by DivideMix. While these questions imply that the authors should provide additional information or analysis, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights or data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the performance of the algorithm on Clothing1M and WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions themselves are specific, as they ask for additional insights or performance evaluations on specific datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for additional insights and performance evaluations on specific datasets. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions that could help the authors gain additional insights into the performance of their algorithm on realworld datasets. By asking about modest performance gains on Clothing1M and the algorithm\"s performance on WebVision, evaluated by DivideMix, the reviewer encourages the authors to provide more detailed evaluations and comparisons. However, the comment lacks specific guidance or suggestions on how to address these questions or what additional insights would be beneficial. While it points out areas for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies potential areas for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. While the comment implies that more experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments but are not given specific details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on different LLMs like LLaMA and Falcon as benchmark baselines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results discussion. The authors can infer that it relates to the experimental results or methodology, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are necessary or how they would impact the results. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the experimental setup by suggesting that more experiments on different LLMs like LLaMA and Falcon are needed as benchmark baselines. This feedback is 3 as it points out an area where the authors could enhance their work by including additional comparisons. However, the comment lacks specific guidance on how to conduct these experiments or what specific aspects of the LLMs should be considered. While it highlights a potential improvement, it does not provide detailed instructions or examples, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant gap in the paper, noting that it does not describe the hyperparameters used by each defense nor how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to include this information, but the lack of concrete guidance on how to do so makes the action implicit. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of description regarding the hyperparameters used by each defense and how those hyperparameters are derived. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. It is also specific because it clearly specifies what needs to be addressed, namely the description of hyperparameters and their derivation. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. The reviewer suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of including this information and might find it challenging to understand the exact implications without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that it lacks a description of the hyperparameters used by each defense and how those hyperparameters are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack and demonstrate how much clean data is required to remove the attack. This feedback is clear and actionable, as it points out a critical area for improvement in the paper. However, it could be more helpful if it provided specific guidance on how to implement this optimization or how to present the results. Overall, the comment is 4 as it directs the authors to a crucial area for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the theoretical results do not have immediate practical implications, but acknowledges that this is understandable given the novelty of the work. It also expresses a desire for more practical takeaways for practitioners, specifically mentioning the idea of querying a cluster proportionally to the square root of its size. However, the comment does not provide explicit guidance on how to incorporate this suggestion or what specific aspects of the paper should be revised to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should focus on making their results more practical and actionable. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their practical implications, suggesting that the paper could provide more practical takeaways for practitioners. It mentions a specific takeaway point regarding querying a cluster proportionally to the square root of its size, but does not specify which part of the paper this relates to. The authors can infer that it pertains to the theoretical results or methodology sections, but this inference is not as direct as it could be. The comment is specific in its suggestion for practical takeaways but lacks grounding in terms of identifying the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results do not have immediate practical implications, which is 3. The reviewer acknowledges the novelty of the work but suggests that more practical takeaways should be provided. The comment provides a specific example of a takeaway point, which is the idea of querying a cluster proportionally to the square root of its size. However, the reviewer does not provide a detailed explanation or evidence to support why this takeaway point is not novel or how it could be improved. The lack of detailed justification or references makes the claim 3, as it provides some support but not enough to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and suggests that the theoretical results may not have immediate practical implications. It identifies a specific takeaway point, which is the idea of querying a cluster proportionally to the square root of its size. However, the comment lacks depth and does not provide detailed guidance on how to incorporate this takeaway point into the paper or what specific aspects of the theoretical results should be emphasized for practical relevance. While it points out a potential area for improvement, the feedback is 3 as it highlights a specific aspect that could be addressed, but it does not offer actionable steps for the authors to take. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. While the comment identifies an area for clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to provide more information or explanation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the purpose of separators and what additional information they provide beyond T/I/O. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the purpose of separators in section 4 and asks for additional information on what they contribute beyond T/I/O. This is a request for clarification and does not make a subjective claim or express an opinion. It is a factual inquiry seeking more information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of separators in section 4, specifically asking for additional information on what they contribute beyond T/I/O. This feedback is 3 as it identifies a potential area for clarification or expansion in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it points out a potential gap in the explanation, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. While it implies that the authors should consider alternative approaches, it does not explicitly instruct them to do so or provide specific guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative pooling strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. It does not present an opinion, judgment, or suggestion that requires verification. It is a request for clarification and does not contain subjective claims or assertions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind using mean pooling for token pooling and suggests exploring other pooling strategies. This is a thoughtprovoking observation that could lead to a deeper understanding of the methodology and its implications. However, the comment lacks specific guidance or suggestions on how to explore alternative pooling strategies or what specific aspects of mean pooling should be questioned. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison of the real search cost in terms of GPU days. The comment is specific and provides concrete guidance on how to enhance the table, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison of the real search cost in terms of GPU days. This provides clear guidance on what the authors should add to the table to improve its utility. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the table. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, specifically in terms of GPU days. This feedback is 3 as it identifies a potential area for improvement in the table, which could provide more comprehensive information for readers. However, the comment lacks depth and does not explain why this comparison is important or how it would enhance the understanding of the results. Additionally, it does not offer suggestions on how to implement this change or what specific metrics should be included. While it points out a potential improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. While the comment implies that the authors should provide more information about the training process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the training details but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VQGAN\" and \"Computer Vision Figures dataset,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the training details of the VQGAN, specifically inquiring whether it is pretrained or only trained on a subset of images from the dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the training details of the VQGAN, specifically whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, particularly inquiring whether it is pretrained or only trained on a subset of images from the Computer Vision Figures dataset. This question highlights a potential gap in the paper that could impact the reader\"s understanding of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include works such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and compare them to their work conceptually. Additionally, it recommends discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). These suggestions provide clear and explicit actions for the authors to take, including identifying relevant works and discussing their differences. The comment is concrete and provides specific guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests including works such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and discussing how their work differs from other chatbox research works, such as [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015). However, it does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in suggesting the inclusion of these works and the need for a discussion on differences, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include specific works, such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. The comment also recommends discussing how their work differs from other chatbox research works. While the suggestion is based on logical reasoning and common knowledge about the importance of including relevant works, it lacks specific examples or detailed justification for why these works are particularly relevant or how they differ from others. This makes the claim 3, as it provides a general direction but lacks detailed evidence or references to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include relevant works, such as [] Li, Xiujun, et al. \"Endtoend taskcompletion neural dialogue systems.\" arXiv preprint arXiv:1703.01008 (2017) and [] He, Ji, et al. \"Deep reinforcement learning with a natural language action space.\" arXiv preprint arXiv:1511.04636(2015), to compare their work with. It also recommends discussing how their work differs from other chatbox research works. This feedback is 4 as it guides the authors on how to enhance their draft by incorporating relevant references and discussing their unique contributions. However, it could be more helpful if it provided additional context or examples of how these works differ from the current paper. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed methods, DualIS and DualDIS, in terms of their generic applicability on crossmodel retrieval tasks, specifically noting minor improvements in MSVD (Table 3). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the methods or what specific aspects of the methods need to be addressed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed methods, DualIS and DualDIS, in crossmodel retrieval tasks, specifically mentioning Table 3 and MSVD. However, it does not specify which part of the paper this performance analysis is discussed in, making it weakly grounded. The comment is specific in detailing the issue of generic applicability and the minor improvements in MSVD, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3) showing minor improvements. However, the comment does not provide any supporting evidence, such as data or comparisons, to substantiate this claim. Without additional details or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the proposed methods, DualIS and DualDIS, by pointing out that they are not generic on some crossmodel retrieval tasks, as evidenced by the performance in MSVD (Table 3) showing minor improvements. This feedback is 3 as it highlights an area for improvement, but it lacks specific suggestions or guidance on how to address this issue. The authors are informed of a potential weakness but are not provided with actionable steps to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not provide explicit instructions on how to implement this alternative method or why it might be preferable. While the suggestion is clear, it lacks concrete guidance on how to execute it, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. It suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. However, the comment does not specify which part of the paper this critique is based on, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the alternative method and the rationale behind it, but without clear grounding, it is difficult for the authors to effectively address the critique. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the experimental strengths of the approach, specifically the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This claim is 3 as it provides a logical reasoning for the alternative method, but it lacks specific examples or references to support the claim that running vanilla Adam would be sufficient. The comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the need for running a descent procedure for 40 different networks from the training phase. The reviewer suggests an alternative method of running vanilla Adam on the final network with 40 random initial points, which could potentially achieve the same results. This feedback is 3 as it points out a potential weakness in the experimental setup and offers a suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the alternative method, or if it offered guidance on how to implement the suggested change. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to establish this relationship or what specific steps to take to improve the study. As a result, the authors are left without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the study, namely the lack of establishment of the relationship between the top selected patches and the disease. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this relationship should be discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. The comment is specific in identifying the issue of incomplete study, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant gap in the study, noting that the relationship between the top selected patches and the disease is not yet established. This is a critical point that could impact the validity and reliability of the study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to establish this relationship. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but no clear path forward. Therefore, the comment is 3, as it points out a critical area for improvement but does not provide enough detail for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a typographical error in the phrase \"for \"inbetween\" uncertainty\" by noting that the first quotation mark should be a forward mark rather than a backward mark. This is a clear and concrete action for the authors to take, as they are provided with specific guidance on how to correct the error. The comment is 5 as it directly instructs the authors on what to change to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the quotation marks, providing detailed guidance on how to correct the typographical error. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a typographical error in the paper, specifically noting the incorrect placement of the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific typographical error in the paper, namely the incorrect placement of the quotation marks in the phrase \"for \"inbetween\" uncertainty.\" This is a minor but important detail that can impact the clarity and professionalism of the paper. By pointing out this error, the comment provides actionable feedback that the authors can easily address to improve the quality of their draft. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the performance of FedSP is not the best in Tables 1 and 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the performance or what specific aspects of FedSP need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of FedSP is not the best in these tables on some datasets. However, it does not provide detailed guidance on what aspects of FedSP need improvement or how to address the performance issue. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the performance of FedSP is not the best in Tables 1 and 2 on some datasets. However, it does not provide any specific data, comparisons, or references to support this claim. Without detailed evidence or reasoning, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of FedSP in Tables 1 and 2 on some datasets. It highlights that the theme of the paper is mainly about FedSP, but the performance is not the best. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might improve the performance or address this issue. Without specific recommendations or examples, the feedback does not assist the authors in making meaningful improvements to their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the clarity of certain aspects in the paper, specifically asking for more explicit explanations. It suggests that the authors should clarify what Omega is mentioned in L178 and provide more explicit information about the OMD family of algorithms. Additionally, it asks for clarification on the link function and the theorem in [32] that is being referred to for the regret guarantee. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations, but the guidance is somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the clarity of certain aspects, such as the definition of Omega and the OMD family of algorithms, and requests more explicit information about the link function and the theorem in [32] that is being referred to for the regret guarantee. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved by requesting more explicit explanations. It asks for clarification on the definition of Omega and the OMD family of algorithms, as well as the link function and the theorem in [32] that is being referred to for the regret guarantee. By providing these specific questions, the comment offers actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered additional context to guide the authors in their responses. Overall, the comment is 4 as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. However, it does not provide any guidance or suggestions on how the authors should address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what the implications of this observation might be. As a result, the comment lacks actionability and does not provide any direction for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment mentions \"the models are learned directly from pixels without a Markovian state,\" which suggests that the models are not Markovian. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the models being Markovian, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific aspect of the models being learned directly from pixels without a Markovian state. While it identifies a potential issue, it lacks depth and does not provide any actionable suggestions or guidance on how the authors might address this concern. Without further explanation or examples, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and explicit action. The comment is specific in identifying the need for references and provides a concrete direction for the authors to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"sequence example\" and \"Example 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the surprise regarding the use of the Hamming distance over entire parts of the sequence as a scoring loss, and it suggests providing references for this approach. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF, suggesting that this is a \"common\" practice. The reviewer acknowledges that they are not familiar with this approach and asks for references to support it. This claim is 3 as it highlights a potential gap in the paper\"s explanation and seeks clarification, but it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of a \"common\" practice in the context of CRF, specifically using the Hamming distance over entire parts of the sequence as a scoring loss. The reviewer suggests that the authors should provide references for this approach, which is a clear and actionable suggestion. By addressing this point, the authors can enhance the clarity and completeness of their paper. However, the comment could be more helpful if it provided specific references or examples of works that use this approach. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear path for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment provides a clear action to take, it lacks specific guidance on how to implement these changes or what specific metrics should be included. The authors are given a general direction but may need to infer the details of execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation or metrics sections. The suggestion to change the name and mention metrics is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections. It also suggests mentioning the metrics along with the datasets or in the captions of the tables. This claim is 3 as it provides a logical reasoning for the name change and suggests a way to present the metrics. However, the comment lacks specific examples or references to wellknown metrics or standard practices, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to change the name of the \"Evaluation\" element to \"Metrics,\" which is a more accurate and standard term. It also recommends removing the corresponding sections and mentioning the metrics along with the datasets or in the captions of the tables. This feedback is clear and offers a straightforward way for the authors to improve the clarity and accuracy of their paper. By following this advice, the authors can enhance the readability and comprehensibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the authors should explore the new proposed dataset, DRRI, more thoroughly in the paper. However, it does not provide specific guidance on how to do so or what aspects of the dataset should be highlighted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their exploration of the dataset but without detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper should have more exploration or what aspects of the dataset should be highlighted. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any supporting evidence, reasoning, or examples to justify why this exploration is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide specific guidance or examples on how the authors could expand their exploration of the dataset or what aspects of the dataset should be highlighted. Without actionable advice or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. While the comment provides a specific suggestion to use more objective terms, it does not offer concrete guidance on what terms to use or how to present the improvement in a more objective manner. The action is implicit and somewhat vague, as the authors need to infer the specific terms to use and the exact way to present the improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"axes\" and \"squished,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement and points out that the axes are squished, making it difficult to characterize the improvement as remarkable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the term \"remarkable\" is subjective and that the axes are squished, making it difficult to characterize the accuracy improvement as remarkable. However, the comment does not provide specific examples or references to support why \"remarkable\" is inappropriate or how the axes are squished. Without additional context or evidence, the claim is not 5, as it lacks detailed justification or examples. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment provides a specific suggestion to use more objective terms than \"remarkable\" in describing the accuracy improvement. It also points out that the axes are squished, making it difficult to characterize the improvement as remarkable. This feedback is actionable and can help the authors improve the clarity and precision of their language in describing the results. However, the comment could be more helpful if it provided examples of alternative, objective terms to use or explained why \"remarkable\" is not appropriate in this context. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from using longer video sequences, such as 16 frames, to address issues with inconsistent motion, changing color, or object disappearing over time. It also mentions that running the LSTM over many time steps could be interesting. While the comment implies that the authors should consider these changes, it does not provide explicit instructions or concrete steps on how to implement them. The authors are left to infer that they should explore longer video sequences, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the synthesized results for UCF101, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with inconsistent motion, changing color, or object disappearing over time and suggests using longer video sequences. Additionally, it provides a positive assessment of the paper, noting its interesting idea and extensive experiments. However, it lacks specific suggestions on how to address the issues or improve the results. Therefore, the comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the synthesized results for UCF101 exhibit inconsistent motion, changing color, or object disappearing over time. It suggests that using longer video sequences could address these issues. The comment provides a logical reasoning by pointing out the limitations of the current results and suggesting a potential improvement. However, it lacks specific examples or references to support the claim about the synthesized results, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment provides a positive assessment of the paper, noting its interesting idea and extensive experiments. It also identifies specific issues with the synthesized results, such as inconsistent motion, changing color, or object disappearing over time. The comment suggests that using longer video sequences could address these issues. While the feedback highlights areas for improvement, it lacks detailed guidance or suggestions on how to implement these changes. The authors are given a general direction but are not provided with specific steps or examples to follow. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment states a fact about the current state of work on pruning, specifically noting that it is not yet possible to achieve efficiency gains on GPUs. However, it does not provide any guidance or suggestions for the authors to address this issue or improve their work. There is no explicit or implicit action for the authors to take, nor is there any indication of what aspects of the paper might need revision or improvement. As a result, the comment lacks actionability and is not helpful for the authors to understand how to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses. It is a general statement about the state of work on pruning, specifically mentioning GPUs. Without specific references to sections, figures, or elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity as it does not provide details on what aspects of the work on pruning are not yet efficient on GPUs. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it is not yet possible to realize efficiency gains on GPUs,\" which is a factual statement about the current state of work on pruning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment provides a factual observation about the current state of work on pruning, specifically noting that it is not yet possible to achieve efficiency gains on GPUs. While this information is relevant, it does not offer any actionable insights or suggestions for improvement. It lacks depth and does not guide the authors on how to address this issue or what aspects of their work might need revision. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair because [5] is designed for a more complex problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the evaluation. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the numerical evaluation and the comparison with [5], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is not fair due to the complexity of the problem. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the numerical evaluation is not convincing due to the method being evaluated only on synthetic data and the comparison with [5] being unfair. The reviewer supports this claim by explaining that [5] is designed for a more complex problem, specifically mentioning the absence of knowledge of camera pose parameters. This provides a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to the complex problem addressed by [5], which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with [5] is unfair due to the complexity of the problem addressed by [5]. This feedback is valuable as it highlights a potential weakness in the evaluation, which could impact the credibility of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending additional experiments or data sources to validate the method. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors studied the effect of using numbers of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment implies that the authors should consider this experiment, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this experiment to strengthen their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"PGD attack\" and the \"32bit logit,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. This provides clear guidance on what the authors should consider in their work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether the study of numbers of bits in logits helps against a larger epsilon in the PGD attack. The reviewer suggests that intuition suggests that having a 32bit logit might improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it 3. The authors would need to make a logical deduction or conduct additional research to verify the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the study of numbers of bits in logits and their effect on robustness against a larger epsilon in the PGD attack. It suggests that intuition suggests that having a 32bit logit might improve robustness against a more powerful adversary. While the comment identifies a potential area for exploration, it does not provide specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. The feedback is 3 as it points out a potential area for improvement but lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. While it does not explicitly instruct the authors to provide this information, the question implies that the authors should include this analysis in their paper. The action is implicit but concrete, as the authors can infer that they need to include this information to address the reviewer\"s concern. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment poses a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this information should be addressed. Additionally, the comment lacks specificity regarding what aspects of the insurance costs should be analyzed or how the method affects them. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a specific question about the impact of the method on insurance costs for men and women. This is a clear and actionable request for additional information that could help the authors better understand the practical implications of their work. By addressing this question, the authors could provide more comprehensive and relevant information about their method\"s realworld applications. However, the comment does not offer suggestions on how to present this information or what specific aspects to focus on. While it identifies a relevant area for improvement, it lacks depth and guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, specifically mentioning a reference to Foester et al. (NIPS 2016) as an example. This provides a clear and concrete action for the authors to take, as they are given a specific area to address and a reference to guide their understanding. The comment is 5 because it directly tells the authors what to do and provides a concrete example to follow.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta solvers\" and the \"centralized RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the difference between the meta solvers and centralized RL. The reference to Foester et al. (NIPS 2016) provides additional clarity and guidance on how to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the meta solvers are centralized controllers, and suggests that the authors should clarify the difference between them and centralized RL. The reviewer provides a reference to Foester et al. (NIPS 2016) as an example of centralized RL. This reference provides a logical basis for the claim, as it suggests that the centralized RL approach is relevant to the discussion of the meta solvers. However, the comment could be strengthened by providing more detailed reasoning or examples from the reference to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the classification of the meta solvers as centralized controllers. It suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a specific reference to Foester et al. (NIPS 2016) as an example of centralized RL, which is a clear and actionable suggestion. This feedback is valuable as it directs the authors to a specific area that needs clarification, helping them to improve the clarity and accuracy of their work. However, the comment could be more helpful if it provided additional guidance on how to address this issue or explained why the distinction is important. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October, suggesting that the authors should consider this issue in their paper. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the availability of papers on arxiv. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of splitting papers according to their publication years on the ACL anthology, noting that many papers are available on arxiv much earlier. It provides an example of the BERT paper being available on arxiv in October. However, the comment does not specify which part of the paper discusses the splitting of papers, making it weakly grounded. The comment is specific in pointing out the issue of papers being available on arxiv before being published in the ACL anthology. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. The reviewer provides an example of the BERT paper being available on arxiv in October, which supports the claim. However, the comment could be strengthened by providing more examples or detailed reasoning on why this issue is significant. As it stands, the claim is 3, as it relies on a specific example but lacks comprehensive evidence or detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s methodology, noting that it splits papers according to their publication years on the ACL anthology, but many papers are available on arxiv much earlier. This is a relevant observation that could impact the paper\"s credibility and relevance. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it lacks actionable advice or detailed feedback, making it 3 but incomplete. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should consider providing examples to explain the concept of M_T, which is defined over the probabilities of atomic events. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific in its request for examples, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the definition of M_T and the notation used, and suggests providing examples to clarify the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of M_T is over the probabilities of atomic events and that the notation is not clear. It provides a specific request for examples to clarify the concept. This claim is 3 as it logically points out a potential issue with the notation and suggests a solution, but it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, specifically the definition of M_T over the probabilities of atomic events. It suggests that the notation is not clear and recommends providing examples to clarify the concept. This feedback is actionable and can help the authors improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided specific examples of what kind of examples would be beneficial or how they could be integrated into the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two concerns: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to clarify the use of \u03b2 and the difference between QRS and RS, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the proposed relaxation of rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. The comment provides a clear direction for improvement by suggesting that the authors clarify the use of \u03b2 and the difference between QRS and RS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the use of an arbitrary parameter \u03b2 in rejection sampling and questions the lack of clarity regarding the difference between QRS and RS in Algorithm 1. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the authors should have used Importance sampling instead of rejection sampling. Additionally, the comment lacks specific examples or detailed explanations to support the claim about the difference between QRS and RS. As a result, the claim is not verifiable, as it does not provide sufficient evidence or justification for the authors to understand or address the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the use of an arbitrary parameter \u03b2 in rejection sampling and the lack of clarity regarding the difference between QRS and RS in Algorithm 1. While the comment highlights these areas for improvement, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial if it offered actionable steps or examples to improve the draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment suggests that the observed performance enhancements are modest and implies that there is room for further refinement in the future. However, it does not provide specific guidance on how to achieve this refinement or what aspects of the work need improvement. The action is implicit and vague, as the authors are left to infer that they need to make improvements but without clear direction on what those improvements should be. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, it does not specify which part of the paper this observation is based on, such as specific results or sections where the enhancements are discussed. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the work need refinement or how to achieve this refinement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the observed performance enhancements are modest, implying that there is room for further refinement in the future. However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. It lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand the basis of the observation. As a result, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that the observed performance enhancements are modest, indicating that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work need improvement. Without actionable feedback or detailed insights, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235, and to clarify what \"MLP\" refers to in Figure 2. These are clear and direct actions that the authors can take to improve their draft. Additionally, the comment highlights a missing reference, which is also actionable. The feedback is specific and provides concrete guidance on what needs to be added or clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in Section 3.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for references for two passages and clarifies what \"MLP\" refers to in Figure 2. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of requests for references and clarifications, which are factual in nature and do not contain subjective claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying specific lines in Section 3.2 that lack references and clarifying what \"MLP\" refers to in Figure 2. This guidance is clear and directs the authors to specific areas that need attention, ensuring that the paper is wellreferenced and accurate. Additionally, the comment highlights a missing reference, which is important for the paper\"s completeness. Overall, the comment is 5 as it offers concrete steps for the authors to improve their draft, making it fully comprehensive and beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, it does not provide specific guidance on how the authors should address this issue or what steps they should take to improve the results. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, specifically mentioning the performance being similar to IRM. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the issue with the experimental results, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method. However, it does not provide specific reasoning or evidence to support this claim, such as detailed analysis or comparisons with other methods. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the validity of the proposed method. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their experimental results. Without detailed guidance or examples, the authors are left without a clear path forward, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. While the comment implies that the authors should provide a clearer explanation or rationale for this distinction, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the distinction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of detecting both entities in the example and asking for clarification on the difference between detecting both entities and just detecting the long one. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in the example of Figure 2, and it asks for clarification on the difference between detecting both entities and just detecting the long one. This feedback is 3 as it prompts the authors to clarify their reasoning or explanation for the distinction. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue. While it points out a potential area for improvement, it does not fully support the authors in making those improvements. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no empirical validation and suggests including experiments to validate the bounds. This provides a clear and direct action for the authors to take, which is to conduct experiments to validate the bounds. The comment is specific in its request for empirical validation and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the lack of empirical validation, which provides full grounding as it allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of experiments to validate the bounds. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no empirical validation and suggests including experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical validation for the bounds. It suggests that including experiments to validate the bounds would be beneficial. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending empirical validation. However, the comment could be more helpful if it offered examples of what types of experiments might be appropriate or how to design them. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. However, it does not provide any explicit guidance or suggestions on how the authors should address this confusion or clarify their terminology. The action is implicit and vague, as the authors are left to infer that they need to reconsider their terminology. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the phrase \"nonsequential information such as chunks,\" suggesting that the term \"chunks\" might be considered sequential information. This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the phrase \"nonsequential information such as chunks.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the phrase \"nonsequential information such as chunks\" in line 285, suggesting that the term \"chunks\" might be considered sequential information. This question highlights a potential confusion in the paper that could be clarified to improve the clarity and coherence of the text. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their terminology. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a discrepancy between equation 9 and figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address it or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider Figure 1 and possibly use bilinear sampling. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"eq. 9\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions, and suggesting that bilinear sampling might provide better results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or masked versions. The reviewer suggests that the figure is misleading and proposes an alternative method, bilinear sampling, for better results. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the misleading nature of Figure 1. The suggestion to use bilinear sampling is logical but could be strengthened with more detailed explanation or references. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, noting that the output patches from equation 9 appear to be masked versions of the input image rather than cropped parts. It questions the accuracy of Figure 1 and suggests that bilinear sampling might provide better results. This feedback is 3 as it points out a potential issue with the clarity and accuracy of the figures, prompting the authors to reconsider their representation. However, the comment could be more helpful if it provided specific guidance on how to address the discrepancy or how to improve the figures. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the upper bound in Theorem 1, which seems correct but contains an exception. The reviewer asks how to explain this exception, implying that the authors should provide a clarification or explanation. However, the comment does not explicitly instruct the authors to address this issue or suggest specific ways to do so. The action is implicit and somewhat vague, as the authors can infer that they need to provide an explanation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the upper bound in Theorem 1 and asks for an explanation of an exception. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the correctness of Theorem 1 and an observation about an exception. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the correctness of Theorem 1 and points out an exception regarding a separate node with 0 neighbors. This question highlights a potential issue in the paper that the authors may need to address. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the theorem need clarification. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). It suggests that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous papers. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their draft. It lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the two papers (Xing and Tsang, 2022a, b), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of technical novelty and the similarity to the mentioned papers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks technical novelty, comparing it to two mentioned papers (Xing and Tsang, 2022a, b). The reviewer supports this claim by referencing the papers, which focus on graphbased approaches, and points out that the idea, coattention mechanism, and architecture of the paper are similar to those in the previous works. This provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the papers to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, noting that it lacks technical novelty and is similar to two mentioned papers (Xing and Tsang, 2022a, b). This feedback is 3 as it points out a potential weakness in the paper\"s originality, which the authors should address to enhance the manuscript. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the paper from the existing literature or how to improve its originality. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, which is fine if the authors choose to delete the \"Discussion\" label. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting a revised approach or additional analysis. The action is implicit and somewhat vague, as the authors need to infer that they should revise the Discussion section to include this observation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. This provides clear guidance on what needs to be addressed in the Discussion section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the training time reduction is less drastic than the parameter reduction, as most gradients are still computed for early downsampling layers. It suggests that this observation has not been revisited in the Discussion section, which is fine if the authors choose to delete the \"Discussion\" label. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the discussion. While it points out a potential oversight, it lacks actionable feedback that would help the authors enhance their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem being discussed is specific to binding affinity prediction or applies to other downstream tasks. It implies that the authors should provide a justification for why the problem is specific to binding affinity prediction. However, the comment does not explicitly instruct the authors to provide this justification or specify how it should be presented. While the action is implied, it is not concrete, as the authors are left to infer what additional information is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or whether it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a justification or explanation of why the problem is specific to binding affinity prediction. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the applicability of the problem to other downstream tasks or its specificity to binding affinity prediction. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem to other downstream tasks or its specificity to binding affinity prediction. This is a relevant point that could prompt the authors to clarify the scope and limitations of their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what additional information would be beneficial. While it identifies a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific analyses or solutions could be proposed. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the handling of rumors generated by GPT, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the need for further analysis or solutions regarding the challenges of detecting rumors generated by GPT, and it questions the rationale behind why GPTgenerated rumors are similar to natural rumors. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It suggests that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. The comment provides a logical reasoning by questioning the experimental result and suggesting that the rationale might be flawed. However, it lacks specific examples or references to support the claim that GPTgenerated rumors are easier to detect than natural rumors. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the handling of rumors generated by GPT, specifically questioning the rationale behind why GPTgenerated rumors are similar to natural rumors in terms of difficulty to detect. It points out that Artificial Rumor, which is also written by humans, should be about the same difficulty as Natural Rumor, but the experimental result shows the opposite. This feedback is 3 as it highlights an area where the authors could provide further analysis or solutions to address the challenge of detecting rumors generated by GPT. However, the comment could be more helpful if it suggested specific analyses or experiments that could be conducted to explore this issue further. Overall, the comment provides some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the technical contribution or what specific changes should be made to Section 4. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, stating that it is limited and not about a formal and principled solution but rather about heuristics. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather about heuristics. This feedback highlights an area where the paper could be improved by providing a more comprehensive and rigorous approach to the technical contribution. However, the comment lacks specific suggestions or guidance on how to address this issue or what aspects of the heuristics should be improved. While it points out a potential weakness, it does not offer actionable steps for the authors to take, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly states that the font size in Figure 6 is too small, providing a clear and direct action for the authors to take. This feedback is specific and concrete, as it instructs the authors to adjust the font size to make it more readable. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a factual observation about the font size in Figure 6, which does not contain any subjective claims, opinions, or suggestions. It is a descriptive statement that requires no verification or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment identifies a specific issue with the font size in Figure 6, noting that it is too small. This feedback is clear and actionable, as it provides the authors with a concrete step to improve the readability of their figure. However, the comment could be more helpful if it suggested a specific font size or provided guidance on how to adjust the font size to improve legibility. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, which can enhance the clarity and accessibility of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the probability mass function (PMF) is not being fully utilized in the experimental setting and recommends considering various PMFs for each learner class. It also mentions that the quasiuniform distribution used in MixBoost is dependent on a single parameter and suggests that individual consideration of each learner class would add depth to the experimental setting. However, the comment does not provide specific guidance on how to implement this suggestion or which PMFs to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"probability mass function\" and the \"MixBoost\" setting, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the use of a quasiuniform distribution and suggests considering various probability mass functions for each learner class. This provides clear guidance on what needs to be addressed in the experimental setting. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the probability mass function is not being fully utilized in the experimental setting, specifically mentioning the use of a quasiuniform distribution in MixBoost. The reviewer suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that a quasiuniform distribution is not ideal. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setting, noting that the probability mass function is not being fully utilized in the MixBoost setting. It suggests that considering various probability mass functions for each learner class would add depth to the experimental setting. While the comment highlights a potential area for improvement, it lacks specific guidance on how to implement this suggestion or which probability mass functions to consider. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should address this issue, provide additional context, or clarify their methodology. As a result, the authors are left without any clear direction on how to respond to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how the authors should address this concern. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and act upon the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is unfair. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment raises a valid question about the fairness of comparing the accuracies of ChatGPT and other models, given that ChatGPT shows a high percentage of abstentions. This is an important point that could impact the interpretation and comparison of results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the fairness of the comparison. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is 3, as it identifies a potential issue but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. However, the comment does not provide explicit instructions on how to incorporate these references or discuss the connections. While the authors can infer that they need to include these references and discuss the connections, the lack of concrete guidance on how to do so makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the missing references and the need to discuss connections with [a], which uses supervised learning in QBF solving. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper is missing relevant references, specifically mentioning [a], which uses supervised learning in QBF solving. The reviewer provides a specific reference to support the claim that this work is relevant to the paper\"s topic. However, the comment lacks detailed reasoning or explanation about why this reference is crucial or how it relates to the paper\"s content. While the reference is provided, the lack of detailed justification makes the claim 3, as the authors would need to explore the connection themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue by pointing out the missing references, specifically mentioning [a], which is relevant to the topic of the paper. It suggests discussing connections with [a], which uses supervised learning in QBF solving, where QBF generalizes SMT. This feedback is clear and actionable, as it directs the authors to include relevant references and explore potential connections with the existing literature. However, the comment could be more helpful if it provided specific guidance on how to incorporate these references or discuss the connections effectively. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider whether the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss can be replaced by other relationships. It also suggests that explaining this point may be beneficial. While the comment implies that the authors should explore alternative relationships, it does not provide specific guidance on how to do so or what specific alternative relationships to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the training process and the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests exploring alternative relationships and provides a reference to a related work for further consideration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss is replaced by other relationships. The reviewer supports this claim by referencing a related work, \"Learning the Pareto Front with Hypernetworks,\" which suggests that the mono tonic relationship can be replaced by other relationships. However, the comment does not provide detailed reasoning or examples from the referenced work to fully substantiate the claim. This makes the comment 3, as it provides a reference but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific aspect of the training process that could be improved by exploring alternative relationships to the mono tonic relationship between the degree of a singletask predictor participation and the weight of the corresponding task loss. It suggests that this could lead to a continuous parameterization of the Pareto Front. The comment also references a related work, \"Learning the Pareto Front with Hypernetworks,\" which provides a potential direction for further exploration. While the comment highlights an area for improvement, it lacks specific guidance on how to implement this exploration or what alternative relationships to consider. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what aspects of the computation cost or running time should be compared, nor is there any suggestion for how the authors might address this issue. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment poses a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the computation cost or running time should be compared or how the authors might address this issue. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the comparison in terms of computation cost or running time, but it does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison in terms of computation cost or running time, which could be an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the computation cost or running time should be compared. Without actionable feedback or detailed insights, the comment offers limited value to the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a specific suggestion for improvement, it lacks concrete guidance on how to implement this change or what specific aspects of the paper need to be revised to address this issue. The authors are left with a general idea of what to do but without detailed instructions on how to execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the choice of examples and the relevance of the paper\"s results in the context of samplingbased Bayesian methods. The comment provides a clear direction for improvement by suggesting a focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a clear goal in the introduction and questions the relevance of the examples chosen. The reviewer suggests that the paper should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current examples are unconvincing or inappropriate. This makes the claim 3, as the authors would need to further explore and substantiate the critique themselves.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the introduction regarding the paper\"s goal and suggests that the examples chosen may not effectively demonstrate the need for interprocess communication. It provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild. This feedback is 3 as it points out a potential weakness in the paper and offers a direction for improvement. However, it could be more helpful if it provided more detailed guidance on how to address this issue or examples of how the authors might apply the suggested focus. Overall, the comment offers some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address these concerns or improve the paper in response. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the privacy preservation issue and the example of traffic signal control, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. However, the comment lacks any supporting evidence, reasoning, or references to substantiate these claims. Without detailed justification or examples, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the privacy preservation of the proposed approach compared to other federated learning approaches. It also questions whether privacy preservation is an issue in the context of traffic signal control, suggesting that this example is a poor choice for demonstrating federated learning. While the comment identifies a potential weakness in the paper\"s argument, it lacks specific guidance or suggestions on how the authors might address this issue or improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more beneficial with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of fairness in the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module. It suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This feedback provides a clear and explicit action for the authors to take, specifying which model to compare and why. The suggestion is concrete, as it directly instructs the authors on how to improve the fairness and clarity of their comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"line 529lin534,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of fairness in the comparison between CPEF and PMEF. The comment suggests that the authors should compare CPEF with another pretrained model, such as ExpertBert, to showcase the advantage of the innovative pretraining module design of CPEF. This provides clear guidance on how to improve the fairness and clarity of the comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison between CPEF and PMEF is unfair due to the lack of a pretraining module in PMEF. The reviewer suggests that to ensure fairness, the authors should compare CPEF with another pretrained model, such as ExpertBert. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a potential solution. However, the comment could be strengthened by providing specific examples or references to similar comparisons in the literature that demonstrate the importance of pretraining for fairness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the fairness of the comparison between CPEF and PMEF in Figure 3, noting that PMEF lacks a pretraining module. It provides a clear and actionable suggestion to ensure fairness by recommending a comparison with another pretrained model, such as ExpertBert. This feedback is valuable as it guides the authors on how to improve the fairness and clarity of their comparison, which is crucial for the validity of their findings. However, the comment could be more helpful if it explained why the comparison with ExpertBert is particularly relevant or how it would enhance the understanding of the advantages of the pretrained question representation model. Overall, the comment is 4 as it provides a clear direction for improvement but could be expanded to be fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and potentially fix the links. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnotes 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the hyperlinks not working, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hyperlinks for footnotes 3 and 4 do not work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable piece of feedback that the authors can address to improve the quality and accessibility of their paper. By addressing this issue, the authors can ensure that their references are properly linked and accessible to readers, which is an important aspect of academic writing. However, the comment could be more helpful if it provided additional guidance on how to verify the links or suggested alternative solutions. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is explicit and provides concrete details on what changes need to be made, making it 5. The authors know exactly what needs to be revised to improve the clarity of their discussion.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific guidance on what needs to be revised, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The comment also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This provides full grounding as it explicitly mentions the sections and elements being addressed, allowing the authors to identify and address the issues. The comment is specific in detailing what needs to be revised, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, to improve clarity. It provides specific examples of areas that need improvement, such as better formalizing the architecture in section 2 and clarifying the role of Label Embeddings. The reviewer also points out that the figure may be misleading, suggesting that the Label Embeddings are the output of the encoder. This feedback is 4 as it provides logical reasoning and specific examples to support the claim. However, it could be strengthened by referencing external works or providing more detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity of the discussion in the modeling section. It suggests revising the architecture section to better formalize the architecture and clarify the role of Label Embeddings. The reviewer also points out that the figure may be misleading, as it suggests that Label Embeddings are the output of the encoder. This feedback is 5 as it guides the authors on how to improve the clarity and accuracy of their discussion, which is crucial for effective communication of their work. By addressing these points, the authors can significantly enhance the comprehensibility and impact of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the description of the neural network is difficult to understand and recommends starting the section with the final paragraph that clarifies it. While the comment provides a specific suggestion to improve the clarity of the section, it does not offer detailed guidance on how to achieve this clarity or what specific changes should be made to the description. The action is implicit and somewhat vague, as the authors need to infer that they should start the section with the clarifying paragraph. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"528,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of the neural network, suggesting that it is hard to understand and recommending starting the section with the final paragraph that clarifies it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of the neural network is hard to understand and suggests starting the section with the final paragraph that clarifies it. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the description of the neural network, noting that it is hard to understand. It suggests starting the section with the final paragraph that clarifies the description, providing a clear and actionable suggestion for improvement. This feedback is 3 as it points out a specific area that needs attention and offers a concrete way to address it. However, it could be more helpful if it included additional context or examples to help the authors understand the problem more fully. Overall, the comment is 3 as it provides a clear direction for improvement but lacks depth and detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it implies that the authors should consider this option, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not specify which part of the paper this limitation or suggestion pertains to, making it weakly grounded. The comment is specific in suggesting an alternative approach, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. However, it does not provide any supporting evidence, reasoning, or references to justify why the current approach is limited or how attentionbased training might be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of the model and suggests exploring attentionbased encoderdecoder training as an alternative. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or examples on how to implement this change or what benefits it might offer. The comment is 3 as it points out a potential direction for improvement, but it does not offer actionable steps or detailed reasoning to support the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what changes should be made to the tables. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3 (line 247252),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the division of tables into three types and suggesting that one type (the column header) should work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any supporting evidence, reasoning, or references to justify why this division is problematic or how it could be improved. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the division of tables into three types, specifically questioning the necessity of having three types. However, it does not provide any actionable feedback or suggestions for improvement. Without further explanation or guidance, the authors are left without a clear understanding of what changes, if any, should be made to address this concern. As a result, the comment lacks helpfulness, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. It provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment does not explicitly instruct the authors to use these methods or provide guidance on how to integrate them into their work. While the action is implied, it is not as clear as it could be, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attack methods\" and \"toy setting with classification tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not consider other classical attack methods in NLP and suggests specific examples from other papers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the attack methods used in the paper are naive and suggests that other classical attack methods in NLP should be considered. The reviewer provides specific examples of such methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. However, the comment lacks detailed reasoning or evidence to support why these methods are more effective or why the current methods are inadequate. While the examples are provided, the justification for the claim is not fully developed, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the attack methods used are naive and that the paper does not consider other classical attack methods in NLP. It provides specific examples of alternative methods, such as randomly adding tokens as suffixes and generating a universal adversarial suffix. This feedback is clear and actionable, as it guides the authors to consider a broader range of attack methods that could enhance the robustness and generalizability of their work. However, the comment could be more helpful if it explained why these alternative methods are more effective or how they might be integrated into the paper. Overall, the comment is 4 as it directs the authors to consider a wider range of attack methods, but it could be further improved with additional guidance or rationale."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to mitigate the impact of mitigation methods or suggestions for improving image quality. As a result, the authors are left without any clear direction on how to improve their draft in response to this comment. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation methods on the image generation capabilities of diffusion models, suggesting that this could lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with the mitigation methods affecting image quality. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, which could lead to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their mitigation methods. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance on how to address these concerns or what specific steps the authors should take to mitigate these risks. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper this concern is related to, such as specific sections or experiments where this issue might arise. Without explicit references to sections or figures, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specific guidance on how to address these concerns or what steps to take to mitigate the risks. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references to studies or literature that demonstrate similar risks or offer guidance on how to address them. As a result, the claim is 3, as it provides a logical concern but lacks the necessary evidence or examples to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that there is a potential risk of leaked information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. While the comment identifies a critical issue, it lacks specific guidance or suggestions on how the authors might address this concern or mitigate the risks. The feedback is 3 as it points out a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes they should make to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by expressing surprise about the dominance of function words over content words in a Japanese sentence. However, the comment lacks specificity regarding what aspect of the dominance is surprising or how it might impact the paper. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses surprise about the dominance of function words over content words in a Japanese sentence, but it lacks any actionable feedback or suggestions for improvement. Without further explanation or context, the authors are left without a clear understanding of what aspect of this observation is relevant to their work or how it might impact their analysis. As a result, the comment does not provide any meaningful guidance for the authors to enhance their draft. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer provides a rationale by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This explicit suggestion and the inclusion of references provide clear guidance on what the authors should consider as a more reasonable baseline for their analysis. The action is explicit and concrete, as the authors know exactly what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of the average of multiple kmeans objectives with different seeds as a baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion to use the minimum kmeans objective over multiple seeds instead. This provides clear guidance on what the authors should consider as a more reasonable baseline for their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that using the average of multiple kmeans objectives with different seeds as a baseline is not ideal and recommends using the minimum kmeans objective over multiple seeds instead. The reviewer supports this claim by referencing two external sources, [1] and [2], which discuss the properties of kmeans clustering and its applicability to different datasets. This provides a logical basis for the claim, as it aligns with the literature on kmeans clustering. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced sources to fully substantiate the claim. Therefore, the comment is 4, as it provides some evidence but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to improve the paper by recommending the use of the minimum kmeans objective over multiple seeds as a baseline instead of the average of multiple kmeans objectives. This feedback is based on a logical reasoning that aligns with the literature on kmeans clustering, as referenced in the comment. By referencing specific sources, the reviewer offers a solid foundation for the suggestion, making it easy for the authors to understand and implement the change. However, the comment could be more helpful if it provided additional context or examples on why the minimum kmeans objective is more appropriate. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment implies that the authors should clarify these differences, it does not provide specific guidance on how to do so or what aspects of the task should be clarified. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences against Argument Mining/Discussion Summarization, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the task described in the paper is closer to Argument Mining rather than Summarization. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why the task is closer to Argument Mining, making it difficult for the authors to understand and address the critique. As a result, the claim is 1, as it does not provide sufficient evidence or justification to support the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the task described in the paper is closer to Argument Mining rather than Summarization and recommends further clarification on the differences between the two. While the comment identifies a potential issue with the task classification, it lacks specific guidance on how to clarify these differences or what aspects of the task should be emphasized. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically questioning whether both are required for uncertainty calibration. It suggests that the authors clarify this point and provides a specific example of where the confusion arises (lines 155160). Additionally, it questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. While the comment provides a clear direction for clarification, it does not offer specific guidance on how to address the issue or suggest alternative explanations. The action is explicit but somewhat vague in terms of execution, as the authors know they need to clarify the confusion but may not be entirely sure of the exact steps to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (155160) and the training regularization term (H), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the relationship between temperature calibration and uncertainty calibration, and it questions the motivation of reducing entropy to make predictions more confident. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a confusion regarding the relationship between temperature calibration and uncertainty calibration, specifically questioning whether both are required for uncertainty calibration. The reviewer provides a specific example from the paper (lines 155160) to illustrate the confusion, which helps clarify the issue. However, the comment lacks detailed reasoning or references to support the claim that temperature calibration is required for uncertainty calibration. While the example is helpful, the lack of detailed justification or evidence makes the claim 3, as the authors would need to further explore the issue to fully understand and address the confusion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the relationship between temperature calibration and uncertainty calibration. It points out that while the training regularization term (H) requires temperature calibration, the temperature calibration is applied after training. This observation is valuable as it highlights a potential inconsistency in the paper that could be clarified for readers. Additionally, the comment questions the motivation of reducing entropy to make predictions more confident, as this contradicts the paper\"s goal of calibrating networks. While the comment provides clear and actionable feedback, it could be more helpful if it offered suggestions on how the authors might clarify this point or address the inconsistency. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the absence of an important reference, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. It also highlights the importance of discussing similarities and differences with Lista and placing the paper in appropriate context. This feedback provides a clear and concrete action for the authors to take, which is to include the missing reference and discuss the similarities and differences with Lista. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing reference, \"Lista,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the importance of discussing similarities and differences with the paper \"Lista\" and placing the paper in appropriate context. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that an important reference is missing, specifically the paper \"Lista,\" which is relevant to the idea of unrolling. The reviewer provides a link to the paper and highlights the similarities and differences between the proposed work and \"Lista.\" This provides a clear and specific justification for the claim, making it 5. The inclusion of external references and logical reasoning supports the claim, making it 5. Therefore, the comment is labeled as 5.", "helpfulness_rationale": "The review comment identifies a critical omission in the paper, specifically the absence of an important reference, \"Lista,\" which is relevant to the idea of unrolling. It highlights the importance of discussing similarities and differences with \"Lista\" and placing the paper in appropriate context. This feedback is clear and actionable, as it directs the authors to include the missing reference and address the relationship with \"Lista\" in the paper. By providing this guidance, the comment helps the authors improve the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the linear program in Theorem 3 needs to be explained more intuitively. It acknowledges that this is a main theorem but suggests that providing an explanation of the objective and constraints in (3) would be beneficial for the reader. This feedback is clear and provides a concrete action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the explanation of the linear program and the objective and constraints in (3). This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the linear program in Theorem 3 needs to be explained more intuitively. While it acknowledges that this is a main theorem, it does not provide specific reasoning or examples to support why the explanation is necessary or how it would benefit the reader. The comment lacks detailed justification or references to common practices or standards, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need to provide a more intuitive explanation of the linear program in Theorem 3. It acknowledges that this is a main theorem but emphasizes the importance of explaining the objective and constraints in (3) to enhance the reader\"s understanding. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their work that could enhance its clarity and accessibility. However, the comment could be more helpful if it provided examples or suggestions on how to present this explanation more effectively. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing element in the paper, specifically the FLOT cost matrix in Algorithm 1, which is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1\" and \"FLOT cost matrix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of the FLOT cost matrix in Algorithm 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how it affects the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of the FLOT cost matrix in Algorithm 1. This is a clear and actionable point that the authors can address to improve the clarity and completeness of their draft. By pointing out this missing element, the comment provides valuable guidance for the authors to enhance the accuracy and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to define or present the FLOT cost matrix, which would provide even more detailed guidance. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and points of confusion regarding the algorithm, specifically regarding the use of multiple connected nodes and the computation of \"avg.\" The reviewer suggests that the authors clarify these points and provide more information on \"j\"\" and \"i\".\" While the comment identifies areas that need clarification, it does not explicitly instruct the authors on how to address these issues or provide specific guidance on how to improve the clarity of the algorithm. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying the use of multiple connected nodes and the computation of \"avg,\" as well as the meaning of \"j\"\" and \"i\".\" This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of Algorithm 2, specifically regarding the use of multiple connected nodes and the computation of \"avg.\" The reviewer also questions the meaning of \"j\"\" and \"i\".\" While the comment identifies areas of confusion, it does not provide specific examples or references to support the claim that these elements are unclear. The lack of detailed reasoning or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is 3, as it highlights areas that need clarification but lacks the necessary evidence or justification to be 5.", "helpfulness_rationale": "The review comment identifies several areas of confusion and potential improvement in the paper, specifically regarding the clarity of Algorithm 2 and the use of multiple connected nodes. It points out that \"avg\" is computed but not used, and questions the meaning of \"j\"\" and \"i\".\" While the comment provides some insight into areas that need clarification, it lacks depth and does not offer specific suggestions or guidance on how to address these issues. The authors are given a general direction to clarify the algorithm, but the comment could be more helpful if it provided more detailed feedback or examples of how to improve the clarity. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the specific definition of the sparsity of the residual term in the paper. It explicitly asks for clarification on whether the residual term includes many zero elements and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it implies that the authors should compare the advantages of their method with existing methods. While the comment provides a clear direction for improvement, it does not specify how to present the evidence or what specific aspects of the method should be compared. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"specific definition of the sparsity of the residual term,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the meaning of \"sparsity\" and the need for evidence to support the sparsity assumption across various noisy cases. Additionally, it suggests providing comparisons with existing methods to highlight the advantages of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the specific definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests providing evidence to support the sparsity assumption across various noisy cases. The reviewer also implies that the authors should compare the advantages of their method with existing methods. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the sparsity assumption is unclear or that evidence is needed. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, it implies that the authors should compare the advantages of their method with existing methods. This feedback is clear and actionable, as it guides the authors to clarify the definition and provide evidence to support their claims. However, it could be more helpful if it offered specific suggestions on how to present this evidence or what aspects of the method should be compared. Overall, the comment is 4 as it directs the authors to address a critical aspect of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, it does not provide any guidance on how the authors should address this issue or what specific changes should be made to the terminology. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"connectivity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is wrong with the term \"connectivity,\" explaining that it does not refer to the structural connections between the brain and body. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not refer to the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the term \"connectivity,\" noting that it is misleading as it does not refer to the structural connections between the brain and body. This feedback is valuable as it highlights a potential source of confusion in the paper, which could be clarified to improve the accuracy and precision of the terminology. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what alternative terminology might be more appropriate. While it points out a relevant concern, it does not offer actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific guidance on what aspects are missing or how to address these issues. The authors are left to infer that they need to improve the clarity, quality, novelty, and reproducibility of their work, but without concrete suggestions or examples, they may struggle to know exactly what changes to make. The comment is vague and lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment indicates that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which parts of the paper are missing these details, making it difficult for the authors to pinpoint the exact sections that need improvement. Additionally, the comment references \"Clarity, Quality, Novelty And Reproducibility,\" but does not provide specific examples or details from these sections. This lack of specificity and grounding makes it challenging for the authors to understand and address the issues effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper is lacking, including clarity, quality, novelty, and reproducibility. However, it does not provide specific examples or detailed feedback on what aspects of these categories are missing or how they could be improved. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that these are areas of concern, but without further elaboration or suggestions, the authors are left without actionable guidance on how to address these issues. The comment lacks depth and specificity, making it 2 for the authors to improve their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on what the authors should do to improve their draft. It suggests that the authors should study the essentialness of using an orthogonal matrix weight for the local window MLP, which is not currently presented. This feedback is clear and concrete, as it specifies the need for further exploration and validation of the orthogonal matrix weight. The authors know exactly what needs to be done to address this point, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Step 2\" and \"Step 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of studying the essentialness of using an orthogonal matrix weight for the local window MLP. The comment provides a clear direction for the authors to improve their draft by suggesting that they should explore the validity of using an orthogonal matrix weight. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Step 2 and Step 3 are important for validating the essentialness of using an orthogonal matrix weight for the local window MLP. The reviewer suggests that Step 2 can be done regardless of the weight matrix, and Step 3 is crucial for using an orthogonal matrix weight. However, the comment lacks specific examples or references to support these claims, making it 3. The authors may find it challenging to fully understand and address the claims without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that needs improvement, namely the lack of exploration into the essentialness of using an orthogonal matrix weight for the local window MLP. It suggests that Step 2, which involves the transpose of the matrix, can be done regardless of the weight matrix, and that Step 3 is crucial for validating the use of an orthogonal matrix weight. The comment provides a clear and actionable suggestion for the authors to further explore the implications of using an orthogonal matrix weight, which could enhance the paper\"s contribution. However, the comment could be more helpful if it offered specific examples or references to support the claim about the importance of Step 3. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any explicit or implicit actions for the authors to take, such as suggesting further analysis or clarification. The comment lacks guidance on how the authors should address this question or what steps to take to improve the draft. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the drop in accuracy after a certain order around 45 and asks if it is due to overfitting. This provides clear guidance on what needs to be addressed in the paper, namely the explanation of the accuracy drop. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification regarding the drop in accuracy in Figure 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the drop in accuracy in Figure 5, specifically asking why it occurs after a certain order around 45. It does not provide any suggestions or guidance on how the authors might address this issue or improve the figure. While it prompts the authors to consider the potential cause of the accuracy drop, it lacks actionable feedback or detailed analysis that could help the authors understand and resolve the issue. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the models and datasets used are too toylike and recommends using CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also asks if there are foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides specific recommendations for datasets and models, it lacks concrete guidance on how to implement these changes or what specific aspects of the language tasks should be addressed. The action is explicit but somewhat vague, as the authors know what changes to make but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the models and datasets, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the need for CIFAR100, ResNet 34 or 50, and ViTtiny or small, and raises questions about language tasks. However, the comment does not provide specific guidance on how to address these issues or what aspects of the language tasks should be considered. Therefore, it is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the models and datasets used are \"toylike\" and suggests that the authors should consider using CIFAR100, ResNet 34 or 50, and ViTtiny or small. The reviewer also asks about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides a logical reasoning for the need for more diverse datasets and models, it lacks specific examples or references to support the claim that the current models are too toylike. The suggestion to use CIFAR100 is a specific example, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is 3, as it provides a logical basis for the claim but lacks sufficient evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the models and datasets used in the paper, noting that they are too toylike and suggesting the inclusion of more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also raises a question about the foreseeable challenges for language tasks and suggests that addressing these questions would improve the reviewer\"s score. While the comment provides clear and actionable feedback on improving the dataset and model selection, it could be more helpful by offering specific guidance on how to address the language task challenges. Overall, the comment is 4 as it directs the authors to make significant improvements in their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of natural ablation studies, specifically mentioning the impact of pretraining on scratchGAN. It suggests that this is a crucial baseline to include, especially given the central argument against pretraining. The comment also includes minor comments and questions, such as the need for more discussion on the results. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these changes or what specific aspects of the ablation studies should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of natural ablation studies, specifically mentioning scratchGAN and the need for a baseline with pretraining. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a baseline with pretraining and the need for more discussion on the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some natural ablation studies are missing, specifically mentioning the impact of pretraining on scratchGAN. The reviewer claims that this is a crucial baseline to include, as it relates to the central argument against pretraining. However, the comment lacks specific examples or detailed reasoning to support why this baseline is crucial or how it would impact the central argument. The suggestion is 3, as it provides a direction for improvement but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of natural ablation studies, particularly the impact of pretraining on scratchGAN. This is a crucial baseline that could strengthen the paper\"s argument against pretraining. Additionally, the comment includes minor comments and questions, such as the need for more discussion on the results. While the comment provides actionable feedback, it could be more helpful if it offered specific guidance on how to conduct these ablation studies or what aspects of the results should be discussed. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides some additional suggestions for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. It also points out that the authors pad the shorter sequence by replicating its last state to compare both trajectories, which could lead to an increase in the distance with T and favor longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code. The comment provides clear and concrete actions for the authors to take, ensuring that they know exactly what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the handling of comparisons between episodes with different lengths and the use of padding to compare trajectories. The comment provides a detailed explanation of the issue and suggests that the authors should explain these decisions in the paper to avoid readers needing to check the code. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths in the equation between lines 282 and 283. The reviewer provides specific observations, such as the use of padding to compare trajectories and the lack of a normalization factor of 1/T, which could lead to an increase in distance with T and favor longer trajectories. These observations are supported by logical reasoning and specific examples from the code, making the claim 4. However, the comment could be strengthened by providing more detailed explanations or references to similar issues in the literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the paper regarding the handling of comparisons between episodes with different lengths in the equation between lines 282 and 283. It points out that the authors pad the shorter sequence by replicating its last state, which could lead to an increase in distance with T and favor longer trajectories. The reviewer suggests that these decisions should be explained in the paper to avoid readers needing to check the code. This feedback is clear and actionable, providing the authors with a concrete step to improve their draft by clarifying their methodology. By addressing this issue, the authors can enhance the clarity and transparency of their work, making the comment 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential oversight in the experiment, noting that the Vision Transformer was not considered and questioning its applicability to larger image datasets like ImageNet. It also raises a question about the pruning strategy in selfattention layers. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should consider including the Vision Transformer and address the pruning strategy question, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the omission of the Vision Transformer, which is an important SOTA model in image classification, and questions its applicability to larger datasets like ImageNet. The comment also raises a question about the pruning strategy in selfattention layers, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment did not consider the Vision Transformer, which is an important SOTA model in image classification. It also questions whether such a technique would still work for larger datasets like ImageNet. The comment suggests that the pruning strategy in selfattention layers might differ. While the comment identifies a potential oversight, it lacks specific examples or references to support the claim that the Vision Transformer is an important model. The suggestion to consider it is logical, but the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant oversight in the experiment, noting that the Vision Transformer, an important SOTA model in image classification, was not considered. It also raises a question about the applicability of the technique to larger datasets like ImageNet and suggests that the pruning strategy in selfattention layers might differ. This feedback is clear and actionable, as it prompts the authors to consider including the Vision Transformer and addressing the pruning strategy question. However, the comment could be more helpful if it provided specific guidance on how to implement these changes or what potential implications they might have. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of comparison against baselines and notes that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. It suggests that this is a widelyunderstood binary analysis application and that many papers have developed architectureagnostic similarity comparison (or codesearch). While the comment implies that the authors should include baselines in their analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include baselines in their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study\" and the \"baselines,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing: the inclusion of baselines in the analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparison against baselines and that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The reviewer supports this claim by referencing the widelyunderstood nature of binary analysis applications and the existence of architectureagnostic similarity comparison (or codesearch) in many papers. This provides a logical basis for the claim, but the comment could be strengthened by providing specific examples or references to these papers. Therefore, the comment is 3, as it provides a logical reasoning but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries without considering baselines, which is a widelyunderstood binary analysis application. The reviewer suggests that many papers have developed architectureagnostic similarity comparison (or codesearch) as a similar task. This feedback is clear and actionable, as it points out a critical omission in the paper and provides a direction for improvement. However, it could be more helpful if it included specific suggestions on how to incorporate baselines or examples of similar studies that could serve as a reference. Overall, the comment is 4 as it guides the authors on a crucial aspect of their analysis that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the preprocessing in SI 6.5 is identical to that in Mnih et al. [7], but the evaluation is slightly different because no human starts are used. This is a clear and direct action for the authors to take, as it provides a specific point to address in their draft. The comment is concrete, as it specifies the exact part of the paper where the mention should be made and the issue with the evaluation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to mention that the preprocessing is identical to that in Mnih et al. [7], despite the evaluation being slightly different due to the absence of human starts. This provides clear guidance on what needs to be added to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in SI 6.5 is slightly different from that in Mnih et al. [7] because no human starts are used. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation in SI 6.5, noting that the preprocessing is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to make a specific mention in the paper to clarify this difference. By addressing this point, the authors can improve the clarity and accuracy of their evaluation. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively communicate this difference in evaluation. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the figures, including the size of the text, the clarity of the inputs and outputs, and the selfcontained nature of the captions. It provides a clear and concrete action for the authors to take, suggesting that they make the figures more readable by increasing the font size, explaining the inputs and outputs, and ensuring that the captions are selfcontained. This feedback is explicit and provides concrete details on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the small font size, unclear inputs and outputs, and the lack of selfcontained captions. This provides clear guidance on what needs to be addressed to improve the clarity of the figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures in question are difficult to parse due to small font size, unclear inputs and outputs, and lack of selfcontained captions. While the comment identifies specific issues, it does not provide detailed reasoning or examples to support why these elements are problematic or how they impact the clarity of the figures. The lack of specific examples or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is 3, as it provides some basis but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies specific issues with the figures in the paper, noting that they are difficult to parse due to small font size, unclear inputs and outputs, and lack of selfcontained captions. It provides a clear and actionable suggestion for improvement by recommending that the authors increase the font size, clarify the inputs and outputs, and ensure that the captions are selfcontained. This feedback is valuable as it directly addresses the clarity and readability of the figures, offering concrete steps for the authors to enhance the presentation of their work. However, the comment could be more helpful if it provided examples of how these improvements might be achieved or suggested alternative approaches. Overall, the comment is 4 as it effectively guides the authors on how to improve the clarity and accessibility of their figures."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while the authors claim advantages over previous work in terms of efficiency, the paper does not report any metric to substantiate this claim. This implies that the authors should include metrics to demonstrate the efficiency of their proposed method. However, the comment does not specify which metrics should be used or how they should be presented, leaving the authors with a general direction but without concrete guidance on execution. The action is implicit and somewhat vague, as it highlights a gap in the paper but does not provide detailed instructions on how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the authors discuss advantages over previous work in terms of efficiency. This allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of metrics to demonstrate the efficiency of the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks metrics to demonstrate the efficiency of the proposed method. However, it does not provide any supporting evidence or examples to substantiate this claim. Without specific metrics or references to previous work that demonstrate the efficiency of the proposed method, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting that while the authors claim advantages over previous work in terms of efficiency, they do not report any metrics to substantiate this claim. This is a critical point that could impact the credibility of the paper, as it lacks empirical evidence to support the claim. The comment highlights a clear area for improvement, suggesting that the authors should include metrics to demonstrate the efficiency of their proposed method. However, it does not provide specific guidance on which metrics to use or how to present them, leaving some room for interpretation. Overall, the comment is 3 as it points out a critical issue but could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. There is no guidance on how to expand the contribution or what specific aspects of the paper could be strengthened. As a result, the authors are left without any clear direction on how to address the reviewer\"s concerns. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not specify which part of the paper this critique is based on, such as the introduction, methodology, or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are considered limited or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment lacks specific reasoning or evidence to support why the contribution is considered limited. It does not provide examples, comparisons, or references to similar work that might substantiate the claim. As a result, the claim is 3, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the contribution of the paper is limited, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, it does not provide any specific feedback or suggestions on how the authors could enhance the contribution or what aspects of the paper could be improved. The comment lacks actionable guidance or detailed critiques, leaving the authors without clear direction on how to address the reviewer\"s concerns. As a result, the feedback is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide more details about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment provides clear and direct actions, it does not specify how to implement these changes or what specific details should be included. The authors are left to infer the exact steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing more details about the statespace, whether it is finite or continuous, and the actions involved. The comment also questions the space in which theta lies and suggests that the authors should be precise in their explanations. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for more details about the statespace, whether it is finite or continuous, and the actions involved. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a lack of detail in the paper, specifically asking for more information about the statespace, whether it is finite or continuous, and the actions involved. It also questions the space in which theta lies and suggests that the authors should be precise in their explanations. While the comment highlights areas where the paper could be improved, it does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential gaps in the paper, but it lacks actionable advice or detailed guidance for improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the method\"s effectiveness on general reasoning tasks or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes they should make to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method are not effective on general reasoning tasks or how they could be improved. Without clear guidance on where to focus the revision or what changes are needed, the authors are left without a clear path for action. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method is not effective on general reasoning tasks compared to mathematical reasoning. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of this assertion and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the method\"s performance. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The reviewer also mentions that the authors acknowledge this issue in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the proof technique and its applicability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Appendix A,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The comment further specifies that this issue is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique in Appendix A relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. The reviewer provides a specific reference to Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique in Appendix A, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment highlights a potential problem, it does not provide actionable suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a specific area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. The comment provides explicit actions for the authors to take, such as including the continuous diffusion model as a baseline and considering the conditional framework based on GDSS. The suggestions are concrete and provide clear guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of the continuous diffusion model (e.g., GDSS) as a baseline in Table 3 and the suggestion to use a conditional molecule generation framework based on GDSS. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. The reviewer provides a logical reasoning by pointing out that the continuous diffusion model should be considered as a baseline for the conditional generation task. Additionally, the comment suggests using a conditional molecule generation framework based on GDSS, which was recently proposed in [2]. This provides a clear and logical basis for the claim, making it 4. However, the comment could be strengthened by referencing [2] directly or providing more detailed reasoning on why GDSS should be considered a baseline. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the continuous diffusion model (e.g., GDSS) should be compared as a baseline in Table 3, given its superior performance compared to the discrete diffusion model (e.g., DiGress) in Table 2. It also proposes using a conditional molecule generation framework based on GDSS, which was recently proposed in [2], as a baseline. This feedback is valuable as it guides the authors on how to improve the comparison and analysis of their results, providing a clear direction for enhancing the paper. However, the comment could be more helpful if it explained why the continuous diffusion model is particularly relevant or how the proposed conditional framework would benefit the analysis. Overall, the comment is 4 as it offers actionable suggestions for improving the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation is the best choice due to its ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment does not provide explicit instructions or concrete steps on how to implement this change or what specific aspects of the current approach need to be adjusted. While the suggestion is clear, the lack of detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using LiDARbased segmentation as the downstream task instead of object detection. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this change could be implemented. The comment also lacks specificity regarding why LiDARbased segmentation is considered the best choice or how it would improve the paper. Without explicit references or detailed reasoning, the authors cannot confidently determine which parts of the paper need revision. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that LiDARbased segmentation is a better choice for the downstream task than object detection, citing the ability to learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific examples or detailed reasoning to support this claim, such as how LiDARbased segmentation would improve the performance of the downstream task or why it is considered superior to object detection. This makes the claim 3, as it provides a general argument but lacks the necessary evidence or detailed reasoning to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a subjective opinion on the choice of downstream task, suggesting that LiDARbased segmentation is a better option than object detection. The reviewer provides a rationale for this suggestion, stating that LiDARbased segmentation can learn accurate locations and poses, especially in benchmarks using IoUbased metrics like KITTI and Waymo. However, the comment lacks specific guidance or suggestions on how the authors might implement this change or what aspects of their current approach might need adjustment. While the feedback provides a direction for improvement, it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). However, it does not provide any guidance on how the authors should address this issue or suggest specific actions to resolve the contradiction. The comment lacks explicit instructions or concrete details on how to improve the draft, leaving the authors uncertain about what steps to take. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the objective of Equation (12) and its relation to the Inverse Proportionality Operator (IPO). However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the contradiction between the objective and IPO, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the objective of Equation (12) is in contradiction with the Inverse Proportionality Operator (IPO). However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential contradiction between the objective of Equation (12) and the Inverse Proportionality Operator (IPO). This is a critical observation that could impact the validity and applicability of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the contradiction. Without actionable advice or detailed feedback, the authors are left with a general direction for improvement but no clear path forward. Therefore, the comment is 3, as it points out a potential problem but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. While the comment explicitly states the action to take, it lacks concrete guidance on how to implement this change or why it is necessary. The authors are left to infer that they should make this change to enhance clarity, but without specific instructions or examples, the action remains somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of \"t\" in the kernel and the suggestion to replace it with the size of T to improve clarity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel to improve clarity. However, the comment does not provide any reasoning or evidence to support why \"t\" is unclear or why replacing it with the size of T would improve clarity. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests a specific improvement to the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the readability and understanding of the methodology. However, the comment could be more helpful if it explained why \"t\" is unclear or why the change would improve clarity. Despite this, the suggestion is valuable and offers a straightforward way for the authors to improve their draft, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the adaptation capacity. The comment lacks actionable details, such as recommending specific experiments or modifications to the model architecture. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. However, the comment does not specify which part of the paper this concern is related to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its concern about the adaptation capacity and the potential impact on concepts with different levels of geometric information. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. The reviewer provides a logical reasoning by mentioning that DINO representations are observed to contain rich geometric information, which could affect the adaptation capacity. However, the comment lacks specific examples or references to support the claim that the adaptation capacity might be affected for concepts with different levels of geometric information. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the adaptation capacity of the proposed visual memory when accommodating evergrowing concepts. It suggests that the image encoder should produce meaningful embeddings for new concepts, particularly for those with rich geometric information. While the comment identifies a potential concern regarding the adaptation capacity, it lacks specific suggestions or guidance on how the authors might address this issue or improve their model. The feedback is 3 as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This is a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment provides a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions commonly used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be added to, such as the results or discussion sections. The authors can infer that it relates to the experimental evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting what needs to be added. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This claim is 3 as it provides a logical suggestion for enhancing the paper\"s contribution by including a comparison with established methods. However, the comment lacks specific examples or references to these stateoftheart loss functions, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions commonly used in face/iris verification. This is a clear and actionable suggestion that could enhance the paper\"s contribution by demonstrating the effectiveness of the proposed method against established benchmarks. By including this comparison, the authors can provide a more comprehensive evaluation of their work and potentially improve its impact. However, the comment could be more helpful if it specified which loss functions should be included or provided examples of how they might be used in the comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more detailed to be fully comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific and concrete actions for the authors to take. It suggests giving the EF and D2 transcription norms, corrects grammatical errors in specific lines, and points out repetitions in the text. Additionally, it highlights a discrepancy in the DOI number and the link behind the title. These are all explicit and detailed actions that the authors can easily implement to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and tables, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the corrections needed, such as correcting grammatical errors, providing missing information, and pointing out repetitions. The comment also specifies the issue with the DOI number and the link behind the title. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual corrections and technical comments, such as correcting grammatical errors and pointing out repetitions. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a mix of technical and editorial corrections, which are all actionable and can significantly improve the clarity and accuracy of the paper. It points out specific grammatical errors, such as \"lightweight\" vs. \"in a lightweight,\" and corrects the acronyms to their full forms. Additionally, it highlights repetitions in the text and provides a detailed correction for the DOI number and the link behind the title. These corrections are clear and specific, offering the authors direct guidance on how to improve their draft. However, the comment could be more helpful if it included suggestions for further improvements or additional details on the technical aspects being addressed. Overall, the comment is 4, as it provides actionable feedback that can significantly enhance the clarity and accuracy of the paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the notation used in the paper, including the lack of definitions for M and N and the small font size in Figure 1. It provides a specific suggestion to spell out F.L.T.R in Figure 4 and recommends crossreferencing notation and figures to avoid confusion. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and actionable, providing concrete steps for the authors to improve the clarity and readability of their paper. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as spelling out F.L.T.R in Figure 4 and making the text larger. The comment also suggests crossreferencing notation and figures to avoid confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation is confusing and suggests spelling out F.L.T.R in Figure 4. It also mentions that the font size in Figure 1 is too small to see and recommends crossreferencing notation and figures. While the comment identifies specific issues with the notation and figure presentation, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to crossreference notation and figures is a logical step, but the lack of specific examples or detailed explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including confusing notation and font size in figures. It provides specific suggestions for improvement, such as spelling out F.L.T.R in Figure 4 and making the text larger in Figure 1. Additionally, it recommends crossreferencing notation and figures to avoid confusion. These suggestions are clear and actionable, offering the authors a concrete path to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided additional guidance on how to address the confusion in the notation or why it is confusing. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. While the comment identifies an issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should clarify or rename the variable to avoid confusion. The action is implicit and somewhat vague, as it lacks concrete details on how to implement the suggested change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1\" and \"Phase 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2, suggesting that this might be confusing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"$p$\" to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm1, specifically regarding the use of $p$ to denote the phase mixing probability and a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific issue that could be clarified or addressed to improve the clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to clarify or rename the variable to avoid confusion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from a more detailed mathematical formulation, particularly in the appendix, to enhance the understanding of the approach. It also points out that the figure is confusing and recommends adding text labels to clarify its purpose and align it with the main contribution of the paper, which is improvements on the WiC task. The comment provides specific suggestions for reworking the figure to better align with the WiC task, offering actionable steps for the authors to improve their draft. The explicit nature of these suggestions and the concrete guidance on how to implement them make the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for a more detailed mathematical formulation in the appendix and the confusion caused by the figure, including the need for text labels and better alignment with the main contribution of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the highlevel description and figure are confusing and could benefit from a more detailed (e.g., mathematical) formulation and clearer labels. The reviewer provides specific examples of how the figure is abstract and does not align with the main contribution of the paper, which is improvements on the WiC task. The suggestion to rework the figure to depict the WiC task is a concrete and actionable step for the authors to improve their draft. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the figure\"s abstraction and misalignment with the main contribution. This makes the claim 3, as it provides a clear direction for improvement but lacks comprehensive evidence or detailed justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the paper\"s highlevel description and figure. It suggests that while the highlevel description helps intuitively understand the approach, a more detailed mathematical formulation, particularly in the appendix, would be beneficial. The reviewer also points out that the figure is confusing and does not align well with the main contribution of the paper, improvements on the WiC task. The comment offers a concrete suggestion to rework the figure to better align with the WiC task, which is a clear and actionable improvement. This feedback is 4 as it guides the authors on how to enhance the clarity and comprehensiveness of their paper. However, it could be more helpful if it provided additional context or examples of how the figure could be reworked to better align with the WiC task. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment suggests that it would be beneficial to include additional benchmarking tasks outside of AitW. However, it does not provide specific guidance on which tasks should be included or how they should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should consider additional benchmarking tasks but are not given concrete steps on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not specify which parts of the paper should include these tasks or which specific benchmarking tasks should be considered. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that additional benchmarking tasks outside of AitW would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific details or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that additional benchmarking tasks outside of AitW would be beneficial for the paper. However, it does not provide specific tasks or examples of what these tasks could be, nor does it explain why these tasks are important or how they would enhance the paper. While the suggestion is 3 in identifying an area for improvement, it lacks depth and actionable guidance, making it 3 but not comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly asks for clarification on the comparison results between YOSO and linformer in terms of iterationwise convergence and accuracy in downstream tasks. It also suggests that an explanation should be provided to analyze the difference in performance. The feedback is clear and provides specific actions for the authors to take, such as including the steps vs PPL of linformer with YOSO in Figure 4 and analyzing the performance difference. The comment is concrete and provides detailed guidance, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments: YOSO takes linformer as baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the lack of comparison results between YOSO and linformer in Figure 4, and the need for an explanation of the difference in performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of comparison results between YOSO and linformer in Figure 4, specifically regarding iterationwise convergence and accuracy in downstream tasks. The reviewer suggests that an explanation is needed to analyze the difference in performance. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the importance of these comparisons and the potential impact on the paper\"s conclusions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the pretraining experiment part does not provide steps vs PPL of linformer with YOSO in Figure 4. It also questions the comparison result of YOSO with linformer on iterationwise convergence and suggests that an explanation is needed to analyze the difference in performance. Additionally, it points out that linformer demonstrates better accuracy in downstream tasks such as SST2. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given direction on what to include but are not provided with detailed steps or examples to follow. Therefore, the comment is 3, as it identifies areas for improvement but could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. While it identifies the issue, it does not provide explicit guidance on how the authors should address this discrepancy. The comment lacks concrete suggestions or actions for the authors to take, such as suggesting a correction or clarification in the abstract or text. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and the text, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This provides clear guidance on what needs to be corrected or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract statement about requiring the proposal distribution to upper bound the target everywhere is not true, as the authors themselves clarify in the text. However, the comment does not provide specific references or examples from the text to support this claim, making it difficult for the authors to verify the accuracy of the claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the abstract and the text regarding the requirement for the proposal distribution to upper bound the target everywhere. This is a critical issue that could impact the validity of the paper\"s claims. However, the comment does not provide specific guidance or suggestions on how the authors might address this discrepancy or clarify the text. While it points out a potential problem, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in resolving it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the name \"PointNet\" in Figure 1, noting that it is not mentioned in the paper and that there is another paper with the same name. The reviewer suggests that the authors should clarify this issue by referring to the correct paper or providing additional context. While the comment explicitly identifies the problem and suggests a solution, it does not provide detailed guidance on how to implement this correction. The action is clear but somewhat vague in terms of execution, as the authors need to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"PointNet,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"PointNet\" as it is not mentioned in the paper and there is another paper with the same name. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that referring to [15] as \"PointNet\" is confusing because the name does not appear in the paper and there is another paper with the same name. The reviewer provides a specific reference to another paper titled \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation,\" which supports the claim by providing a clear example of the correct name. This reference helps verify the claim by providing a concrete example of the correct terminology, making the comment 4. However, the comment could be strengthened by further explaining why this confusion is problematic or how it affects the reader\"s understanding of the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the labeling of \"PointNet\" in Figure 1, noting that it is confusing as the name does not appear in the paper and there is another paper with the same name. This feedback is clear and actionable, as it provides the authors with a specific correction to make in their paper. By addressing this issue, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to avoid similar confusion in future work or provided additional context on the significance of the name \"PointNet.\" Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the policy gradient and the phrases in question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the policy gradient and the phrases in question. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and observations about the policy gradient in Equation 6 and its relation to the optimal problem. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, seeking clarification or explanation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the policy gradient in Equation 6 and its relation to the optimal problem. It suggests that the authors might need to clarify this aspect to ensure that the policy gradient is indeed solving the optimal problem. Additionally, it points out an unnecessary phrase in Line 78 and a potential issue with Line 132. While the comment identifies areas that need clarification and potential improvements, it does not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need attention, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. While it does not explicitly instruct the authors to make a specific change or provide guidance on how to address this question, it does prompt the authors to consider the implications of these assumptions and the potential differences between them. The action is implicit but concrete, as the authors can infer that they need to explore the implications of these assumptions and potentially make a change. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these assumptions are discussed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its inquiry about the difference between these distributions, it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian distribution in the proposed algorithm, seeking clarification on the difference between these distributions. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback or constructive advice, making it 2 for the authors in terms of improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss the limitations of freezing the partitioning in the first iteration, which seems like a risky choice. This feedback is clear and provides a specific action for the authors to take, which is to address the limitations of this choice. The comment is concrete because it specifies the need for a discussion on the limitations, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the risky choice of freezing the partitioning in the first iteration and the need to discuss its limitations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that at least the limitations of this choice should be discussed. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors may understand the concern but would need to make a significant effort to address it without detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of freezing the partitioning in the first iteration, which could be considered a risky choice due to its potential impact on the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a clear and actionable suggestion for improvement. However, the comment could be more helpful if it provided additional context or examples of how this choice might impact the results or analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or how to clarify the intent of the section. Without any actionable suggestions or advice, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper, such as a specific section or figure, is being addressed. It lacks specificity because it does not provide any details on what the reviewer finds unclear or what needs to be clarified about the intent of Section 5.2. Without explicit references or detailed feedback, the authors cannot effectively identify the areas that need improvement. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question about the intent of Section 5.2, which does not contain any subjective claims, opinions, or suggestions. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid point as it could be unclear or misleading. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might clarify or improve this section. Without actionable feedback or detailed feedback, the authors are left without a clear path forward. Therefore, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It acknowledges that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific guidance on what aspects need clarification or how to clarify them. It lacks concrete suggestions or examples of what the authors should focus on to improve the clarity of their approach. As a result, the authors are left without actionable steps to take in response to the feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. It mentions that the paper gets into highly technical details too quickly without explaining the overall approach and its benefits. However, the comment does not specify which parts of the paper need clarification or provide detailed comments on what is unclear. Without specific references or examples, the authors cannot confidently determine which sections need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that many aspects of the approach need clarification and expresses concern about the lack of understanding regarding how the approach interacts with knowledge about verbs to overcome reporting bias. The reviewer mentions that the paper dives into technical details too quickly without explaining the overall approach and its benefits. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas of concern regarding the clarity and understanding of the approach presented in the paper. It highlights that many aspects need clarification and expresses particular worry about the interaction between knowledge about objects and verbs in overcoming reporting bias. The comment acknowledges that the paper dives into technical details too quickly, without providing a clear explanation of the overall approach and its benefits. While it points out a significant issue, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the clarity of their work. This limits the comment\"s usefulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. This feedback provides clear and concrete actions for the authors to take, such as creating a new section or expanding the existing one to address the clarity issues. The explicit nature of the suggestion and the detailed guidance on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, including the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section to enhance clarity. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This claim is 3 as it logically suggests that such clarification would enhance the clarity of the paper, particularly around the assumed whitebox access to the victim model. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the threat model. It suggests that the authors should define the assumed threat model more explicitly, including the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the clarity of their work. By suggesting a dedicated section for this information, the reviewer offers a practical way to improve the paper\"s presentation and understanding. However, the comment could be more helpful if it included specific examples or references to similar works that have successfully addressed this issue. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests an explanation for the decision to use early stopping only based on link prediction accuracy. It does not provide suggestions for alternative explanations or methods to consider. The action is clear and concrete, as the authors know exactly what needs to be addressed: providing an explanation for the decision. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"590,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely an explanation for the decision to use early stopping only based on link prediction accuracy. The comment provides a clear direction for improvement by asking for an explanation of the decisionmaking process. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the decision to use early stopping only based on link prediction accuracy, suggesting that an explanation is needed. However, it does not provide any reasoning or evidence to support why this decision might be problematic or inadequate. Without additional context or examples, the claim lacks verifiability, as it does not provide a clear basis for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further explanation, namely the decision to use early stopping only based on link prediction accuracy. It suggests that the authors should provide an explanation for this choice, such as why not to average with type accuracy. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It explicitly asks the authors to provide concrete details on how to set a reasonable classimbalanced task, given the few examples available for each class. This feedback is clear and actionable, as it directly instructs the authors on what information is missing and how to address it. The request for concrete details provides a specific action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions how to set a reasonable classimbalanced task in the fewshot learning setting, given the limited number of examples per class. The comment provides a clear request for the authors to explain their approach with concrete details, which adds to the specificity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim made in the paper regarding classimbalanced tasks in the fewshot learning setting. It suggests that the authors should provide concrete details on how to set a reasonable classimbalanced task, given the limited number of examples per class. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is problematic or how it could be addressed. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to respond to it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s statement about classimbalanced tasks in the fewshot learning setting. It questions how to set a reasonable classimbalanced task given the limited number of examples per class. The comment is 3 as it prompts the authors to provide concrete details on their approach, which is a critical aspect of the paper. However, the comment could be more helpful if it offered specific suggestions or examples of how to address this issue, such as discussing potential methods or metrics for balancing classes. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the chatgpt baseline is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a clear action to test a fewshot approach and includes a suggestion for enhancing the baseline, it lacks specific guidance on how to implement these changes or what specific aspects of the fewshot approach should be tested. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the chatgpt baseline, suggesting that it is rudimentary and recommends testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. However, the comment does not specify which part of the paper discusses the chatgpt baseline or the fewshot approach, making it weakly grounded. The suggestion to include discourse relation information is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the chatgpt baseline is \"very rudimentary\" and suggests testing a fewshot approach. It also proposes including discourse relation information in the prompts, potentially in a ChainofThought style approach. While the comment provides a logical reasoning for the need to test a fewshot approach and includes a specific suggestion for enhancing the baseline, it lacks detailed evidence or references to support the claim that the chatgpt baseline is indeed rudimentary. The suggestion for including discourse relation information is 3, as it provides a direction for improvement but lacks detailed justification or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the chatgpt baseline, noting that it is \"very rudimentary\" and recommends testing a fewshot approach. It also suggests including discourse relation information in the prompts, potentially in a ChainofThought style approach. This feedback is clear and actionable, as it provides a concrete direction for improving the baseline and enhancing the evaluation of the paper. However, the comment could be more helpful if it included specific examples or references to support the suggestion for including discourse relation information. Overall, the comment is 4 as it offers valuable insights and suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It points out that the authors only state that they estimate a layer\"s sensitivity by pruning, but do not provide details on how the actual pruning was done. The comment implies that the authors should provide more information on the pruning process to clarify the methodology. While the action is implicit, it is clear and concrete, as it specifies the need for more detailed information on the pruning process. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail on how the ground truth of sensitivity is achieved and the need for more information on the pruning process. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. The reviewer suggests that the authors should provide more information on the pruning process to clarify the methodology. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without additional context or detailed reasoning, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides a general observation but lacks the necessary evidence or justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not provide sufficient detail on how the ground truth of sensitivity is achieved. It points out that the current explanation, which mentions pruning, lacks details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to provide more information on a crucial aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific details should be included. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. It provides clear and concrete actions for the authors to take, such as explicitly explaining the concepts in these sections. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the definition of a proper rotation matrix and the problem of the matrix being non positive semidefinite. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for clarification regarding specific terms and concepts in the text. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific parts of the text that could be written more clearly, such as line 97 regarding proper rotation matrices and line 105106 regarding the matrix being non positive semidefinite. By pointing out these areas for clarification, the comment provides actionable feedback that can help the authors improve the readability and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of how they might be explained more effectively. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is explicit and provides a clear action for the authors to consider, making it 5. The authors know exactly what change to make and how it aligns with the suggestion from Cohen and Shashua.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The comment also references the activationpooling operator introduced by Cohen and Shashua, which provides a concrete example of what the authors should consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it might be more appropriate to refer to the g activation function as a binary operator, similar to Cohen and Shashua (2016). The reviewer provides a specific example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This reference provides a logical basis for the suggestion, making the claim 3. However, the comment could be strengthened by providing more detailed reasoning or examples from the Cohen and Shashua work to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion to consider referring to the g activation function as a binary operator, similar to Cohen and Shashua (2016). It offers a concrete example of the activationpooling operator introduced by Cohen and Shashua, which fulfills the required conditions. This feedback is actionable and can help the authors improve the clarity and consistency of their terminology. However, the comment could be more helpful if it explained why this change would be beneficial or how it aligns with the broader context of the paper. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors consider shrinking the captions of Fig. 1 and Fig. 2 to leave more space for their methods or related work. This is a clear and direct action that the authors can take to improve the presentation of their figures. The comment provides a specific suggestion for how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they should be shrunk to leave more space for the authors\" methods or related work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Fig. 1 and Fig. 2 have large overlaps with the content, and it provides a specific suggestion to shrink the captions to leave more space for the authors\" methods or related work. This claim is 3 as it logically suggests a way to improve the presentation of the figures, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors might need to experiment with different caption sizes to determine the optimal size for their purposes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Fig. 1 and Fig. 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion to shrink the captions to leave more space for the authors\" methods or related work. This feedback is valuable as it directs the authors to a specific area that could be improved, offering a concrete way to enhance the clarity and presentation of their figures. However, the comment could be more helpful if it included examples of how the captions could be revised or if it explained why this change would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. While the comment implies that the authors should consider including Vidgen et al, 2021, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this work as a benchmark. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. The comment suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide specific reasoning or evidence to support why Vidgen et al, 2021, should be included as a benchmark. The absence of detailed justification or references makes the claim 3, as the authors would need to infer the importance of including Vidgen et al, 2021, based on the suggestion alone. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of several works in Table 2 but notes the absence of Vidgen et al, 2021, which might be relevant to the dataset presented in the paper. It suggests that this dataset could be a potential benchmark for evaluation, particularly in investigating the role of context in detecting hate. This feedback is 3 as it points out a potential oversight in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to incorporate Vidgen et al, 2021, or provided examples of similar studies that could be included. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to present the results comparing standard vs. evolutional dropout on shallow models as a mean over many runs (at least 10) and ideally with errorbars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. The comment provides clear and concrete actions for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results comparing standard vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely presenting the results as a mean over many runs (at least 10) with errorbars, and it points out that the plotted curves are from single runs and might be subject to significant fluctuations. Additionally, it suggests that the models are small, so there is no excuse for not providing statistics. This provides clear guidance on how to improve the presentation of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results comparing standard vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with errorbars. The reviewer supports this claim by pointing out that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the reviewer suggests that the models are small, so there is no excuse for not providing statistics. This reasoning is logical and based on common knowledge about statistical analysis and model size. However, the comment could be strengthened by providing specific examples or references to similar studies that have used similar methods. Despite this, the claim is 4, as it provides a clear rationale for the suggestion.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the presentation of results comparing standard vs. evolutional dropout on shallow models. It suggests that the results should be presented as a mean over many runs (at least 10) with errorbars, which is a standard practice in statistical analysis. This suggestion is based on the observation that the plotted curves are from single runs, which could be subject to significant fluctuations. Additionally, the comment points out that the models are small, so there is no excuse for not providing statistics. This feedback is 5 as it guides the authors on how to improve the presentation and robustness of their results. By addressing these points, the authors can enhance the credibility and reliability of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, which is a specific solver. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to improve the draft. The authors are left to infer that they need to improve the approach\"s universality and adaptability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction for improvement but not detailed guidance on execution.", "grounding_specificity_rationale": "The comment critiques the proposed approach for learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these aspects are discussed. The comment is specific in detailing what needs to be addressed, such as the need for universality and adaptability. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach is merely learning a surrogate model for solving linear/linearized systems arising in FEM, and it highlights the need for careful choice of basis functions and meshes. It also points out that the approach heavily relies on FEniCS, a specific solver. The comment provides logical reasoning by explaining the limitations of current operator learning methods compared to specialized numerical solvers, suggesting that the proposed approach needs to be more universal and adaptable. However, the comment lacks specific examples or references to support the claim about the limitations of current operator learning methods. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the proposed approach, noting that it is merely learning a surrogate model for solving linear/linearized systems arising in FEM. It highlights the need for careful choice of basis functions and meshes and points out that the approach heavily relies on FEniCS, a specific solver. The comment suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal and do not need to be adapted to specific PDEs. While the comment provides a clear critique of the approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the universality and adaptability of their method. The feedback is 3 as it points out a potential weakness but does not offer actionable steps for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This is a clear and concrete action for the authors to take, as it provides a specific aspect of the environment that needs to be addressed. The comment also highlights the importance of this detail, noting that different versions of the environment can impact training and inference speed. Therefore, the authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the impact of different versions of the experimental environment on training and inference speed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental environment needs to be described in more detail, specifically mentioning the CUDA and PyTorch versions. This is a logical suggestion based on the understanding that different versions of the environment can impact training and inference speed. However, the comment lacks specific examples or references to support the claim that different versions of these tools would have a significant impact on performance. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors need to provide more detailed information about the experimental environment, including the CUDA and PyTorch versions. This is a clear and actionable suggestion that can help the authors ensure that their results are reproducible and comparable across different experimental setups. By addressing this feedback, the authors can improve the transparency and reliability of their work. However, the comment could be more helpful if it provided examples of how different versions of these tools might impact training and inference speed, or if it suggested specific ways to present this information. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve their draft to account for the limitations of realistic datasets. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the issue of controlling multiple aspects of variation with precision in the context of fully realistic datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its agreement with the authors\" judgement about the lack of immediate societal impact, but it does not provide further details or suggestions on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement about the lack of immediate societal impact and notes that using fully realistic datasets can make it difficult to control multiple aspects of variation with precision. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides explicit guidance on what needs to be clarified and improved, offering concrete suggestions for the authors to enhance the clarity of their draft. Therefore, the comment is 5, as it clearly instructs the authors on how to enhance the comprehensibility of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paragraph number (L156166), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the paragraph, including the difficulty in understanding the content and the vagueness of the figure description. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paragraph is difficult to understand, particularly regarding the Gittins strategy and the figure. The reviewer suggests that the description is vague and provides examples of unclear phrases, such as \"Dashed lines indicate that the agent can plan ahead...\". However, the comment lacks specific references or detailed explanations to support the claim that the description is unclear or vague. While the reviewer provides some examples, the lack of detailed reasoning or references makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides some evidence but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific paragraph (L156166) that is difficult to understand, particularly regarding the Gittins strategy and the figure. It points out that the description is vague and suggests that the authors clarify the concept of bandit algorithms and the figure. The comment provides actionable feedback by highlighting specific areas that need improvement, which can help the authors enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the content or provided examples of how similar concepts have been explained in other works. Overall, the comment is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The comment is specific and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (078079 and Line 08), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the mention of the evaluation metric and the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs),\" which was used in a previous work. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work. While the comment provides a logical reasoning for why clarity is needed, it lacks specific references or examples to fully substantiate the claim. The suggestion is 3, as it provides a clear rationale but could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the evaluation metric should be mentioned in the paper to clarify the scale of the improvement and for comparability with other works. It also points out that the expression \"labelled Fmeasure scores (LF1) (including ROOT arcs)\" was used in a previous work, which is relevant to the clarity and understanding of the results reported in this paper. This feedback is specific and offers a concrete suggestion for improvement, making it 5 for the authors to enhance the clarity and comprehensiveness of their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should study the behavior of the model under higher noise levels, as the standard deviation of the noise in the simulation study is stated as 3 but appears to be too low based on the observations in the plot compared to the true trajectories. While the comment implies that the authors should investigate higher noise levels, it does not explicitly instruct them to do so or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"standard deviation of the noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the behavior of the model under higher noise levels. The comment suggests that the standard deviation of 3 might be too low and recommends studying the model\"s behavior under higher noise. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is too low, based on observations in the plot compared to the true trajectories. However, the comment does not provide specific evidence or references to support this claim, such as data or comparisons to other studies. Without detailed reasoning or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the standard deviation of the noise in the simulation study, suggesting that it might be too low based on observations in the plot compared to the true trajectories. It recommends studying the behavior of the model under higher noise levels. While the comment highlights an area for improvement, it lacks specific guidance on how to conduct this study or what aspects of the model behavior should be examined. The feedback is 3 as it points out a potential weakness but does not provide detailed instructions on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the bounds having o(1) terms and suggests that this could limit the applications of the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific steps the authors should consider to ensure the applicability of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the approach, specifically mentioning the o(1) terms and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the potential limitation of the approach due to the o(1) terms, but it does not provide details on how this limitation affects the applicability of the approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of the approach have o(1) terms and that this could limit the applicability of the approach for arbitrarily long inputs. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the approach, specifically the use of bounds with o(1) terms. It points out that this could limit the applicability of the approach for arbitrarily long inputs, which could be a significant concern for the authors. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the approach might be affected. While it highlights a potential problem, it lacks actionable advice or detailed insights that would help the authors improve their draft. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to conduct this analysis or what specific aspects of DVP performance should be examined. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it does not specify which part of the paper this observation pertains to, such as a specific section or experiment. Without explicit references to sections or experiments, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of DVP performance should be examined or how the results should be interpreted. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses interest in seeing how DVP performs on videos with different lengths. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual observation or request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment expresses interest in seeing how DVP performs on videos with different lengths. However, it lacks any specific guidance or suggestions on how the authors might explore this topic or what aspects of DVP performance should be examined. Without actionable feedback or detailed instructions, the comment does not provide much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how the authors should address this issue. The comment lacks explicit guidance on how to clarify the target or what specific aspects need clarification. As a result, the authors are left without clear instructions on how to improve the draft to better communicate the focus of the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. However, it does not specify which part of the paper this confusion arises from, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment does not provide specific guidance on how to address this issue, such as suggesting where the clarification should be added or what aspects need to be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. The reviewer acknowledges that the clarification is provided in the conclusion but does not provide any supporting evidence or reasoning to justify this confusion. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the confusion and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the target of the paper, specifically whether it focuses on singletoken cloze queries or multitoken ones. It acknowledges that the clarification is provided in the conclusion but does not specify how this affects the paper\"s focus or what aspects need clarification. The comment lacks actionable feedback or suggestions for improvement, leaving the authors without clear guidance on how to address the confusion or enhance the clarity of their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. It provides a clear and concrete action for the authors to take, specifying the exact calculation that needs to be performed. This level of detail makes the comment 5, as the authors know exactly what steps to take to address the issue. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely evaluating the approximation error in the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating the approximation error by calculating the actual KLdivergence. The comment provides a specific suggestion for improvement by asking the authors to check whether the approximation error approaches zero. However, the comment lacks detailed reasoning or references to support why this evaluation is necessary or how it would impact the results. This makes the claim 3, as the authors would need to infer the importance of this evaluation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that it has ignored the KLdivergence term in equation (3). It provides a clear and actionable suggestion by asking the authors to evaluate the approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is valuable as it directs the authors to a specific area for improvement, which could enhance the rigor and accuracy of their work. However, the comment could be more helpful if it included additional context or explanation on why this evaluation is important or how it might impact the results. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not provide explicit guidance on how to address these issues or what specific changes should be made to improve the connection or depth of the analysis. The comment implies that the authors should make improvements, but it lacks concrete details on how to implement these changes. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, it does not specify which part of Section 2 is lacking a connection or how the theoretical analysis could be improved. The authors can infer that the comment relates to the theoretical analysis and its connection to the methodology section, but this inference is not direct. The comment is specific in identifying the issue of a lack of connection and the need for more depth in the theoretical analysis, but it is 1 as it does not explicitly mention the sections being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Section 2 lacks a connection with the methodology section and that the theoretical analysis is simplistic and closely related to a specific reference. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the connection between Section 2 and the methodology section, noting that the theoretical analysis appears simplistic and closely related to a specific reference. This feedback is 3 as it points out a potential weakness in the paper, but it lacks depth and does not provide specific suggestions on how to address the issue or improve the connection between sections. The comment could be more helpful if it offered guidance on how to enhance the theoretical analysis or suggested ways to differentiate it from the reference. Overall, the comment provides some insight but lacks actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. While the comment implies that the authors should provide more details about the effectiveness of the losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the effectiveness of the losses in specific situations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations in which the losses help, particularly in specular areas. However, it does not specify which part of the paper this discussion should be added to, such as a particular section or figure. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a particular area for further discussion, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the losses discussed in the paper might be particularly helpful in specular areas. However, it does not provide any evidence, examples, or references to support this claim. The comment lacks specific reasoning or data to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss the situations in which the losses help, particularly in specular areas. This feedback is 3 as it identifies a potential area for improvement by encouraging the authors to provide more detailed information about the effectiveness of their losses. However, the comment lacks specific guidance on how to implement this discussion or what aspects of the losses should be highlighted. While it points out a potential gap in the paper, it does not offer actionable steps for the authors to address this issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, but it does not provide any specific guidance or suggestions on how the authors might improve their draft to meet the standards of the conference. There is no explicit or implicit action for the authors to take, nor are there any concrete details on what aspects of the paper need improvement. As a result, the comment lacks actionability, leaving the authors without a clear path forward to enhance their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment does not specify which part of the paper is being addressed, making it 1. It also lacks specificity as it does not provide details on what aspects of the paper are insufficient for the ICLR conference or how the authors might improve their draft to meet those standards. Without clear guidance or references to specific sections, the authors cannot effectively address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is \"doubtful\" for the ICLR conference, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references to the paper\"s weaknesses or how it compares to other works, the authors are left without a clear understanding of what needs to be improved or addressed. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment expresses doubt about the paper\"s current strength for the ICLR conference, indicating that it may not be suitable for the event. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft to meet the standards of the conference. Without actionable guidance or detailed insights into what aspects of the paper need improvement, the comment offers limited value to the authors. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks clarity regarding its major contributions, specifically questioning whether analyzing previous work constitutes a contribution. However, it does not provide any explicit guidance or suggestions on how the authors might clarify or enhance their contributions. The comment is vague and lacks concrete steps for the authors to take, leaving them without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"major contributions\" of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding the paper\"s contributions and the critique of analyzing previous work as a contribution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding its major contributions and questions whether analyzing previous work constitutes a contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the major contributions are unclear and questioning whether analyzing previous work constitutes a contribution. This feedback is 3 as it points out a critical area for improvement, but it lacks depth and does not provide specific suggestions or examples on how the authors might clarify their contributions or differentiate their work from previous studies. While it highlights an important area for enhancement, the comment could be more actionable and detailed to be fully helpful. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also mentions that the answer is difficult to find in reference [30]. This provides a clear and concrete action for the authors to take, which is to clarify the definition and usage of n_t in the algorithm. The comment is specific and provides a direct path for the authors to follow in order to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2\" and \"line 225,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"appropriate number\" in line 225 and notes that the answer is difficult to find in reference [30]. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of \"appropriate number\" in Algorithm 2, specifically in line 225, and notes that it is difficult to find the answer in reference [30]. This claim is 3 as it highlights a potential issue with the clarity of the algorithm, but it lacks specific examples or references to the exact phrases or sections that need clarification. The reviewer could provide more detailed guidance on how to clarify the \"appropriate number\" or suggest alternative phrasing, which would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Algorithm 2, noting that it does not explain how to determine the value of n_t and questioning the meaning of \"appropriate number\" in line 225. It also points out that the answer is difficult to find in reference [30]. This feedback is clear and actionable, as it directs the authors to clarify the definition and usage of n_t in the algorithm. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanation or offered additional context on the importance of n_t. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks whether the code will be publicly available. While the comment implies that the authors should make the code available, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make the code available to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not specify which part of the paper this issue pertains to, such as the results section or the methodology. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts need attention. The comment is specific in its request for the code to be publicly available, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty in reproducing the results and asks about the availability of the code. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code should be made publicly available. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the difficulty in reproducing the results and questions the availability of the code. While it identifies a potential issue with reproducibility, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the transparency of their work. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it points out a potential problem but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claims about the mixing time being better in practice are not adequately supported by the experiments. It suggests that the evidence provided is limited, which is a clear indication that the authors need to provide more robust data or analysis to substantiate their claims. However, the comment does not specify what additional evidence or analysis would be needed or how to present it. While the action is implicit, it is clear that the authors need to address this issue, but the lack of concrete guidance on how to do so makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claims about the mixing time being better in practice, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficient support for these claims in the experiments and the limited evidence provided to practitioners. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims about the mixing time being better in practice are not sufficiently supported by the experiments. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks specific evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made about the mixing time being better in practice. It points out that the evidence provided to support these claims is limited, which undermines the credibility of the claims. This feedback is valuable as it highlights a critical area for improvement in the paper, namely the need to provide more robust data or analysis to substantiate the claims. However, the comment could be more helpful if it suggested specific ways to enhance the experimental evidence or provided examples of how similar claims have been effectively supported in other works. Overall, the comment is 4 as it directs the authors to a crucial area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should consider this extension and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to extend the protected feature to a vector form, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this extension would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically by representing multiple attributes. This is a 3 suggestion as it points out a potential way to enhance the paper\"s contribution by expanding the scope of the protected feature. However, the comment lacks depth and does not provide specific guidance on how to implement this extension or what benefits it might bring. Additionally, it does not address other aspects of the paper, such as its methodology or results. While the suggestion is a starting point, it could be more actionable and comprehensive with additional details and examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the reviewer should denote the vector representations of the words in the equation and whether they are L2normalized. Additionally, it asks for clarification on whether the nearest neighbor examples are computed using cosine or dotproduct. These questions are direct and specific, providing clear guidance on how the authors can improve their draft. The action is explicit and the authors know exactly what needs to be done to address the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223\" and \"following ones,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including denoting the vector representations of the words, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples. This level of detail provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the notation used for vector representations and the method for computing nearest neighbor examples. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas for clarification and improvement in the paper. It points out that the notation for vector representations of words is not clearly defined and suggests that the authors denote these somehow. Additionally, it asks whether the vectors are L2normalized and whether the nearest neighbor examples are computed using cosine or dotproduct. These questions provide the authors with actionable steps to improve the clarity and accuracy of their work. However, the comment could be more helpful if it offered suggestions on how to denote the vector representations or provided examples of how this could be done. Overall, the feedback is valuable but could be more comprehensive with additional guidance. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should run experiments multiple times and report statistics, as a way to address the reproducibility issue in deep RL. It references a recent paper that discusses the importance of reproducibility in deep RL and suggests that the authors should consider this community effort. While the comment provides a clear action to take, it does not specify how many times the experiments should be run or what specific statistics should be reported. The authors are given a general direction but may need to infer the exact details of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that experiments should be run multiple times and that statistics should be reported, as a way to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. However, the comment does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on reproducibility. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for multiple experiments and reporting statistics, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL. This reference provides a logical basis for the claim, as it supports the need for increased reproducibility in the field. However, the comment could be strengthened by providing more detailed examples or specific suggestions on how to implement these changes. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or detailed guidance.", "helpfulness_rationale": "The review comment suggests that experiments should be run multiple times and that statistics should be reported to address the reproducibility issue in deep RL. It references a recent paper by Henderson et al. that discusses the importance of reproducibility in deep RL, providing a logical basis for the suggestion. While the comment identifies a critical area for improvement, it lacks specific guidance on how to implement these changes or what specific statistics should be reported. The authors are given a clear direction but may need to infer the exact details of execution. Therefore, the comment is 3, as it provides a valuable insight but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to check Figure 2, Line 433, and Line 468 for minor issues with the ending punctuation of equations. It also explicitly states that they should ensure consistency in the punctuation, providing clear and concrete guidance on what needs to be done. This level of detail and specificity makes the action 5, as the authors know exactly what to check and how to ensure consistency in their work. Therefore, this comment is rated as a 5 on the actionability scale.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2, Line 433, and Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the ending punctuation of equations, instructing the authors to ensure consistency in the punctuation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for clarification regarding the ending punctuation of equations in Figure 2, Line 433, and Line 468. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the punctuation of equations in Figure 2, Line 433, and Line 468. It provides clear and actionable feedback by instructing the authors to ensure consistency in the ending punctuation of equations. This is a minor but important detail that can enhance the clarity and professionalism of the paper. However, the comment could be more helpful if it explained why this consistency is important or provided examples of how it affects the overall presentation. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a 4 on the helpfulness scale."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to differentiate the method or what specific aspects need to be improved. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not specify which part of the paper discusses $kNNECD$ or $kNNMT$, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the similarity should be addressed or how the authors might differentiate their method. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the method proposed in the paper, $kNNECD$, is similar to $kNNMT$, which limits the technical contribution of the paper. However, it does not provide any specific guidance or suggestions on how the authors might differentiate their method or what aspects of the similarity should be addressed. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon depicted in the figures. This feedback implies that the authors should either clarify the nature of the figures or conduct additional experiments to provide more robust evidence. While the action is implicit, it is clear and concrete, as it specifies what the authors need to do to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially, and suggests conducting realworld experiments to support the phenomenon depicted in the figures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon depicted in the figures. This claim is 3 as it logically suggests that realworld experiments could provide additional evidence for the proposed method. However, the comment lacks specific examples or references to support the need for such experiments, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon depicted in the figures. This feedback is valuable as it prompts the authors to consider whether their method is adequately validated and whether realworld experiments could provide additional evidence. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is 4 as it identifies a potential area for improvement and offers a clear direction for the authors to enhance the robustness of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the authors did not clearly state the number of parameters used in each approach in Section B.3. This is a direct request for clarification, providing the authors with a clear action to take. The comment is specific and concrete, as it identifies the exact part of the paper that needs attention and the specific information that is missing. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the number of parameters used in each approach. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a request for clarification regarding the number of parameters used in each approach in Section B.3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement seeking clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper, specifically the lack of information about the number of parameters used in each approach in Section B.3. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the parameters used in their methods. By addressing this point, the authors can improve the clarity and comprehensibility of their paper, which is valuable for both readers and reviewers. However, the comment could be more helpful if it suggested how to present this information or provided examples of how similar details have been presented in other works. Overall, the comment is 4 as it effectively guides the authors on how to enhance the clarity of their paper."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This provides a clear and direct action for the authors to take, which is to include these elements in their draft to enhance understanding. The suggestion is concrete, as it specifies exactly what needs to be added, making it 5.", "grounding_specificity_rationale": "The comment suggests adding an example and a figure to help explain the definition of uniform shattering. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the definition is discussed. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of an example and a figure, but without grounding, it lacks clarity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any reasoning or evidence to support why this addition would be beneficial or how it would enhance the understanding of the concept. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to determine the necessity or impact of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. This feedback is 3 as it identifies a specific area where the paper could be improved by providing visual aids to enhance understanding. However, the comment lacks depth and does not explain why examples or figures would be beneficial or how they could be integrated into the paper. While it points out a potential improvement, it does not offer detailed guidance or suggestions on how to implement this change. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve the novelty of their method. The comment lacks actionable details, such as recommending ways to differentiate the method or suggesting alternative approaches to enhance its originality. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspect of the method is considered common or how it could be improved to enhance its novelty. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed transductive method is not novel because it is related to a common approach in semisupervised learning, specifically selftraining methods. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment questions the novelty of the proposed transductive method, suggesting it is related to a common approach in semisupervised learning, specifically selftraining methods. While it identifies a potential issue with the novelty of the method, it lacks specificity and actionable guidance on how the authors might address this concern or differentiate their approach. The comment does not provide suggestions for improving the novelty or suggest alternative ways to present the method as novel. As a result, the feedback is 3, as it points out a potential weakness but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a concern about the assumption among classes not being practical, but it does not provide any explicit or implicit actions for the authors to take. It mentions that the formulation or definition is trivial but suggests that the focus should be on optimization and theoretical property analysis for potential insights. However, without specific guidance or suggestions on how to address this issue, the authors are left without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the assumption among classes and suggests that the formulation or definition is trivial, but highlights the importance of optimization and theoretical property analysis for potential insights. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the assumption and the potential value of optimization and theoretical analysis, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the assumption among classes is not practical, but it does not provide any evidence or reasoning to support this claim. The comment suggests that the formulation or definition is trivial, but it lacks specific examples or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it may not be practical. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their work. The comment mentions the importance of optimization and theoretical property analysis, but it lacks depth and actionable advice. Without detailed feedback or examples, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation results in Table 1 are based on only three trials for each case, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the evaluation or the claims made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the statistical significance of their results and potentially revise their claims. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the statistical significance is low due to the small number of trials and that the deviation is often 0. This provides clear guidance on what needs to be addressed, namely the statistical significance and the claims made based on these results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It suggests that the deviations reported are not meaningful and that statements like \"our performance is at least two standard deviations better than the next best baseline\" do not make sense. The comment provides a logical reasoning by pointing out the insufficient statistical power of the trials, which is a commonsense observation. However, it lacks specific references or examples to support the claim about the statistical significance or the impact on the claims made. This makes the comment 3, as it provides a clear rationale but could benefit from more detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation results presented in Table 1, noting that the statistical significance is low due to the small number of trials (only three for each case). It points out that the deviations reported are often 0, which undermines the claims made about performance improvements. The comment highlights the problem with statements like \"our performance is at least two standard deviations better than the next best baseline,\" suggesting that these claims are not valid based on the presented data. This feedback is clear and actionable, as it directs the authors to reconsider the statistical significance of their results and the validity of their claims. However, it could be more helpful if it provided suggestions on how to address this issue, such as recommending a larger sample size or alternative statistical methods. Overall, the comment is 4 as it effectively identifies a critical weakness in the evaluation and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions the absence of two relevant papers. However, it does not provide specific guidance on which papers should be included or how to improve the depth of the feature comparison. The authors are left to infer that they need to include these papers, but without concrete instructions or examples, the action remains vague. Therefore, the comment is 3, as it identifies an issue but lacks detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment explicitly mentions the feature comparison with prior work, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the shallow comparison and the absence of two relevant papers. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is \"shallow\" and mentions the absence of two relevant papers. However, it does not provide specific details about which papers are missing or how they would enhance the comparison. Without these details, the claim lacks sufficient evidence or justification to be 5. The authors would need to infer the relevance of the missing papers and determine how they could improve the comparison. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the shallow feature comparison with prior work and the absence of two relevant papers. This feedback is clear and actionable, as it points out a gap in the literature review that the authors can address to enhance the depth and relevance of their analysis. However, the comment could be more helpful if it provided the names or titles of the missing papers, which would guide the authors in their literature search. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims of equivalence without verification. While the comment provides a specific suggestion for improvement, it does not offer concrete guidance on how to apply this suggestion or what specific changes should be made to the wording or claims. The authors are left to infer that they should be more cautious in their usage of the word \"equivalent,\" but without detailed instructions on how to implement this change, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it suggests a more cautious usage of the word \"equivalent\" and advises caution when making claims without verification. This provides clear guidance on what needs to be addressed in these sections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should be more cautious in their usage of the word \"equivalent\" and advises caution when making claims without verification. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the usage of the word \"equivalent\" in the paper, suggesting that the authors should be more cautious in their claims and provide verification for any equivalence claims. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it offered examples of how the authors might verify equivalence or provided guidance on how to use the word \"equivalent\" more appropriately. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a lack of understanding regarding the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests that there is a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be explored. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed analysis of the views. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the multiview clustering approach and questions the usefulness of the other views. It highlights the dominance of the paraphrase similarity view and suggests a need for a more detailed analysis of the differences and similarities between the views. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its critique of the lack of detailed analysis and the need for more comprehensive exploration of the views. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the effectiveness of the multiview clustering approach and highlights the dominance of the paraphrase similarity view over other views. It suggests that there is a need for a more detailed analysis of the differences and similarities between the views, except for the task directly. The comment provides a logical reasoning for the need of such an analysis, but it lacks specific examples or references to support the claim that the other views are not useful. This makes the claim 3, as it provides a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the effectiveness of the multiview clustering approach, specifically the dominance of the paraphrase similarity view over other views and their combination. It questions the usefulness of the other views and suggests that a more detailed analysis of the differences and similarities between them is needed. The comment highlights a gap in the analysis and provides a specific example of how the different views help in clustering paraphrases of the word \"slip.\" However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment provides valuable insights and actionable feedback, but it could be more comprehensive with additional guidance. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This implies that the authors should provide a more detailed explanation of the architecture in their paper. However, the comment does not specify how to improve the explanation or what aspects of the architecture should be covered. While the action is implied, it is not concrete, as the authors are left to infer the specific details that need to be added. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"architecture used for the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear explanation of the architecture and the reliance on external work for details. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper and that the authors refer to another work for details. This suggests that the paper lacks selfcontainment. However, the comment does not provide specific examples or references to the architecture or the external work, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the specifics of the issue themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained and that the authors rely on external work for details. This lack of selfcontainment makes it difficult for readers to fully understand the experimental setup and results. The comment provides a clear and actionable suggestion for improvement, recommending that the authors provide a more detailed explanation of the architecture within the paper. This feedback is valuable as it guides the authors to enhance the clarity and selfcontainment of their work, which is crucial for effective communication and reproducibility. However, the comment could be more helpful if it offered specific suggestions on how to improve the explanation or what aspects of the architecture should be covered. Overall, the comment is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out an inconsistency in the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to ensure consistency in the typesetting of these terms. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BertScore\" and \"BLEURT,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistent typesetting of these terms throughout the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"BertScore\" and \"BLEURT\" are inconsistently typeset throughout the paper, suggesting that maintaining consistency would be beneficial. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the typesetting of \"BertScore\" and \"BLEURT\" throughout the paper, suggesting that maintaining consistency would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their work. By addressing this issue, the authors can enhance the readability and professionalism of their paper. However, the comment could be more helpful if it provided examples of how the inconsistencies affect the paper or suggested alternative ways to maintain consistency. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback implies that the authors should include these results to support their claims about model size and performance. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. While the action is implied, it is not as clear as it could be, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or analysis sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the inclusion of detailed experimental results. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that increasing the model size can hurt performance, citing a recent paper by Ni et al. that demonstrates the scaling law applies to dense retrieval models. However, the comment does not provide specific details or references to the Ni et al. paper, making it difficult for the authors to fully understand or verify the claim. Without additional context or references, the authors may find it challenging to address the suggestion effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the authors should provide detailed preliminary experimental results on Wikipedia regarding the model size, as recent work by Ni et al. demonstrates that scaling laws also apply to dense retrieval models. This feedback is 3 as it points out a potential weakness in the authors\" argument regarding the impact of model size on performance. However, the comment lacks specific guidance on how to present these results or what aspects of the results should be emphasized. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it 3 but not fully actionable. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the figures, tables, and the management of figures and tables. It provides a list of examples, including the use of a \"Dataset\" column in tables that is not informative, the management of Figure 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific improvements. The authors are left to infer that they need to improve the presentation quality, but without detailed instructions or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific figures and tables, such as Figs 1&2, Table 1, and Table 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with these figures and tables, such as the use of a \"Dataset\" column that is not informative, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, specifically mentioning examples such as Figs 1&2, tables with a \"\" for the method, the \"Dataset\" columns in the tables, the management of Fig 3 and Table 2, and the use of a \"*\" in Table 1 without indication of its meaning. These examples provide a clear rationale for the claim, offering specific observations that can help the authors understand and address the issues. However, the comment could be strengthened by providing more detailed explanations or references to similar practices in highquality publications like NeurIPS. Despite this, the claim is 4, as it offers a solid basis for the authors to improve their presentation quality.", "helpfulness_rationale": "The review comment identifies specific weaknesses in the presentation quality of the paper, such as the use of a \"Dataset\" column in tables that is not informative, the management of Figures 3 and 2, and the use of a \"*\" in Table 1 without indication of its meaning. By providing examples and detailed descriptions of these issues, the comment offers clear and actionable feedback that can help the authors improve the presentation quality of their paper. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered guidance on how to improve the clarity and informativeness of the tables and figures. Overall, the comment is 4 as it highlights specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include related experiments to demonstrate the utility of the information axis tool. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct additional experiments, but the lack of explicit instruction makes it somewhat vague.", "grounding_specificity_rationale": "The comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the conclusion or discussion, but this inference is not direct. The comment is specific in suggesting the need for related experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support this claim. The comment is based on a logical assumption that additional experiments would be beneficial, but it lacks the necessary evidence or reasoning to fully substantiate the claim. Therefore, the comment is considered 2, as it provides a suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors include additional experiments to validate their claims. However, the comment lacks specific guidance on which experiments to conduct or how to integrate them into the paper. While it points out a gap in the paper, it does not provide detailed suggestions or examples to help the authors address this issue effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific steps they could take to investigate it further. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, nor does it provide any context or details about the current setup or the Greek language. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspect of the Greek language might be causing issues in other multilingual setups. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for information about whether other multilingual pretraining setups also struggle with Greek. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment expresses curiosity about whether other multilingual pretraining setups also struggle with Greek. While it raises an interesting question, it does not provide any actionable feedback or suggestions for the authors to address this issue or improve their work. Without further context or guidance, the authors may find it challenging to understand how this information could be relevant to their paper or how to incorporate it into their analysis. Therefore, the comment is rated as 2, as it identifies a potential area of interest but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" The reviewer implies that the authors should clarify this point to improve clarity. However, the comment does not provide specific guidance on how to clarify this point or what aspects need to be addressed. While the action is implicit, it is clear that the authors need to make changes to improve the clarity of the text. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 293295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the statement \"we manually observed the generated examples and find the results acceptable.\" This provides clear guidance on what aspect of the text is unclear and needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text in lines 293295 makes a particular point unclear, specifically mentioning that it is difficult for readers to understand and evaluate the statement \"we manually observed the generated examples and find the results acceptable.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the text in lines 293295, noting that it makes a particular point unclear. It points out that the statement \"we manually observed the generated examples and find the results acceptable\" is difficult for readers to understand and evaluate. While the comment highlights an area for improvement, it does not provide detailed guidance or suggestions on how to clarify the text or what specific aspects need clarification. This limits the comment\"s helpfulness, as it offers some insight but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to conduct experiments on realworld datasets, but the lack of explicit instruction means the action is not as direct as it could be.", "grounding_specificity_rationale": "The comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, it does not specify which part of the paper discusses the synthetic versus realworld datasets or the outofdistribution setting. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this suggestion fits, the comment lacks full grounding. It is specific about the need for realworld datasets but does not provide detailed guidance on how to implement this change. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should conduct experiments on realworld datasets instead of synthetic datasets, particularly for the outofdistribution setting. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental setup. However, the comment lacks specific guidance on how to conduct these experiments or what aspects of the synthetic datasets might be problematic. While it points out a potential issue, it does not provide detailed instructions or examples on how to address it. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, it does not provide explicit guidance on what specific aspects of the explanation are unclear or how they could be clarified. The comment implies that the authors should clarify these parts, but it lacks concrete instructions or examples of what needs to be improved. As a result, the authors are left with a vague understanding of what changes are needed to make the explanation clearer. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the last paragraph of Section 3 (lines 207210), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the explanations are vague and provides a specific example of the last paragraph in Section 3. This level of detail helps the authors understand what needs to be clarified or improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) regarding the single image case. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the vagueness and how it affects the clarity of the explanation. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the explanations in the paper, particularly in the last paragraph of Section 3 (lines 207210) regarding the single image case. This feedback is valuable as it points out a specific area where the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the explanations or examples of what might be unclear. Despite this, the feedback is 3 as it directs the authors\" attention to a specific area needing improvement, which can guide them in enhancing the clarity of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not provide explicit instructions or concrete steps on how to extend the analysis to multiple trucks and drones. The authors are left to infer that they should consider this extension, but without specific guidance on how to implement it, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors cannot confidently determine which part of the paper needs to be addressed, making this comment weakly grounded. The suggestion is specific in terms of what the authors should consider, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider multiple trucks and drones, implying that this would be a more interesting and practical setting. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this change or what benefits it might bring. The comment highlights a potential enhancement but does not provide actionable steps or detailed reasoning to support the authors in making this change. Therefore, the comment is 3, as it points out a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or make their approach more novel. There is no guidance on potential modifications, alternative approaches, or additional research directions that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the proposed approach to pretraining, specifically mentioning that it follows the strategies used in ELECTRA. However, it does not specify which part of the paper discusses this approach, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not direct the authors to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows the strategies used in ELECTRA. However, the comment does not provide any specific examples or references to the strategies used in ELECTRA, nor does it explain how the proposed approach is similar or different from those used in ELECTRA. Without detailed comparisons or references, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a limitation in the novelty of the proposed approach to pretraining, noting that it follows the strategies used in ELECTRA. While this observation highlights a potential issue, it does not provide specific guidance or suggestions on how the authors might address this limitation or differentiate their approach from existing work. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path forward to enhance the novelty or impact of their work. Therefore, it is rated as 2, as it identifies a weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It also points out that even a basic bisecting line search will converge linearly, questioning the impact of quadratic convergence on runtime. The reviewer suggests that experiments along these lines would help motivate the need for the analysis/algorithm. While the comment implies that the authors should conduct these experiments, it does not explicitly instruct them to do so. The action is concrete but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of motivation or need for the Newton algorithm and the suggestion to conduct experiments to motivate the analysis/algorithm. The comment provides a clear direction for improvement by suggesting experiments to demonstrate the impact of the algorithm on runtime. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function and that even a basic bisecting line search will converge linearly. The reviewer argues that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment provides a logical reasoning for why the Newton algorithm might not be necessary, but it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as the authors would need to conduct their own experiments to fully understand the impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation or need for the Newton algorithm in section 4, suggesting that it is a 1dimensional line search on a convex function. It questions the significance of the analysis/algorithm, noting that even a basic bisecting line search will converge linearly. The reviewer further suggests that while quadratic convergence is better than linear convergence, the impact on runtime is unclear. The comment provides a clear and actionable suggestion for the authors to conduct experiments to demonstrate the impact of the algorithm on runtime, which could help motivate the need for the analysis/algorithm. This feedback is 4 as it guides the authors to a specific area for improvement and offers a concrete step to enhance the clarity and relevance of their work. However, it could be more helpful if it included specific suggestions on which experiments to conduct or how to present the results. Overall, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their methods. It lacks concrete steps or detailed advice on how to make the methods more idiomspecific or how to improve the results. As a result, the authors are left without clear direction on how to address the critique. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed upweighing and KNN methods\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed upweighing and KNN methods are not idiomspecific and that the results indicate that better NMT systems are better at idiomatic translations. The comment supports this claim by referencing \"Figure 3,\" which presumably shows the impact of the methods on idiomatic vs. random data. However, the comment does not provide detailed analysis or specific examples from the figure to substantiate the claim fully. While the reference to Figure 3 suggests that the claim is based on empirical evidence, the lack of detailed explanation or additional context makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that they are not idiomspecific and that the results merely indicate that better NMT systems are better at idiomatic translations. While the comment identifies a potential weakness in the methods, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methods to be more idiomspecific. The feedback is 3 as it points out a potential limitation, but it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. It also mentions that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer implies that the current setup is confusing and suggests that the authors should address this issue. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or what specific aspects of the volume and biases need clarification. The action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the volume calculation and the number of biases, suggesting that the authors should clarify the volume and the number of biases. Additionally, it points out the confusion regarding the number of biases and the fact that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the volume should be WxHx1 and that the bias is a scalar, based on the authors\" belief. The reviewer questions the number of biases, noting that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The comment suggests that the current setup is confusing, as the number of biases does not align with the authors\" intent. However, the comment lacks specific examples or references to support the claim that the volume and biases are incorrect. The reasoning is based on logical deduction and inference, but without concrete evidence or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the volume calculation and the number of biases, suggesting that the volume should be WxHx1 and the bias is a scalar. It points out that the authors want to have several kernels but only found a hyperparameter for feedforward models in section 3.4. The reviewer also notes the confusion regarding the number of biases, which is not aligned with the authors\" intent. This feedback is 3 as it highlights a potential issue in the paper that the authors may need to address to clarify their work. However, the comment could be more helpful if it provided specific suggestions on how to resolve the discrepancy or clarify the volume and biases. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, specifically that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the equation. The comment lacks actionable details, such as suggesting alternative approaches or methods to mitigate the loss of dynamic information. As a result, the authors are left without a clear understanding of how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, noting that subtracting s from the dynamic information could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 could result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information in the LSTM module could result in the loss of some dynamic information. This is a valuable observation that could help the authors improve the accuracy and completeness of their model. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or methods to mitigate the loss of dynamic information. While it points out a potential problem, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions about the impact of the number of MC samples and the network structure on performance. While it implies that the authors should provide empirical evidence to address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence to answer these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of MC samples and the network structure on performance, but it does not specify which part of the paper these questions pertain to. The authors cannot confidently determine whether these questions are related to specific sections, figures, or results. Additionally, the comment lacks specificity in terms of what aspects of the network structure or MC samples should be addressed or how they might affect performance. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of questions asking for empirical evidence regarding the impact of the number of MC samples and the network structure on performance. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for information and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment raises two important questions about the impact of the number of MC samples and the network structure on performance, prompting the authors to provide empirical evidence to address these questions. This feedback is 3 as it highlights areas where the authors could enhance their analysis and provide more detailed explanations of their results. However, the comment could be more helpful if it offered specific suggestions on how to conduct the empirical analysis or what aspects of the network structure should be considered. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the smoothed GT shapes should be shown in Figures 3 and 5 to enhance the understanding of the reconstruction quality. This is a clear and direct action for the authors to take, as it provides a specific request for visual clarity. The comment also mentions a minor concern, which could be addressed by providing additional context or explanation. Overall, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include the smoothed GT shapes, but without full grounding, the authors may struggle to identify the exact figures being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests showing the smoothed GT shapes in Figures 3 and 5 to enhance the understanding of the reconstruction quality. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the understanding of the reconstruction. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion to enhance the clarity of the paper by showing the smoothed GT shapes in Figures 3 and 5. This suggestion directly addresses a potential issue in the presentation of the results, which could help readers better understand the quality of the reconstruction. Additionally, the comment acknowledges a minor concern, which could be further elaborated upon to provide even more detailed guidance. Overall, the comment is clear and offers a concrete way for the authors to improve their draft, making it 4. However, it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of direct comparisons between the proposed approach and the prior approach PRANC, particularly in the language and vision tasks used for evaluation. It notes that while there is a comparison of training loss and a comparison of the rank of possible solutions, there is no direct comparison of test accuracy. The comment implies that the authors should include direct comparisons of test accuracy to demonstrate the improvement over the baseline. However, it does not explicitly instruct the authors to add these comparisons, leaving the action implicit. The comment is 3 as it provides a clear direction for improvement but lacks concrete guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"prior approach PRANC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of direct comparisons with PRANC in the language and vision tasks used to evaluate the proposed approach. The comment provides a clear direction for improvement by suggesting the inclusion of direct comparisons of test accuracy. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in the language or vision tasks used to evaluate the proposed approach. It notes that while there are comparisons of training loss and the rank of possible solutions, there is no direct comparison of test accuracy. The comment suggests that without such comparisons, it is unclear if the proposed approach is an improvement over the baseline that it directly modifies. This claim is 3 as it logically points out the need for direct comparisons to substantiate the claims of improvement. However, it lacks specific examples or references to similar studies that might provide a more robust basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach, noting the lack of direct comparisons with the prior approach PRANC in the language or vision tasks used to assess the proposed approach. It highlights the importance of including direct comparisons of test accuracy to demonstrate the improvement over the baseline that is directly modified by the authors. This feedback is clear and actionable, providing the authors with a specific area to address in order to strengthen their evaluation and substantiate their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or provided examples of similar studies that have successfully demonstrated such comparisons. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides a clear direction for enhancing the evaluation section."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It explicitly asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and providing more details on the coverage. The comment is specific and actionable, giving the authors a clear path to improve their draft by addressing these questions. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the selection of 21 event types from Freebase and asking about their coverage on the 33 event types in the ACE data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of 21 event types from Freebase. It asks for clarification on how these event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the selection process is problematic. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is 3, as it points out a potential issue but requires more detailed explanation or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the method to other domains, specifically questioning the selection of 21 event types from Freebase and their coverage on the 33 event types in the ACE data. This is an important point that could impact the applicability and robustness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve the generalizability of their method. While it identifies a potential weakness, it lacks actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. While the comment implies that these tasks should be included, it does not explicitly instruct the authors to do so. The action is clear but not stated directly, making the comment 3. The authors can infer that they need to include additional tasks to demonstrate the language modeling capabilities, but the comment lacks concrete details on which tasks to include or how to implement them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section 5.3, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of experiments on tasks that require a wellperforming language model, such as language modeling, machine translation, or text summarization. This provides clear guidance on how to improve the paper by including these tasks. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not conduct experiments on tasks that require a wellperforming language model, such as language modeling, machine translation, or text summarization. The reviewer suggests that these tasks should be included to strengthen the evaluation of the language modeling capability. However, the comment lacks specific examples or references to support the claim that these tasks are necessary or how they would improve the evaluation. The reasoning is based on general assumptions and lacks detailed justification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of experiments on tasks that require a wellperforming language model. It suggests that the authors should include tasks like language modeling, machine translation, or text summarization to strengthen the evaluation of the language modeling capability. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their draft by including additional experiments that are relevant to the main motivation of COCOLM. However, the comment could be more helpful if it included specific examples or references to similar studies that have used these tasks to evaluate language modeling capabilities. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to cite and discuss important references for domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for references and discussions on domain adaptation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be added, namely references and discussions on domain adaptation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact references that are missing. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the lack of important references for domain adaptation. This feedback is clear and actionable, as it directly instructs the authors to include these references and discussions in the revised manuscript. By addressing this issue, the authors can significantly enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided specific examples or references of what is missing, which would guide the authors in selecting and integrating these references effectively. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps to take. It lacks concrete details on how to verify the suspicion or improve the model. As a result, the authors are left without clear instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its concern about the hyperparameters and the potential issue with the model\"s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the suspicion. As a result, the claim is 3, as it requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the \"luck\" of the SCNN model in domain pricing, given the hyperparameter tuning. It suggests that the chosen hyperparameters might not be at the end of the searched range, and the distance to the next best model is suspiciously large. This is a relevant observation that could impact the validity of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or verify the suspicion. It does not provide actionable steps or detailed feedback on how to improve the presentation or analysis of the results. As a result, the comment is 3, as it points out a potential issue but does not fully support the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that certain aspects of the experimental setup are unclear or poorly motivated, specifically regarding corpora and datasets. However, it does not provide any specific details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. The comment lacks explicit guidance or concrete steps for the authors to take, leaving them without a clear understanding of what needs to be addressed or how to address it. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"w.r.t. to corpora and datasets,\" indicating that it pertains to the experimental setup. However, it does not specify which part of the paper this pertains to, such as a particular section or table where these aspects are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what is unclear or poorly motivated about the corpora and datasets, making it difficult for the authors to understand the exact issues that need to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"some aspects of the experimental setup were unclear or poorly motivated,\" specifically regarding corpora and datasets. However, it does not provide any specific examples or detailed reasoning to support this claim. Without specific examples or references, the authors may find it challenging to understand which aspects are unclear or poorly motivated. This lack of detailed justification makes the claim 1, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that certain aspects, such as corpora and datasets, are unclear or poorly motivated. However, it does not provide any details or examples of what is unclear or poorly motivated, nor does it offer suggestions on how to clarify or improve these aspects. Without specific guidance or actionable feedback, the authors are left without a clear understanding of what needs to be addressed or how to address it. Therefore, the comment is 2, as it points out a potential weakness but lacks depth and specificity in its critique."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The comment states that the proposed method does not show significant improvement over existing RL methods, but it does not provide any specific guidance or suggestions on how the authors could address this issue. There is no explicit or implicit action for the authors to take, such as suggesting ways to improve the method or providing examples of existing RL methods that could be compared. Without actionable advice or detailed feedback, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, but it does not specify which part of the paper discusses this improvement or where the comparison is made. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the issue effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method does not show significant improvement over existing RL methods. However, it does not provide any specific examples, comparisons, or evidence to support this claim. Without detailed reasoning or references to existing methods, the authors may find it challenging to understand the basis of the critique or how to address it. This lack of supporting information makes the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment suggests that the proposed method does not show significant improvement over existing RL methods, which is a critical observation that could impact the paper\"s contribution. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the method\"s performance. Without actionable feedback or detailed insights into what aspects of the method need improvement, the authors are left without a clear path forward. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. While the comment implies that the authors should include this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the model size. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"size of the model\" and the \"hourglass modules,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of the model size to competing approaches and the details on the size of each hourglass module. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the authors do not provide details on the size of each hourglass module. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it affects the paper\"s analysis or conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, noting that the authors do not provide details on the size of each hourglass module. This feedback is clear and actionable, as it prompts the authors to include this information in their paper. However, the comment could be more helpful if it provided suggestions on how to present this information or what specific details to include. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the claim about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the claim or the paper. The action is implicit and vague, as the authors are left to infer that they need to clarify or differentiate their approach from existing work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is misleading about the claim, namely that prior work (e.g., ClimateBench or ClimateSet) already does this. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about treating climate emulation as a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, already does this. However, the comment does not provide specific examples or references to these works, nor does it explain how the proposed PACE method differs from these existing approaches. Without detailed evidence or comparisons, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a misleading claim in the paper regarding the treatment of climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, already does this, which undermines the novelty of the proposed PACE method. This feedback is valuable as it highlights a potential misrepresentation in the paper and suggests that the authors clarify or differentiate their approach from existing work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or what aspects of the claim need clarification. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or suggestions for improvement. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make or how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"metric learning theory\" and \"generalization theory of neural networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed metric perspective analysis does not yield better results compared to previous theoretical results, and that the part of metric learning does not seem to work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. However, the comment lacks specific references to the theoretical works mentioned, such as Bartlett et al. (2017), which would provide context and support for the claim. Without these references, the authors may find it challenging to verify the claim or understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the metric learning theory is based on the generalization theory of neural networks and that the proposed metric perspective analysis does not yield better results compared to previous theoretical results. It also points out that the part of metric learning does not seem to work. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their work. Without specific advice or constructive feedback, the authors are left without a clear path forward. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should move some visual results from the supplementary to the main paper. It also points out that there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The reviewer suggests condensing the illustration of the proposed network architecture from three figures to two, and using the extra space for visual results. This feedback provides clear and concrete actions for the authors to take, such as selecting specific visual results to include and condensing the figures. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the main paper and the supplementary material, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that some visual results should be moved from the supplementary to the main paper, and it provides a specific suggestion to condense the illustration of the proposed network architecture from three figures to two. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that visual results should be moved from the supplementary to the main paper, as there are almost no visual results on crowd density estimation, which is the main experiment of the paper. The comment provides a logical reasoning by pointing out the lack of visual results in the main paper and suggesting that condensing the illustration of the proposed network architecture could make room for visual results. However, the comment lacks specific examples or references to support the claim that visual results are necessary or how they would enhance the paper. This makes the claim 3, as it provides a logical argument but requires more detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should move some visual results from the supplementary to the main paper. It highlights the lack of visual results on crowd density estimation, which is the main experiment of the paper, and recommends condensing the illustration of the proposed network architecture from three figures to two. This suggestion is clear and constructive, as it offers a concrete way for the authors to improve the presentation and clarity of their work. By addressing these points, the authors can enhance the reader\"s understanding and engagement with their research. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should change the notation, provide additional clarification, or revise the terminology. As a result, the comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems, which is confusing. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the confusion regarding the use of \"r\" for both risks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems is confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this notation is confusing or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper regarding the use of \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. This is a clear and actionable observation that can help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative notations or explaining the context in which these terms are used. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether a test example is crucially different, such as a patient being \"British\" versus \"American,\" and whether this difference can be detected using the corpus residual value. While the comment implies that the authors should consider this issue, it does not provide explicit guidance on how to address it or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in its question about detecting crucial differences, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this difference might be crucial or how it could be detected. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a thoughtprovoking question about the detection of crucial differences in test examples, specifically mentioning the example of a patient being \"British\" versus \"American\" and using the corpus residual value. This question highlights an important consideration for the authors regarding the potential impact of such differences on their analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific steps they could take to ensure the validity of their results. While it prompts the authors to consider a relevant aspect of their analysis, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using the most popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. It provides a rationale for this suggestion, noting that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. While the comment explicitly states the action to take, it lacks concrete details on how to implement this change or what specific aspects of the WebQuestions benchmark set would be most beneficial. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"WebQuestionsSP\" dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of dataset and suggesting that using the more popular WebQuestions benchmark set would be more intuitive and straightforward. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP as the testbed. The reviewer provides a logical reasoning by explaining that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions would be more appropriate for the study. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to consider using a more popular dataset, WebQuestions, instead of WebQuestionsSP as the testbed for their study. It offers a logical reasoning that using WebQuestions would be more intuitive, straightforward, and could facilitate direct comparison with mainstream QA research. This feedback is valuable as it guides the authors to make a simple but impactful change that could enhance the clarity and relevance of their work. However, the comment could be more helpful if it provided specific examples or references to support the argument for using WebQuestions. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the need for making claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity, and that any potential training speed increases or cost savings must be demonstrated. While the comment implies that the authors should provide evidence or examples to support their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or examples to address the reviewer\"s concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It mentions that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment does not specify which part of the paper these claims are made in, nor does it provide details on what specific evidence or demonstrations are needed. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its critique of the claims and the need for evidence, but without explicit references to sections or examples, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. The reviewer provides a logical reasoning by pointing out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. However, the comment lacks specific examples or references to support the claim that sparsity is not beneficial. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the need for claims about the benefits of sparsity in training, suggesting that it is not obvious that it is desirable. It points out that a larger network may perform better without sparsity and that any potential training speed increases or cost savings must be demonstrated. While the comment identifies a potential weakness in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address this issue or present evidence to support their claims. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to differentiate their design or what aspects could be improved to enhance novelty. As a result, the authors are left without any clear direction on how to respond to this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of novelty, specifically mentioning that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what aspect of novelty is lacking, but without explicit references to sections or details, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the paper, specifically noting that the design is not new due to the use of attention for motion learning, which is widely used in video understanding. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should include analysis or results on other datasets, specifically mentioning ImageNet derivatives. It clearly states the need for verifying the effectiveness of the framework on these datasets and suggests that these results should be presented in the main paper. This provides a direct and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for analysis or results on other datasets, specifically ImageNet derivatives. This allows the authors to accurately identify the part of the paper being addressed, which is the analysis or results section. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on ImageNet1k or ImageNet100. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks analysis or results on other datasets, specifically ImageNet derivatives. It provides a logical reasoning by stating that verifying the effectiveness of the framework on these datasets is important. However, the comment does not provide specific examples or references to support the claim that these datasets are necessary for a comprehensive evaluation. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. The authors would need to make a significant effort to understand and address the suggestion fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should include analysis or results on other datasets, such as ImageNet derivatives. This feedback is clear and actionable, as it points out a gap in the paper\"s evaluation and suggests a way to enhance its comprehensiveness. By addressing this suggestion, the authors can provide a more comprehensive evaluation of their framework\"s effectiveness, which could strengthen the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to present these results or what aspects to focus on. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of clarity in the model design, specifically mentioning that the architecture and learning details are fragmented or missing. It provides a clear suggestion for the authors to address this issue by either providing a plot of model illustration, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesserknown nature of Neurochaos Learning. The explicit action and concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"model design\" and \"model architecture and learning details,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the fragmented or missing details of the model design, and provides a concrete suggestion to address this issue by providing a plot, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesserknown nature of Neurochaos Learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model design is unclear due to fragmented or missing details, specifically mentioning the importance of demonstrating integrated details to facilitate reproducibility. The comment suggests providing a plot, pseudocode table, or code repository to address this issue. However, the comment lacks specific examples or references to support the claim that Neurochaos Learning is not wellknown, which would strengthen the verifiability. Therefore, the claim is 3, as it provides a logical basis but could be further substantiated with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design, noting that the architecture and learning details are fragmented or missing. It provides a clear and actionable suggestion for the authors to address this by either providing a plot of model illustration, pseudocode table, or code repository. Additionally, it highlights the importance of demonstrating integrated details to facilitate reproducibility, especially considering the lesserknown nature of Neurochaos Learning. This feedback is valuable as it guides the authors on how to improve the clarity and accessibility of their model design, which is crucial for the success of their work. However, the comment could be more helpful if it included specific examples or additional suggestions on how to present the model details. Overall, the comment is 4 as it provides clear and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be better to state them as datasets throughout the paper unless the authors provide an extended explanation for their use as models. This feedback is explicit and provides a clear action for the authors to take, which is to update the paper to reflect the correct usage of these models. The suggestion is concrete, as it specifies the exact change needed in the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Abstract\" and \"Introduction\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between how BigFive and MBTI are described in the abstract and introduction sections as models to be extended, versus their usage as datasets in the experiments. The comment provides a clear suggestion to correct this discrepancy by stating the models as datasets throughout the paper, unless there is a specific reason to extend the explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that BigFive and MBTI are stated as models to be extended in the abstract and introduction sections, while they are used as datasets in the experiments. The reviewer suggests that it would be better to state them as datasets throughout the paper unless there is a specific reason to extend the explanation. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these models are not being used as models. This makes the claim 3, as the authors would need to make a concerted effort to verify the claim themselves.", "helpfulness_rationale": "The review comment identifies a discrepancy between how BigFive and MBTI are described in the abstract and introduction sections, where they are stated as models to be extended, while in the experiments, they are used as datasets. The reviewer suggests that it would be more appropriate to state these models as datasets throughout the paper, unless the authors provide an extended explanation for their use as models. This feedback is clear and actionable, as it provides a specific guidance on how to improve the paper by aligning the terminology with the actual usage in the experiments. By addressing this issue, the authors can enhance the clarity and consistency of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates or consider misclassifications as rejections in their experiments. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion for how to present the results, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"rejection rate\" and \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of rejection rates or the consideration of misclassifications as rejections in the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that one could view a misclassification as a rejection. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it affects the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that one could view a misclassification as a rejection, and recommends including rejection rates or considering misclassifications as rejections in the results. This feedback is clear and actionable, as it provides a direct suggestion for how the authors can improve their experimental design and presentation. By addressing this point, the authors can enhance the transparency and clarity of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment implies that the authors should clarify these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation and comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific issue of generalization to the TSP instances, particularly the finetuning step in DIMES. It also specifies what needs to be clarified, namely, the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the generalization gaps in their work, specifically regarding the finetuning step in DIMES, and provide a comparison of DIMES with other methods on TSP100. While the comment identifies a potential issue with the generalization of DIMES, it lacks specific examples or references to support the claim that these gaps need clarification. The suggestion to compare DIMES with other methods is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the generalization of the finetuning step in DIMES and suggests that the authors should clarify the difference between DIMES and other methods on TSP100 indistribution testing performance with/without metalearning. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for the authors to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included examples or references to support the claim about generalization gaps or the need for a comparison with other methods. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The request for the hyperparameters is specific, and the mention of reproducibility highlights the importance of sharing these details. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for the final thresholds used for the results and requests the sharing of the full set of hyperparameters. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. The comment is also specific because it clearly specifies what information is needed to improve the reproducibility of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of requests for information, specifically asking for the final thresholds used for the results and the full set of hyperparameters. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for a claim.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by requesting the final thresholds used for the results and the full set of hyperparameters. This information is crucial for reproducibility and understanding the methodology. However, the comment could be more helpful if it provided guidance on how to present this information or why it is important for reproducibility. Despite this, the feedback is clear and actionable, which makes it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. However, it does not provide any explicit or implicit actions for the authors to take. The comment implies that the authors should clarify their methodology or consider alternative methods for answer detection, but it does not specify how to do so or what specific changes should be made. Without concrete guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the potential inconsistency in the authors\" claim and suggests that it depends on the method/features used for answer detection, such as POS/dependency parse features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim made by the authors regarding the readability of RC datasets and its impact on question difficulty. It suggests that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the authors\" claim regarding the readability of RC datasets and its impact on question difficulty. It points out that the authors\" claim is dependent on the method/features used for answer detection, such as POS/dependency parse features. This feedback is 3 as it highlights a potential weakness in the authors\" argument and suggests a direction for clarification or further exploration. However, the comment could be more helpful if it provided specific suggestions on how to address this inconsistency or how to better substantiate the claim. Overall, the comment offers some guidance but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The comment explicitly instructs the authors to optimize Figure 1 to use less whitespace. This is a clear and direct action, providing the authors with a specific task to improve the visual presentation of their data. The comment is concrete, as it specifies the exact change needed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, optimizing the use of whitespace in Figure 1. This provides clear guidance on how to improve the visual presentation of the data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests optimizing Figure 1 to use less whitespace. However, it does not provide any reasoning, evidence, or examples to support why this optimization is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to optimize Figure 1 by using less whitespace. This feedback is clear and direct, giving the authors a concrete step to improve the visual presentation of their data. By addressing the issue of excessive whitespace, the authors can enhance the clarity and readability of their figure, making it more effective in communicating their findings. However, the comment could be more helpful if it provided additional guidance on how to achieve this optimization, such as suggesting alternative layouts or techniques. Overall, the comment is 4 as it identifies a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. While the comment implies that the authors should conduct some form of analysis or provide evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional analysis or evidence to address the reviewer\"s concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"vector space where morphological variants are just close together,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the resulting space is meaningful and suggests providing evidence or analysis to support the claim. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. The reviewer does not provide specific examples or references to support their claim, making it 3. The authors would need to infer the need for such evidence or analysis themselves, as the comment lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the meaningfulness of the morphological space and suggests that the authors should provide evidence or analysis to support the claim that the morphfitting results in a more meaningful space. This feedback is valuable as it prompts the authors to consider the significance of their results beyond just improved embeddings. However, the comment could be more helpful if it provided specific suggestions on how to conduct the analysis or what kind of evidence would be most relevant. While it identifies an important area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper needs improvement, specifically noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should focus on improving the writing quality and expanding the related work section, but the comment lacks concrete details on how to achieve these improvements. Therefore, the action is implicit and somewhat vague, making this comment 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in identifying areas for improvement, such as the uneven distribution of space and the missing related work sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper needs improvement, specifically mentioning the uneven distribution of space between explaining basic memory networks and the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. However, the comment lacks specific examples or references to support the claim that the writing is uneven or that the related work section is incomplete. Without detailed evidence or reasoning, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication but lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing quality of the paper, noting that the authors spend too much space on explaining basic memory networks and then the forward model. It also points out that the related work section is missing pieces on more reinforcement learning tasks in the literature. This feedback is 3 as it highlights areas where the paper could be improved in terms of balance and comprehensiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending which sections to prioritize or which related work to include. While it provides some direction, the lack of detailed advice limits its utility for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific line (Line 140) and raises a concern about the first column of Qo being replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to resolve it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 140,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the replacement of the first column of Qo by vo to form P\"o, which results in the first state not being reachable anymore. The comment further assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. However, the comment lacks specific reasoning or evidence to support these claims, such as examples or references to similar studies. This makes the claim 3, as the authors would need to infer the basis of the claim and potentially conduct additional research to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the first column of Qo is replaced by vo to form P\"o, which results in the first state not being reachable anymore. The reviewer assumes that either Assumption 1 (finite length of an option) or Assumption 2 (the existence of a terminating state) is violated. While the comment highlights a potential problem, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what alternative assumptions might be considered. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides a specific example of the recurrent model, suggesting that the sequential relationship might be easier to model. While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these areas to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment does not specify which part of the paper discusses FLOPs or inference time, making it weakly grounded. The suggestion to explore accuracy or specific properties is specific, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvements in FLOPs or inference time, they should explore improvements in accuracy or specific properties. It provides an example of the recurrent model, suggesting that the sequential relationship might be easier to model. However, the comment lacks specific examples or references to support the claim that exploring accuracy or specific properties would lead to improvements. The suggestion is logical but lacks detailed evidence or examples, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to explore if there are improvements in accuracy or specific properties if they did not find improvements in FLOPs or inference time. It offers an example of the recurrent model, suggesting that the sequential relationship might be easier to model. This feedback is actionable and provides a clear direction for the authors to consider when evaluating their results. However, the comment could be more helpful if it included specific examples or references to support the claim about the sequential relationship. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the assumption that d_e are good replacements for entity embeddings was tested. While it implies that the authors should address this assumption, it does not explicitly instruct them to do so. The comment is 3 because it provides a clear direction for the authors to consider testing the assumption, but it lacks concrete guidance on how to conduct the test or what specific aspects to focus on. Therefore, the authors can infer that they need to test the assumption but may not be entirely sure of the exact steps to take.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption that \"d_e are good replacements for entity embeddings,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether this assumption was tested, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this assumption should be tested or how it might impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a critical question about the assumption that \"d_e are good replacements for entity embeddings,\" suggesting that this assumption has not been tested. This is an important point that could impact the validity and reliability of the paper\"s conclusions. However, the comment lacks depth and does not provide specific guidance on how the authors might test this assumption or what aspects of the assumption should be considered. While it identifies a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the components of the \"scoring function\" and the different threshold values/ranges. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included to clarify the methodology. The action is implicit and vague, as the authors are left to infer that they need to provide more information about the scoring function and threshold values. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"scoring function\" and the different components and threshold values/ranges, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the components and threshold values/ranges. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"scoring function\" and different threshold values/ranges are unclear. However, it does not provide any specific examples or detailed reasoning to support this claim. The comment lacks supporting evidence or references to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the components of the \"scoring function\" and the different threshold values/ranges. It highlights a lack of clarity in the methodology, which is an important aspect for readers to understand. However, the comment does not provide specific suggestions or guidance on how the authors might clarify these aspects in their paper. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the table or what specific changes could be made to enhance the information presented. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the factors in a table do not effectively convey more messages than pure text, and there is no additional information. However, it does not specify which table or part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the table\"s effectiveness, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the factors in a table do not effectively convey more messages than pure text, as there is no additional information. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the table, suggesting that the factors included do not effectively convey more messages than pure text. It highlights the lack of additional information and implies that the table is redundant. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the table\"s utility. Without specific advice or examples, the authors are left without a clear path forward to enhance the clarity and effectiveness of their table. Therefore, the comment is rated as 2, as it identifies a weakness but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the simulation should be considered. The comment lacks actionable details, such as recommending ways to categorize or analyze the different physical interactions, or suggesting methods for evaluating the simulation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what kind of physical interactions are being considered or how they might impact the simulation. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it highlights an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the simulation should be considered. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. The comment provides explicit actions for the authors to take: to include more datasets with categorical features and to employ one hot encoding for the dataset with categorical features. These actions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Model Comparison\" and the \"wide range\" of datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of datasets, noting that only one dataset has categorical features and that the authors do not employ one hot encoding for this dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model comparison in the paper is inadequate due to the selection of datasets, which lacks categorical features. The reviewer supports this claim by explaining that categorical features are generally more challenging for deep learning and that the omission of one hot encoding for the dataset with categorical features could negatively affect performance. This reasoning is logical and based on common knowledge, providing a clear rationale for the claim. However, the comment could be strengthened by referencing specific studies or examples that support the importance of categorical features in deep learning. Despite this, the claim is 4, as it provides a solid foundation for the authors to address the issue.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s model comparison, specifically the choice of datasets and the lack of categorical features. It points out that the paper claims a thorough comparison on a wide range of datasets but only includes one dataset with categorical features, which may affect the conclusions. Additionally, it notes that the authors do not employ one hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it provides specific guidance on how the authors can improve their model comparison by including more datasets with categorical features and employing one hot encoding for the dataset with categorical features. By addressing these points, the authors can significantly enhance the robustness and credibility of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. While the comment identifies a potential issue with the choice of datasets, it does not provide explicit guidance on how to address this issue or what specific datasets would be better options. The authors are left to infer that they should consider alternative datasets, but the comment lacks concrete suggestions or detailed reasoning on how to make these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of two unpopular IoT datasets for benchmarking and suggests that there should have been better options, such as wearable health or mobile activity recognition data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the choice of two unpopular IoT datasets for benchmarking is a strange and unhelpful choice, as they are not widely followed or used. The reviewer supports this claim by referencing specific datasets (FlatCam Face and Headpose detection) and their relative unpopularity, as well as the fact that the latter was published in 2004. This provides some evidence for the claim, but it could be strengthened by referencing more recent studies or datasets that would be better suited for benchmarking. Overall, the comment is 4, as it provides a logical basis for the claim but lacks detailed references or examples to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets for benchmarking in Section 4, noting that the two datasets (FlatCam Face and Headpose detection) are unpopular and not widely followed. It suggests that there should have been better options, such as wearable health or mobile activity recognition data, or even some sets in UCI. This feedback is 3 as it points out a specific area for improvement in the paper, but it lacks detailed guidance on how to select better datasets or why these particular datasets are problematic. While the authors can infer that they should consider alternative datasets, the comment could be more helpful with additional suggestions or reasoning. Therefore, it is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider this aspect. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"pruning\" and \"distributed settings,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential need to find global top Q values of the metric over the average of gradients, which could impact acceleration techniques like quantization and sparsification. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks trained in distributed settings and suggests that the authors should consider finding global top Q values of the metric over the average of gradients. This is a logical claim based on the observation that pruning is often used with large networks and that distributed settings are common for training. However, the comment lacks specific examples or references to support the claim that finding global top Q values is necessary to avoid breaking acceleration techniques like quantization and sparsification. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" approach, noting that pruning majorly works with large networks trained in distributed settings. It suggests that the authors should consider the necessity of finding global top Q values of the metric over the average of gradients, as this could break big portions of acceleration techniques like quantization and sparsification. This feedback is valuable as it highlights a potential gap in the authors\" discussion of pruning techniques and their impact on distributed settings. However, the comment could be more helpful if it provided specific examples or references to support the claim about the necessity of global top Q values. Overall, the comment is 3 as it points out a relevant area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether some subfigures in Figures 1 and 2 have been swapped by mistake. While it implies that the authors should check the figures and potentially correct any errors, it does not provide explicit instructions on how to do so or what specific subfigures might be affected. The action is implicit and somewhat vague, as the authors need to infer that they should verify the figures themselves. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about whether some subfigures have been swapped by mistake, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking whether some subfigures in Figures 1 and 2 have been swapped by mistake. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the possibility of subfigures in Figures 1 and 2 being swapped by mistake. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or verify the accuracy of the figures. The comment lacks actionable feedback or detailed analysis, making it 3 as it points out a potential problem but does not assist the authors in resolving it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the potential increase in false positives due to the dropout probe improving sensitivity. While it implies that this should be a substantial part of the discussion, it does not explicitly instruct the authors to include this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"dropout probe\" and its impact on sensitivity, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should discuss the potential increase in false positives due to the dropout probe. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the dropout probe improves sensitivity and finds a causal role for syntactic representations that previous approaches might have missed. However, it also suggests that this improvement could lead to an increase in false positives, which is a valid concern. The comment provides a logical reasoning for this concern but lacks specific examples or references to substantiate the claim about false positives. This makes the claim 3, as the authors would need to further explore and substantiate the potential increase in false positives to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific improvement in the sensitivity of the dropout probe and its ability to find causal roles for syntactic representations. It acknowledges the positive aspect of this improvement but also highlights a potential concern about the increased risk of false positives. The comment suggests that this should be a substantial part of the discussion, which is a valuable point for the authors to consider. However, the comment could be more helpful by providing specific examples or references to support the claim about false positives. Overall, the comment is 4 as it directs the authors to consider an important aspect of their results that could impact the interpretation and conclusions of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer explicitly states that they could not find the regret bound in the supplementary, which implies that the authors should include it. However, the comment does not provide specific guidance on how to present the regret bound or where it should be located in the paper. While the action is clear, the lack of detailed instructions on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the regret bound for the proposed minibatch method being cast to the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the regret bound is not provided in the supplementary material and references a specific work for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support the claim. This reference provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors claim a regret bound for their proposed minibatch method but do not provide it in the supplementary material. The reviewer references a specific work, \"Online Variance Reduction for Stochastic Optimization,\" by Zalan Borsos, Andreas Krause, and Kfir Y Levy, to support their claim. This feedback is clear and actionable, as it directs the authors to include the missing regret bound in the supplementary material. However, the comment could be more helpful if it provided additional guidance on how to present the regret bound or why it is important for the paper. Overall, the comment is 4 as it highlights a critical oversight in the paper, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the paper formatting does not follow the NeurIPS formatting style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the paper style, the authors could gain some space and include the NLP experiments in the main body of the paper. This feedback provides clear and concrete actions for the authors to take, such as adjusting the formatting style to conform to the NeurIPS guidelines and reorganizing the content accordingly. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper formatting, allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the formatting, such as the font size of the abstract and the bottom page margins, and suggests that these issues could be addressed by following the NeurIPS formatting style. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper formatting is off, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that following the NeurIPS formatting style could improve the paper. While the comment identifies specific formatting issues, it lacks detailed reasoning or references to justify why the current formatting is problematic or how following NeurIPS guidelines would improve the paper. This makes the claim 3, as the authors would need to make an effort to understand and address the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not follow the NeurIPS formatting style. It points out issues with the font size of the abstract and the bottom page margins, suggesting that these could be improved by following the NeurIPS guidelines. The comment also suggests that this formatting change could gain some space and allow the inclusion of the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the formatting and organization of their paper. However, it could be more helpful if it included examples of how the NeurIPS formatting style should be applied or provided additional context on why this change is beneficial. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear path for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND and ICM). However, it does not provide any explicit guidance on how the authors should address this issue. The comment implies that the authors should include a discussion or comparison of these methods, but it lacks concrete instructions on how to structure this discussion or what specific aspects to cover. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on these methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"exploration methods in RL literature, such as countbased methods and intrinsic motivations (RND, ICM),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion and comparison of these methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to these methods, making it difficult for the authors to understand the exact methods being referred to. Without detailed explanations or references, the claim is not 5, as it relies on general knowledge of RL literature. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that it does not discuss or compare exploration methods in RL literature, specifically mentioning countbased methods and intrinsic motivations (RND, ICM). This is a critical oversight, as these methods are widely used and relevant to the field. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as which methods to discuss or how to structure the comparison. While it points out a significant gap in the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it implies that the authors should make the annotations larger, it does not provide specific guidance on how to achieve this or what size would be appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should make the annotations larger but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the enlargement of annotations for better visibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 could be enlarged for better visibility. However, it does not provide any supporting evidence, reasoning, or examples to justify why the annotations are currently too small or how enlarging them would improve visibility. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 could be enlarged for better visibility. While it provides a specific suggestion for improvement, it lacks depth and does not explain why the current annotations are too small or how enlarging them would impact the figure\"s readability. The comment could be more helpful if it included additional context or examples to guide the authors on how to implement this suggestion effectively. As it stands, the feedback is 3, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific changes should be made to the paper. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the claim regarding the existence of multiple entities in both sentences and documents, including relation classification. The comment provides a clear critique of the claim and suggests that the authors should clarify or reconsider their statement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the claim made in the paper regarding the existence of multiple entities in both sentences and documents, including relation classification. This is a relevant observation that could impact the validity of the paper\"s claims. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or what changes could be made to improve the paper. Without actionable feedback or suggestions, the authors are left without a clear path forward. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 4, noting that one of the labels on the color bar should likely say \"worse\" instead of \"better.\" This is an explicit observation that the authors can directly address by changing the label. The action is clear and concrete, as the authors know exactly what needs to be corrected. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, noting that one of the labels should say \"worse\" instead of \"better.\" This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a specific figure, Figure 4, noting that one of the labels on the color bar is incorrect. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that one of the labels on the color bar is incorrect. This is a clear and actionable observation that the authors can easily address to improve the accuracy and clarity of their visual presentation. However, the comment does not provide additional context or suggestions on how to improve the figure or what other labels might be mislabeled. While it points out a specific error, it lacks depth and could be more helpful by offering additional guidance or explanation. Therefore, the comment is 3, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and direct action for the authors to take, as it provides a specific correction to make in their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely, changing \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on how to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation, noting a specific error in the text regarding the use of \"training/validation/test\" instead of \"training/validation/test sets.\" It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, noting that \"training/validation/test\" should be \"training/validation/test sets.\" This is a clear and actionable suggestion that can help the authors improve the accuracy and clarity of their draft. By addressing this error, the authors can ensure that their manuscript is consistent and professional in its presentation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions and concerns about the paper, but it does not provide explicit or implicit actions for the authors to take. It asks about the coefficient of the p(L, E | X) term in line 307 and why it is 1, but it does not instruct the authors to investigate this or provide guidance on how to address the issue. Similarly, it mentions the missing hyperparameter details, the need for baselines to be welltuned, and the potential impact on ablation studies, but it does not offer specific steps for the authors to take. The comment also points out issues with the writing style, but it does not provide suggestions for improvement. Overall, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, it is rated as 1.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the paper, but it does not specify which part of the paper these issues pertain to. It mentions \"line 307\" and \"hyperparameter details,\" but these references are not explicit enough for the authors to pinpoint the exact sections or parts of the paper being addressed. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved, such as the coefficient of the p(L, E | X) term or the writing style. Without clear guidance or specific examples, the authors cannot effectively address the issues raised. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the inference speed, the coefficient of the p(L, E | X) term, and the hyperparameter details. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique or how to address it. As a result, the claim is 1, as it does not provide sufficient justification or evidence to support the claims made. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises several issues with the paper, including concerns about inference speed, the coefficient of the p(L, E | X) term, and the hyperparameter details. It questions the clarity of the writing and suggests that the authors should provide more information about the baselines and ablation studies. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The feedback is 3 as it points out potential weaknesses, but it could be more beneficial if it offered actionable steps or examples for the authors to improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile is confusing and recommends adding extra brackets around the term or defining the bracketed term separately if space allows. This provides a clear and explicit action for the authors to take, which is to clarify the definition by adding brackets or defining the bracketed term. The comment is specific and provides concrete guidance on how to improve the clarity of the definition. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"definition of the quantile,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to clarify the definition by adding extra brackets or defining the bracketed term separately if space allows. This level of detail provides the authors with clear guidance on how to improve the clarity of the definition. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile is confusing and provides a specific suggestion to clarify it by adding extra brackets or defining the bracketed term separately. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks detailed explanation or examples to fully substantiate the claim. The authors might need to infer the exact impact of the suggested changes, making the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the definition of the quantile, which is described as \"a little confusing.\" It provides a clear and actionable suggestion to improve the clarity of the definition by adding extra brackets or defining the bracketed term separately if space allows. This feedback is valuable as it directly addresses a potential source of confusion and offers a concrete way to enhance the clarity of the paper. However, the comment could be more helpful if it explained why the current definition is confusing or provided examples of how the suggested changes might improve clarity. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. This feedback provides a clear and explicit action for the authors to take, specifying the exact change needed to update the text. The suggestion is concrete, as it offers a specific alternative phrase to use, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the outdated nature of the model by Dozat and Manning (2016) and suggests replacing it with a more current description. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a phrase like \"very high performing model\" or similar. However, the comment does not provide any supporting evidence, references, or reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a more appropriate description. This feedback is clear and actionable, as it provides a concrete suggestion for improving the accuracy and relevance of the paper. By addressing this issue, the authors can enhance the credibility and uptodate nature of their work. However, the comment could be more helpful if it included additional context or examples of alternative models that might be more appropriate. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is identified as the main weakness of the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the performance or suggestions for potential modifications to the method. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed compression\" and \"PQ,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is that the proposed compression performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment does not provide any supporting evidence, comparisons, or references to substantiate this claim. Without additional details or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is considered the main weakness of the method, which is important for the authors to address. However, the comment lacks depth and does not provide suggestions or guidance on how to improve the performance or address this issue. Without actionable feedback or specific recommendations, the authors are left with only a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper, including inappropriate subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment explicitly instructs the authors to provide a detailed explanation to verify these statements. While the action is clear, it is somewhat vague in terms of how to present the explanation, as it does not specify the exact format or content of the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references, and the laborintensive nature of designing effective architectures. It also mentions the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. However, the comment does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for proofs and references, and the need for a detailed explanation of the statements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims and suggestions, including the need for proofs and references to support subjective statements, the laborintensive nature of designing effective architectures, and the uncertainty regarding when to fuse multiscale features. The reviewer also suggests that models with skip connections could be considered implicit multiscale methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The lack of detailed evidence or examples makes the claims 3, as the authors would need to make a significant effort to understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the appropriateness of subjective statements, the need for proofs and references to support claims, and the laborintensive nature of designing effective architectures. It also points out the uncertainty regarding when to fuse multiscale features and suggests that models with skip connections could be considered implicit multiscale methods. The comment provides clear and actionable feedback by suggesting that the authors should provide detailed explanations to verify these statements and address the issues raised. This guidance is valuable for the authors to improve their draft, making the comment 4. However, it could be more comprehensive by offering specific examples or suggestions on how to present the explanations. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how the proposed method compares with prior art. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so or offer guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not be entirely sure of the specifics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section where the comparison with prior art is discussed, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison with prior art. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about how the proposed method compares with prior art. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the comparison of the proposed method with prior art. While it highlights an important area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison should be emphasized. The comment lacks actionable feedback or detailed advice, leaving the authors without a clear path forward. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful enhancements to their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the analysis could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that the authors should explore potential biases in the data and compare them across different languages/nationalities. While the comment does not explicitly instruct the authors to conduct this analysis, it provides a clear direction for improvement by highlighting a specific area that could be expanded upon. The action is implicit but concrete, as the authors can infer the need to conduct a more detailed analysis and compare biases across different languages/nationalities. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by exploring potential biases in the data and comparing them across different languages/nationalities. This provides clear guidance on what the authors could address to improve their work. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section. It implies that there might be interesting observations to be made about biases towards different languages/nationalities. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such observations would be interesting or valuable. Without additional context or evidence, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the analysis could be more detailed, particularly in the \"language/nationality\" section. It points out that the data includes multiple languages and nationalities, implying that there might be interesting observations about biases towards different groups. While the comment highlights a potential area for exploration, it lacks specific guidance or suggestions on how to conduct this analysis or what specific observations might be interesting. This limits the comment\"s helpfulness, as it provides a general direction but does not offer detailed guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not provide explicit guidance or suggestions on what other properties could be considered or how to incorporate them into the approach. The action is implicit and somewhat vague, as the authors can infer that they should consider other properties but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this discussion might be relevant. The authors can infer that it relates to the methodology or approach sections, but this inference is not direct. The comment is specific in its suggestion to consider other properties, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in addition to norm, suggesting that this would be necessary and helpful for the approach design. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is the case or how it would improve the approach. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a relevant question about the use of other properties of features in addition to norm, suggesting that this could be necessary and helpful for the approach design. This is a valuable point as it prompts the authors to consider alternative approaches or features that could enhance the robustness and effectiveness of their method. However, the comment lacks specific suggestions or examples of other properties that could be explored, which limits its helpfulness. While it provides a direction for further exploration, it does not offer detailed guidance or actionable steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. However, it does not provide explicit guidance on how to address these weaknesses or suggest specific changes. The authors are left to infer that they should make changes to the method, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the weaknesses in the method, including the lack of network changes or losses, the use of two SIRENs for f and d, and the contribution in the signed distance function and a pipeline for transferable implicit displacement fields. The comment also questions why the d is a simpler network. However, it does not provide specific suggestions or examples on how to address these issues, leaving the authors to infer the necessary changes. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the method is mostly constructed on top of previous methods, lacks network changes or losses, and questions the use of two SIRENs for f and d. The reviewer also questions why the d should be a simpler network. While the comment identifies specific weaknesses, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the basis of the critique and determine how to address it. Therefore, the comment is 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several weaknesses in the method, including the lack of network changes or losses and the use of two SIRENs for f and d. It questions why the d should be a simpler network and suggests that the contribution in the signed distance function and a pipeline for transferable implicit displacement fields might not be necessary. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these weaknesses. The authors are left with a general understanding of the issues but without actionable steps to improve their draft. Therefore, the comment is 3, as it provides insight but not comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and does not provide additional information. It also proposes an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a specific reference to a related work that could guide the authors in conducting this analysis. While the comment implies that the authors should reconsider their RQ1 and explore the proposed analysis, it does not explicitly instruct them to do so. The action is concrete but somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RQ1\" and \"RQ2\" and \"RQ3 tsne plots,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the redundancy of RQ1 and the potential analysis on the effect of explicit hate information on implicit hate speech detection performance. The comment provides a reference to a related work, which is helpful in guiding the authors on how to proceed with their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and does not provide additional information. It suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance and its impact on RQ2 and RQ3 tsne plots. The reviewer provides a reference to a related work, which supports the claim by suggesting a specific direction for analysis. This provides a clear rationale and logical reasoning for the claim, making it 4. However, the comment could be strengthened by including more detailed examples or specific data from the reference to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper and suggests an alternative analysis on the effect of explicit hate information on implicit hate speech detection performance. It also proposes an exploration of how this affects RQ2 and RQ3 tsne plots. The comment provides a specific reference to a related work, which could guide the authors in conducting this analysis. While the comment offers actionable suggestions, it could be more helpful if it provided more detailed guidance on how to conduct the analysis or what specific metrics to use. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a starting point for further exploration."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not provide any specific guidance on what these tasks might be or how the authors should address this expectation. The action is implicit and vague, as the authors are left to infer that they need to expand their discussion on the importance of PE in tasks beyond link prediction. Without concrete instructions or examples, the authors may find it challenging to know how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, it does not specify which part of the paper this expectation is based on, nor does it provide details on what specific tasks should be discussed. Without explicit references to sections or specific tasks, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this expectation is necessary or how it would benefit the paper. Without specific examples or references, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the paper should discuss tasks beyond link prediction where PE (presumably, PE stands for \"personalization\") is important. While it identifies a potential area for expansion, it lacks specificity and does not provide any guidance on what tasks or aspects of PE should be discussed. The comment does not offer actionable advice or examples, leaving the authors without clear direction on how to address this suggestion. As a result, the feedback is not helpful, as it does not provide the authors with a concrete path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. While it implies that the authors should provide a comparison or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this difference. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the difference between the authors\" work and other works focusing on semantic face editing. However, it does not specify which part of the paper this comparison should be made, nor does it provide details on what aspects of the work need to be compared. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the difference between the authors\" work and other works focusing on semantic face editing. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a valid point by asking the authors to elaborate on the difference between their work and other works focusing on semantic face editing. This is a constructive suggestion that could help the authors better position their contribution in the context of existing research. However, the comment lacks specific guidance on how to address this difference or what aspects of the work should be compared. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to reduce the use of footnotes and move important content into the main body of the paper. It provides a specific example by suggesting that details around parameter settings can be moved to the appendix. This feedback is clear and concrete, giving the authors a direct action to take to improve the clarity and readability of their draft. The suggestion to move content to the appendix is also detailed, making the action explicit and specific. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of footnotes, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of excessive use of footnotes and suggests moving important content into the main body of the paper. The comment provides a specific example by suggesting that details around parameter settings can be moved to the appendix. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that footnotes are used excessively in the paper, which is distracting. It suggests that much of the content is important and should be moved into the main body of the paper. The reviewer provides a specific example by suggesting that details around parameter settings can be moved to the appendix. This suggestion is based on logical reasoning and common knowledge about the importance of main content versus supplementary information. However, the comment could be strengthened by providing more detailed examples or references to support the claim about the excessive use of footnotes. Overall, the claim is 4, as it provides a clear rationale but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the excessive use of footnotes. It suggests that much of the important content should be moved into the main body of the paper, which would improve the readability and clarity of the draft. The comment provides a specific example by suggesting that details around parameter settings could be moved to the appendix. This feedback is clear and actionable, offering the authors a concrete way to improve the organization and flow of their paper. However, it could be more helpful if it provided additional guidance on how to effectively integrate the content into the main body or how to prioritize which sections to focus on. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of zeroshot generation results in the paper is somewhat unusual and raises a question about its relevance. However, it does not provide explicit guidance on whether the authors should remove these results or explain their inclusion. The comment lacks concrete instructions on how to address this issue, leaving the authors uncertain about how to proceed. Therefore, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the inclusion of zeroshot generation results in the paper, suggesting that it is somewhat unusual and raises a question about its relevance. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its critique of the inclusion of zeroshot generation results, but without clear guidance on where this discussion should be placed, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of zeroshot generation results, suggesting that it is somewhat unusual and raises a curiosity about its relevance. However, the comment does not provide specific reasoning or evidence to support why this inclusion is unusual or why it might not be relevant. Without detailed justification or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results in the paper, suggesting that it might be somewhat unusual and raises a question about its relevance. While the comment acknowledges the interest of the experiments, it does not provide specific guidance or suggestions on how the authors might address this issue or justify the inclusion of zeroshot generation results. The feedback is 3 as it points out a potential weakness but lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific problem, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to update the caption or add references to the body text, but the comment lacks concrete details on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that \"OAA\" is never referenced in the body text and suggesting that there might be more content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"OAA\" is never referenced in the body text of Figure 3, suggesting that there might be more content in the appendix that is missing or that the caption is out of date. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be more content in the appendix that is missing or that the caption is out of date. While the comment highlights a specific problem, it lacks depth and does not provide actionable guidance or suggestions on how to address the issue. The authors are left with a clear indication of a problem but without detailed instructions on how to resolve it. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. It provides a specific suggestion to make this clarification by mentioning the reference in lines 2930. The action is clear and concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (2930) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of whether the proposed solution is a fix of [12] or a new PIC approach. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the authors need to clarify in the introduction that the proposed solution is a fix of [12], rather than a new PIC approach. The reviewer supports this claim by referencing specific lines in the paper (2930) where the proposed solution is introduced as a new PIC approach. This provides a clear and specific example of the issue, making the claim verifiable. However, the comment could be strengthened by referencing [12] directly or providing more context on why this distinction is important. Overall, the claim is 4, as it is supported by a specific example from the paper.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the introduction, noting that the proposed solution is presented as a new PIC approach rather than a fix of [12]. It provides a clear and actionable suggestion by recommending that the authors clarify this distinction in the introduction. This feedback is valuable as it helps the authors ensure that their work is accurately presented and understood by readers. However, the comment could be more helpful if it explained why this distinction is important or how it affects the overall contribution of the paper. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. However, it does not provide explicit instructions or suggestions on how the authors should address this question or investigate the impact of the GS module on the effective receptive field. The comment lacks concrete guidance on what specific analyses or experiments the authors should conduct to answer this question. As a result, the authors are left without clear direction on how to proceed with this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GS module\" and suggests that the effective receptive field can be computed from a reference [2]. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks a question about the effectiveness of the GS module and suggests that the authors investigate how the effective receptive field changed after applying it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the effectiveness of the GS module in propagating context information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information and suggests that the effective receptive field can be computed from a reference [2]. This is an interesting point that could lead to further exploration and analysis of the GS module. However, the comment lacks specific guidance or suggestions on how the authors might investigate or analyze the impact of the GS module on the effective receptive field. While it points out a potential area for improvement, it does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for further exploration but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network computing the value functions for the states during the finetuning stage. While the comment provides a clear action\u2014adding another head to the network\u2014it does not specify how to implement this addition or what specific changes are needed in the code or methodology. The authors are left to infer the details of execution, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the objective for the LSTM part, specifically mentioning the probabilities of actions and the finetuning stage. However, it does not specify which part of the paper this pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the objective and the potential approach for finetuning, but it lacks grounding as it does not explicitly mention where this information is discussed in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, and that the authors may add another head to the network during the finetuning stage. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the objective of the LSTM part, suggesting that it is the same for pretraining and finetuning. It also provides a possible solution by suggesting that the authors may add another head to the network during the finetuning stage to compute the value functions for the states. This feedback is 3 as it points out a potential weakness in the methodology and offers a direction for improvement. However, it could be more helpful if it provided more detailed guidance on how to implement this suggestion or what specific changes are needed. Overall, the comment offers some insight but lacks depth and actionable steps, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. While the comment implies that the authors should provide an explanation or clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors can infer that they need to address the question but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HRACG4RL,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind combining G4RL with HRAC and whether G4RL requires HRAC\"s regularization in the latent space. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind combining G4RL with HRAC and asks whether G4RL requires HRAC\"s regularization in the latent space. This is a relevant question that could help the authors understand the basis of their method and its potential limitations. However, the comment does not provide any suggestions or guidance on how to address this question or improve the draft. While it points out an area for clarification, it lacks actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works related to supervised, multilingual systems. While the comment implies that the authors should include this acknowledgment, it does not provide specific guidance on which works to mention or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related works\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works related to supervised, multilingual systems, providing clear guidance on what needs to be addressed in this section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works related to supervised, multilingual systems. However, it does not provide specific examples of these older works or explain why acknowledging them is important. Without additional context or references, the claim lacks verifiability, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works related to supervised, multilingual systems. While it identifies a potential gap in the literature review, it does not provide specific examples of older works to consider or explain why acknowledging them would be beneficial. The feedback is 3 as it points out an area for improvement, but it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer points out that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their results. The suggestion is implied and lacks concrete details, making it 3. The authors can infer that they need to reconsider their sampling strategy, but the comment does not offer specific steps or examples on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the results in Table 2, particularly the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The comment further explains the potential reason for this underperformance, based on the authors\" argument about the predictor\"s accuracy in the good subregion. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning by pointing out that if the predictor is accurate in the good subregion, increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling, especially when the performance of architectures in the good subregion is close. This reasoning is based on a logical assumption and provides a plausible explanation for the potential underperformance. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is 3, as it provides a reasonable argument but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment questions the results in Table 2, specifically the linear/exponentialdecay sampling, and suggests that it may underperform uniform sampling. The reviewer provides a logical reasoning based on the authors\" argument about the predictor\"s accuracy in the good subregion, suggesting that increasing the sampling probability for topperforming architectures should lead to better performance than uniform sampling. This feedback is 3 as it points out a potential issue with the results and provides a direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or what specific tests or analyses could be conducted to verify the authors\" claims. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights several issues with the time complexity of the proposed method, including the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the time complexity. The comment lacks concrete details on how to implement these improvements, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the time complexity, such as the potential for many users associated with a typical item and the larger number of hidden units compared to matrix factorizationbased methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. However, the comment does not provide specific examples or detailed reasoning to support these claims. It lacks references or examples to substantiate the assertion that the time complexity is high, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered 2, as it provides some evidence but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the proposed method, specifically noting the use of an itemoriented autoencoder, the elementwise function, and the number of hidden units. While it highlights these factors as contributing to the high time complexity, it does not provide specific suggestions or guidance on how the authors might address or mitigate this issue. The comment lacks actionable advice or detailed analysis, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is rated as 2, as it points out a potential weakness but does not offer sufficient guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the figures would be clearer if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback provides a specific action for the authors to take, which is to add this information to the figures to enhance clarity. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests that many of the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting what needs to be clarified, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they mentioned \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the figures. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that many of the figures would be more clear if they explicitly mention \"pretrained solution encoders & solution decoders,\" as there are multiple types of autoencoders. This feedback is 3 as it identifies a specific area for improvement in the clarity of the figures, which could enhance the readers\" understanding of the content. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why it is important. Additionally, it does not address other aspects of the paper, such as the content or methodology. Therefore, the comment is 3, as it points out a specific area for improvement but lacks comprehensive guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison with a NeRFbased method, specifically mentioning the recent Zero1to3 and pointe. Additionally, it questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment provides explicit actions to include comparisons and question the relevance, it lacks concrete details on how to implement these suggestions. The authors are given a clear direction but may need to infer the specifics of how to conduct these comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including comparisons with NeRFbased methods, specifically mentioning Zero1to3 and pointe. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment does not specify which part of the paper these comparisons should be included in or how the relevance of the occlusion experiment should be addressed. While the authors can infer that the suggestions relate to the experimental section, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting comparisons and questioning the relevance, but it lacks detailed guidance on implementation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a comparison with NeRFbased methods, specifically mentioning Zero1to3 and pointe, is missing. It also questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of Zero1to3 and pointe provides some context, but the lack of detailed justification or references makes the claim 3. The authors would need to infer the relevance and potential benefits of these comparisons, which may not be immediately clear. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting the inclusion of comparisons with NeRFbased methods, such as Zero1to3 and pointe. This suggestion is clear and can help the authors enhance the comprehensiveness and relevance of their evaluation. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that the method does not propose anything specific to occlusion. While the comment identifies areas for improvement, it could be more helpful if it provided additional context or examples of how these comparisons could be conducted. Overall, the comment is 4 as it offers clear and actionable suggestions for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the subscripts s and t in Figure 1, suggesting they should be 1 and 2. While the comment implies that the authors should provide an explanation and clarify the subscripts, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation and clarify the subscripts. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a brief explanation of \"multiaspect\" and questions the subscripts s and t in Figure 1, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful and questions the subscripts s and t in Figure 1. However, it does not provide any supporting evidence, reasoning, or references to justify why an explanation is necessary or why the subscripts should be changed. The comment lacks specificity and does not provide a clear rationale for the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement, namely the need for a brief explanation of the term \"multiaspect\" and the questionable subscripts s and t in Figure 1. While it provides clear guidance on what needs to be addressed, it lacks depth and does not offer detailed suggestions or examples on how to improve the explanation or clarify the subscripts. The feedback is 3 as it points out specific areas for improvement, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It explicitly requests a more detailed analysis of these aspects. While the comment identifies areas for improvement, it does not provide specific guidance on how to conduct the analysis or what aspects should be emphasized. The authors are left to infer that they need to provide more detailed information, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p,\" which likely refers to a specific parameter or value used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it raises questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek additional information, making them purely descriptive. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the methodology used to extract parts of sentences and documents, and whether the rules of extraction affect the experiment. It requests a more detailed analysis of these aspects, which could significantly improve the clarity and robustness of the paper. However, the comment lacks specific guidance or suggestions on how to conduct the analysis or what aspects should be emphasized. While it identifies areas for improvement, the feedback is 3 as it points out potential gaps in the methodology but does not provide detailed guidance on how to address them. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point asks for information about the computational requirements and runtime of the experiments, specifically mentioning the type of hardware used. This is an explicit request for additional details that the authors need to provide to improve the clarity of their draft. The action is clear and concrete, as it specifies exactly what information is needed and how it should be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for information about the computational requirements and runtime of the experiments, including the type of hardware used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what additional details are needed to improve the clarity of the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions asking for additional information about the computational requirements and runtime of the experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by asking for information about the computational requirements and runtime of the experiments. This is important as it can help the authors understand the feasibility and scalability of their experiments. However, the comment could be more helpful if it provided guidance on how to present this information or what specific details should be included. Overall, the feedback is actionable and provides a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the authors only apply the meta sampler in a decoupled way, specifically when the features are fixed. It also requests more discussion on this aspect and asks for clarification on when the authors start applying the meta sampler. While the comment implies that the authors should provide more information on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more discussion and clarification. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"meta sampler\" and the \"linear classifier,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on whether the meta sampler is applied in a decoupled way and requests more discussion on this topic. Additionally, it asks for clarification on when the meta sampler is applied, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler in a decoupled way and requests more discussion on this topic. It highlights a potential area for clarification and improvement in the paper, which is important for ensuring the accuracy and completeness of the methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or what specific aspects of the meta sampler should be discussed. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and encourages them to follow a cited AAAI paper on fairnessaware metrics like Equality Odds (EO). While the comment provides a specific recommendation to conduct more experiments and mentions a relevant paper, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of a vanilla metric and suggests conducting more experiments on datasets like COMPAS and Drug Consumption. It also references a specific paper, \"Exacerbating Algorithmic Bias through Fairness Attacks,\" which provides a clear context for the authors to understand the feedback. However, the comment lacks specificity regarding what aspects of the paper need improvement or how the authors should conduct these experiments. While it provides a clear direction, the lack of detailed guidance on execution makes it fully grounded but underspecific. Therefore, this comment aligns with category 4.", "verifiability_rationale": "The review point suggests that the authors should conduct more experiments on datasets like COMPAS and Drug Consumption, and mentions a specific paper for reference. However, the comment does not provide any specific reasoning or evidence to support why these additional experiments are necessary or how they would improve the paper. The mention of the cited paper suggests that the reviewer believes it could be relevant, but without further explanation or justification, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors use their own vanilla metric and lack related fairnessaware metrics like Equality Odds (EO). It suggests conducting more experiments on datasets like COMPAS and Drug Consumption, and references a specific paper for guidance. While the comment provides a clear direction for improvement, it lacks detailed guidance on how to implement these suggestions or what specific aspects of the paper should be revised. The feedback is 3 as it points out a gap in the paper but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to either state the content as a remark or move it to a Discussion section, or to remove it altogether. This provides a clear and direct action for the authors to take, ensuring that the content is either appropriately labeled or removed from the paper. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely whether the content is speculative or overly opinionated and suggests that it should be stated as a remark or moved to a Discussion section. This provides clear guidance on how to handle the content. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"L107114 seems speculative or overly opinionated.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (L107114) as potentially being speculative or overly opinionated. It suggests that this content should be either stated as a remark or moved to a Discussion section, or removed altogether. This feedback is clear and actionable, providing the authors with a concrete suggestion on how to address the issue of potentially overly subjective content. However, the comment could be more helpful if it explained why this section is considered speculative or overly opinionated, which would give the authors a better understanding of the rationale behind the suggestion. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. While the comment implies that the authors should include these baselines, it does not explicitly instruct them to do so. The action is concrete, as it specifies the baselines to consider, but it is somewhat vague because it does not provide detailed guidance on how to implement this suggestion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the results or methodology sections. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not direct. The comment is specific in suggesting the inclusion of these baselines, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these baselines are relevant or necessary for verifying the performance improvement. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered 5. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by making the changes suggested in the paper. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or why these specific baselines are relevant. While it points out a potential enhancement, it could be more helpful if it included more detailed reasoning or examples of how these baselines could be integrated into the evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness is essential, and that the authors should consider using a constant set of parameters to evaluate performance. The comment is clear and provides specific actions for the authors to take, such as conducting an analysis of h and using a constant set of parameters. The feedback is concrete and actionable, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"analysis of its influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the importance of understanding the value of h and its influence on performance, as well as the use of different hyperparameter sets per dataset. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the value of the neighborhood size h and its influence on the model\"s performance are missing elements in the paper. It suggests that this is a key parameter and that providing insights into its value and robustness is essential. The comment also mentions the use of different hyperparameter sets per dataset, which is not ideal. However, the comment does not provide specific examples or references to support the claim that the value of h is crucial or that the use of different hyperparameter sets is problematic. While the claim is logical and makes sense, the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two important missing elements in the paper: the value of the neighborhood size h and an analysis of its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It suggests that providing insights into the value of h and its robustness is essential, as it is a key parameter of the proposed strategy. Additionally, the comment points out that using different hyperparameter sets per dataset is not ideal and questions the authors on how performance varies with a constant set of parameters. This feedback is clear and actionable, as it directs the authors to address these missing elements and provide more comprehensive analysis. By addressing these points, the authors can significantly enhance the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. While the comment does not explicitly instruct the authors to conduct an analysis or provide specific guidance on how to address this issue, it does prompt the authors to consider the implications of missing data on their model. The action is implicit but clear, as the authors can infer that they need to explore the effects of imperfect multimodal data on their model. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically asking about the effects of missing modalities on the model\"s ability to construct higherorder interactions and polynomial tensors. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue is discussed. The authors can infer that it relates to the model\"s performance or analysis, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its inquiry about the impact of imperfect multimodal data. This aligns with a score of 3.", "verifiability_rationale": "The review point poses a question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities lead to compounding effects on the model\"s construction of polynomial tensors. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically asking whether missing modalities lead to compounding effects on the model\"s construction of polynomial tensors. This is a relevant and insightful question that could guide the authors in understanding the robustness of their model to missing data. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore its implications. While it points out a potential area for further investigation, it lacks actionable advice or detailed guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It provides a specific example of how this could be done by showing the frequency of these words in the dataset. The comment is explicit in its request for additional data analysis, providing concrete guidance on what the authors should do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The comment provides a specific example of how this could be done, making it clear and actionable. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. The reviewer provides a specific example of how this could be done, which is to show the frequency of these words in the dataset. This suggestion is based on logical reasoning and common knowledge about the nature of datasets and analysis. However, the comment lacks references or detailed justification for why this analysis is necessary or how it would enhance the paper. Therefore, the claim is 3, as it provides a logical suggestion but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the paper by requesting the inclusion of statistics on the times that negation or intensity words, such as \"nothing,\" actually take effect. It offers a clear example of how this could be done, which is to show the frequency of these words in the dataset. This feedback is actionable and can help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it provided additional context or justification for why this analysis is important or how it would contribute to the paper\"s overall contribution. Therefore, the comment is rated as 3, as it offers a clear direction for improvement but lacks depth and context."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the authors not verifying the stability of the OGEAug on OOD benchmarks, such as DrugOOD, where SPE is validated. However, it does not provide any guidance on how the authors should address this issue or what specific steps they should take to verify the stability. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"OGEAug\" and \"OOD benchmarks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of verification of the stability of the OGEAug on OOD benchmarks, such as DrugOOD, where SPE is validated. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not verify the stability of the OGEAug on OOD benchmarks, specifically mentioning DrugOOD and SPE. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors do not verify the stability of the OGEAug on OOD benchmarks, such as DrugOOD, where SPE is validated. This is a clear and actionable point, as it highlights a gap in the experimental evaluation that the authors should address to strengthen their work. However, the comment could be more helpful if it provided additional context or suggestions on how to conduct the verification or what specific aspects of the OGEAug should be tested. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. These suggestions are explicit and provide clear actions for the authors to take, such as considering these methods for experimental comparison. The comment also specifies the potential benefits of these approaches, making it clear what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests considering freezing some layers of the model while only training a few layers or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the model training or parameter efficiency sections, but this inference is not direct. The comment is specific in suggesting alternative methods to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers of the model or using LoRA, for parameterefficient model training. While the comment provides a logical reasoning for considering these methods, it lacks specific examples or references to support the claim that these methods are \"natural to think about\" or \"valuable for experimental comparison.\" This makes the claim 3, as the authors would need to infer the benefits and applicability of these methods themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods for parameterefficient model training, such as freezing some layers or using LoRA. This feedback is actionable and provides a clear direction for the authors to explore additional approaches that could enhance their experimental comparison. By suggesting these methods, the reviewer highlights a potential area for improvement that could enhance the rigor and comprehensiveness of the study. However, the comment could be more helpful if it provided specific examples or references to these methods, which would guide the authors more directly in implementing these suggestions. Overall, the comment is 4 as it offers a clear and actionable direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their work to strong baselines that use coordinates. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the paper. The suggestion is concrete, as it specifies the exact content that needs to be included, making it 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section and comparing to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is currently located in, making it weakly grounded. The comment is specific in its request to expand the related work section and compare to strong baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing to strong baselines that use coordinates. However, it does not provide any supporting evidence, reasoning, or examples to justify why this expansion is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests expanding the related work section and comparing the paper to strong baselines that use coordinates. This feedback is 3 as it identifies a specific area for improvement, namely expanding the related work section to include more detailed comparisons. However, the comment lacks depth and does not provide specific guidance on how to structure the expanded section or what aspects to focus on in the comparison. While it points out a potential area for improvement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the experiments should be expanded to include multiple seed experiments, which would provide a more robust evaluation. This suggestion is clear and concrete, as it specifies the exact action the authors need to take to improve their draft. The comment provides a specific direction for enhancing the experimental design, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Single Seed Experiments\" and the \"experiments in the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for multiple seed experiments to provide a more robust evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This claim is 3 as it logically argues that multiple seed experiments would offer a more comprehensive assessment. However, it lacks specific examples or references to support the claim, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental design, specifically the use of single seed experiments, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it directs the authors to expand their experimental design to include multiple seeds. However, it could be more helpful if it provided specific guidance on how to implement this change or what additional insights could be gained from multiple seed experiments. Overall, the comment is 4 as it highlights a critical area for improvement and offers a concrete suggestion for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, asking for clarification on the motivation behind this choice. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, indicating a lack of clarity in the motivation behind this choice. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification on the motivation behind the choice, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, suggesting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is problematic or unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a potential lack of clarity in the paper regarding the rationale behind this choice. While the comment identifies an area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue or clarify their motivation. The feedback is 3 as it points out a potential weakness, but it could be more beneficial with additional guidance on how to improve the explanation or rationale. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, making it less accessible for many potential users. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to make the method more accessible or suggestions for alternative approaches. As a result, the authors are left without any clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed method, noting that an entire multiGPU setup is required for optimizations, which makes it less accessible for many potential users. However, it does not specify which part of the paper this issue is discussed in, nor does it provide details on how this requirement affects the accessibility of the method. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible for many potential users. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the accessibility of the method. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue with the accessibility of the proposed method, noting that an entire multiGPU setup is required for optimizations. This is a relevant point that could impact the practicality and applicability of the method for many potential users. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or suggesting ways to make the method more accessible. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing citation for the public skipgram data set in L425. This is a clear and direct action for the authors to take, as it specifies the exact part of the paper that needs to be revised. The comment provides concrete guidance on what needs to be added, making it 5. Authors know exactly what to do to address this issue, ensuring that the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the missing citation for the public skipgram data set. This provides clear guidance on what needs to be corrected in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. This is a factual statement that does not require any verification or justification. It is a request for clarification or correction, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the missing citation for the public skipgram data set in L425. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. By pointing out this oversight, the comment provides valuable guidance for the authors to ensure their work is properly cited and referenced. However, the comment could be more helpful if it included suggestions on how to properly cite the data set or provided additional context on its relevance to the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. It provides a clear and concrete action for the authors to take, which is to compare their system with another that captures semantics. However, the comment does not specify which aspects of the current system should be compared or how to implement the comparison. While the action is explicit, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, potentially using Ref[2] as a baseline. However, it does not specify which part of the paper this comparison should be made, such as a specific section or experiment. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not direct. The comment is specific in suggesting a potential baseline and a comparison approach, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, potentially using Ref[2] as a baseline. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to be considered actionable. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that also captures semantics, potentially using Ref[2] as a baseline. This is a constructive suggestion that could help the authors improve the evaluation of their system by providing a more comprehensive comparison. However, the comment lacks specific guidance on how to implement this comparison or which aspects of the current system should be compared. While it identifies a potential area for improvement, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the data used for training, validating, and testing. However, it does not provide explicit guidance on how the authors should address this issue or what specific details should be included. The comment implies that the authors should clarify the data sources, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the quantitative results, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the quantitative results, specifically asking about the data used for training, validating, and testing. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the results are unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the quantitative results, specifically questioning the clarity of the data used for training, validating, and testing. This is a relevant point that could impact the reproducibility and interpretability of the results. However, the comment lacks depth and does not provide specific suggestions or examples on how the authors might clarify this aspect of their work. While it points out a potential issue, it does not offer actionable guidance or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset. It suggests that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not provide specific guidance on how the authors should address these issues or what steps to take to improve the model. The comment lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the assumptions and learning difficulties, but without clear grounding, the authors cannot confidently determine which part of the paper needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the assumptions are not met or that learning difficulties exist. Without such evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the model\"s inability to fully identify the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there could be learning difficulties. It prompts the authors to consider whether these issues are related to assumptions or learning difficulties. While the comment identifies a potential problem, it lacks specific guidance or suggestions on how the authors might address these issues or improve their model. The feedback is 3 as it points out a potential area for improvement but does not provide detailed guidance or actionable steps. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment requests that the authors provide a rationale for why their SE framework can help improve the system and how it does so. It suggests that the authors should not just present their achievements but also explain why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not explicitly instruct the authors to use this reference or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their approach and its benefits. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4\" and \"2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a rationale and explanation of how the SE framework can help improve the system. The reference to [1] Luo, et al. provides additional context and guidance on what kind of explanation is expected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale and explanation behind the SE framework\"s ability to improve the system. It suggests that the authors should provide a detailed explanation of how the framework works and why it is effective. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. However, the comment does not provide specific examples or detailed reasoning from the referenced work to support the claim. While the reference offers a starting point, the comment lacks sufficient evidence or detailed justification to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed evidence or reasoning to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of a clear rationale and explanation for why the SE framework can help improve the system. It suggests that the authors should not just present their achievements but also provide a detailed explanation of why and how they managed to achieve them. The reviewer references a specific work, [1] Luo, et al. \"Neural architecture search with gbdt,\" which provides a framework for neural architecture search. This reference could be helpful for the authors in understanding how to provide a more comprehensive explanation of their approach. However, the comment does not offer specific guidance or examples on how to address this issue, leaving the authors to infer the necessary steps. While it highlights an important area for improvement, the comment could be more helpful with additional suggestions or examples. Therefore, it is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or what specific steps to take to improve the generalization of the system. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its suggestion that the system should be able to generalize to more views, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. However, it does not provide any supporting evidence, reasoning, or references to justify why this limitation is problematic or how it could be addressed. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the limitation of the approach to only two views and suggests that the system should be able to generalize to more views without much difficulty. While it identifies a potential weakness in the approach, it lacks specificity and does not provide actionable guidance or suggestions on how to address this limitation. The comment is 3 as it points out an area for improvement, but it does not offer detailed advice or examples on how to enhance the generalization of the system. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It notes that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to adapt the metrics or suggest alternative approaches for evaluating continual learning in such settings. As a result, the authors are left without clear direction on how to improve their draft in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the metrics used for evaluating continual learning, loss after switch, and recovery time after switch, which are key aspects of the paper. It also specifies the issue by pointing out that these metrics would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the metrics used for evaluating continual learning are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This claim is 3 as it provides a logical reasoning based on the nature of the metrics and their applicability to specific scenarios. However, the comment lacks specific examples or references to support the claim, which would strengthen the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically mentioning the loss after switch and recovery time after switch. It points out that these metrics are suitable for the datasets provided but would not be applicable in settings where task boundaries are not known or hard task boundaries are not identifiable. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation methodology, which could impact the generalizability of the results. However, the comment could be more helpful if it provided suggestions on how to address this limitation or offered alternative metrics that might be more suitable for the paper\"s context. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement, but it lacks detailed guidance on how to address the issue."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. While the comment identifies an area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind the user decoder\"s information usage but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"user decoder\" and \"agent decoder,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the user decoder only uses information up to time step t and does not consider information from all time steps. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the user decoder\"s use of information from the agent decoder, specifically asking why it only uses information up to time step t and does not consider information from all time steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the user decoder\"s use of information from the agent decoder, specifically questioning why it only uses information up to time step t and does not consider information from all time steps. This feedback identifies a potential area of confusion or inconsistency in the paper, prompting the authors to clarify their methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional information might be needed to clarify the rationale. While it points out a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the missing discussion on arbitrary hyperparameter \u03b3, including how to set it in practice for a given graph and analyzing its sensitivity. This provides a clear and direct action for the authors to take, which is to include this discussion in their paper. The comment also highlights the importance of this discussion for readers to understand the practical implications of the work. Therefore, the action is explicit and concrete, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion on \"arbitrary hyperparameter \u03b3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the discussion on how to set the hyperparameter in practice and the sensitivity analysis of this hyperparameter. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion on \"arbitrary hyperparameter \u03b3\" is missing, including how to set it in practice and analyzing its sensitivity. This claim is 3 as it highlights a specific omission in the paper, but it lacks detailed justification or examples to fully substantiate the importance of this discussion. The authors may need to infer the significance of this omission themselves, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the lack of discussion on \"arbitrary hyperparameter \u03b3,\" including how to set it in practice and analyzing its sensitivity. This feedback is clear and actionable, as it points out a critical area that needs to be addressed in the paper to ensure that readers can understand and replicate the work. By highlighting the importance of this discussion, the comment provides the authors with a concrete direction for improving their draft. However, it could be more helpful if it offered suggestions on how to integrate this discussion into the paper or provided examples of how to conduct the sensitivity analysis. Overall, the comment is 4 as it effectively guides the authors on a specific area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should consider a controlled baseline that ablates heads at different locations in the model to address the confounding factor of head location in the induction and FV heads. This feedback provides a clear and explicit action for the authors to take, which is to implement a controlled baseline that can help isolate the effect of head location on ICL performance. The comment is specific in its suggestion and provides concrete guidance on how to proceed, making it 5.", "grounding_specificity_rationale": "The comment suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. It suggests that a controlled baseline should be considered to isolate the effect of head location. However, the comment does not specify which part of the paper discusses the induction and FV heads or where the controlled baseline should be implemented. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding as it does not explicitly mention sections or figures. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be due to the confounding factor of head location within the model. The reviewer proposes a controlled baseline to isolate the effect of head location. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of head location and the need for a controlled baseline, which could be challenging without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confounding factor in the difference in ICL performance when ablating induction heads versus FV heads, suggesting that the location of these heads within the model could be a contributing factor. It provides a specific suggestion to address this issue by proposing a controlled baseline that ablates heads at different locations in the model. This feedback is clear and actionable, offering a concrete step for the authors to take in order to improve their draft. By suggesting a controlled baseline, the comment provides a direct and meaningful way for the authors to test and validate their hypothesis, making it 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, as they are instructed to add this section to their draft. The comment is specific and concrete, giving the authors a clear idea of what needs to be done to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely a section on synonym identification that describes how the multiplechoice task is approached. This provides clear guidance on what needs to be added to the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under similarity measurement, which would describe how the multiplechoice task is approached. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, namely the absence of a section on synonym identification under similarity measurement. This feedback is clear and actionable, as it directs the authors to add a section that would provide important context and explanation for the multiplechoice task. By addressing this gap, the authors can enhance the clarity and completeness of their paper. However, the comment could be more helpful if it offered suggestions on how to structure or present this section, or provided examples of what should be included. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the action is implicit, it is concrete because it specifies what needs to be added (an overview of the workflow and the model). This provides a clear direction for the authors to enhance their draft by including this information. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, nor does it provide details on what aspects of the workflow and model should be covered. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning or examples to support why this overview is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary information to guide the authors in making improvements. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. This feedback is 3 as it identifies a potential area for improvement in presenting the key components of the paper. However, it lacks specific guidance on what aspects of the workflow and model should be covered or how this overview should be structured. While it points out a need for clarity, the comment does not provide detailed suggestions or examples to help the authors effectively implement this feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It also mentions that this information cannot be computed accurately without the same runtime as required for ridge regression. The reviewer suggests that this issue is not discussed in the paper and raises a similar concern regarding the surrogate sketch. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors can infer that they need to discuss this issue but are not given clear instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to know the statistical dimension d_lambda of the design matrix A and the issue with computing it accurately without the same runtime as ridge regression. It also mentions a similar issue with the surrogate sketch. This allows the authors to accurately identify the parts of the paper being addressed, such as the sections discussing debiasing and surrogate sketch computation. The comment is specific because it clearly outlines the problem with the approach and suggests that it may not achieve its intended purpose due to the computational requirements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the debiasing approach requires knowledge of the statistical dimension d_lambda of the design matrix A, which cannot be computed accurately without the same runtime as ridge regression. The reviewer suggests that this issue may defeat the purpose of the approach and points out that it is not discussed in the paper. The comment is 3 as it provides a logical reasoning for the claim, but it lacks specific examples or references to substantiate the claim fully. The authors would need to further explore the issue and provide evidence to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing approach, specifically the need to know the statistical dimension d_lambda of the design matrix A. It points out that this information cannot be computed accurately without the same runtime as required for ridge regression, which could lead to bias and defeat the purpose of the approach. The comment also notes that this issue is not discussed in the paper. While the comment highlights a significant concern, it lacks specific suggestions or guidance on how the authors might address this issue or discuss it in the paper. The feedback is 3 as it alerts the authors to a potential problem but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3 as the expected quantities are scalars but shown as a vector. This is a clear and direct action that the authors can take to address the issue. The comment provides a specific guidance on how to modify the figure, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the redefinition of the figure to reflect the expected quantities as scalars rather than a vector. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the figure should be redefined as the expected quantities are scalars but shown as a vector. However, it does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for improving the clarity of Figure 3. It points out that the expected quantities, which are scalars, are shown as a vector, and suggests redefining the figure to accurately reflect the data. This feedback is clear and direct, giving the authors a clear path to enhance the clarity and accuracy of their presentation. By addressing this issue, the authors can improve the readability and comprehensibility of their work, making the comment 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance on how to improve the experiment setup or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions on how to enhance the experiment setup, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not specify which part of the paper this pertains to, such as the experimental section or the results section. The authors cannot confidently determine which part of the paper is being addressed, making this comment 1. Additionally, the comment lacks specificity as it does not detail what questions arise or how the experiment setup could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the ablations deserve better experiment setup due to the many questions that arise. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the ablations deserve better experiment setup, as many questions arise. However, it does not provide specific guidance or examples on what aspects of the experiment setup need improvement or how to address the questions that arise. Without actionable advice or detailed suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful, as it lacks depth and specificity in its feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. While the comment implies that the authors should conduct additional experiments, it does not specify which experiments to conduct or how to conduct them. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about the proposed models being particularly useful for learning representations for lowfrequency words, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of empirical evidence to test the hypothesis and suggests exploring this aspect further. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed models are particularly useful for learning representations for lowfrequency words but lacks empirical evidence to support this claim. The reviewer suggests that it would be interesting to explore this aspect further, implying that the absence of empirical evidence is a significant issue. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to make a significant effort to understand and address the issue, as the comment does not provide enough guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of empirical evidence to support the argument that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should explore this aspect further by providing empirical evidence to test the hypothesis. This feedback is clear and actionable, as it points out a critical area for improvement and offers a specific direction for the authors to enhance their draft. However, the comment could be more helpful if it provided examples of what kind of empirical evidence would be useful or how to conduct the experiments. Overall, the comment is 4 as it effectively guides the authors on how to strengthen their paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. It specifically mentions that the resolution of the 3D voxel should be considered and that the study should be included in Sec4.2. The comment provides a clear and explicit action for the authors to take, which is to conduct a study comparing the global feature with different voxel resolutions. The suggestion is concrete and provides a specific direction for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the study of the global feature and its resolution, and suggests comparing it with different resolutions of voxel features. This provides clear guidance on what the authors should consider in their analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the study of global features should include a comparison with different resolutions of voxel features. The reviewer provides a logical reasoning by explaining that methods like PiFu avoid using voxellike features due to their high computational and memory cost. The comment also suggests that studying the importance of the global feature in Sec4.2 would be more convincing by comparing it with different resolutions of voxel features. However, the comment lacks specific examples or references to support the claim about the computational and memory cost of voxel features. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3, as it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a study comparing the importance of the global feature with different resolutions of voxel features. It highlights the potential issue of high computational and memory cost associated with voxellike features and suggests that studying the global feature at different resolutions could be more convincing. This feedback is valuable as it guides the authors to a specific area for improvement and provides a clear direction for enhancing the paper\"s analysis. However, the comment could be more helpful if it included examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4 as it offers a concrete suggestion for improving the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing and highlights the need for understanding the cases where the model fails. This provides a clear and direct action for the authors to include an error analysis in their draft. The comment is specific about what is missing and why it is important, making it 5. The authors know exactly what needs to be added to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the error analysis on the movie dataset, and why it is important for other researchers to understand the cases where the model fails. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper\"s contribution. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance of this omission. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers who may continue this work. However, the comment does not provide specific guidance on how to conduct the error analysis or what aspects should be covered. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer recommends exploring development set trends with respect to these hyperparameters. While the comment implies that the authors should investigate these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these trends. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in seeing trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests exploring development set trends with respect to these hyperparameters, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to see trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters. However, the comment lacks specific examples or detailed reasoning to support why these trends are important or how they could be explored. Without additional context or evidence, the claim is 3, as it requires the authors to infer the significance of the trends and how to investigate them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to see trends in the data, particularly regarding the behavior of PM+CL compared to PM or CL alone. The reviewer suggests exploring development set trends with respect to these hyperparameters, which could provide valuable insights into the behavior of the models. This feedback is clear and actionable, as it directs the authors to investigate a specific area that could enhance the understanding and interpretation of their results. However, the comment could be more helpful if it included suggestions on how to explore these trends or what specific analyses might be useful. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of Figure 5, noting that there are many lines on top of each other, making it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies what needs to be added or clarified, but it is somewhat vague in terms of how to implement these changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the difficulty in understanding the figure due to the overlapping lines and suggests reporting additional metrics like flops or model size to provide a more concrete understanding of the results. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to the overlapping lines and suggests that the authors could report additional metrics like flops or model size to provide a more concrete understanding of the results. However, the comment does not provide specific examples or detailed reasoning to support why the current presentation is unclear or how the suggested metrics would improve clarity. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of Figure 5, noting that the overlapping lines make it difficult to understand. It also suggests that the authors could report additional metrics, such as flops or model size, to provide a more concrete understanding of the results. This feedback is clear and actionable, as it directs the authors to improve the clarity and comprehensiveness of their figures and metrics reporting. However, the comment could be more helpful if it provided specific guidance on how to present these additional metrics or how to improve the figure\"s clarity. Overall, the comment is 4 as it offers concrete suggestions for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment mentions the \"questions section below,\" which implies that it is referring to a specific part of the paper. However, without explicit mention of a section or page number, the authors cannot confidently determine the exact part being addressed. The comment also lacks specificity regarding what details are missing or how they should be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"some details of the proposed method are missing,\" but it does not provide specific examples or reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to identify which details are missing or how they could address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that some details of the proposed method are missing, as noted in the questions section below. However, it does not provide specific details on what these missing details are or how they affect the paper. Without this information, the authors are left without actionable guidance on how to address the issue. The comment lacks depth and specificity, making it 2 for the authors in improving their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends simplifying the description and explaining the architecture and computations better. It also suggests reducing Figure 7, Section 8, and specific lines (3964) to gain more space. These explicit actions provide clear guidance on what the authors need to do to improve the draft. The comment is concrete, as it specifies which parts of the paper need simplification and reduction, making it 5.", "grounding_specificity_rationale": "The comment addresses the issue of the paper being too dense and difficult to follow, suggesting that it needs simplification and better explanation of the architecture and computations. It provides specific examples of sections and lines that could be reduced to gain more space. However, it does not explicitly mention which sections or lines should be reduced, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as simplifying the description and explaining the architecture and computations better. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to understand the concepts and contributions. It suggests simplifying the description and explaining the architecture and computations better. The comment provides specific examples of sections and lines that could be reduced to gain more space. This claim is 3 as it offers a logical reasoning for simplifying the paper, but it lacks detailed justification or references to support the claim that the paper is too dense. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is too dense and difficult to follow. It suggests simplifying the description and explaining the architecture and computations better, which is a crucial improvement for the clarity and accessibility of the paper. The comment provides specific examples of sections and lines that could be reduced to gain more space, offering actionable guidance for the authors. However, the comment could be more helpful if it provided additional suggestions on how to simplify the description or explained why these sections are particularly challenging to understand. Overall, the comment is 4 as it effectively points out a significant weakness and offers concrete steps for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of comparison to be made, but it is somewhat vague in terms of how to implement it. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests a specific comparison to be made regarding the evaluation of oversmoothing, particularly with respect to the EIGNN model and variants that focus on dealing with oversmoothing, such as GCNII. However, it does not specify which part of the paper this evaluation is currently included in, making it weakly grounded. The comment is specific in suggesting a particular comparison to be made, but without explicit references to sections or figures, the authors may struggle to identify the exact location of the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation on oversmoothing should include a comparison with the EIGNN model under standard settings on realworld datasets, specifically in relation to variants that focus on dealing with oversmoothing, such as GCNII. However, the comment does not provide any supporting evidence, references, or detailed reasoning to justify why this comparison is necessary or how it would benefit the evaluation. Without additional context or examples, the claim remains 3, as it lacks the necessary support to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a specific comparison that could be made in the evaluation of oversmoothing, specifically by comparing the EIGNN model with variants that focus on dealing with oversmoothing, such as GCNII. This feedback is actionable as it provides a clear direction for the authors to enhance their evaluation by including a comparison that could offer insights into the performance of the EIGNN model under standard settings on realworld datasets. However, the comment could be more helpful if it provided additional context or examples of how this comparison might be conducted or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to add a separate section or subsection to introduce the inference strategy, but the comment lacks concrete details on what this section should include or how to implement it. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach method\" and the \"inference strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the lack of a separate part or subsection to introduce the inference strategy, particularly regarding the use of multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting the absence of a separate part or subsection to introduce the inference strategy, particularly regarding the use of multiple prompts in the test stage. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing a dedicated section to explain the inference strategy. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects to cover. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that Figure 4 is confusing and notes that the columns are not explained in the text or caption. This provides a clear and direct action for the authors to take, which is to clarify the meaning of the columns in the figure and its caption. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the confusion regarding the meaning of the columns in the figure and the lack of explanation in the text or caption. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The comment claims that Figure 4 is confusing and points out that the columns are not explained in the text or caption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it is confusing and that the columns are not explained in the text or caption. This feedback is clear and actionable, as it directs the authors to clarify the meaning of the columns and provide explanations in the text or caption. By addressing this issue, the authors can improve the clarity and accessibility of their figure, making it more understandable for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the columns or offered examples of how similar figures have been effectively explained. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, specifically questioning whether the MaxGapTop2UCB algorithm is better than others based on the Streetview experiment. It also points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed in the paper. The authors are left to infer that they need to provide more detailed discussions and address the computational complexity, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Streetview experiment\" and the \"realworld applications of this new problem setting,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the conclusion from the Streetview experiment and asking about the computational complexity of the proposed algorithms in the context of ranking problems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the conclusions drawn from the Streetview experiment and the realworld applications of the problem setting. It suggests that the authors should discuss the results more and questions whether MaxGapTop2UCB is better than other algorithms. The reviewer also points out the complexity of the proposed algorithms in the context of ranking problems, which is a valid concern. However, the comment lacks specific examples or references to support the claim about the complexity or the need for more discussion on the results. This makes the claim 3, as it provides some reasoning but requires further elaboration to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable critique of the paper, identifying areas where the authors could improve the discussion and clarity of their results. It questions the conclusion drawn from the Streetview experiment and suggests that the authors should discuss the results more thoroughly. Additionally, it points out the lack of clarity regarding the realworld applications of the problem setting and the computational complexity of the proposed algorithms in the context of ranking problems. While the comment highlights important areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or what aspects of the discussion should be expanded upon. Overall, the comment is 4 as it guides the authors toward improving the clarity and depth of their analysis and discussion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. The reviewer implies that more explanations are needed to understand the discrepancy. However, the comment does not provide explicit guidance on what specific explanations should be given or how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to provide more information but are not given concrete steps to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that the results are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for more explanations, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or comparisons, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the low results obtained using only ML in the ablation experiments, suggesting that they are lower than those of simple early methods like fCLSWGAN and fVAEGAND2. This prompts the authors to consider providing more explanations for the discrepancy. However, the comment does not offer specific suggestions or guidance on what kind of explanations might be helpful or how the authors might address this issue. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. However, it does not provide explicit guidance on how to include ablation analysis or what specific components should be analyzed. The action is implicit and somewhat vague, as the authors are left to infer that they need to include ablation analysis but without clear instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of ablation analysis in the main paper, which makes it difficult to pinpoint the source of the small performance gain. However, it does not specify which part of the paper lacks this analysis, such as the specific sections or experiments where it should be included. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in identifying the issue of lacking ablation analysis, but without explicit references to sections or experiments, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of ablation analysis, which makes it difficult to pinpoint the source of the small performance gain. This is a critical observation that could significantly impact the authors\" understanding of their work and its implications. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which components should be analyzed or how to conduct the ablation analysis. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a critical issue but lacks depth and specificity in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any guidance or suggestions on how the authors should address this observation or what implications it might have for their work. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2,\" which likely refers to a specific figure or table in the paper. This allows the authors to accurately identify the part of the paper being addressed. However, the comment lacks specificity as it does not provide details on what aspect of the noise rate of similarity labels compared to class labels is problematic or how it affects the paper\"s conclusions. Without additional context or suggestions for improvement, the authors may find it challenging to address the issue effectively. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand or verify the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). However, it does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors may not know how to address this observation or what implications it might have for their work. Therefore, the comment is 1, as it lacks actionable advice or constructive feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a concern about the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It suggests that the base model should be trained on the original dataset along with the adversarial set to better highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to modify the experimental design to include the comparison between the original dataset and the mixture. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This provides clear guidance on how to improve the experiment and make it more convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is interesting but not wellverified by the designed experiment. It supports this claim by referencing Section 3.1, where it is mentioned that models in conventional methods are trained on the original training set in addition to the generated adversarial examples, while the base model is trained on the adversarial set only. The reviewer suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This reasoning is logical and provides a clear justification for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of this comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the verification of the hypothesis, specifically noting that the experiment is not welldesigned. It points out that the base model is trained on the adversarial set only, while conventional methods train on the original dataset in addition to the generated adversarial examples. The comment suggests that comparing the model trained on the original dataset with that trained on the mixture would highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, providing the authors with a specific and concrete suggestion for improving the experiment and making it more convincing. By addressing this issue, the authors can enhance the credibility and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the CNN experiments are not fully convincing, but it does not provide any specific details or examples to support this claim. There is no guidance on what aspects of the experiments are lacking or how they could be improved. Without explicit or implicit suggestions for improvement, the authors are left without a clear understanding of what changes are needed to enhance the credibility of their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions the CNN experiments, but it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. It also lacks specificity as it does not detail what aspects of the experiments are not convincing or how they could be improved. Without clear guidance on what needs to be addressed, the authors cannot effectively address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment mentions that the CNN experiments are not convincing, but it does not provide any specific details or examples to support this claim. Without further explanation or guidance, the authors are left without a clear understanding of what aspects of the experiments are lacking or how they could be improved. This lack of actionable feedback limits the usefulness of the comment, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper and suggests that if the authors computed these results themselves, they should mention it. This provides a clear and direct action for the authors to take, ensuring that they either report the results from the original paper or acknowledge their selfcomputation. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results were taken from the original paper or computed by the authors themselves. This provides clear guidance on what needs to be corrected or clarified in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper, suggesting that the authors should mention if they computed these results themselves. The comment is 3 as it provides a specific reference to the original paper and model, which could help the authors verify the claim. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as explaining why the results should be reported or how the authors\" selfcomputation affects the validity of the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the results for model (3) (Chung et al. 2016) for CsEn in Table 1 are not reported in the paper. It suggests that if the authors computed these results themselves, they should mention it. This feedback is clear and actionable, as it provides a direct and specific suggestion for the authors to either report the results from the original paper or acknowledge their selfcomputation. By addressing this issue, the authors can improve the accuracy and transparency of their work. However, the comment could be more helpful if it provided additional context or explanation about why this issue is important or how it affects the overall paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer implies that discussing how to design prompts effectively is crucial. However, the comment does not provide specific guidance on how to achieve this or what aspects of prompt design should be emphasized. The action is implicit and somewhat vague, as the authors can infer that they need to focus on prompt design but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. However, it does not specify which part of the paper discusses these prompting methods or where the authors should focus their attention. The authors can infer that it relates to sections discussing prompt design, but this inference is not direct. The comment is specific in its suggestion to discuss prompt design effectively, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. The reviewer argues that different prompts may result in varying performance outcomes, emphasizing the importance of discussing how to design prompts effectively. However, the comment lacks specific examples or references to support the claim that different prompts lead to varying performance outcomes. This makes the claim 3, as the authors would need to infer the importance of prompt design and the potential impact on performance outcomes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that more emphasis should be placed on prompt design, as the paper introduces several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, as it directs the authors to focus on a critical aspect of their work that could significantly impact its impact and effectiveness. However, the comment could be more helpful if it provided specific suggestions or examples of effective prompt design strategies. Overall, the comment is 4 as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the suggestion is clear and provides a specific example of what to compare, it does not offer detailed guidance on how to implement this comparison or what aspects to focus on. The authors are given a clear direction but may need to infer additional details to fully execute the action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this comparison should be included in, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. The comment is specific in suggesting a comparison with SoTA approaches, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests a specific improvement by recommending that the authors compare their results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is actionable and provides a clear direction for enhancing the paper by demonstrating the relevance and impact of the authors\" work in the broader context. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what aspects to focus on. Overall, the suggestion is valuable but could be more comprehensive with further elaboration. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if adaptive is good, it would be better to use an adaptive method for subset selection. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the rationale behind using freezing but are not given specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MLS selection,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of freezing in MLS selection and suggesting that adaptive methods could be used instead. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that adaptive methods could be used instead. However, it does not provide any supporting evidence, reasoning, or references to justify why adaptive methods are preferable or how they would improve the selection process. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in making improvements. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the use of freezing in MLS selection and suggests that adaptive methods could be a better approach. This feedback prompts the authors to reconsider their methodology and potentially improve their selection process. However, the comment lacks specific guidance or suggestions on how to implement the adaptive method or what aspects of the current methodology might be problematic. While it identifies an area for improvement, it does not provide detailed instructions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment is specific in its request for a detailed plan, which provides a concrete direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations mentioned in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more detailed plan on how to address the limitations in future work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they intend to address the limitations mentioned in the paper. However, it does not provide any specific examples or reasoning to support why this is necessary or how it would improve the paper. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they intend to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to provide a more comprehensive approach to addressing the drawbacks. However, the comment could be more helpful if it offered specific suggestions on what elements of the plan should include or how to prioritize these limitations. Overall, the comment is 4 as it guides the authors toward a more comprehensive approach to addressing the limitations, but it could be more detailed to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should perform a similar analysis on the proposed knowledgeCLIP model as done in existing work that combines text and KGs. This feedback implies that the authors should conduct a closelyrelated analysis to test the robustness of their model, specifically by adding negation or changing entities in the text. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear direction for further exploration and experimentation. The action is explicit and concrete, as it specifies the type of analysis to be conducted, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed knowledgeCLIP model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests conducting a closelyrelated analysis to test the robustness of the model, such as adding negation or changing entities in the text. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed knowledgeCLIP model should be tested for robustness by conducting a closelyrelated analysis, similar to existing work that combines text and KGs. The comment references an external work, providing a specific example of a related analysis. This reference supports the claim that such an analysis would be valuable for understanding the model\"s robustness. However, the comment does not provide detailed reasoning or evidence to fully substantiate why this analysis is necessary or how it would benefit the paper. While the reference provides some support, the comment could be strengthened by further explanation or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct a closelyrelated analysis on the proposed knowledgeCLIP model. It references existing work that combines text and KGs, suggesting that the authors should perform a similar analysis to test the robustness of their model. This feedback is valuable as it encourages the authors to explore and validate their model\"s capabilities, which could enhance the paper\"s contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, and questions the reason for this choice. It also suggests adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides explicit actions for the authors to consider, such as using the variance for improvement and changing the notation to be consistent. These actions are concrete and provide clear guidance on how to address the issues raised. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 3\" and \"Alg. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of p m in the numerator and p c in the denominator, suggesting that the authors consider adding the variance for further improvement. Additionally, it provides a specific suggestion to use \u03bc g instead of \u03bc f, which is consistent with Eq. The comment is clear and provides detailed guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the use of p m in the numerator and p c in the denominator in Eq. 3, questioning the reason for this choice. It suggests adding the variance for further improvement and recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. The comment provides a logical reasoning for the suggestion to use \u03bc g, but it lacks specific examples or references to support the claim about the variance or the use of \u03bc g. This makes the claim 3, as the authors would need to further explore the reasoning and potential benefits of these suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation in Eq. 3, where p m is used in the numerator and p c in the denominator. It questions the reason for this choice and suggests that the authors consider adding the variance for further improvement. Additionally, it recommends using \u03bc g instead of \u03bc f, which is consistent with Eq. This feedback is clear and actionable, as it provides specific guidance on how to address the notation issue and improve the paper. By suggesting alternative approaches and providing a rationale for the changes, the comment offers valuable insights that can help the authors enhance their draft. Therefore, it is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should provide a more comprehensive discussion about the computational complexity of the proposal and raises a question about whether the approach becomes prohibitive in certain settings. While the comment implies that the authors should address these points, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed discussion and address the computational complexity. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"additional cost\" and the \"computational complexity of the proposal,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be discussed, namely the comprehensive discussion of computational complexity and the potential prohibitive nature of the approach in certain settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost of the proposed approach and questions whether it becomes prohibitive in certain settings. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the computational cost of the proposed approach. It suggests that the paper should provide a more comprehensive discussion about the computational complexity and raises a question about whether the approach becomes prohibitive in certain settings. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are given a direction to consider but are not provided with actionable steps or detailed advice on how to improve their discussion. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to clarify how novel values in the test set are handled for clarity. This is a direct and concrete action, as it specifies a specific area that needs more explanation. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of how novel values in the test set are handled. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment suggests that the authors clarify how novel values in the test set are handled for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where clarity is needed, specifically regarding how novel values in the test set are handled. By pointing out this gap, the comment provides the authors with a clear direction for improving the draft. However, the comment could be more helpful if it offered suggestions on how to clarify this aspect or provided examples of how other studies handle similar issues. While it highlights an important area for improvement, the feedback could be more comprehensive to be fully beneficial. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a discussion of related work or a comparison with existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Similar methods have already been proposed for multitask learning and has not been discussed in this paper [1],\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of discussion on similar methods for multitask learning. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that similar methods have already been proposed for multitask learning and were not discussed in the paper. However, it does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the discussion of similar methods for multitask learning. It points out that similar methods have already been proposed and were not discussed in the paper. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or incorporate related work into their discussion. Without actionable feedback or detailed advice, the authors are left with a general observation but no clear path for improvement. Therefore, the comment is rated as 2, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. While it implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FedMITR,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a question about the amount of computation required for FedMITR compared to other methods, indicating a potential area for improvement or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the authors have compared the amount of computation required for FedMITR with other methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment poses a question about the amount of computation required for FedMITR compared to other methods, suggesting that this might be an area for comparison. While it identifies a potential area for improvement, it lacks depth and does not provide specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. The comment is 3 as it points out a potential area for improvement, but it could be more actionable and detailed to be fully beneficial for the authors. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it unclear whether the suggestion is being implemented. The comment provides a specific action\u2014using a generic external knowledge base\u2014but lacks concrete guidance on how to implement it or address the confusion in the writing. The authors are given a clear direction but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment suggests avoiding \"1) and 2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, it acknowledges that the writing is confusing, making it difficult for the authors to determine whether this suggestion is being implemented. While the comment references \"1) and 2)\" and Figure 3, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in suggesting the use of a generic external knowledge base, but without detailed guidance on how to address the confusion in the writing, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that using a generic external knowledge base can avoid \"1) and 2)\" as demonstrated in Figure 3. However, the comment acknowledges that the writing is confusing, making it difficult for the authors to determine whether the suggestion is being implemented. This lack of clarity and justification makes the claim 1, as it does not provide sufficient evidence or reasoning to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors can avoid using \"1) and 2)\" by using a generic external knowledge base, as demonstrated in Figure 3. However, the reviewer acknowledges that the writing is confusing, making it difficult for the authors to determine whether the suggestion is being implemented. While the comment provides a specific actionable suggestion, it lacks depth and does not offer detailed guidance on how to effectively implement the use of a generic external knowledge base or how to address the confusion in the writing. This limits the comment\"s helpfulness, as it provides a starting point but does not fully support the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of the choice, and whether other influential losses have been considered. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The comment implies that the authors should provide more detailed explanations or experiments to justify their choices, but it does not specify exactly what changes or additions are needed. Therefore, the comment is 3, as it identifies areas for improvement but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity, the potential impact of this choice, and whether other influential losses have been considered. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding in the comment makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the methodology used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the methodology used in the paper, specifically regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also asks whether other influential losses have been considered, such as replacing the min with a mean or NDCG. These questions are relevant and could prompt the authors to reconsider their methodology and potentially improve the robustness of their results. However, the comment lacks specific guidance or suggestions on how to address these issues, such as recommending specific experiments or modifications to the methodology. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of indepth analysis on experimental results, specifically questioning why improvements are limited on one dataset and significant on another. This provides a clear and direct action for the authors to take, which is to conduct a more detailed analysis of the experimental results. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the need for an indepth analysis of the experimental results, particularly regarding the improvements of models on the offense detection dataset and the coarse stereotype set. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the limited improvements of models on the offense detection dataset and the significant improvements on the coarse stereotype set. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of indepth analysis on experimental results. It points out that the improvements of models are limited on one dataset and significant on another, which is a critical observation that could lead to a deeper understanding of the results. By highlighting this issue, the comment provides the authors with a clear direction for enhancing the analysis and interpretation of their experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct the indepth analysis or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests several actions for the authors to take, including training on labeled data, incorporating input mask explanation annotations for a few examples, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. The reviewer also mentions that the current method may not work due to the small number of conv layers. However, the comment does not provide specific guidance on how to implement these suggestions or what specific changes should be made to the method. The action is implicit and somewhat vague, as the authors need to infer the details of how to apply these suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the method of training on labeled data and incorporating input mask explanation annotations, as well as the use of modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. It suggests that the current method may not work due to the small number of conv layers. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of modern baselines and the potential limitations of the current method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method may not work due to the small number of conv layers and the use of modern backbone baselines like Resnet50 or DenseNet121. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to similar interventions that have failed, making it difficult for the authors to understand the basis of the skepticism. As a result, the claim is 3, as it provides a logical argument but lacks sufficient evidence or references to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several suggestions for improving the methodology, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like Resnet50 or DenseNet121 for the feature extraction layer. The reviewer also points out that the current method may not work due to the small number of conv layers, which is a valid concern. However, the comment lacks specific guidance on how to implement these suggestions or what specific changes should be made to the method. While it identifies areas for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is 3, as it provides some direction but could be more comprehensive to be 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method. This implies that the authors should make a comparable effort to optimize the baseline as they do for their proposed method. However, the comment does not provide specific guidance on how to achieve this or what steps to take to ensure a fair comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multiple hyperparameters and the extensive hyperparameter search, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the importance of ensuring that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment highlights the extensive hyperparameter search, it lacks specific examples or references to support the claim that this is necessary. The reasoning is based on a general assumption that ensuring fairness is important, but it does not provide detailed evidence or justification for why this is crucial. Therefore, the claim is 3, as it requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the need to ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This is a relevant point that could impact the validity and fairness of the results. However, the comment lacks specific guidance on how to achieve this or what steps the authors should take to ensure a fair comparison. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the definition of perplexity given in the paper is incorrect and suggests that it should be replaced with the correct definition. Additionally, it notes that the equation labeled as perplexity does not resemble perplexity but instead appears to be crossentropy. While the comment provides explicit guidance on what needs to be corrected, it does not offer specific suggestions on how to revise the text or equations to ensure accuracy. The action is clear but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is incorrect about the definition of perplexity and the equation labeled as perplexity, which is actually crossentropy. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definition of perplexity given in the paper is incorrect and that the equation labeled as perplexity does not resemble perplexity but instead appears to be crossentropy. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the paper regarding the definition of perplexity and the equation labeled as perplexity. It points out that the definition given is incorrect and that the equation does not resemble perplexity but instead appears to be crossentropy. This feedback is clear and actionable, as it provides the authors with a precise correction to make in their draft. However, the comment could be more helpful if it offered suggestions on how to clarify the definition or provided additional context to help the authors understand the issue better. Overall, the comment is 4 as it directs the authors to a specific area needing correction, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action for the authors to take, as it specifies the exact improvement needed and provides a concrete direction for testing. The comment is specific and provides a concrete action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and the \"compared baseline,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing baselines, such as MVGRL[4] and gptgnn[5], and suggests adding more baselines of graph contrastive learning. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline for the graph classification task is insufficient, specifically mentioning the absence of MVGRL[4] and gptgnn[5]. However, the comment does not provide any supporting evidence or reasoning to justify why these baselines are necessary or how their inclusion would improve the study. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the graph classification task, noting that the baseline is insufficient and suggesting the addition of more baselines of graph contrastive learning. This feedback is clear and actionable, as it provides a concrete direction for improvement by recommending the inclusion of additional baselines. However, the comment could be more helpful if it explained why these specific baselines are important or how they might impact the results. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern with the evaluation of the proposed strategies, specifically mentioning the need to test the defense against an adversarial attack. It suggests that the defense should be evaluated against adversarial examples that produce minimal structural alterations to the edge map but mislead the model predictions. However, the comment does not provide specific guidance on how to implement this evaluation or what specific adversarial examples should be used. While the action is implied, it is not detailed enough for the authors to know exactly how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation of the proposed strategies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, namely the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation of the proposed strategies is insufficient, specifically mentioning the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. The comment provides a logical reasoning by highlighting the potential vulnerability of the defense against such attacks. However, it lacks specific examples or references to support the claim that an adversary could optimize the perturbation and remain successful in attacking the model. This makes the claim 3, as it provides a reasonable argument but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern with the evaluation of the proposed strategies, specifically the need to test the defense against an adversarial attack that produces minimal structural alterations to the edge map but misleads the model predictions. This is a crucial point that could significantly impact the effectiveness of the defense strategies. However, the comment does not provide specific guidance or examples on how to implement this evaluation or what types of adversarial attacks should be considered. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to make the legends for tables 1, 2, and 3 longer and clarify whether the numbers are percent errors or percent correct. This feedback provides clear and direct guidance on what changes need to be made to improve the clarity of the tables. The action is explicit and concrete, as it specifies exactly what needs to be done to enhance the legends. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the legends for these tables, and it provides guidance on what should be clarified, such as whether the numbers are percent errors or percent correct. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a factual observation and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the legends for tables 1, 2, and 3 should be longer and clarify whether the numbers are percent errors or percent correct. This is a clear and direct suggestion that can help improve the clarity and readability of the tables, making the comment 5. By addressing this issue, the authors can enhance the comprehensibility of their results, which is crucial for effective communication of their findings. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the experimental results lack standard deviations, making it difficult to assess the significance of the results. This is a clear and direct action for the authors to take, as it instructs them to include standard deviations in their results. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014the inclusion of standard deviations\u2014and why this is important for assessing the significance of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results lack standard deviations, making it difficult to assess the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why standard deviations are necessary or how their absence affects the interpretation of the results. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting the absence of standard deviations. This is a clear and actionable point that the authors can address to improve the clarity and significance of their findings. By including standard deviations, the authors can provide more robust and reliable evidence for their conclusions. However, the comment could be more helpful if it offered suggestions on how to present these deviations or explained their importance in the context of the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the provided analysis seems weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed information about the solution and discretization, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the provided analysis\" and \"the theoretical work on sampling and particlebased optimization methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis, such as the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the provided analysis is \"somewhat weak\" due to the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This claim is 3 as it references theoretical work on sampling and particlebased optimization methods, which provides a basis for the expectation of detailed analysis. However, the comment lacks specific references to that theoretical work or examples of what kind of information is missing, making it somewhat challenging for the authors to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the provided analysis is considered weak, namely the absence of information on the existence and smoothness of the solution of SDE (2a)(2d) and any guarantees of the discretization (in time and space). This feedback is clear and actionable, as it points out specific gaps in the analysis that need to be addressed to strengthen the paper. By highlighting these areas, the comment provides the authors with a clear direction for improving the draft. However, it could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar issues have been addressed in related works. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or suggestions for potential improvements. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make to enhance the quality of their generated images. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, specifically mentioning that the realism of the results is limited. However, it does not specify which part of the paper or supplemental material is being referred to, making it weakly grounded. The comment is specific in detailing the issue of limited realism in the generated images, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, particularly in terms of realism. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks specific references or comparisons to other methods or standards that could substantiate the claim. Without such evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, particularly in terms of realism. It highlights that while good continuous control is achieved, the realism of the generated results is limited. This feedback is 3 as it points out an area for improvement, but it lacks specific suggestions or guidance on how to address the issue. The authors are informed of a potential weakness but are not provided with actionable steps to enhance the realism of their generated images. Therefore, the comment is rated as 3, as it provides insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the size and elements of G, which is the graph used in the DGCN model. It also suggests adding the dimensions of G, X, and W to provide a better understanding of the model. These actions are clear and concrete, as they specify exactly what needs to be added or clarified in the paper. The authors know exactly what steps to take to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the description of G and the addition of dimensions for G, X, and W. This provides clear guidance on what the authors need to improve in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the construction of G, the graph used in the DGCN model. It suggests that the size and elements of G should be described, and the dimensions of G, X, and W should be added to provide a better understanding of the model. This is a request for additional information rather than a claim or opinion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of the paper where additional clarity is needed, specifically regarding the construction of G, the graph used in the DGCN model. It suggests that the size and elements of G should be described, and the dimensions of G, X, and W should be added to provide a better understanding of the model. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensiveness of their explanation. By addressing these points, the authors can improve the readability and accessibility of their work, making the comment 4. However, it could be more helpful if it provided additional guidance on how to effectively present this information in the paper. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not suggest how the authors should address this discrepancy or improve their draft. As a result, the authors are left without any guidance on how to respond to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement regarding Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement regarding Cycle Consistency loss is not entirely true, as it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific discrepancy in the paper regarding the Cycle Consistency loss, noting that it can iterate between two phases of the reconstructions (ABA and BAB) with two separate standard backpropagation processes. This is a clear and actionable point that the authors can address to improve the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or examples to explain the implications of this discrepancy or suggested ways to clarify the statement. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer suggests that the authors should clarify or replace the term with a more appropriate one. While the comment provides a clear suggestion for improvement, it does not offer specific guidance on how to address the issue, such as recommending alternative terms or explaining the context in which the term is used. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the term, explaining that it is confusing and not standard in the field of hyperspectral imaging. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, as it is not a standard term in the field of hyperspectral imaging. The reviewer provides a definition of hyperspectral imaging, which is a clear and accurate explanation. However, the comment could be strengthened by providing a specific example or context in which the term \"hyperspectral\" is used, which would further substantiate the claim. Despite this, the comment is 4 due to the clear definition of hyperspectral imaging and the logical reasoning behind the claim.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the term \"hyperspectral\" is not a standard term in the field of hyperspectral imaging. It provides a clear and concise explanation of what hyperspectral imaging is, which helps the authors understand the issue and make a correction. The comment is actionable as it suggests that the authors should clarify or replace the term with a more appropriate one, which is a straightforward suggestion that can improve the clarity and accuracy of the paper. However, the comment could be more helpful if it offered additional guidance on how to address the issue, such as suggesting alternative terms or explaining the context in which the term is used. Overall, the comment is 4 as it provides clear and actionable feedback on a specific terminology issue."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also mentions that the concept of peak in Figure 5 is not described. While the comment provides explicit actions to take, such as revisiting the energy concept and clarifying the peak concept, it does not specify how to implement these actions or what specific details should be included in the refreshed explanation. The authors are given clear guidance on what needs to be addressed, but the execution of these actions is somewhat vague. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the concept of energy should be refreshed in Section 5.2 and providing a possible interpretation of high energy on a character. Additionally, it points out the lack of description for the concept of peak in Figure 5. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy is mentioned for the first time in Section 3.1 and that it should be refreshed in Section 5.2, where it is used several times. The reviewer also questions the interpretation of high energy on a character, suggesting it might indicate that the current morpheme should be split at that point. Additionally, the reviewer points out that the concept of peak in Figure 5 is not described. While the comment provides a logical suggestion for clarifying the energy concept, it lacks specific examples or references to support the claim that the current explanation is insufficient. Therefore, the claim is 3, as it provides a reasonable basis for improvement but requires more detailed justification to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors refresh the concept of energy in Section 5.2, where it is used several times, and provide some hints about how to interpret it. It also points out that the concept of peak in Figure 5 is not described, which is a clear area for improvement. This feedback is valuable as it directs the authors to clarify and enhance the explanations of key concepts, ensuring that the paper is more comprehensible and accurate. However, the comment could be more helpful if it included examples or additional guidance on how to interpret the energy concept or what specific details should be included in the explanation of the peak. Overall, the comment is 4 as it identifies important areas for improvement and provides clear direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. It specifically mentions that ablation studies in Sections 3 and 4 demonstrate the effectiveness of each component, but the comment implies that a more detailed explanation is needed. While the action is implicit, it is concrete because it specifies what additional information is needed (e.g., how the performance of combining the Linformer and window attention in Big Bird is improved). Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the contribution of each component to the final performance improvements. This provides clear guidance on what the authors need to address in order to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed information about how each component contributes to the final performance improvements. While it mentions ablation studies in Sections 3 and 4, it does not provide specific examples or detailed reasoning to support why this additional information is necessary. The claim is 3 as it highlights a potential gap in the paper, but it lacks the necessary evidence or detailed explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed information about how each component contributes to the final performance improvements. It references ablation studies in Sections 3 and 4, which is a clear indication of where the authors can enhance their explanation. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to present this information. While it highlights a critical area for improvement, the lack of detailed guidance limits its usefulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies specific gaps in the paper regarding the details of the models, particularly the grammar over kernels and the probabilities associated with it. It explicitly asks for clarification on how the approach is applied in practice, including inference. This feedback provides clear and concrete actions for the authors to take, such as explaining the grammar over kernels and the probabilities associated with it, and detailing the inference process. The explicit nature of the questions and the request for clarification makes the comment 5, as the authors know exactly what needs to be addressed to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the models\" and \"the grammar over kernels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, as well as the inference process. This provides clear guidance on what needs to be clarified or expanded in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of detail in the explanation of the grammar over kernels and the probabilities associated with it, making it difficult to understand how the approach is applied in practice. The reviewer questions how inference is performed and suggests that these details are missing. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the missing details themselves, which could be challenging without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the authors have not provided sufficient detail, namely the explanation of the grammar over kernels and the probabilities associated with it. It questions how inference is performed and points out that these details are missing, making it difficult for readers to understand the practical application of the approach. The comment is clear and actionable, as it provides a direct request for clarification and guidance on how to improve the paper. By addressing these points, the authors can enhance the clarity and comprehensibility of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the role of visual information, verify the effectiveness of the ablation study, and ensure that the experiment results are significant. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 10\" and \"w/o perception module and w perception,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the ablation study, the lack of verification, and the questionable significance of the experiment results due to the sample size. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the role of visual information is unknown, questioning the effectiveness of the ablation study and the significance of the experiment results due to the sample size. The comment provides some support by mentioning that the w/o perception module and w perception exhibit similar performance, which suggests that the perception module might not be necessary. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the effectiveness of the ablation study or the significance of the experiment results. This makes the claim 3, as it provides some evidence but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the lack of clarity on the role of visual information, the absence of explicit verification in the ablation study, and the questionable significance of the experiment results due to the sample size. It highlights specific concerns, such as the performance of the w/o perception module and w perception, and the implementation detail of w/o perception. While the comment provides some insight into potential weaknesses, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it could be more beneficial with additional guidance or examples on how to improve the draft. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This implies that the authors should include references to these works to provide a more comprehensive comparison. The comment is explicit in its request for inclusion of these references, making it clear and actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the end of Section 4.2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of references to previous works on Lasso screening, such as Ren et al. (2017), and suggests including these references for a more comprehensive comparison. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening, but it does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This claim is 3 as it highlights a potential omission in the paper\"s literature review, but it lacks specific references to the works that should be included. The reviewer provides a specific example of a relevant work, which would strengthen the claim. However, the comment does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not cite or compare it to previous works on Lasso screening, such as Ren et al. (2017). This feedback is clear and actionable, as it points out a gap in the literature review that the authors should address to provide a more comprehensive analysis. By including these references, the authors can enhance the credibility and depth of their work. However, the comment could be more helpful if it suggested how to integrate these references into the existing text or provided additional guidance on how to conduct a more thorough comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to improve the documentation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed documentation for the hyperparameters. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the model, noting that many components have hyperparameters that are not fully provided. However, it does not specify which components or hyperparameters are in question, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what needs to be done to address this issue, such as suggesting how the hyperparameters should be documented or suggesting specific sections of the code that need to be reviewed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, suggesting that someone may need to trace them in the source code. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that many components have hyperparameters that are not fully provided. This is a relevant observation that could impact the reproducibility and clarity of the work. However, the comment lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue, such as recommending specific documentation or improvements to the model documentation. While it points out a potential problem, it does not offer enough detail to be fully helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This feedback implies that the authors should clarify the meaning of \"%p\" in their results notation. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a possible explanation or alternative notation. While the action is implicit, it is clear that the authors need to clarify the notation, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, pointing out that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This provides clear guidance on what needs to be addressed to improve the clarity of the results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the notation for results is not clear, specifically mentioning that the paper claims an improvement for CIFAR10 of 3%p but does not clarify what \"%p\" stands for. This claim is 3 as it highlights a potential issue with the clarity of the results notation, but it lacks specific examples or references to support the claim that \"%p\" is unclear. The authors might need to provide additional context or clarification to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the results notation, particularly regarding the use of \"%p\" without further explanation. This feedback is clear and actionable, as it directs the authors to clarify the meaning of \"%p\" in their results, which is crucial for ensuring that readers can understand the significance of the claimed improvements. By addressing this issue, the authors can enhance the transparency and accessibility of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that it would be beneficial to include qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or what specific qualitative results should be included. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. However, the comment does not specify which part of the paper these results should be included in, making it weakly grounded. The suggestion is specific, as it clearly outlines what the authors should include to improve their draft. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also recommends showing failure cases and analyzing limitations. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would be beneficial. The absence of detailed justification or evidence makes the claim 3, as the authors would need to infer the benefits of these additions themselves.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of qualitative results, possibly with zoomedin views, for cases where previous methods failed but were successful with the proposed method. It also suggests showing failure cases and analyzing limitations. This feedback is valuable as it offers a concrete way for the authors to enhance the presentation of their results, which could help demonstrate the effectiveness of their method. However, the comment could be more helpful if it provided specific examples of what qualitative results or failure cases should be included. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. This feedback provides a clear and explicit action for the authors to take, which is to clarify the title to avoid confusion. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the ambiguity in the title regarding the scope of machine comprehension of text. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the title is ambiguous and recommends clarifying that it refers to machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the common understanding of \"reading comprehension\" and \"readability\" in the context of human reading. However, it lacks specific examples or references to support the claim that the title is ambiguous. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the title of the paper, suggesting that it is ambiguous and could be misinterpreted as referring to human reading comprehension rather than machine comprehension of text. It provides a clear and actionable suggestion to clarify the title to avoid confusion. This feedback is valuable as it helps the authors ensure that their title accurately reflects the focus of their work, which is important for clarity and effective communication. However, the comment could be more helpful if it offered additional guidance on how to clarify the title or suggested alternative wording. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific claim made by the authors on line 238, which is incorrect according to the Central Limit Theorem (CLT). It highlights that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment explicitly identifies the issue with the claim and provides a clear explanation of why it is incorrect. However, it does not offer any guidance on how the authors should address this issue or suggest alternative statements to correct the claim. The action is explicit but lacks concrete details on how to implement the correction, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 238,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim made by the authors regarding the Central Limit Theorem (CLT) and why it is incorrect. The comment provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement regarding the Central Limit Theorem (CLT) is incorrect. The reviewer provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This logical reasoning and specific examples make the claim verifiable, as it provides a clear and substantiated critique of the authors\" statement. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the Central Limit Theorem (CLT) and points out multiple incorrect assertions. It provides a detailed explanation of why the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, as it guides the authors to correct their claim and ensure the accuracy of their statement. However, the comment could be more helpful if it suggested alternative formulations or references to support the claim. Overall, the comment is 4 as it effectively highlights a critical issue and offers a constructive path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the authors need to analyze the time complexity of the proposed policies mentioned in Section 4. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific direction for the analysis, making it 5. The authors know exactly what needs to be done to address the reviewer\"s concern, ensuring that this feedback is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the time complexity of the proposed policies mentioned in Section 4. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the proposed policies should be analyzed. However, it does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement by suggesting that the time complexity of the proposed policies should be analyzed. This is a clear and actionable suggestion that can help the authors enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific aspects of time complexity should be considered. Overall, the feedback is valuable but could be more comprehensive with additional details. Therefore, it is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make. The comment lacks concrete suggestions or detailed instructions on how to improve the evaluation, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where the evaluation is discussed, the comment lacks full grounding. It is specific in its critique of the use of an automatic metric, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an automatic metric is less convincing than a human metric. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment questions the use of an automatic metric (TSS) in the human evaluation, suggesting that a human metric would be more convincing. This feedback highlights a potential weakness in the paper\"s evaluation methodology, which could impact the credibility of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what alternative human metrics could be used. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be strengthened by including experiments across more diverse domains, specifically mentioning those in TDMPC 2. While the comment implies that the authors should expand their experiments to include more diverse domains, it does not provide specific guidance on how to do so or which domains to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for more diverse domains and determine which ones to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments prove the point made by the authors and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of more diverse domains, but without explicit references to sections or details, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments prove the authors\" point and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these additional domains are necessary or how they would strengthen the paper. Without specific examples or detailed explanations, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the experiments prove the authors\" point and recommends expanding the experiments to include more diverse domains, specifically mentioning those in TDMPC 2. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional experiments to enhance the paper\"s diversity and strengthen the results. However, the comment lacks specific guidance on how to implement this suggestion or which domains to focus on, making it 3 but not fully actionable. The authors are given a direction but need more detailed instructions to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should show confidence intervals and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. The comment provides explicit actions for the authors to take, such as including confidence intervals and expanding the evaluation to more datasets. However, it does not specify which datasets should be used or how to calculate the confidence intervals. While the actions are clear, the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of confidence intervals for results and the limited evaluation on two datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of not showing confidence intervals and the need to evaluate on more datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. The reviewer supports this claim by referencing external works that discuss the importance of confidence intervals and the need for more datasets to evaluate robustness. However, the comment could be strengthened by providing specific examples or references to studies that demonstrate the importance of confidence intervals or by explaining why the two datasets used are insufficient. Despite this, the claim is 4 due to the references to external works, which provide a solid foundation for the critique.", "helpfulness_rationale": "The review comment identifies two significant issues with the paper: the lack of confidence intervals for results and the limited evaluation on two datasets. It suggests that the authors should include confidence intervals to demonstrate statistical significance and evaluate on more datasets, specifically mentioning some standard datasets in the RNP community. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the robustness and credibility of their results. However, the comment could be more helpful if it offered suggestions on how to calculate confidence intervals or which datasets to consider. Overall, the comment is 4 as it effectively directs the authors to address these critical areas for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on what specific aspects of the interpretability tax should be evaluated or how the evaluation should be conducted. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. Without explicit references to sections or specific elements, the authors cannot confidently determine where to address this issue. Additionally, the comment lacks specificity regarding what aspects of the interpretability tax should be evaluated or how it should be measured. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area where the paper could be improved, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This is a relevant point that could enhance the paper\"s comprehensiveness and rigor. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or detailed feedback, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is 3, as it points out an area for improvement but lacks the depth and specificity needed for full utility."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the main contribution of the paper is not in proposing novel techniques but rather in demonstrating that a simple combination of existing techniques can achieve surprisingly good accuracy. However, it does not provide any explicit or implicit actions for the authors to take to improve their draft. The authors are left without guidance on how to address this feedback or what specific changes could be made to enhance the novelty or contribution of their work. As a result, the comment lacks actionability, making it 1.", "grounding_specificity_rationale": "The comment discusses the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not specify which part of the paper this discussion pertains to, such as the sections on the LUQ design or the approaches presented in Section 5. The comment lacks grounding as it does not specify where in the paper these issues are discussed, making it difficult for the authors to identify and address the feedback. Additionally, the comment is not specific about what needs to be improved or how the authors could enhance the contribution of their work. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward and that the approaches in Section 5 are standard and explored in previous literature. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim 1, as it lacks the necessary support to substantiate the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the simplicity of the LUQ design and the standard nature of the approaches presented in Section 5, suggesting that the main contribution of the paper is in demonstrating the effectiveness of a simple combination of existing techniques. However, it does not provide specific suggestions or guidance on how the authors could enhance the novelty or contribution of their work. The comment lacks actionable feedback or constructive advice, leaving the authors without clear direction on how to improve their draft. Therefore, it is rated as 2, as it identifies a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it implies that the authors should provide these losses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include training losses in their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses, but without clear grounding, it is difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. However, it does not present any claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with differentiable Sinkhorn and requests training losses. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer that they should provide training losses, but without detailed instructions or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by highlighting the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability as being the same concept. The reviewer suggests that these are actually different perspectives on applying stronger constraints for samples with higher popularity. While the comment identifies a potential issue with the paper\"s claims, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claims and provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper\"s claims regarding the strength of the proposed BC loss, pointing out that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper overclaims the strength of the proposed BC loss in the theoretical analysis by suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are the same concept from different viewpoints. The reviewer provides a logical reasoning by explaining that these concepts are essentially the same, but they do not provide specific examples or references to support this claim. While the reasoning is somewhat clear, the lack of detailed evidence or examples makes the claim 3, as the authors may find it challenging to fully understand and address the critique without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s claims regarding the strength of the proposed BC loss in the theoretical analysis. It points out that the paper overclaims the novelty of the proposed BC loss by suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hardnegative mining ability are actually the same concept from different viewpoints. This feedback is 3 as it highlights a potential overclaim in the paper, but it lacks specific suggestions on how the authors might address this issue or improve their claims. While it provides some insight into a potential weakness, the comment could be more helpful with additional guidance on how to clarify or substantiate the claims. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer suggests that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific changes should be made to improve the evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the relevance and effectiveness of their method in the context of scorebased evaluation systems. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also mentions the framework FFAEVAL and similar frameworks like Chatbot Arena, suggesting that these systems may not be suitable for evaluating a single dialogue system. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the relevance and effectiveness of the proposed method, but without clear grounding, it is difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also suggests that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. The reviewer provides logical reasoning by explaining that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim that these frameworks are not effective for evaluating single dialogue systems. While the reasoning is sound, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relevance of the proposed method to the authors\" motivations, specifically questioning the effectiveness of automatic scores and the affordability of human evaluation scores. It also points out that the proposed framework FFAEVAL and similar frameworks like Chatbot Arena are not suitable for evaluating a single dialogue system, as they are designed for comparison between dialogue systems. This feedback is 3 as it highlights a potential weakness in the methodology and suggests that the authors should reconsider their evaluation approach. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or what alternative evaluation methods might be more appropriate. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed compared to other methods. The reviewer suggests that this could result in unfair comparisons. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their training approach or provide additional context to justify the use of 2x samples per iteration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and \"training,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. The reviewer supports this claim by referencing the authors\" claim of 1.5x slower running speed compared to other methods. However, the comment lacks specific examples or references to substantiate the claim further, such as detailed comparisons with other methods or specific data to support the claim of slower running speed. While the claim is based on a logical reasoning and a reference to the authors\" claim, it could be strengthened with additional evidence or examples. Therefore, the comment is 3, as it provides a logical basis but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and unfair comparisons. This is a relevant observation that could impact the validity of the results and comparisons made in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. While it points out a potential problem, it does not offer actionable advice or detailed feedback that would help the authors improve their draft. Therefore, the comment is 3, as it highlights an area for consideration but does not fully support the authors in making improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. While the comment identifies an area for improvement, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to consider the differences between classification and regression tasks, but the comment lacks concrete details on how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of focal loss in regression tasks and suggests that the authors may not have considered the differences between classification and regression tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the use of focal loss in regression tasks and the potential inaccuracy caused by lower weight for easy samples. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of focal loss in regression tasks and suggests that it may not be appropriate due to its classificationspecific properties. The reviewer provides a logical reasoning that focal loss could lead to inaccurate results in regression tasks, as it has lower gradients on easy samples. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the issue themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of focal loss in regression tasks, suggesting that it may not be appropriate due to its classificationspecific properties. It points out that focal loss has lower gradients on easy samples, which could lead to inaccurate results in regression tasks. The comment highlights a gap in the authors\" consideration of the differences between classification and regression tasks, implying that the paper may lack a comprehensive understanding of the problem domain. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how the authors might address this issue or what alternative methods might be considered. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of scalability should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of scalability should be considered or how the authors might address this question. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or additional information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it could impact the practicality and applicability of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might investigate or address this issue. While it points out a potential weakness, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to verify whether the proposed model\"s improvements over the RL without feedback model are statistically significant. This is a clear and direct action for the authors to take, as it provides a specific task to ensure the robustness of their findings. The comment is concrete in its request for statistical verification, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the verification of the proposed model\"s improvements over the RL without feedback model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model\"s improvements over the RL without feedback model are not statistically significant, specifically mentioning the comparison between rows 3 and 4 in Table 6. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed model\"s improvements over the RL without feedback model, noting that the improvements are not statistically significant as evidenced by the comparison between rows 3 and 4 in Table 6. The comment suggests that the authors verify if these improvements are statistically significant, providing a clear and actionable piece of feedback. This guidance is valuable as it directs the authors to a specific area that needs further investigation, ensuring that their findings are robust and reliable. However, the comment could be more helpful if it included additional context or examples of how to conduct the statistical verification. Overall, the comment is 4 as it effectively points out a potential weakness and offers a constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific actions the authors should take. The comment is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"in continuation to the above remark,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how to relax the need to visit all ballaction pairs with each iteration and what would happen if partial coverage is considered. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of questions asking for clarification or suggestions regarding relaxing the need to visit all ballaction pairs with each iteration and exploring partial coverage. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about relaxing the need to visit all ballaction pairs with each iteration and suggests exploring partial coverage. While it raises an interesting point, it lacks specific guidance or suggestions on how to address this issue or what specific assumptions might be needed. The comment is 3 as it prompts the authors to consider alternative approaches, but it does not provide actionable steps or detailed analysis to support the authors in making improvements. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. While it does not explicitly instruct the authors to use RoBERTabase, the implication is clear that they should consider this option. The comment is 3 as it provides a concrete suggestion for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"encoder\" and compares it to \"RoBERTabase,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the observed improvement could be achieved with a better encoder, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point poses a question about whether the observed improvement could be achieved with a better encoder, specifically mentioning RoBERTabase instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify why RoBERTabase might be a better choice. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The comment raises a question about the potential improvement in the observed results with a better encoder, specifically mentioning RoBERTabase as an alternative to BERT. While it does not provide specific guidance or suggestions for improvement, it does prompt the authors to consider alternative encoders that could enhance their results. This feedback is 3 as it points out a potential area for exploration, but it lacks depth and actionable steps for the authors to follow. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This is an explicit action, as it clearly specifies the need for additional datasets to be included in the paper. The comment is concrete because it provides specific examples of datasets that the authors should consider, which gives them a clear direction on what to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology discussion. The authors can infer that it relates to the evaluation or experimental sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting the inclusion of additional datasets. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. However, the comment does not provide any specific reasoning or evidence to support why these datasets are necessary or how they would contribute to the paper\"s claims. Without additional context or examples, the authors may find it challenging to understand the importance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique. This feedback is 3 as it identifies a specific area for improvement by recommending the inclusion of additional datasets. However, the comment lacks depth and does not provide detailed guidance on how these datasets should be used or why they are important for the paper\"s claims. While it points out a potential gap in the paper\"s evaluation, it does not offer specific suggestions or examples on how to address this issue. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to use these methods or explain how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods could be improved, specifically recommending RefNeRF and MipNerf as potential baselines for evaluating the appearance decomposition part and larger outdoor scenes, respectively. However, it does not specify which part of the paper these suggestions pertain to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or comparison sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting potential baselines. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. While the comment provides specific examples of potential baselines, it lacks detailed reasoning or evidence to support why these particular methods would be beneficial or how they would enhance the evaluation. The suggestion is based on general knowledge of existing methods, but without further explanation or justification, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the choice of baseline methods could be improved by comparing with other existing methods, such as RefNeRF and MipNerf. This suggestion is based on the authors\" need to evaluate the appearance decomposition part and larger outdoor scenes, respectively. By providing these examples, the reviewer helps the authors identify potential baselines that could enhance their evaluation and improve the robustness of their results. However, the comment could be more helpful if it explained why these specific methods were chosen or how they would contribute to the evaluation. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" While the action is implicit, it is clear that the authors need to provide a method for achieving fair policy learning without negatively impacting the predictive model\"s performance. However, the comment does not specify how to achieve this or what specific steps to take, leaving some ambiguity. Therefore, the comment is 3, as it provides a direction but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a demonstration of fair policy learning without negatively impacting the predictive model\"s performance. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it could be achieved. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without \"severely damaging the performance of the predictive model.\" This feedback is 3 as it identifies a potential weakness in the paper, specifically the impact of the proposed method on the predictive model\"s performance. However, the comment lacks specific guidance or examples on how to achieve this goal or what aspects of the method might be causing performance issues. While it points out an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. This provides a clear and direct action for the authors to take, specifying where the details should be added and what needs to be included. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of implementation details of the proposed methods. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details of the proposed methods is a concern and suggests that these details should be included in Section 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these details are necessary or how they would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details of the proposed methods, which is a critical aspect of the paper. It suggests that these details should be included in Section 4.1, providing a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area where their draft could be strengthened, ensuring that the implementation details are transparent and accessible to readers. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how they could be presented effectively. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of empirical evaluation and comparison with other methods, indicating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. It suggests that the authors should provide empirical evaluation and comparisons with other methods to clarify the practical value of their contribution. The comment is explicit in its request for empirical evaluation and comparison, providing concrete guidance on what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that there is no practical value demonstrated and that the theoretical contributions may be significant but not adequately presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, which is a subjective claim. The reviewer supports this claim by stating that the theoretical contributions may be significant but are not adequately demonstrated in the paper. However, the comment does not provide specific examples or references to support the claim that the theoretical contributions are significant or that the lack of empirical evaluation is a significant issue. This makes the claim 3, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting the lack of empirical evaluation and comparison with other methods. It highlights that the theoretical contributions may be significant but are not adequately demonstrated in the paper, making it unclear what the practical value of the contribution could be. The comment suggests that even a theoretical paper should attempt to argue for its significance, and it concludes that the current submission is not suitable for publication at NeurIPS. This feedback is clear and actionable, providing the authors with a specific direction to enhance the empirical evaluation and comparison sections of their paper. However, it could be more helpful if it offered suggestions on how to conduct the empirical evaluation or what specific comparisons should be made. Overall, the comment is 4 as it effectively points out a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that in the manuscript, P is used to represent a probability but is also used for a cumulative distribution function, leading to confusion. This feedback implies that the authors should clarify the use of P in these instances to avoid confusion. However, the comment does not provide specific guidance on how to address this issue, such as suggesting a change in notation or clarifying the context in which P is used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the clarity of their manuscript. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the manuscript, including \"P mostly represents a probability but sometimes for a cumulative distribution function (e.g., Eqs. (3) and (4) and L44, all in Appendix), which leads to confusion.\" This allows the authors to accurately identify the parts of the manuscript being addressed. The comment is also specific because it clearly specifies the issue of using P for both probability and cumulative distribution functions, which leads to confusion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of P in the manuscript is confusing because it is used to represent both a probability and a cumulative distribution function. This claim is 3 as it provides a specific example (P used in Eqs. (3) and (4) and L44) to illustrate the confusion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why this confusion is problematic or how it affects the understanding of the manuscript. Therefore, the comment is rated as 3, as it provides some support but could be strengthened with additional justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that P is used to represent both a probability and a cumulative distribution function, which leads to confusion. This feedback is clear and actionable, as it points out a specific area where the manuscript could be improved by clarifying the use of P. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a change in notation or explaining the context in which P is used. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the use of artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their analysis or ablation studies. The comment lacks actionable details, such as recommending the use of natural spurious correlations or suggesting specific methods for identifying and analyzing them. As a result, the authors are left without a clear understanding of how to apply this feedback to improve their draft. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the issue of using artificial patterns in analysis and ablation studies, suggesting that natural spurious correlations are more complex and different in every example. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the use of artificial patterns, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that neural networks learn natural rare spurious correlations, which is unknown to the community. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without such evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis and ablation studies in the paper, noting that most studies use artificial patterns instead of natural spurious correlations. It highlights the importance of understanding natural spurious correlations, which are complex and different in every example, as opposed to artificial patterns that are duplicated. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or incorporate natural spurious correlations into their analysis. While it points out an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it offers insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or explore more general tasks. The authors are left without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is limited in its application to navigation problems and points out that combining RL and planning has already been discussed in PRMRL. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the paper\"s applicability to more general tasks, but it lacks grounding as it does not identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is limited in its application to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. However, the comment does not provide specific references or examples from PRMRL to substantiate this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s applicability to navigation problems and suggests that combining RL and planning has already been discussed in PRMRL. It points out that the paper could be more interesting if it explored more general tasks. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might address this limitation or expand their work. While it highlights an area for improvement, the feedback is incomplete and does not offer detailed direction for the authors to enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider whether all feature spaces are wellsuited for 1NN and warns that if a feature space is not close to a spherical Gaussian, it may perform poorly. It also recommends standardizing feature dimensions to avoid this issue. While the comment provides a clear action\u2014to evaluate the suitability of feature spaces and standardize dimensions\u2014it does not offer specific guidance on how to implement this suggestion or what metrics to use for evaluation. The action is explicit but lacks concrete details on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 213,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the feature spaces, suggesting that if they are not close to a spherical Gaussian, they may perform poorly and recommending standardizing feature dimensions to avoid this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the feature spaces may not be wellsuited for 1NN and provides a rationale that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment also recommends standardizing feature dimensions to avoid this issue. While the reasoning is logical and provides a clear suggestion, it lacks specific examples or references to support the claim that standardizing dimensions would solve the issue. This makes the claim 3, as the authors would need to further explore the rationale and potentially conduct experiments to validate the claim fully.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature spaces used in the paper, suggesting that they may not be wellsuited for 1NN. It provides a logical rationale by explaining that if a feature space is not close to a spherical Gaussian, it may perform poorly. The comment also offers a constructive suggestion by recommending standardizing feature dimensions to avoid this issue. This feedback is clear and actionable, as it provides the authors with a specific area to address and a potential solution to improve the robustness of their results. However, the comment could be more helpful if it included examples or references to support the claim about the impact of feature spaces on 1NN performance. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing and points out specific issues with the setting. However, the comment does not provide explicit guidance on how to address these concerns or what specific changes should be made to improve the definition. The authors are left to infer that they need to provide a clearer definition, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is central to the work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a clear and formal definition for the contrastive gap. The comment provides detailed feedback on the example given and the setting, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" is not clearly defined, despite being central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment suggests that a clear, formal definition is needed. While the comment provides some reasoning by pointing out the issue with the example setting, it lacks specific examples or references to support the claim that the definition is unclear. This makes the claim 3, as the authors would need to further explore the issue to fully understand and address the critique.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of a clear and formal definition for the \"contrastive gap,\" which is central to the work. It acknowledges that an example was provided but finds it less convincing due to the setting. The comment highlights the need for a clear definition and provides detailed feedback on the example, suggesting that the setting is less idealized than claimed. This feedback is actionable and constructive, as it guides the authors to clarify and strengthen the definition of the contrastive gap. However, the comment could be more helpful if it offered specific suggestions on how to improve the example or provided additional examples to illustrate the concept. Overall, the comment is 4 as it effectively points out a critical area for improvement and provides some guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It suggests that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it does not provide explicit guidance on how to clarify the description or what changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the description, but it is concrete in that it points to specific lines that need attention. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1, line 143\" and \"line 154,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inaccuracy of the statement regarding rewards in standard MDP formulations and suggests clarifying the description of each action. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. While the comment identifies specific lines and issues, it lacks detailed reasoning or references to standard MDP formulations or examples to fully substantiate the claim. This makes the claim 3, as the authors would need to further explore the topic to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the language used in section 3.1, lines 143 and 154, regarding the reward system in a Markov decision process (MDP). It points out that the statement \"Then the state changes and environment gives a reward\" is not accurate for standard MDP formulations, as rewards are not guaranteed after each action. The reviewer also questions whether each action is a single feature or the power set, suggesting that the description could be clearer. This feedback is clear and actionable, as it directs the authors to clarify their description to avoid misleading statements and improve the accuracy of their work. However, the comment could be more helpful if it provided additional guidance on how to clarify the description or examples of standard MDP formulations. Overall, the comment is 4 as it identifies a specific area for improvement and offers actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. The reviewer provides a specific suggestion to include the explanation of why the chosen baseline makes the most sense. However, the comment does not explicitly instruct the authors to add this explanation or provide guidance on how to integrate it into the paper. While the action is implied, it is not as concrete as it could be, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including other baselines, such as those mentioned in related work [29, 5, 6]. It also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered. However, the comment does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of other baselines and providing a rationale for why they are relevant. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that other baselines should be included, such as those mentioned in related work [29, 5, 6]. However, it does not provide any specific reasoning or evidence to support why these baselines are necessary or how they would enhance the study. The comment also mentions that the authors have addressed the reviewer\"s weakness points and that all unclear parts have been answered, but it does not elaborate on these responses. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the importance of including these baselines and the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include other baselines, such as those mentioned in related work [29, 5, 6]. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of additional baselines. However, the comment lacks specific guidance on how to integrate these baselines into the paper or why they are particularly relevant. While it points out a potential enhancement, it does not provide detailed instructions or examples on how to implement this suggestion. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it does not explicitly instruct the authors to clarify or provide additional information, it implies that the authors should address this question to improve the clarity of their draft. The action is implicit but concrete, as the authors can infer that they need to provide a definition or explanation of \u03b4. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the meaning of \u03b4 in the statement of Lemma 5. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the meaning of \u03b4 in the statement of Lemma 5. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the meaning of \u03b4 in the statement of Lemma 5. While it identifies a potential area of confusion or ambiguity in the paper, it does not provide any guidance or suggestions for clarification or improvement. The comment lacks actionable feedback or context that would help the authors address the issue. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the uniform setting of \u03b1_m in line 113, noting that this implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider dynamically weighting the modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform setting of \u03b1_m and suggests that dynamically weighting the modalities is important in multimodal fusion. This provides clear guidance on what needs to be addressed in this part of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that setting \u03b1_m uniformly to 1/M implies that the contributions from all modalities are the same, which is not accurate. The reviewer supports this claim by referencing works in multimodal fusion that demonstrate the importance of dynamically weighting modalities. This reference provides a logical basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to these works, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform setting of \u03b1_m in line 113, noting that it implies the contributions from all modalities are the same. It suggests that dynamically weighting the modalities is important, as demonstrated in multimodal fusion works. This feedback is 3 as it points out a potential weakness in the paper and provides a direction for improvement. However, the comment could be more helpful if it offered specific examples or references to multimodal fusion works that demonstrate the importance of weighting modalities. As it stands, the authors are left with a general suggestion to explore this further, which may not be immediately actionable without additional guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. However, it does not provide any guidance on how the authors should address this issue or suggest alternative phrasing that might be clearer. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making this comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the pervasive use of the phrase \"to meet\" and how it is difficult to understand. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the pervasive use of the phrase \"to meet\" in the paper is difficult to understand, specifically mentioning line 280. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this phrase is difficult to understand or how it could be improved. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the pervasive use of the phrase \"to meet\" in the paper, particularly on line 280, which is difficult to understand. This feedback is 3 as it points out a potential source of confusion in the text, allowing the authors to consider clarifying this phrase for better comprehension. However, the comment could be more helpful if it provided suggestions on how to rephrase or clarify the phrase to improve clarity. Overall, the comment is 3 as it directs the authors to a specific area needing attention, but it lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and explicit observation that the authors can easily address by correcting the labeling in both the text and the figure. The action is explicit and concrete, as it directly instructs the authors to make a specific correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L_task\" and \"L_class,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the task loss being labeled differently in the text and the figure, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a factual observation that does not require any subjective interpretation or opinion. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy between the labeling of the task loss in the text and the figure, noting that it is labeled as \"L_task\" in the text but as \"L_class\" in the figure. This is a clear and actionable observation that the authors can address to ensure consistency in their presentation. However, the comment does not provide any further guidance or suggestions on how to resolve this issue or why it might be important to maintain consistency. While it points out a specific error, it lacks depth and does not offer additional insights or suggestions for improvement. Therefore, the comment is 3, as it provides a clear observation but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what specific aspects of the method should be considered for improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where the network depth is discussed. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the method\"s limitations should be addressed or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking about the limitations of the method, specifically regarding the depth of the network in the graph case. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically asking about the depth of the network in the graph case. This is a relevant point that could prompt the authors to consider the depth of their network and its implications for the method\"s effectiveness. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what aspects of the method should be considered for improvement. While it identifies a potential area for exploration, it does not offer actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the work should be evaluated in machine translation, which is seen as a more convincing approach due to its lower uncertainty per word. While the comment implies that the authors should consider evaluating their method in machine translation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider this evaluation method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the work should be evaluated in machine translation, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, such as the results or discussion sections. The authors can infer that it relates to the evaluation section, but the comment lacks full grounding as it does not explicitly mention the section. The suggestion is specific, as it highlights the need for evaluation in machine translation, but it is 1 as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work only uses answer generation and summarization, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the proposed method in machine translation would be more convincing due to its lower uncertainty per word. This claim is 3 as it provides a logical reasoning for why machine translation might be a more appropriate evaluation method. However, it lacks specific examples or references to support the claim that machine translation is inherently less uncertain than the tasks mentioned. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization tasks, which are considered \"close to open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that evaluating the method in machine translation, which exhibits lower uncertainties per word, would be more convincing. This feedback is 3 as it points out a potential weakness in the evaluation approach and suggests an alternative method for demonstrating the effectiveness of the proposed method. However, the comment could be more helpful if it provided specific examples or references to support the claim about the differences between open and close domain generation. Overall, the comment offers a valuable suggestion for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and \"multiple stochastic masks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dropout method used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the dropout method used in the paper, specifically asking about the dropping rate and the number of masks generated. This feedback is valuable as it prompts the authors to clarify and provide more detailed information about their methodology, which could enhance the transparency and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of how similar methods have been presented in the literature. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback provides clear and concrete actions for the authors to take, such as including comparisons and benchmarks to support their claims. The explicit nature of the suggestions and the detailed guidance on what needs to be added make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further justifications, comparisons with other singlestage attacks, and benchmarks with other SOTA algorithms to demonstrate the effectiveness of the technical contributions. This provides clear guidance on what the authors need to improve in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification, suggesting that showing only performance drop on fusion models is insufficient. The reviewer suggests that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to justify the effectiveness. This claim is 3 as it provides a logical reasoning for the need for additional comparisons and benchmarks. However, it lacks specific examples or references to support the claim, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the need for further justification of the proposed twostage optimization approach. It suggests that showing only performance drop on fusion models is insufficient and that comparisons with other singlestage attacks and benchmarks with other stateoftheart (SOTA) algorithms are necessary to demonstrate the effectiveness. This feedback is clear and actionable, as it provides specific guidance on what the authors need to address to strengthen their technical contributions. By addressing these points, the authors can significantly improve the clarity and credibility of their work. However, the comment could be more helpful if it included examples of specific comparisons or benchmarks that would be beneficial. Overall, the comment is 4 as it effectively directs the authors to enhance their paper with actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not specify the type of GPUs used for testing or the inference time. This is an explicit observation that the authors can directly address by including this information in their draft. The comment provides a clear and concrete action for the authors to take, ensuring that they know exactly what needs to be added to improve their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the absence of information about the type of GPUs used for testing and the inference time, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be added, namely the type of GPUs and inference time, providing clear guidance on what needs to be included in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used for testing or the inference time. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting the lack of information about the type of GPUs used for testing and the inference time. This is a clear and actionable point that the authors can address to improve the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is important for the paper. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including a comment on the monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and missing symbols in the text. However, it does not provide explicit instructions or suggestions on how the authors should address these issues. The comment lacks actionable guidance, such as recommending specific experiments or changes to the text. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and \"page 3, line 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the monotonic increase in performance of RSD4PG with respect to \u03bb values and the missing symbols in the text. However, it does not provide specific guidance on how to address these issues or what changes should be made. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point consists of factual observations and requests for clarification. It does not contain subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including a monotonic increase in performance of RSD4PG with respect to \u03bb values in Table 1 and missing symbols in the text. It also points out a missing symbol in the bracket on page 3, line 2, and a potential typo in the equation on page 3, line 4. While the comment highlights these issues, it does not provide actionable suggestions or guidance on how the authors might address them. The feedback is 3 as it directs the authors\" attention to specific areas that need clarification or correction, but it could be more helpful with additional guidance on how to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential issue with the Perceptual Metric in Figure 2, suggesting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. While the comment identifies a specific area of concern, it does not provide explicit instructions on how to address this issue or what changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to make a correction but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Perceptual Metric in Figure 2, noting that it should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, as it points out a potential error or inconsistency in the presentation of the data. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as explaining why the current setup is incorrect or offering alternative approaches. Despite this, the comment still offers valuable insight into a potential area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a specific sentence is confusing and suggests that the authors should clarify it. However, it does not provide any explicit guidance on how to improve the sentence or what specific changes should be made to make it clearer. The authors are left to infer that they need to revise the sentence, but without concrete instructions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the sentence, which is that it is confusing and not immediately obvious. However, the comment does not provide specific guidance on how to clarify the sentence or what aspects are confusing. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that a specific sentence is confusing and suggests that the authors should clarify it. However, the comment does not provide any reasoning, examples, or references to support why the sentence is confusing or how it could be clarified. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific sentence that is confusing and suggests that the authors should clarify it. While it highlights a potential issue with the clarity of the text, it does not provide detailed guidance or suggestions on how to improve the sentence or what specific aspects are confusing. The comment is 3 as it points out a potential weakness, but it lacks depth and actionable advice, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several instances where citations are missing or needed, specifically in lines 7879, 129130, 156158, and 217218. While it identifies these areas, it does not provide explicit instructions on how to include the missing citations or what specific references should be used. The actions are implicit and somewhat vague, as the authors need to infer that they should add citations but are not given specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the need for citations in lines 7879, 129130, 156158, and 217218. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of claims that require specific citations to support the assertions. For example, the claim about diffusion models outperforming generative adversarial networks is not substantiated with a reference. Similarly, the claim about previous work having limited success is also unsupported. The reviewer requests citations for these claims, which would provide the necessary evidence to support the claims. Therefore, the comment is considered 1 due to the lack of supporting evidence or references.", "helpfulness_rationale": "The review comment identifies specific areas where citations are missing or needed, which is a clear and actionable piece of feedback. It highlights specific lines in the paper where references should be included, providing the authors with a concrete list of places to improve their draft. However, the comment could be more helpful if it offered suggestions on which specific works or references might be relevant for each of these citations. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between Figures 1 and 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback implies that the authors should reconcile these figures to ensure consistency. However, the comment does not provide explicit instructions on how to address this issue, such as suggesting specific changes or clarifications. While the action is implied, it is not as concrete as it could be, leaving the authors with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a discrepancy between the figures, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This provides clear guidance on what needs to be addressed, namely, reconciling the figures to ensure consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it highlights a discrepancy between the figures, which could be a source of confusion or error. However, the comment lacks detailed explanation or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between Figures 1 and 2, noting that Fig 1 shows a single shared encoderdecoder for multiple tasks, while Fig 2 shows one encoderdecoder per auxiliary task. This feedback highlights an inconsistency in the figures, which could be confusing for readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their figures. While it points out a potential problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. While it highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify or modify the description of N_l^(s) to ensure that each node can attend to its own lowerlevel representation, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions whether each node can attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the ability of each node to attend to its own lowerlevel representation, based on the description of N_l^(s) from equation 2. This is a relevant point that could impact the understanding and interpretation of the model, as it pertains to the attention mechanism. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about how the inequality after line 433 follows from Lemma 7. It suggests that the authors should clarify how Lemma 7 is applied to this inequality. While the comment implies that the authors should provide additional explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433\" and \"Lemma 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the inequality after line 433 follows from Lemma 7, and it suggests that the authors should clarify how Lemma 7 is applied in this context. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on how an inequality follows from a lemma. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the derivation of an inequality after line 433, asking how it follows from Lemma 7. This is a clear and actionable point, as it prompts the authors to clarify the connection between the two elements. By addressing this question, the authors can improve the clarity and coherence of their paper, making it easier for readers to understand the derivation and application of the inequality. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested specific ways to clarify the connection. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance the clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several areas where the paper\"s main contribution is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes should be made to clarify the main contribution. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations or examples to support their claims, but the comment lacks concrete steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically the novel properties of the proposed method and how it copes with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the clarity of the main idea and the automation process. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear, specifically regarding the novel properties of the proposed method and how it copes with dynamic largescale multitasking. The reviewer suggests that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or reasoning makes the claim 3, as the authors would need to make a significant effort to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, which is the clarity of the novel properties and the method\"s ability to cope with dynamic largescale multitasking. It points out that the method\"s ability and applicability are overstated or not wellsupported, and that the automation process is unclear. This feedback is valuable as it highlights areas where the authors need to provide more detailed explanations or evidence to support their claims. However, the comment could be more helpful if it offered specific suggestions on how to clarify these aspects or provided examples of what would be considered clear and wellsupported claims. Overall, the comment is 3 as it directs the authors to address important areas for improvement, but it lacks detailed guidance on how to achieve this."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset to see if there is a drop in performance in easy (non occluded) settings. While the comment explicitly states what needs to be done, it does not provide detailed guidance on how to implement these actions. The authors are given a clear direction but may need to infer the specific steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the bottomup method [9] and the crowdpose dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need to include the method in the tables and to evaluate its performance on the MS COCO dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the bottomup method [9] has reported results on the crowdpose dataset outperforming all methods, including the paper\"s own method, with a ResNet50. The comment also recommends evaluating the method\"s performance on the standard MS COCO dataset to determine if there is a drop in performance in easy settings. While the comment provides a specific example of the bottomup method\"s performance, it lacks detailed justification or references to support the claim that this method outperforms others. The suggestion to evaluate on the MS COCO dataset is logical, but the claim about the bottomup method\"s performance is not fully substantiated. Therefore, the comment is 3, as it provides some evidence but lacks detailed reasoning or references.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include the bottomup method [9] in their tables and evaluate its performance on the standard MS COCO dataset. This suggestion is based on the reported results of the bottomup method on the crowdpose dataset, which outperforms other methods, including the paper\"s own method, with a ResNet50. By including this method in their tables and evaluating its performance, the authors can enhance the comprehensiveness and comparability of their work. The comment is clear and offers a concrete way to improve the paper, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim of using \"annotation guideline\" and points out that the paper only considered label name, label description, and fewshot examples, which may not fully capture the complexity of annotation guidelines in the IE domain. It provides an example from the TACRED slot filling guidelines to illustrate the depth of understanding required. However, the comment does not explicitly instruct the authors to revise their claim or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their claim and provide more detailed information about their understanding of annotation guidelines. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim of using \"annotation guideline\" and provides a specific example of the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This allows the authors to identify the exact part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the overstatement of using annotation guidelines and the need to provide more detailed information about the understanding of annotation guidelines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim of using \"annotation guideline\" and provides an example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This example is used to support the claim that the paper\"s prompts may not fully capture the depth of true guideline understanding. The reasoning is logical and provides a specific example to substantiate the claim, making the comment 4. However, the comment could be strengthened by referencing additional examples or sources to further support the argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the use of \"annotation guideline\" and provides a specific example from the TACRED slot filling guidelines to illustrate the complexity of annotation guidelines in the IE domain. This feedback is valuable as it highlights a potential misrepresentation in the paper and offers a concrete example to help the authors better understand the scope of their work. However, the comment could be more helpful if it suggested ways to address this issue, such as clarifying the understanding of annotation guidelines or proposing a revised claim. Overall, the comment is 3 as it provides a clear direction for improvement but lacks detailed guidance on how to address the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the BERTbaseline. This provides a clear and concrete action for the authors to take, specifying exactly what additional comparisons are needed to strengthen the experiment comparison. The comment is specific and direct, giving the authors a clear path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment comparison\" and the need to compare the method to token pruning and token combination baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of additional baselines for comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because it only compares the method to the BERTbaseline. It suggests that the authors should compare their method to token pruning and token combination baselines. While the comment identifies a potential issue with the experiment comparison, it does not provide specific reasoning or evidence to support why the current comparison is insufficient. The suggestion to include additional baselines is logical, but the lack of detailed justification or examples makes the claim 3. The authors would need to further explore the rationale behind the need for these additional comparisons to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should also compare their method to token pruning and token combination baselines. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance their experimental evaluation by including additional baselines. By addressing this suggestion, the authors can strengthen their analysis and provide a more comprehensive comparison, which could improve the overall quality of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This feedback provides a clear and explicit action for the authors to take, which is to include a comparison to coordinateaware methods in their experimental section. The comment is specific in identifying the missing comparison and offers a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This provides clear guidance on what the authors need to add to their experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, in addition to methods that are unaware of the point coordinates. This claim is 3 as it logically suggests that including such comparisons would provide a more comprehensive understanding of the methods being evaluated. However, the comment lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section, noting that it only compares methods that are unaware of the point coordinates, except for in the input features. It suggests that a comparison to coordinateaware methods, such as TFN or SchNet, would be appropriate. This feedback is clear and actionable, as it provides a concrete suggestion for improvement by recommending the inclusion of additional comparisons. By addressing this point, the authors can enhance the comprehensiveness and relevance of their experimental section. However, the comment could be more helpful if it explained why these specific methods are relevant or how they might impact the results. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending which weaknesses should be explored or how they could be demonstrated. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the authors did not show the possible weaknesses of the proposed model, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where to address this feedback. Additionally, the comment lacks specificity regarding what weaknesses should be explored or how they could be demonstrated. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area for improvement by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or what specific weaknesses should be explored. Without actionable advice or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the lack of related work and experimentation with other extractthengenerate methodologies in the paper. It implies that the authors should include a related work section and experiment with other methods to demonstrate the novelty and effectiveness of their proposed system. While the comment does not explicitly instruct the authors to add a related work section or conduct additional experiments, it provides a clear direction for improvement. The action is implicit but concrete, as the authors can infer the need to address these gaps in their work. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the idea of long document summarization and questions the novelty of the proposed system compared to previous methodologies. It specifically mentions the absence of a related work section and the lack of experimentation with other extractthengenerate methodologies. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. While the authors can infer that it relates to the sections discussing the methodology and results, the comment is not fully grounded as it does not explicitly mention these sections. The comment is specific in identifying the need for a related work section and experimentation with other methods, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the novelty and effectiveness of the proposed system compared to previous methodologies in the area of long document summarization. It questions the absence of a related work section and experimentation with other extractthengenerate methodologies. However, the comment lacks specific examples or references to previous work that could be considered relevant to the paper. Without such references or detailed reasoning, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a logical basis for the concern but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a related work section and experimentation with other extractthengenerate methodologies. It questions the novelty and effectiveness of the proposed system compared to previous methodologies in the area of long document summarization. This feedback is valuable as it highlights an important area for improvement, particularly in demonstrating the novelty and competitiveness of the proposed system. However, the comment could be more helpful if it provided specific examples of related work or suggested ways to address the lack of experimentation. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not provide explicit instructions or concrete steps on how to implement these suggestions. The authors are left to infer that they should consider these directions but are not given specific guidance on how to integrate them into their work. The lack of actionable details makes the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. However, it does not specify which part of the paper these suggestions pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in suggesting alternative approaches, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints. However, it does not provide any supporting evidence, reasoning, or references to justify why these directions are more appealing or effective. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is not verifiable, and the authors may find it challenging to implement the suggestions without further guidance. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests two alternative directions for dealing with churn, namely using unlabeled data or applying constraints to improve model stability. While these suggestions are interesting and could potentially improve the paper, the comment lacks depth and does not provide specific guidance on how to implement these directions or integrate them into the existing work. The authors are left with a general idea of what could be explored but are not given actionable steps or detailed explanations to follow. Therefore, the comment is 3, as it points out potential areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is not sufficient and recommends providing more information on the advantages or differences of the proposed method, specifically in comparison to BGLN. While the comment implies that additional work on GLN is needed, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add more information about GLN and its differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the insufficiency of the introduction of related work and the need for more work on GLN to reflect the advantages or differences of the proposed method, such as the difference from BGLN. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests that more work on GLN is needed to reflect the advantages or differences of the proposed method, specifically in comparison to BGLN. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of related work, noting that it is insufficient and recommends providing more information on the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed to provide a more comprehensive understanding of the methodology. However, the comment could be more helpful if it offered suggestions on how to present this additional information or what specific aspects of the methodology should be highlighted. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of hyperparameters in Moon\"s approach, specifically questioning why only one dropout rate is used when Variational dropout has inputoutput and recurrent dropout parameters. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. There is no guidance on how the authors might improve their draft in response to this observation. Without actionable advice or concrete steps, the authors are left without a clear understanding of what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Moon\"s approach\" and \"Variational dropout,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the choice of hyperparameters, particularly the use of only one dropout rate for Moon\"s approach compared to Variational dropout, which has inputoutput and recurrent dropout parameters. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the paper\"s conclusions. Without additional context or explanation, the claim remains 3, as it lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of hyperparameters in Moon\"s approach, specifically noting that Variational dropout has inputoutput and recurrent dropout parameters, while Moon\"s approach only uses one dropout rate. This observation highlights a potential inconsistency in the paper\"s approach and suggests that the authors might consider expanding their hyperparameter choices to include more options. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what specific changes to make. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a clear and specific action for the authors to take, which is to conduct these experiments and compare their results against other approaches. The comment is explicit and provides concrete details on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. This provides clear guidance on what aspects of the paper need to be addressed. The comment is also specific in detailing what kind of experiments should be conducted and how they could be conducted, such as using publicly available simulators and comparing against other approaches. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the current experiments are insufficiently largescale and do not include nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer questions whether this is due to a lack of time or severe scalability issues with the method. The comment proposes conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace, and suggests using publicly available simulators for these experiments. This provides a logical reasoning for the need to conduct largerscale experiments and suggests specific domains to consider. However, the comment lacks specific examples or references to support the claim that conducting these experiments would be beneficial. Therefore, the comment is 3, as it provides a logical argument but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending largerscale experiments with nontrivial dynamics, specifically mentioning gridworlds with walls and other nontrivial tiles. It also suggests conducting experiments on simple videogame domains, which would naturally have a lowcardinality discrete state and actionspace. The reviewer provides a logical rationale for why these experiments are necessary, as they would help determine whether the method has severe scalability issues or if it is simply a matter of time. The comment is specific and offers detailed guidance on how to enhance the experimental section of the paper. By suggesting concrete experiments and domains to consider, it empowers the authors to make significant improvements to their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not provide any guidance on what specific quantitative measurement should be used or how to implement it. The comment lacks explicit instructions or concrete suggestions for the authors to follow, leaving them without clear direction on how to address this issue. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the absence of quantitative measurement to assess occupation bias. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to assess the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors have not provided quantitative measurements to assess the extent of occupation bias relative to real distributions in society. This is a relevant point that could impact the validity and generalizability of the study. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might address this issue or what specific quantitative measurements could be used. While it points out a potential weakness, it does not offer actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. While the comment implies that the authors should consider this aspect, it does not provide explicit instructions or concrete suggestions on how to address this issue. The authors are left to infer that they should explore the potential impact of using adaptive gradient methods, but the comment lacks specific guidance on how to conduct this exploration or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making this comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where this issue might be relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the potential impact, but it lacks full grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. The comment does not present any claims or opinions but rather seeks clarification or additional information. It is a request for further exploration rather than a statement that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the potential impact of using adaptive gradient methods instead of SGD on the findings, specifically whether it might amplify updates for weights associated with hard features. This is a valuable observation that could lead to a deeper understanding of the results and their robustness. However, the comment lacks specific guidance or suggestions on how the authors might explore this aspect or what specific experiments or analyses could be conducted to address it. While it points out an important area for consideration, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a direction for further exploration but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not provide explicit guidance on how to address these issues or suggest specific actions for improvement. The authors are left to infer that they need to expand the types of teacher architectures and consider more recent methods, but the comment lacks concrete details on how to achieve this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of insufficient experiments, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the issues with the experiments, such as the limited types of teacher architectures and the age of the compared methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient, specifically mentioning the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the experiments: the limited types of teacher architectures and the fact that most compared methods are proposed before 2019. While it highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address them. The comment lacks depth and actionable advice, leaving the authors with a general understanding of the issues but without clear steps to improve their draft. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to include information from 2hop neighbors or how to clarify the effectiveness of the method. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the lack of information and the need to clarify the effectiveness of the method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"no information from 2hop neighbors is included\" and questions the effectiveness of the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting the lack of information from 2hop neighbors and questioning the effectiveness of the method. However, it does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the clarity of their work. Without specific recommendations or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit guidance on the use of real DICOM images as experiment data, recommending the FastMRI challenge dataset for comparison. It also suggests comparing inference speeds between different methods. This feedback is clear and concrete, giving the authors specific actions to take, such as using the recommended dataset and comparing inference speeds. The explicit nature of the suggestions and the detailed guidance on what to compare make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of real DICOM images as experiment data and recommends the FastMRI challenge dataset for comparison. It also suggests comparing inference speeds between different methods. This level of detail allows the authors to accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the use of real DICOM images and the comparison of inference speeds. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using real DICOM images as experiment data and recommends the FastMRI challenge dataset for comparison. It also advises comparing inference speeds between different methods. While the comment provides a logical suggestion for improving the experiment setup, it lacks specific examples or references to support the claim that using DICOM images would be more beneficial than PNG images. The suggestion to compare inference speeds is more concrete, but the lack of detailed justification or evidence makes the claim 3. The authors would need to further explore the rationale behind these suggestions to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by recommending the use of real DICOM images as experiment data instead of PNG images. It also suggests using the FastMRI challenge dataset for comparison and advises comparing inference speeds between different methods. This guidance is specific and offers a concrete direction for the authors to improve their draft. By addressing these points, the authors can enhance the quality and relevance of their experimental setup. However, the comment could be more helpful if it provided additional context or examples on why DICOM images are preferred or how to effectively compare inference speeds. Overall, the comment is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the binder design needs further optimization and validation, specifically mentioning that ProtPainter only provides empirical conformation estimation. However, it does not provide any explicit guidance on how to optimize or validate the binder design or what specific aspects need attention. The action is implied but lacks concrete details, leaving the authors to infer what steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for further optimization and validation of the binder design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter only provides empirical conformation estimation for binder design, suggesting that further optimization and validation are required. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the binder design, noting that ProtPainter only provides empirical conformation estimation and that further optimization and validation are required. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address to improve the quality and robustness of their work. However, the comment could be more helpful if it provided suggestions on how to optimize or validate the binder design, such as recommending specific methods or studies to consider. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically inquiring about the stimulus used and the duration of the cycle. It also raises a question about whether the time scale of adaptation would shorten if the duration of the cycle changes, referencing a specific work by Smirnakis et al. in Nature 1997. The comment provides clear and direct actions for the authors to take, such as clarifying the training process and addressing the potential impact of cycle duration changes on adaptation. The explicit nature of the request and the concrete details on how to implement it make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely the training process and the potential impact of cycle duration changes on adaptation. The comment references a specific work by Smirnakis et al. in Nature 1997, providing a clear basis for the question. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the training process of the model in Figure 7, specifically inquiring about the stimulus used and the duration of the cycle. It also references a specific work by Smirnakis et al. in Nature 1997 to support the claim that the time scale of adaptation might change with cycle duration. While the comment does not make a subjective claim or opinion, it does require clarification and evidence to be fully understood. Therefore, it is classified as \"3\" as it provides some support but lacks detailed justification or references.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific area of the paper that requires clarification regarding the training process of the model in Figure 7. It asks for clarification on the stimulus used and the duration of the cycle, which are crucial details for understanding the methodology. Additionally, it raises a relevant question about the potential impact of cycle duration changes on the time scale of adaptation, referencing a specific work by Smirnakis et al. in Nature 1997. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing these points. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about what happens if the original CAD model is already associated with spatiallyvarying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this question should be addressed in the paper, nor is there any suggestion for how the authors might respond to it. As a result, the comment lacks actionability and does not provide any direction for the authors to improve their draft. Therefore, it is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment raises a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the potential consequences of this association, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification or information, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment poses a question about the implications of having a CAD model associated with spatiallyvarying (SV) BRDF maps. While it highlights an area of interest, it does not provide any guidance or suggestions for the authors to address this question or explore its implications in their work. Without actionable feedback or context, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. While the comment implies that additional evaluation is necessary, it does not provide specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without concrete instructions on what to evaluate or how to do it, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or experiment. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what kind of evaluation is needed, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. However, it does not provide any supporting evidence, reasoning, or examples to justify why this additional evaluation is necessary or how it would benefit the paper. Without such information, the claim remains 1, as it lacks the necessary justification to guide the authors in improving their draft. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that more evaluation is needed, specifically on CIFAR10 in the full label and lower label scenarios. This feedback is 3 as it identifies a potential area for improvement in the evaluation section of the paper. However, it lacks specific guidance on what aspects of the evaluation should be expanded or how to conduct it. The authors are left to infer that they should conduct more evaluations, but without detailed instructions or examples, the comment does not fully support the authors in making improvements to their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment raises concerns about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. It suggests that comparisons should be made between using the same amount of data, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their comparisons and ensure they are using the same amount of data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparisons made in the table, questioning whether they are comparing apples to apples by using the same amount of data. The comment provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparisons made in Table 2, specifically questioning whether they are comparing apples to apples by using the same amount of data. The reviewer provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This provides a logical reasoning and specific examples to support the claim, making the comment 4. However, the comment could be strengthened by referencing specific studies or literature that support the importance of using the same amount of data for comparisons. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparisons made in Table 2, questioning whether they are comparing apples to apples by using the same amount of data. It provides specific examples of comparisons that should be made, such as H>N and H>B using less data than H>N+B. Additionally, it points out that H>N>H and H>N>H use less data than H>N+B>H. This feedback is clear and actionable, as it guides the authors on how to improve the comparisons in their table to ensure they are making valid and meaningful assessments. By addressing these points, the authors can enhance the clarity and robustness of their analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should add references or reconsider the placement of Alg 1, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to execute them.", "grounding_specificity_rationale": "The comment addresses several issues, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, it does not specify which part of the paper these issues are located in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific concerns, it lacks grounding as it does not specify where these issues are addressed in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several issues with the paper, including the counterintuitive placement of Alg 1, the lack of reference to Laplacian eigenmaps in Line 224, and the absence of a reference to Laplacian eigenmaps in the introduction. These points highlight areas where the paper could be improved by providing additional context or references to better situate the work within the broader literature. However, the comment does not offer specific suggestions or guidance on how to address these issues, such as recommending specific references or explaining why the placement of Alg 1 is counterintuitive. While the feedback highlights important areas for improvement, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and provide more motivation for the CBN approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the section and provide more motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It also recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of Section 2.1 is problematic or where the ResNet architecture is discussed, making it weakly grounded. The comment is specific in suggesting that the time spent on the ResNet architecture could be better used, but it lacks detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. The reviewer argues that Batch Normalization is a general technique and that the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or references to support the claim that the inclusion of Section 2.1 is unnecessary or that the ResNet architecture could be better utilized. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the critique without additional guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the inclusion of Section 2.1 and suggests that the description of the proposed methodology is independent of the choice of model. It recommends that the time spent describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is 3 as it identifies a potential area for improvement by suggesting that the authors focus on the ResNet architecture to provide more context and motivation for the proposed methodology. However, the comment could be more helpful if it provided specific suggestions on how to enhance the motivation and intuition sections or how to better integrate the ResNet architecture into the paper. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending clarification or potential solutions to the confusion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a confusion regarding the expected outcome of multiplying in equation (1) by a dense projection matrix, questioning how the resulting matrix can be sparse. The comment provides a clear issue to address, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the assumption that multiplying in equation (1) by a dense projection matrix would result in a sparse matrix, given that the projection matrix is assumed to be dense. This is a logical observation that challenges the authors\" understanding of the process. However, the comment lacks specific examples or references to support the claim, making it 3. The authors may need to further explore the reasoning behind the assumption to fully address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the assumption that multiplying in equation (1) by a dense projection matrix would result in a sparse matrix. This is a clear and actionable point that prompts the authors to reconsider their reasoning or provide additional clarification. However, the comment could be more helpful if it suggested ways to address this issue or provided examples of how the authors might clarify their reasoning. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This is a clear and concrete action that the authors can take to address the issue of lacking direct evidence for the motivation. The comment provides a specific suggestion for how to present the evidence, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of direct evidence for the motivation and the need to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence for the motivation is not direct, suggesting that the authors need to plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This claim is 3 as it provides a logical reasoning for the need to present such a figure, but it lacks specific examples or references to similar studies or existing literature that could further substantiate the claim. The authors might need to explore this further to fully understand and address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of direct evidence for the motivation of the study. It provides a clear and actionable suggestion by recommending that the authors plot a figure showing the decline in accuracy of a predictor over time (search steps) in different settings to support their claim. This feedback is valuable as it guides the authors on how to strengthen their argument and provide more robust evidence for their work. However, the comment could be more helpful if it explained why this figure is necessary or how it would enhance the paper\"s credibility. Overall, the comment is 4 as it offers a concrete direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It suggests that the authors should explain more about the concept of excessive risk and how it is calculated in practice, including the expectation. Additionally, it questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment provides a clear direction for the authors to clarify their explanation of excessive risk, it does not offer specific guidance on how to address these questions or improve the draft. The action is explicit but somewhat vague, as the authors need to determine the exact details of how to implement the suggested improvements. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"line 103\" and \"Figure 3 and Figure 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the definition of excessive risk, how it is calculated in practice, and the comparability of values among different groups. The comment also seeks clarification on the relevance of excessive risk as a fairness metric. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the definition and calculation of excessive risk, particularly in relation to the optimal solution and data from different groups. It suggests that the values of excessive risk in Figure 3 and Figure 7 are positive, despite the fact that the optimal solution is not the optimal solution for the loss function w.r.t. data of group a. The reviewer questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. While the comment identifies a potential issue with the definition and calculation of excessive risk, it lacks specific examples or references to support the claim that the values are positive. This makes the claim 3, as the authors would need to provide additional evidence or clarification to fully address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions about the definition and calculation of excessive risk in the paper, particularly in relation to the optimal solution and data from different groups. It questions the comparability of excessive risk values among different groups and the relevance of excessive risk as a fairness metric. This feedback is valuable as it prompts the authors to clarify their explanation of excessive risk and how it is calculated in practice, which could enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how other studies have handled similar questions. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance on how to implement them."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It also references a specific paper, [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should reconsider their statement about initialization, it does not provide explicit guidance on how to revise the statement or what specific aspects should be addressed. The reference to the external work is helpful but does not fully address the actionability of the comment. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the statement about initialization, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a more careful statement about initialization. The reference to the external work, [1] Kunstner et al. (2019), provides additional context and support for the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that initialization plays a role in natural gradient descent (NGD) and suggests that it should be considered as pretraining. The reviewer supports this claim by referencing [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim, as it suggests that initialization could be a crucial aspect of the pretraining process. However, the comment could be strengthened by providing more detailed explanations or examples of how initialization affects the pretraining process. Overall, the claim is 4, as it is supported by a relevant reference but could benefit from additional justification or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization, suggesting that it should be more carefully stated. It references a specific paper, [1] Kunstner et al. (2019), which discusses the limitations of the empirical Fisher approximation for natural gradient descent. This reference provides a logical basis for the claim and offers a potential explanation for the role of initialization in the context of natural gradient descent. However, the comment could be more helpful by providing specific suggestions on how to rephrase the statement or what aspects of initialization should be emphasized. Despite this, the feedback is 4 as it points out a potential weakness in the paper and offers a reference for further exploration. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of clarity regarding how named entities were extracted from datasets and the need for an Englishproofreading to improve the readability of the paper. While the first point is explicit in asking for clarification on the extraction process, the second point is more implicit in suggesting an improvement. However, both points are concrete in their request for clarification and action, respectively. Therefore, the comment is 4, as it provides clear guidance on what needs to be addressed to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for clarification on how named entities were extracted from datasets, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for an Englishproofreading to improve the readability of the paper. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding how named entities were extracted from datasets and suggests that an Englishproofreading would significantly improve the readability of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement: clarity regarding the extraction of named entities from datasets and the need for an Englishproofreading to enhance the readability of the paper. While the comment highlights these issues, it does not provide detailed guidance or suggestions on how to address them. The feedback is 3 as it points out areas that could be improved, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which would improve the condition slightly. This feedback is explicit and provides a concrete action for the authors to take, as it specifies the exact change to make and the potential benefits of doing so. The authors know exactly what needs to be done to address the issue, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines, \"L200\" and \"L303,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement \"for every arm a,\" suggesting that it implies a single optimistic parameter, and provides a specific alternative suggestion for improving the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a logical reasoning by pointing out that this statement is misleading, as it does not account for the possibility of multiple optimistic parameters. The comment suggests an alternative approach by proposing a different condition, which is based on a specific mathematical formula. This provides a clear and logical argument for the claim, making it 4. However, the comment could be strengthened by providing a more detailed explanation or reference to support the alternative approach. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement \"for every arm a\" in line 200, suggesting that it implies a single optimistic parameter. The reviewer provides a specific suggestion to consider using T_0 = m Sqrt(T) in line 303, which could improve the condition slightly. This feedback is clear and actionable, as it points out a potential misinterpretation and offers a specific improvement that the authors can consider. However, the comment could be more helpful if it provided additional context or explanation about why this change would be beneficial or how it would impact the overall analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the terms \"L\" and \"E\" should be defined in the immediate vicinity and highlights the inconsistency in whether they are italicized or not. This provides a clear and concrete action for the authors to take, as they are instructed to define these terms and ensure consistency in their presentation. The comment is specific and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 296,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inconsistency in the presentation of \"L\" and \"E\" and the inconsistency in whether they are italicized or not. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the inconsistency in the presentation of \"L\" and \"E\" and the inconsistency in whether they are italicized or not. However, it does not provide any supporting evidence, reasoning, or references to justify why this inconsistency is problematic or how it affects the clarity or readability of the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of \"L\" and \"E\" in the paper, noting that they are inconsistently italicized. This is a clear and actionable observation that can help the authors improve the clarity and consistency of their writing. By pointing out this inconsistency, the comment provides the authors with a concrete step to take in order to enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to standardize the presentation of these terms or provided examples of how they should be consistently presented. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the experimental section is weak and suggests that more experiments are required. However, it does not provide specific guidance on what additional experiments should be conducted or how they should be structured. The authors are left to infer that they need to expand their experimental section, but without concrete suggestions or examples, the action remains vague. Therefore, this comment is 3, as it identifies an area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and needs more experiments. However, it does not specify which part of the experimental section is considered weak or what specific experiments are needed. Without explicit references to sections, figures, or experiments, the authors cannot confidently determine which parts of the paper need attention. The comment is 1 and lacks specificity, making it difficult for the authors to understand and address the feedback. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a weakness in the experimental section, suggesting that more experiments are required. However, it lacks specificity and does not provide any guidance on what additional experiments should be conducted or how they could enhance the paper. Without specific suggestions or examples, the authors are left without actionable feedback on how to improve their experimental section. Therefore, the comment is not helpful, as it does not provide the authors with a clear path to address the identified weakness."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript should include more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. While the comment implies that additional comparisons are needed, it does not specify which models or techniques should be included or how to conduct these comparisons. The action is implicit and somewhat vague, as the authors can infer that they need to expand their comparisons but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, it does not specify which parts of the paper should include these comparisons or which models or techniques should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these comparisons could be added, the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. However, the comment does not provide any specific examples or references to support the claim that these comparisons are necessary or how they would enhance the manuscript. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the manuscript could benefit from more extensive comparisons with a wider range of models and parameterefficient finetuning techniques beyond LoRA and SPP. This feedback is 3 as it identifies an area where the manuscript could be strengthened by expanding its comparisons. However, the comment lacks specificity and does not provide guidance on which models or techniques should be included or how to conduct these comparisons. While it points out a potential improvement, the lack of detailed suggestions limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies four specific errors in the text, including incorrect grammar and spelling. It provides explicit corrections for each error, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" These corrections are direct and concrete, providing clear guidance for the authors to make the necessary changes to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections to errors in the text, such as incorrect grammar and spelling. It explicitly mentions lines 2, 56, 158, and 265, allowing the authors to accurately identify the parts of the paper being addressed. Each correction is clearly specified, providing full grounding. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of corrections to errors in grammar and spelling, which are factual statements. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific errors in the text, including incorrect grammar and spelling, which are important to correct for clarity and professionalism. It provides direct and actionable feedback by pointing out the errors and offering corrections, such as \"Despite being compact\" to \"Despite being compact\" and \"We refer to multiway arrays\" to \"We refer to multiway arrays.\" Additionally, it corrects \"HPFN to a even deeper ConAC\" to \"HPFN to an even deeper ConAC\" and clarifies \"Effect of the modelling mixed temporalmodality features\" to \"Effect of modeling mixed temporalmodality features.\" This level of detail and specificity makes the comment 5, as it empowers the authors to make significant improvements to their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the inversion of matrix determination or the division of the number of samples is being referred to in the context of Eqs. The reviewer does not provide any explicit or implicit actions for the authors to take, nor does it offer suggestions on how to clarify or correct the issue. Without any guidance or direction, the authors are left without a clear understanding of what needs to be addressed or improved. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the context of the equations, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the context of Eqs. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a factual statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the context of Eqs., specifically whether it is the inversion of matrix determination or the division of the number of samples. This question highlights a potential confusion in the paper, which could be clarified to improve the understanding of the authors\" work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their draft. There is no guidance on how to make the work more innovative or differentiate it from existing work. As a result, the authors are left without any clear direction on how to enhance their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not specify which part of the paper this assessment is based on, such as the introduction, methodology, or results sections. Without explicit references to specific sections or details, the authors cannot confidently determine which parts of the paper need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the model extension are considered incremental or straightforward. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assessment and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and notes that the developed model is a straightforward extension of the GAN for static images. However, it does not provide any specific feedback or suggestions on how the authors might address this issue or improve their work. Without actionable guidance or constructive criticism, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While the comment implies that the authors should conduct a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting a comparison between sequential and combinational designs, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is relevant or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests comparing it with sequential design. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this comparison or what specific aspects to focus on. The comment is 3 as it points out a potential area for further exploration, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3 but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a discussion of the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While the comment implies that the authors should include this analysis, it does not explicitly instruct them to do so. The action is concrete, as it specifies the metric to be analyzed and provides a clear direction for improvement, but it is somewhat vague because it does not provide detailed guidance on how to conduct the analysis or what specific aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides clear guidance on what aspect of the experiment needs further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline, LDA+LSTM, can capture sequential information and provide topic assignment for each word. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that could be improved by discussing the performance of a baseline model, LDA+LSTM, in terms of the topic switch percent metric. This feedback is clear and actionable, as it prompts the authors to include a discussion of the model\"s performance in their results section. However, the comment could be more helpful if it provided additional context or suggestions on how to interpret or analyze the results. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to provide more information about the motivation and potential applications of their work, but the comment lacks specific suggestions on how to do so. Therefore, the comment is 3, as it points out areas for improvement but does not offer concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for the task and questions the potential downstream applications or benefits of amodal tracking. It also asks about how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its request for clarification on the motivation and potential applications of the work, as well as the handling of uncertainty in predictions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of the motivation for the task and the potential downstream applications or benefits of amodal tracking. It also questions how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies areas for improvement, it lacks specific examples, references, or detailed reasoning to support the claim that the motivation is unclear or that the task is difficult to predict. This makes the claim 3, as the authors would need to further develop the reasoning and evidence to fully address the reviewer\"s concerns.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the motivation for the task, which is the difficulty in predicting the state of an object when it is occluded. It questions the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance the clarity of their motivation. The feedback is 3 as it points out a critical area for improvement, but it could be more beneficial with additional direction or examples. Therefore, it is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is explicit and provides a clear action for the authors to take, which is to include experiments with GPT3.5. The comment is concrete because it specifies the exact change needed to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the proposed approach. The authors can infer that it relates to the experimental setup or evaluation, but this inference is not direct. The comment is specific in suggesting the inclusion of GPT3.5 experiments but lacks grounding as it does not explicitly mention which part of the paper should include this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. However, the comment does not provide any supporting evidence or reasoning to justify why GPT3.5 is a better option or how it would enhance the evaluation. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, which is a more affordable option than GPT4, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly advises the authors to include a more costeffective option in their experiments. However, the comment could be more helpful if it explained why GPT3.5 is a better choice or how it would impact the evaluation. Despite this, the suggestion is valuable as it encourages the authors to consider a broader range of options for their experiments. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to add, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Table 4 should include bold numbers for the baselines of previous work, specifically for WMT17WIKT, where the best result in terms of BLEU is in the baselines. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this change is necessary or how it would improve the paper. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with Table 4, suggesting that bold numbers should be included for the baselines of previous work, particularly for WMT17WIKT where the best result in terms of BLEU is in the baselines. This feedback is clear and actionable, as it provides a concrete suggestion for improving the presentation of the data. However, the comment could be more helpful if it explained why this change is important or how it would enhance the clarity or impact of the table. Overall, the comment is valuable for guiding the authors in making a specific improvement to their draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. This request is clear and direct, providing the authors with a specific action to take by asking for examples. The comment is concrete because it specifies the exact part of the paper where the examples should be provided, making it easy for the authors to understand and implement the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 170 to 171,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for examples of \"unreliable neighbors\" mentioned in those lines. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a request for examples of \"unreliable neighbors\" mentioned in lines 170 to 171. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is a factual request for clarification and does not fit the criteria for verifiability.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area in the paper where examples of \"unreliable neighbors\" are mentioned. By asking for examples, the reviewer prompts the authors to provide more detailed explanations or examples to support their claims. This feedback is actionable and can help the authors improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it provided suggestions on how to present these examples or what specific aspects to focus on. Overall, the comment is 3 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of support for the claim about the synergies between DQD and PPO, specifically noting the absence of mention of the TD3GA algorithm in the main paper. It also suggests that the comparison to TD3GA should be central to the paper. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and its relevance to the synergies between DQD and PPO. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of the TD3GA algorithm and the importance of comparing it to TD3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synergies between DQD and PPO are insufficiently supported, specifically mentioning the absence of the TD3GA algorithm in the main paper. The reviewer suggests that the comparison to TD3GA should be central to understanding these synergies. This claim is 3 as it highlights a gap in the paper\"s discussion and provides a specific suggestion for improvement. However, the comment lacks detailed reasoning or references to support the importance of including TD3GA or the centrality of the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the paper. This feedback is clear and actionable, as it points out a gap in the paper\"s discussion and provides a specific direction for improvement. By addressing these points, the authors can enhance the clarity and robustness of their claims. However, the comment could be more helpful if it offered additional guidance on how to integrate the TD3GA algorithm or the comparison to TD3GA into the paper. Overall, the comment is 4 as it effectively directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain why the treesliced Wasserstein distance outperforms the original optimal transport distance, as observed in Sections 6.1 and 6.2. This request is clear and provides a specific action for the authors to take, which is to provide an explanation for this observation. The comment is concrete in its request for clarification, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 6.1 and 6.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it asks for an explanation of why the treesliced Wasserstein distance outperforms the original optimal transport distance, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the observation that the treesliced Wasserstein distance outperforms the original optimal transport distance, suggesting that an explanation is needed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific observation in the paper regarding the treesliced Wasserstein distance outperforming the original optimal transport distance. It asks the authors to explain this observation, which is a clear and actionable request for further clarification. By prompting the authors to provide an explanation, the comment helps guide them in understanding and potentially resolving a potential issue or misunderstanding in their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this observation. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the word \"confident\" in the sentence is unclear and suggests rephrasing it to clarify whether it refers to model confidence or human interpretability. While the comment implies that the authors should rephrase the sentence to improve clarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should revise the sentence to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence containing the word \"confident,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, suggesting that the word \"confident\" should be rephrased to clarify whether it refers to model confidence or human interpretability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the word \"confident\" in the sentence, suggesting that it may refer to model confidence or human interpretability. The reviewer provides a logical reasoning by questioning the word choice, which is a common practice in scientific writing. However, the comment lacks specific examples or references to support the claim that the word is unclear or misleading. While the reasoning is sound, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the word \"confident\" in the sentence, suggesting that it may be unclear whether it refers to model confidence or human interpretability. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to rephrase the sentence or clarify the intended meaning. The feedback is 3 as it points out a potential source of confusion, but it lacks actionable suggestions or examples to fully assist the authors in making the necessary changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the practicality of the proposed work, specifically regarding the use of known causal relationships between features. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the practicality of their work or what specific steps they could take to ensure the validity of their causal relationships. As a result, the comment lacks actionability, leaving the authors without a clear path forward to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.", "grounding_specificity_rationale": "The comment addresses the paper\"s proposal to use known causal relationships between features, noting that prior knowledge might not always be available or accurate for specific subpopulations. It raises a concern about the practicality of the work, which is relevant to the paper\"s focus on causal relationship mining from data automatically. However, the comment does not specify which part of the paper discusses this proposal or where the authors should address the concern. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific about the concern regarding practicality, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed work relies on known causal relationships between features, which might not always be available or accurate for specific subpopulations. The reviewer supports this claim by noting that most researchers focus on mining causal relationships from data automatically. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3, as it requires more detailed support to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s proposal, noting that the use of known causal relationships between features might not always be available or accurate for specific subpopulations. This is a relevant concern that could impact the practicality of the work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the practicality of their approach. While it highlights an important consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of polishing in figures and empirical results, which affects clarity and confidence in empirical findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. However, the comment does not explicitly instruct the authors on how to address these issues or provide guidance on how to improve the clarity and polish of the figures and results. The action is implicit and somewhat vague, as the authors can infer that they need to improve the presentation of their results, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the figures and empirical results, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the lack of polishing in figures and empirical results, including missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks polishing in figures and empirical results, which affects clarity and confidence in empirical findings. The comment provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These examples provide a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar studies that have addressed these issues. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and confidence in the empirical findings of the paper. It points out specific problems, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and core findings conducted on smallscale datasets and a single architecture type. These observations highlight areas where the paper could be improved in terms of polish and presentation, which are crucial for ensuring the validity and impact of the results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending specific improvements or examples of how similar studies have handled these challenges. Overall, the comment is 4 as it highlights important areas for improvement, but it lacks detailed guidance on how to achieve those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the novelty of their work. There is no guidance on how to enhance the generalizability of the findings or suggestions for further exploration. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the work, specifically noting that the findings are expected due to taskspecific finetuning. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the novelty, but it lacks grounding as it does not reference a specific section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the work is limited due to the expected outcome of taskspecific finetuning. However, it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific examples or references to similar studies or observations that would help the authors understand the basis of the critique. As a result, the claim is not verifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work but points out that the findings are limited due to the expected outcome of taskspecific finetuning. It suggests that the novelty is expected given the general trend of taskspecific finetuning increasing confidence for specific tasks while potentially reducing generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the generalizability of their findings. While it identifies a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. It explicitly states that this would further test the conjecture and provide valuable insights, even if the phenomenon weakens in this setting. The comment is clear and provides a direct action for the authors to take, which is to include these numbers in their report. The action is concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, specifically mentioning the nontail classes. This provides a clear direction for the authors to consider, as it specifies the part of the paper where the additional information should be included. However, the comment does not explicitly mention which section or part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific, as it details what additional information would strengthen the case of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this additional information is necessary or how it would impact the paper\"s conclusions. Without such justification, the claim remains 1, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper\"s case. This feedback is actionable as it provides a clear and specific direction for the authors to enhance their work by including additional data that could further substantiate their findings. The comment also acknowledges the potential weakening of the phenomenon in this setting but emphasizes the importance of including the numbers for completeness and insight. However, the comment could be more helpful if it explained why this additional data is crucial or how it would impact the paper\"s conclusions. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. It implies that the authors should provide additional feedback to explain this choice and potentially justify it. However, the comment does not explicitly instruct the authors to provide this feedback or specify what additional information should be included. While the action is implied, it is not concrete, as the authors are left to infer what specific feedback is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this metric is discussed. The authors can infer that it relates to the discussion of metrics or experimental results, but this inference is not direct. The comment is specific in its question about the choice of metrics, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the number of weight updates is a better metric. Without additional context or explanation, the claim remains 1, as it lacks the necessary support to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid question about the choice of metrics used in the paper, specifically questioning the rationale behind using the number of weight updates as a metric rather than the number of network updates, given that the brain operates in parallel. This is a relevant point that could lead to a deeper understanding of the paper\"s methodology and its implications. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it identifies a potential weakness, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the objective should be clarified. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the objective, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point poses a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a request for clarification, which is factual in nature. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the objective given by the adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. This is a relevant point that could help the authors clarify the purpose and significance of their proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this question or improve their explanation. While it identifies an area for clarification, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It also suggests that the paper should explore the effects of varying the number of InContext Examples. While the comment provides explicit actions for the authors to take, such as including more details on the experiment setup and exploring different datasets, it does not specify how to implement these actions or provide concrete guidance on how to address the issues. Therefore, the comment is 3, as it clearly identifies areas for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluation\" and \"experiments\" sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. The comment suggests exploring the effects of varying the number of InContext Examples and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not comprehensive and lacks transparency regarding the experiment setup. It specifically mentions the absence of information on the number of different sets of incontent examples used and the lack of exploration of varying the number of InContext Examples. The comment also highlights the reliance on a single dataset, which could limit the generalizability of the results. While the comment provides some logical reasoning by pointing out the absence of specific details, it lacks specific examples or references to support the claim about the effects of varying the number of InContext Examples. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation in the paper, including a lack of transparency regarding the experiment setup, the absence of information on the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the paper should explore the effects of varying the number of InContext Examples and provide more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to address specific areas that could enhance the transparency and robustness of their evaluation. However, the comment could be more helpful if it offered suggestions on how to implement these improvements or provided examples of how other studies have addressed similar issues. Overall, the comment is 4 as it effectively points out areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the contrastive learning framework used in the paper is the same as SimCLR, which is a direct observation. However, it does not provide any guidance or suggestions on how the authors should address this observation or what changes they should make to their framework. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the contrastive learning framework used in the paper is the same as SimCLR, but it does not specify which part of the paper this observation is based on. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what needs to be addressed or improved regarding the comparison to SimCLR. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion or how it affects the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which could be a potential issue or a point of comparison. However, it does not provide any further context, explanation, or suggestions on how the authors might address this observation or what implications it might have for their work. Without actionable feedback or guidance, the authors are left without a clear understanding of how to proceed or what improvements could be made. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. It suggests that these comparisons could showcase the unique advantages or potential shortcomings of the proposed method in a broader context. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what comparisons are needed and why they are important. The authors know exactly what to add to their draft to improve it, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides clear guidance on what needs to be addressed in this section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests that these comparisons could provide a broader context for the proposed method. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the importance of these comparisons and consider whether they are necessary for their work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback highlights the importance of including such comparisons to showcase the unique advantages or potential shortcomings of the proposed method in a broader context. By suggesting these comparisons, the comment provides clear and actionable guidance for the authors to enhance the comprehensiveness and impact of their work. However, the comment could be more helpful if it offered specific examples or references to similar studies that have conducted such comparisons. Overall, the comment is 4 as it directs the authors to a meaningful area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While the comment implies that the authors should include these references, it does not explicitly instruct them to do so or provide guidance on how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, it does not specify which part of the paper should include this additional attention or how it should be integrated. The authors can infer that it relates to the literature review or discussion sections, but the comment lacks full grounding as it does not explicitly mention these sections. The suggestion is specific in terms of the references to include, but it is 1 in the context of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. However, the comment does not provide any reasoning or explanation as to why these references are relevant or how they could enhance the paper. Without additional context or justification, the claim lacks verifiability, as it does not provide sufficient evidence or guidance for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning references [1], [2], and [3]. While this feedback identifies a potential area for improvement, it lacks depth and does not provide specific guidance on how the authors should integrate these references into their work or what aspects of the related work are most relevant to their study. The comment is 3 as it points out a potential gap in the literature review, but it could be more beneficial with additional details or suggestions for incorporating the references. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps for the authors to take. The authors can infer that they should include comparisons with existing text GANs and test SeqGAN with pretrained versions, but the comment lacks specific guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of a comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in detailing what is missing, namely the comparison with existing GANs and the testing of SeqGAN with pretrained versions. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no comparison against existing text GANs, specifically mentioning that many of them have opensource implementations. It also notes that SeqGAN is mentioned but not tested with the pretrained version. However, the comment lacks specific examples or references to existing GANs or SeqGAN implementations to support the claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, noting the absence of a comparison against existing text GANs, many of which have opensource implementations. It also points out that SeqGAN is mentioned but not tested with the pretrained version. This feedback is clear and actionable, as it highlights specific areas where the paper could be strengthened by including comparisons with existing models and testing SeqGAN with pretrained versions. However, the comment could be more helpful if it provided examples of existing GANs or suggested specific ways to conduct the comparisons. Overall, the comment is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. While the comment implies that the paper lacks depth in this area, it does not provide specific guidance on how to address this issue or what aspects of the algorithmic aspects should be covered. The action is implicit and somewhat vague, as the authors can infer that they need to expand on the algorithmic aspects but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. However, it does not specify which part of the paper this suggestion pertains to, such as the sections discussing the algorithmic aspects or the introduction of the Blackwell winner. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the algorithmic aspects should be addressed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This claim is based on the observation that the novelty of the paper seems limited after introducing the Blackwell winner. However, the comment lacks specific examples or detailed reasoning to support why the algorithmic aspects are crucial or how they could enhance the paper\"s contribution. The lack of specific evidence or detailed justification makes the claim 3, as it provides a logical basis but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment suggests that the paper should focus on the algorithmic aspects of the solution, particularly after introducing the concept of the Blackwell winner. This feedback is 3 as it identifies a potential area for improvement by suggesting that the paper could provide more depth on the algorithmic aspects. However, the comment lacks specific guidance on which algorithmic aspects to focus on or how to address the issue of limited novelty after introducing the Blackwell winner. While it points out a potential weakness, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that Table 4 and 5 should be split into two tables each, with one table per measure. This provides a clear and concrete action for the authors to take, as it specifies the exact change needed to improve the readability of the tables. The suggestion is specific and actionable, leaving no ambiguity about what the authors should do to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of the tables by splitting them into two tables each, with one table per measure. This gives the authors a clear idea of what needs to be addressed to improve the clarity of the tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that splitting tables 4 and 5 into two tables each would improve their readability. This claim is based on a logical reasoning that splitting the tables would make it easier to follow the data presentation. However, the comment does not provide specific examples or references to support this claim, such as how other papers or studies have successfully implemented this structure. While the suggestion is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and constructive piece of feedback that can help the authors enhance the clarity and organization of their data presentation. By following this suggestion, the authors can make their tables more intuitive and easier to navigate, which is a valuable improvement for the overall readability of their paper. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. This is a direct and concrete action for the authors to take, as it clearly identifies a specific aspect of the figure that needs clarification. The comment provides a clear and specific guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of \"valid\" and \"orig\" in the context of Fig. 5. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it would be helpful to specify what \"valid\" and \"orig\" differ in, as presented in Fig. 5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Fig. 5, noting that it would be helpful to specify what \"valid\" and \"orig\" differ in. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and understanding of the figure. By addressing this point, the authors can enhance the readability and comprehensibility of their draft. However, the comment could be more helpful if it provided additional context or examples of how this clarification might be achieved. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could be improved by making the comparisons with the most closely related work more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and concrete action for the authors to take. The comment is explicit in its suggestion and offers a specific improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"most closely related work of Zemel et al. (2013)\" and the present paper, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be improved, namely making comparisons more systematic with respect to the tuning of each method. This provides clear guidance on how to enhance the originality and comparative analysis of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons with the most closely related work more systematic, specifically by comparing the best performance of each method. The comment provides a logical reasoning by suggesting that this would enhance the originality and comparative analysis of the paper. However, it lacks specific examples or references to the Zemel et al. (2013) work or the current paper\"s comparisons, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the comparisons with the most closely related work. It suggests that the paper could be strengthened by making these comparisons more systematic, particularly by comparing the best performance of each method. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the originality and comparative analysis of the paper. By addressing this point, the authors can significantly improve the quality and impact of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. While the comment implies that the authors should consider including such a comparison, it does not provide specific guidance on which method to compare or how to adapt it to language tasks. The action is implicit and somewhat vague, as the authors need to infer the specific method and adaptation steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to one of the methods mentioned in the computer vision setting, specifically mentioning lossbased sampling as an example. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the comparison could be included. While the authors might have an idea of where this suggestion fits, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting a potential improvement by including a comparison to computer vision methods, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some could be adapted to language tasks relatively easily. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that these methods could be adapted. The authors would need to infer the specific methods and their applicability to language tasks, which adds a degree of uncertainty to the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. The reviewer acknowledges that these methods may not always be applicable and require a supervised setup, but suggests that some of them could be adapted to language tasks relatively easily. This feedback is 3 as it provides a specific suggestion for enhancing the paper by including a comparison that could offer insights into the applicability of computer vision methods to language tasks. However, the comment could be more helpful if it included specific examples of methods that could be adapted or how they could be applied to language tasks. Overall, the comment provides a clear direction for improvement but lacks detailed guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to explicitly estimate the time complexity of the learning algorithm to prove its scalability properties. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion for how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the need to estimate the time complexity of the learning algorithm to prove its scalability properties, which provides full grounding as it clearly identifies the part of the paper being addressed. It is specific because it clearly specifies what needs to be addressed, namely the estimation of time complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper\"s conclusions. Without additional context or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the time complexity of the learning algorithm should be explicitly estimated to prove its scalability properties. This is a clear and actionable suggestion that can help the authors strengthen their claims about the algorithm\"s performance. By addressing this point, the authors can provide more robust evidence to support their conclusions. However, the comment could be more helpful if it included examples or guidance on how to estimate the time complexity effectively. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that there may be a connection between the third point of definition one and properties of universal kernels, specifically mentioning chapter 4 of Steinwart and Christmann. However, it does not provide explicit instructions or guidance on how the authors should explore or incorporate this connection. The comment implies that the authors should investigate the relationship but lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential connection to properties of universal kernels, referencing chapter 4 of Steinwart and Christmann. This provides clear guidance on what aspect of the paper should be explored further. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. However, the comment does not provide a detailed explanation or reasoning for why this connection is relevant or how it could be explored. The reference to Steinwart and Christmann is specific, but the lack of further elaboration on the connection makes the claim 3. The authors would need to infer the significance of the reference and explore it themselves, which requires additional effort. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a potential connection between the third point of definition one and properties of universal kernels, specifically referencing chapter 4 of Steinwart and Christmann. This is a valuable suggestion that could lead to a deeper understanding of the topic and potentially enhance the paper\"s contribution. However, the comment lacks specific guidance on how to explore this connection or what aspects of the universal kernel properties are relevant to the paper. While it points to a potentially interesting direction, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a starting point for the authors but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the discussion around equation (10) is terse and not clearly explained. However, it does not provide any explicit or implicit actions for the authors to take to improve the discussion. There is no guidance on what aspects of the discussion need to be expanded or clarified, nor are there suggestions for how to present the information more effectively. As a result, the authors are left without any actionable steps to follow in order to address the issue. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. However, it does not specify what aspect of the discussion is lacking or how it could be improved, making the comment weakly grounded but specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is \"very terse\" and not \"very clearly explained.\" However, it does not provide any specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. However, it does not provide any suggestions or guidance on how the authors might improve the clarity or depth of this discussion. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of enhancing their draft. Therefore, it is rated as 2, as it points out a weakness but lacks depth and specificity in its critique."}
