{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the authors are dealing with a challenging min-max optimization problem, which is typically difficult to train and execute correctly, especially for PDEs with advective terms. It also notes that the methodology performs better than the baselines but highlights the lack of clarity in the presentation and precise steps. The reviewer suggests that the paper would benefit from a revision. While the comment identifies an area for improvement, it does not provide specific guidance on what aspects of the presentation or methodology need to be revised or how to address the lack of clarity. The action is implicit and somewhat vague, as the authors are left to infer which parts of the presentation or methodology need improvement and how to make those changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the challenge of min-max optimization, which is typically difficult to train and execute correctly, especially for PDEs with advective terms. It acknowledges that the methodology provided by the authors performs better than the baselines but notes the lack of clarity in the presentation and precise steps. However, the comment does not specify which part of the paper is lacking clarity or where the precise steps are missing. This makes it difficult for the authors to pinpoint the exact areas needing revision. While the authors might have an idea of where the issues lie, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the challenge of min-max optimization, which is typically difficult to train and execute correctly, especially for PDEs with advective terms. It notes that the methodology provided by the authors performs better than the baselines but highlights the lack of clarity in the presentation and precise steps. The reviewer suggests that the paper would benefit from a revision. While the comment identifies a potential issue with the methodology and suggests a need for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer which parts of the presentation or methodology need clarification, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the challenge of min-max optimization, which is typically difficult to train and execute correctly, especially for PDEs with advective terms. It notes that while the methodology provided by the authors performs better than the baselines, the presentation lacks clarity in the precise steps. The reviewer suggests that the paper would benefit from a revision, implying that the authors should address the lack of clarity in their methodology. However, the comment does not provide specific guidance or suggestions on how to improve the clarity or what aspects of the presentation need revision. While it identifies an area for improvement, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical use of the modified TD learning algorithm defined in Definition 5.1, compared to the original proposal (Algorithm 1). While the comment implies that the authors should justify the use of the original algorithm in practice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for the practical use of the original algorithm. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the practical use of the modified TD learning algorithm defined in Definition 5.1, compared to the original proposal (Algorithm 1). The comment clearly specifies what needs to be addressed, namely, the justification for using the original algorithm in practice. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the practical use of a modified TD learning algorithm compared to the original proposal. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the practical implications of using a modified TD learning algorithm defined in Definition 5.1, compared to the original proposal (Algorithm 1). This question prompts the authors to justify the choice of the original algorithm in practice, which is a valuable consideration for the authors to address. However, the comment does not provide specific guidance or suggestions on how to address this question or what aspects of the original algorithm make it preferable in practice. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical utility of the data quality metric suggested in the paper, specifically the diversity coefficient. It points out that the paper does not empirically validate this claim, which is a significant issue given the emphasis on Task2Vec and model diversity. While the comment identifies a critical gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct empirical validation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"diversity coefficient\" as a potential data quality metric and references the paper\\'s emphasis on Task2Vec and model diversity. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of not empirically validating the claim of the diversity coefficient as a data quality metric. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s suggestion of the diversity coefficient as a data quality metric lacks empirical validation, which is a significant concern given the paper\\'s emphasis on Task2Vec and model diversity. The comment provides a logical reasoning by highlighting the importance of empirical validation in establishing the practical utility of the proposed metric. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and address this concern to strengthen their paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper regarding the practical utility of the data quality metric suggested, specifically the diversity coefficient. It points out that the paper does not empirically validate this claim, which is a significant concern given the emphasis on Task2Vec and model diversity. This feedback is clear and actionable, as it highlights a specific area where the authors need to provide empirical evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how to conduct the empirical validation or what specific aspects should be addressed. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. However, it does not explicitly instruct the authors to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they should consider using canary examples instead of clients and allocate more resources accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or examples, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the resource allocation might be needed or how to address the inefficiency. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or detailed explanations of why canary clients are inefficient or how resource allocation could be adjusted. As a result, the claim is not fully verifiable, as it requires additional information or justification to be understood and addressed by the authors. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that using canary clients is more inefficient compared to using canary examples and implies that more resource allocation might be needed. While it identifies a potential inefficiency, the comment lacks specific guidance or suggestions on how to address this issue or improve the resource allocation. Without detailed advice or examples, the authors may find it challenging to implement the suggested changes effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide enough detail to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models.\" The reviewer implies that the authors should clarify the significance of Carefl in their work, but does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of Carefl\\'s relevance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (6)\" and references \"On Causal Discovery with Cyclic Additive Noise Models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of Carefl and suggests that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in the referenced work. This provides clear guidance on what the authors need to address to clarify the relevance of Carefl in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to \"On Causal Discovery with Cyclic Additive Noise Models,\" which could be relevant to the discussion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that Carefl is a standard definition. While the reference provides some support, the comment could be strengthened with more detailed justification or examples to fully verify the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references a specific equation (Equation 4) from a related work, \"On Causal Discovery with Cyclic Additive Noise Models,\" which could provide context for the authors to clarify the significance of Carefl in their study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their work. While it identifies a potential area for clarification, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer references Equation (4) from a related work, \"On Causal Discovery with Cyclic Additive Noise Models,\" which could provide context for the authors to clarify the significance of Carefl in their study. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to clarify the relevance of Carefl. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (6)\" and references \"On Causal Discovery with Cyclic Additive Noise Models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of Carefl and suggests that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in the referenced work. This provides clear guidance on what the authors need to address to clarify the relevance of Carefl in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to \"On Causal Discovery with Cyclic Additive Noise Models,\" which could be relevant to the discussion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that Carefl is a standard definition. While the reference provides some support, the comment could be strengthened with more detailed justification or examples to fully verify the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It references a specific equation (Equation 4) from a related work, \"On Causal Discovery with Cyclic Additive Noise Models,\" which could provide context for the authors to clarify the significance of Care"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It suggests that if the assumption about the GAA model's performance is not valid, it could lead to larger annotation times, questioning the speedup claim of the proposed approach. While the comment identifies a potential problem, it does not provide explicit guidance on how to address it. The authors are left to infer that they might need to consider alternative approaches or provide evidence supporting the GAA model\\'s performance. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It also raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the potential problem with the approach and the implications for the speedup claim. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. The comment provides a logical reasoning for the concern, suggesting that if the assumption is not valid, it could impact the speedup claim of the proposed approach. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and address this concern to strengthen their argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. This feedback is somewhat helpful as it highlights a critical aspect of the approach that could impact its efficiency and effectiveness. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative approaches to consider. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the potential problem with the approach and the implications for the speedup claim, but without explicit references or detailed guidance, it remains somewhat vague. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the GAA model is performant enough to provide meaningful prompts, which could lead to larger annotation times. The comment provides a logical reasoning for the concern, suggesting that if the assumption is not valid, it could impact the speedup claim of the proposed approach. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and address this concern to strengthen their argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the proposed method, specifically its dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method. The comment lacks actionable guidance, leaving the authors without a clear path to follow in order to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, namely its dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this dependence, making it weakly grounded. The comment is specific in identifying the limitation and its impact on the method\\'s generality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, specifically its dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights an important area for improvement that the authors should consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance the generality of their method. While it points out a critical issue, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, specifically its dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method. Without actionable guidance or specific recommendations, the authors are left without a clear path to follow in order to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the proposed method, namely its dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this dependence, making it weakly grounded. The comment is specific in detailing the limitation and its impact on the method\\'s generality, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, specifically its dependence on the server dataset, which restricts its potential use cases and reduces its generality. This feedback is valuable as it highlights an important area for improvement that the authors should consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance the generality of their method. While it points out a critical issue, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, specifically its dependence on the server dataset, which restricts its potential use cases and reduces its generality. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the generality of their method. Without actionable guidance or specific recommendations, the authors are left without a clear path to follow in order to enhance their draft. Therefore, this comment"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider adding additional downstream search methods, such as BO and LS, to their analysis. While the comment implies that the authors should expand their exploration of search methods, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to implement this change or why these particular methods should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding additional downstream search methods, such as BO and LS, to the analysis. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these methods are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting the addition of specific methods, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that only a single downstream search method (EA) is provided, and it recommends adding other methods like BO and LS. However, the comment does not provide any reasoning or evidence to support why these additional methods would be beneficial or necessary. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider adding additional downstream search methods, such as BO and LS, to their analysis. This feedback is somewhat helpful as it identifies a potential limitation in the current approach and provides a specific suggestion for improvement. However, the comment lacks depth and does not explain why these additional methods might be beneficial or how they could enhance the analysis. To be more helpful, the comment could include reasoning or examples of how these methods could improve the study. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. It explicitly suggests that a direct comparison with other sparse models is missing. This feedback provides a clear and direct action for the authors to take, which is to include a comparison with other sparse models. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: a direct comparison of FLOPs and FPS with other sparse models. This provides clear guidance on what needs to be added to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not sufficiently highlight the comparison of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. The comment provides a logical reasoning by stating that a direct comparison with other sparse models is missing, which is a relevant point. However, it lacks specific examples or references to other sparse models for comparison, making it somewhat verifiable. The authors would need to infer which models should be compared, which adds a layer of complexity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by highlighting the comparison of FLOPs and FPS in sparse network research. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it directs the authors to include a comparison with other models to provide a more comprehensive analysis. However, the comment could be more helpful if it suggested specific models or methods for comparison. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the metrics described in Appendix A.1 are difficult to understand, leading to confusion about the meaning of the numbers in the result tables. It provides a specific example of how reversing the prediction of Dolly-V2-7B in Table 5 would yield an incorrect accuracy of 97%. This feedback is clear and provides a concrete action for the authors to take, which is to clarify the metrics and ensure they are correctly interpreted. The authors know exactly what needs to be done to improve the draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and providing a specific example of how reversing the prediction of Dolly-V2-7B in Table 5 would yield an incorrect accuracy. This level of detail helps the authors understand what needs to be addressed to improve the clarity of the metrics and their interpretation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are hard to understand, leading to confusion about their meaning in the result tables. The reviewer provides a specific example to illustrate the issue, mentioning that reversing the prediction of Dolly-V2-7B in Table 5 would yield an incorrect accuracy of 97%. This example provides a clear and logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific sections or providing more detailed examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand and that the numbers in the result tables are unclear. It provides a concrete example of how reversing the prediction of Dolly-V2-7B in Table 5 would yield an incorrect accuracy of 97%, which highlights the need for clarification. This feedback is clear and actionable, as it guides the authors to improve the clarity and accuracy of their metrics and results. However, the comment could be more helpful if it suggested ways to improve the presentation or interpretation of the metrics. Overall, the comment is mostly helpful, as it effectively directs the authors to address a significant issue in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the Gaussian assumption and its implications for the analysis. It asks whether this assumption is typical in practice, whether it is always possible to compute the effective variance for non-gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the questions imply that the authors should consider these aspects, they do not provide explicit guidance on how to address them. The authors are left to infer that they need to explore these questions further, but without concrete suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its implications for the analysis. It asks whether this assumption is typical in practice and whether it is always possible to compute the effective variance for non-gaussian outputs. Additionally, it inquires about a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the analysis or methodology sections. The questions are specific, as they clearly outline what needs to be addressed regarding the Gaussian assumption and its implications. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the Gaussian assumption and its implications for the analysis. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual in nature and seek additional information or clarification, making them normal statements. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the Gaussian assumption and its implications for the analysis. It inquires whether this assumption is typical in practice, whether it is always possible to compute the effective variance for non-gaussian outputs, and whether there is a finite-N expansion that characterizes the departure from Gaussianity in the non-ideal case. While the comment identifies areas of potential concern and prompts the authors to consider these questions, it does not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it encourages the authors to explore these aspects further, but it lacks depth and actionable advice, leaving the authors with a general direction rather than a concrete path for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach to the math and science categories suggests an open vocabulary problem that is not clearly addressed. It also mentions that other categories are tackled via Wikipedia and a popularity metric. However, the comment does not provide explicit guidance or suggestions on how the authors should address the open vocabulary problem or improve the approach for the math and science categories. The feedback lacks concrete steps or examples, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. It also mentions that other categories are addressed through Wikipedia and a popularity metric. However, the comment does not specify which part of the paper discusses these categories or how they are currently being addressed, making it weakly grounded. The comment is specific in identifying the issue with the approach to the math and science categories and the use of Wikipedia and popularity metrics for other categories. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly addressed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach to the math and science categories, suggesting that it presents an open vocabulary problem that is not clearly addressed. It also notes that other categories are addressed through Wikipedia and a popularity metric. However, the comment lacks specific guidance or suggestions on how the authors might address the open vocabulary problem or improve the approach for the math and science categories. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given some insight into an area needing improvement but are left without clear direction on how to proceed. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include a more thorough discussion of stochastic routing, as it shares similarities with the work in question. While the comment implies that a more detailed discussion is needed, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer that they need to expand their discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a more thorough discussion of stochastic routing, implying that the similarity to this work is significant. However, it does not specify which part of the paper should include this discussion or where the current discussion is lacking. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a more detailed discussion of stochastic routing, but without clear grounding, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should include a more thorough discussion of stochastic routing due to its similarity to the work in question. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a more thorough discussion of stochastic routing, as it shares similarities with the work in question. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this discussion or what aspects should be emphasized. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s discussion, but it does not offer actionable advice or examples to help the authors address this issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential nature of the problem. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific changes should be made to their draft. The action is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion about convergence, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. While it provides a logical reasoning for this suggestion, it lacks specific guidance or examples on how the authors might address this issue in their draft. The comment does not offer actionable steps or detailed feedback that would help the authors improve their work. As a result, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide sufficient detail for the authors to effectively implement the suggestion. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific changes should be made to their draft. The action is implicit and lacks concrete details, making it difficult for the authors to understand and implement the feedback. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section, figure, or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion about convergence, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not provide any specific guidance or examples on how the authors might address this suggestion or why it is relevant to their work. The comment lacks actionable feedback and does not offer detailed insights or constructive advice that would help the authors improve their draft. As a result, the comment is not helpful at all, as it does not provide the authors with meaningful information to enhance their work. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the exponential problem. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific changes should"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors claim flexibility in their framework by allowing components to be replaced by other models, but they have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework. This feedback implies that the authors should conduct experiments or evaluations to substantiate their claim of flexibility and robustness. However, the comment does not provide specific guidance on which components to replace or how to conduct these experiments, leaving the authors with a general idea of what needs to be done but without detailed instructions. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the flexibility of their framework, which allows components to be replaced by other models. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in that it points out the lack of experimentation or alternatives to demonstrate the robustness of the proposed framework. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have stated flexibility in their framework but have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework. This claim is somewhat verifiable as it highlights a gap in the paper\\'s experimental validation. However, it lacks specific examples or references to support the claim, such as which components were considered for replacement or how the robustness of the framework could be demonstrated. The authors would need to infer the extent of the claim and determine what experiments or alternatives might be necessary to address it. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the authors claim flexibility in their framework by allowing components to be replaced by other models, but they have not attempted any changes or alternatives to demonstrate the robustness of their proposed framework. This feedback is clear and actionable, as it highlights a gap in the experimental validation of the framework\\'s flexibility. By suggesting that the authors conduct experiments or evaluations to substantiate their claim, the comment provides a concrete direction for improvement. However, it could be more helpful if it offered specific suggestions on which components to replace or how to conduct these experiments. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 30 disentangled factors in the Atari game experiments. It implies that the authors should provide an explanation or justification for this choice, as it might be difficult to specify for an arbitrary domain. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation but are not given specific steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of 30 disentangled factors and highlights the difficulty in specifying this number for an arbitrary domain. This provides clear guidance on what aspect of the paper needs clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of 30 disentangled factors in the Atari game experiments. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of 30 disentangled factors in the Atari game experiments, which is a relevant point for the authors to address. However, the comment does not provide any suggestions or guidance on how the authors might justify or explain this choice, nor does it offer alternative approaches or considerations. While it identifies an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the use of colloquial expressions in the paper, particularly the phrase \"By the way.\" However, it does not provide any guidance on how to address this issue or suggest alternative phrasing. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific colloquial expression used in the paper, \"By the way,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the use of colloquial expressions that are considered unprofessional. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that colloquial expressions are unprofessional, specifically mentioning the phrase \"By the way.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this particular expression is inappropriate or how it affects the professionalism of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the use of colloquial expressions in the paper, particularly the phrase \"By the way.\" However, it does not provide any guidance or suggestions on how to address this issue or improve the professionalism of the language used. Without actionable feedback or examples of alternative phrasing, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a problem but lacks actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly points out that the abbreviation \"LLH\" has never been defined, despite the abbreviation \"OOD\" being explicitly defined. It also notes that the abbreviation \"ECE\" has never been defined and lacks explanation, despite being a pivotal metric in the work. This feedback provides clear and explicit actions for the authors to take, namely, to define the abbreviations \"LLH\" and \"ECE\" and provide explanations for them. The comment is specific in its requests, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the abbreviation \"LLH,\" indicating that it was never defined, and points out that \"OOD\" has been explicitly defined. It also notes that \"ECE\" has never been defined and lacks explanation, despite being a pivotal metric in the work. This provides full grounding as it clearly identifies the specific abbreviations and metrics being discussed. The comment is also specific, as it details what needs to be addressed regarding the definitions and explanations of these abbreviations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abbreviation \"LLH\" was never defined, despite \"OOD\" being explicitly defined. It also notes that \"ECE\" has never been defined and lacks explanation, despite being a pivotal metric in the work. This claim is somewhat verifiable as it points out specific instances where definitions are missing, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of these definitions and the impact on the paper\\'s clarity and comprehensibility. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of definition for the abbreviation \"LLH,\" which has not been defined despite being used in the text. It also points out that the abbreviation \"ECE\" has never been defined, despite being a pivotal metric in the work. This feedback is clear and actionable, as it directly points out areas where the authors need to provide additional context or definitions to improve the clarity and comprehensibility of their work. By addressing these issues, the authors can enhance the reader\\'s understanding of their methodology and results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic or random projections at each layer. It explicitly asks the authors to justify the stability of their method and to provide information on how stable it is and what happens when more layers are stacked. This feedback provides a clear and direct action for the authors to take, which is to address the stability of their method and provide evidence or analysis to support it. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the stability of the proposed method when stacking multiple layers of WLS units. It raises a question about the probability of failure cases in stochastic or random projections at each layer and asks for justification on the stability of the method. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the stacking of layers is discussed. The comment is specific in detailing the issue and the need for justification, but it lacks full grounding as it does not explicitly mention the section being addressed. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, given the increased probability of failure cases in stochastic or random projections at each layer. The reviewer questions the impact on the proposed method\\'s ability to form deeper GNNs. While the comment highlights a potential issue, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors are left with a general concern about the method\\'s stability without clear guidance on how to address it. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the concern but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units. It points out that the increased probability of failure cases in stochastic or random projections at each layer could hinder the formation of deeper GNNs. The comment is specific in asking the authors to justify the stability of their method and to provide information on how stable it is and what happens when more layers are stacked. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology that could impact the effectiveness of their proposed method. However, the comment could be more helpful if it offered suggestions on how to assess or improve the stability of the method. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific area of the paper that lacks clarity, namely the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify this section, but it does not offer concrete steps or examples of what needs to be clarified. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific section of the paper, \"Definition 4.1,\" which lacks clarity regarding the computation of the Bottleneck Distance. This provides full grounding as it allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the clarity of the computation method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any supporting evidence, examples, or detailed reasoning to justify why this section is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks clarity, namely the computation of the Bottleneck Distance in Definition 4.1. This feedback is somewhat helpful as it points out a potential weakness in the paper that the authors need to address. However, the comment does not provide detailed guidance or suggestions on how to improve the clarity of this section, such as by offering examples, explanations, or alternative approaches. While it highlights an important area for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the visualization in Figure 5, suggesting that it is weaker compared to Balikas COLING16\\'s work. The reviewer implies that the authors should provide a longer exemplar and ensure that the color assignment is consistent with the topics listed in Figure 4. While the comment suggests specific actions to improve the visualization, it does not provide explicit instructions on how to achieve these improvements. The authors can infer that they need to enhance the visualization and ensure consistency, but the comment lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the visualization, suggesting that it is weaker compared to Balikas COLING16\\'s work and recommending improvements by providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has a weaker visualization compared to Balikas COLING16\\'s work, which raises doubts about the segmenting and assigning results of the document. The reviewer suggests that providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4 could make the results more convincing. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to Balikas COLING16\\'s work to substantiate the comparison. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visualization in Figure 5, noting that it is weaker compared to Balikas COLING16\\'s work. It suggests that providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4 could enhance the paper\\'s credibility. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by addressing the visualization issue. However, the comment could be more helpful if it provided additional guidance on how to achieve these improvements or examples of what constitutes a longer exemplar. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using a parameter-efficient training method with a small backbone model, P5-small. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. There is no guidance on whether the authors should reconsider their choice of model, explore alternative training methods, or provide a justification for their current approach. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of P5-small as the backbone model and questions the necessity of using a parameter-efficient training method. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the purpose of using a parameter-efficient method with a small model, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of using a parameter-efficient training method with a small backbone model, P5-small. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is questionable or unnecessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the use of P5-small as the backbone model and the necessity of employing a parameter-efficient training method. While it identifies a potential issue with the choice of model and training method, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern. Without actionable feedback or a clear direction for improvement, the comment offers limited value to the authors. Therefore, it is rated as barely helpful, as it highlights a potential area for consideration but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors\\' goal of proposing a way to create a challenging set is not scalable, as what they describe appears to be specific. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or make their proposal more scalable. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors\\' goal of proposing a way to create a challenging set is not scalable, as what they describe appears to be specific. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the proposal are considered specific or not scalable. Without clear grounding or detailed feedback, the authors cannot effectively address the critique. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors\\' goal of proposing a way to create a challenging set is not scalable, as what they describe appears to be specific. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed method for creating a challenging set. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. The comment highlights a potential weakness but does not offer constructive advice, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their approach. There is no guidance on whether the authors should consider alternative methods, provide additional justification, or explore different approaches to mitigate this reliance. Without any actionable advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this concern relates to, such as a particular section, figure, or table. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of this reliance are problematic or how it could be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any supporting evidence, reasoning, or examples to justify why this reliance is a concern or how it might impact the method\\'s effectiveness. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. The comment lacks depth and specificity, making it difficult for the authors to effectively use this feedback to improve their work. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, and finds this acceptable as long as it works. However, it does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might enhance their work. The comment lacks actionable advice or specific recommendations, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the approach are considered derivative or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively address the comment. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this combination is acceptable or how it might work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand or address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not provide any constructive feedback or suggestions for improvement. The comment lacks specificity and does not offer guidance on how the authors might enhance their work or address potential weaknesses. Without actionable advice or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks explicit or implicit guidance on how the authors might enhance their work or address potential weaknesses. Without specific advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the approach are considered derivative or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively address the comment. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this combination is acceptable or how it might work. Without such information, the claim lacks verifiability, making it difficult for the authors to understand or address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not provide any constructive feedback or suggestions for improvement. The comment lacks specificity and does not offer guidance on how the authors might enhance their work or address potential weaknesses. Without actionable advice or detailed insights, the comment does not assist the authors in improving their draft. Therefore, it is rated as not helpful at all.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not provide any actionable feedback or suggestions for improvement. The comment lacks explicit or implicit guidance on how the authors might enhance their work or address potential weaknesses. Without specific advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but finds this acceptable as long as it works. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the approach are considered derivative or how they could be improved. Without specific references or detailed feedback"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of comparisons against other baseline approaches in the evaluation, suggesting that a simple photographic style transfer method might achieve similar or better results. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons and determine which specific baseline approaches to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the lack of comparisons against other baseline approaches in the evaluation, specifically mentioning the results shown in the paper and supplementary material. It suggests that a simple photographic style transfer method might achieve similar or better results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include comparisons is specific, but without explicit grounding, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no comparisons against other baseline approaches in the evaluation, suggesting that a simple photographic style transfer method might achieve similar or better results. The reviewer provides a logical reasoning by referencing the results shown in the paper and supplementary material, which supports the claim. However, the comment lacks specific examples or references to other baseline approaches, making it somewhat verifiable. The authors would need to further explore the literature to fully understand the scope of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against other baseline approaches in the evaluation. It suggests that a simple photographic style transfer method might achieve similar or better results, which provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on which baseline approaches to consider or how to incorporate these comparisons into the paper. Overall, the feedback is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, making it difficult to understand the proposed method. It explicitly points out that the authors did not explain the meaning of C_i, Q_i, R_i, and A_i in Figure 2, and questions the computation of each node. Additionally, it highlights a potential inconsistency in the notation of S_i and S_j, asking for clarification on how to compute S_i. The comment provides clear and specific actions for the authors to take, such as explaining the symbols' meanings and addressing the notation inconsistency. These actions are direct and concrete, giving the authors a clear path to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"line 431,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with mapping symbols from Figure 2 to equations, questioning the explanation of C_i, Q_i, R_i, and A_i, and noting the potential inconsistency in the notation of S_i and S_j. The comment provides clear guidance on what needs to be clarified or explained, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the difficulty in mapping symbols from Figure 2 to equations, specifically questioning the explanation of C_i, Q_i, R_i, and A_i in Figure 2. It also points out a potential inconsistency in the notation of S_i and S_j, asking for clarification on how to compute S_i. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The authors are left with a general understanding of the problem but without explicit guidance on how to address it. Therefore, the comment is somewhat verifiable, as it provides some insight but requires more detailed justification or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, making it difficult for readers to understand the details of the proposed method. It highlights the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, which are crucial for understanding the computation of each node in Figure 2. Additionally, it questions the potential inconsistency in the notation of S_i and S_j, asking for clarification on how to compute S_i. This feedback is clear and actionable, providing the authors with specific areas to clarify and improve in their draft. By addressing these issues, the authors can enhance the clarity and comprehensibility of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider studying additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. While the comment implies that these aspects should be explored, it does not provide explicit instructions or detailed guidance on how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, it does not specify which part of the paper these hyper-parameters are discussed in, making it weakly grounded. The comment is specific in its suggestion to study additional hyper-parameters and their tuning requirements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these parameters are important or how they might impact the results. Without such context or explanation, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider studying additional hyper-parameters, specifically the number of backtracking steps and the acceptance rate, and how much tuning was required to achieve good results. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting additional parameters to explore. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific aspects to focus on. Without actionable advice or examples, the authors may find it challenging to fully address the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the objective function used in GSdyn and FABOLAS, specifically asking for clarification on the accuracy measure used in Section 5.1. While the comment identifies a specific area of confusion, it does not provide explicit instructions or suggestions for how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the objective function and specify which accuracy measure is used. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the objective function for GSdyn and FABOLAS, and questions the accuracy measure used in Section 5.1. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the objective function used in GSdyn and FABOLAS, as well as the accuracy measure used in Section 5.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the objective function used in GSdyn and FABOLAS, specifically regarding the accuracy measure employed in Section 5.1. It highlights a potential ambiguity in the paper regarding whether the accuracy is measured on the validation or test dataset. This feedback is valuable as it prompts the authors to clarify their methodology and ensure that their results are clearly presented and understood by readers. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific accuracy measures or suggesting ways to present the results. Overall, the comment is somewhat helpful as it identifies a critical area for clarification but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a reorganization of the paper\\'s structure, specifically recommending that the \"General Discussion\" section be moved to the \"Related Work\" section and that the \"3.2\" section be renamed as \"Section 3\" with the proposal included. This feedback provides a clear and explicit action for the authors to take, specifying exactly what changes need to be made to the paper\\'s structure. The suggestion is concrete, as it outlines the exact sections and their new designations. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a reorganization of the paper\\'s structure, specifically recommending that the \"General Discussion\" section be moved to the \"Related Work\" section and that the \"3.2\" section be renamed as \"Section 3\" with the proposal included. This provides a clear and specific suggestion for improving the paper\\'s structure. However, the comment does not explicitly mention which part of the paper this recommendation pertains to, such as the specific sections or subsections. While the authors can infer that it relates to the structure of the paper, the comment lacks full grounding. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a reorganization of the paper\\'s structure, proposing that the \"General Discussion\" section be moved to the \"Related Work\" section and that the \"3.2\" section be renamed as \"Section 3\" with the proposal included. This suggestion is based on the reviewer\\'s perception that the current structure is not optimal. However, the comment lacks specific reasoning or evidence to support why this reorganization would improve the paper\\'s structure or clarity. Without detailed justification or examples, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for reorganizing the paper\\'s structure by recommending that the \"General Discussion\" section be moved to the \"Related Work\" section and that the \"3.2\" section be renamed as \"Section 3\" with the proposal included. This feedback is clear and actionable, offering a concrete way for the authors to improve the organization and flow of their paper. By suggesting a more logical placement for the \"General Discussion,\" the comment helps the authors enhance the coherence of their work. However, the comment could be more helpful if it explained why this reorganization is beneficial or provided additional guidance on how to integrate the new section effectively. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional context or suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about obtaining priors efficiently and requests examples. It also suggests that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. While the comment identifies a specific issue and requests examples, it does not provide explicit guidance on how to address this problem or what specific actions the authors should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples or a practical method for obtaining the priors. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a practical way to obtain the required prior {$U_{k_n}$}. The comment provides a clear direction for improvement by asking for examples or a practical method, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the methodology of obtaining priors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the methodology for obtaining priors, which is a significant aspect of the paper. It suggests that the authors may not have a practical way to obtain the required prior {$U_{k_n}$}, indicating a potential gap in the methodology section. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide examples of efficient methods. While it identifies an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. While the action is explicit, it is somewhat vague because it does not specify which metrics should be used or how the evaluation should be structured. The authors are given a clear direction to expand their evaluation, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. The reviewer provides a logical reasoning by pointing out that the current evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets uses the same metrics of AUC and precision, and that expanding the evaluation to the VOT dataset would provide a more comprehensive comparison. This reasoning is clear and supports the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to how these metrics are typically used in the VOT dataset. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to expand their evaluation by including the VOT dataset in their analysis. It highlights the current evaluation on OTB-50, OTB-100, OTB-2015, and LASOT datasets, which evaluate methods using AUC and precision metrics. The reviewer recommends that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. This feedback is valuable as it guides the authors to enhance the comprehensiveness of their evaluation, which can lead to a more robust conclusion. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate the VOT dataset into the analysis. Overall, the comment is mostly helpful, as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It explicitly states that the paper claims the proposed method is comparable to supervised semantic segmentation but does not report the performance of any state-of-the-art methods. This feedback implies that the authors should include comparisons to relevant state-of-the-art methods to substantiate their claims. While the action is explicit, it is somewhat vague because it does not specify which state-of-the-art methods should be included or how to conduct these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"method\" and the \"paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques and the claim of performance comparable to supervised semantic segmentation without reporting any state-of-the-art method performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is not compared to any state-of-the-art unsupervised semantic segmentation techniques, and it highlights a discrepancy between the claim of performance comparable to supervised semantic segmentation and the lack of reported state-of-the-art method performance. The comment provides a logical reasoning by pointing out the inconsistency between the claim and the lack of comparison, which is a valid concern. However, it lacks specific examples or references to state-of-the-art methods, making it somewhat verifiable. The authors would need to identify and include relevant state-of-the-art methods to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It points out that while the paper claims the proposed method is comparable to supervised semantic segmentation, it does not report the performance of any state-of-the-art methods. This feedback is clear and actionable, as it directs the authors to include comparisons with relevant state-of-the-art methods to substantiate their claims. However, the comment could be more helpful if it suggested specific state-of-the-art methods to consider or provided guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it highlights a significant gap in the paper and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It points out a potential issue with the cyclical learning rate scheduling and its impact on the weight changes. However, the comment does not provide explicit guidance or suggestions on how the authors should improve the explanation or address the issue. The feedback lacks actionable details, such as recommending specific changes or providing examples of how to clarify the explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first curve-finding part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the explanation regarding why the FGE work is relevant and the potential issue with the cyclical learning rate scheduling. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions the effectiveness of the cyclical learning rate scheduling in perturbing the weight around the initial converged weight and its impact on the weight changes described in the first part. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or incomplete. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It points out a potential issue with the cyclical learning rate scheduling and its impact on weight changes, suggesting that the explanation may be unclear. However, the comment lacks specific suggestions or guidance on how the authors might improve the explanation or address the issue. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It points out a potential issue with the cyclical learning rate scheduling and its impact on weight changes. However, the comment does not provide explicit guidance or suggestions on how the authors might improve the explanation or address the issue. Without specific recommendations or actionable steps, the authors are left without a clear understanding of what changes are needed to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first curve-finding part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the explanation regarding why the FGE work is relevant and the potential issue with the cyclical learning rate scheduling and its impact on weight changes. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions the effectiveness of the cyclical learning rate scheduling in perturbing the weight around the initial converged weight and its impact on the weight changes described in the first part. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or incomplete. Without sufficient evidence or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It points out a potential issue with the cyclical learning rate scheduling and its impact on weight changes, suggesting that the explanation may be unclear. However, the comment lacks specific suggestions or guidance on how the authors might improve the explanation or address the issue. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that presenting a case study with synthetic datasets would enhance the paper by illustrating why and when a distillation strategy is beneficial. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and asks the authors to provide reasoning or hypotheses based on the performance. This feedback is explicit and provides concrete guidance on how the authors can improve their draft by offering additional context and explanation. The authors are given clear instructions on what to include in their case study, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests presenting a case study with synthetic datasets to illustrate why and when a distillation strategy is better. The comment provides a clear request for additional reasoning or hypotheses based on the performance, which helps the authors understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that presenting a case study with synthetic datasets would enhance the paper by illustrating why and when a distillation strategy is better. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and asks the authors to check the reason behind this. The comment also requests more reasoning or hypotheses based on the performance. While the suggestion is logical and could be beneficial, it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a clear direction but requires additional evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that presenting a case study with synthetic datasets would enhance the paper by illustrating why and when a distillation strategy is beneficial. It provides specific examples, such as Table 3, where LFADS-Hard performs better than LFADS-Soft, and asks the authors to check the reason behind this. The comment also requests more reasoning or hypotheses based on the performance. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by providing additional context and explanation. However, it could be more helpful if it included specific suggestions on how to structure the case study or what aspects to focus on. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should create cloze-style or question answering evaluation sets to focus on factual knowledge generation, rather than just evaluating LM loss. While the comment implies that the authors should make these changes, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of evaluation sets to create, but it is inferred rather than explicitly stated. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of LM loss throughout the paper, specifically mentioning that it is fine for style and topics but not clean enough for factual knowledge. It suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improving the evaluation of factual knowledge. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating LM loss is not clean enough for factual knowledge because only a few tokens in a sentence are related to facts. The reviewer proposes creating cloze-style or question answering evaluation sets to focus on factual knowledge. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that evaluating LM loss is not clean enough for factual knowledge. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of LM loss, specifically noting that it may not be clean enough for factual knowledge because only a few tokens in a sentence are related to facts. It suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge generation. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear direction for enhancing the evaluation of factual knowledge. However, it could be more helpful if it included examples or detailed guidance on how to implement these evaluation sets. Overall, the comment offers valuable insights but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters. It suggests that while the authors claim sensitivity to clusters, they should also explain the theoretical or topological reasons behind it. Additionally, the reviewer questions why the proposed RTD score specifically works for network representation and not just any vectors of the same size. While the comment implies that the authors should provide more theoretical or topological explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RTD score\" and its sensitivity to clusters, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the theoretical or topological aspects of the RTD score\\'s sensitivity and why it specifically works for network representation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters, suggesting that while the authors claim sensitivity, they should also explain these aspects. The comment also questions why the proposed RTD score specifically works for network representation and not just any vectors of the same size. While the comment raises valid points, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors would need to provide additional context or evidence to fully address these questions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters. It questions why the proposed RTD score specifically works for network representation and not just any vectors of the same size. This feedback is somewhat helpful as it prompts the authors to provide a more comprehensive explanation of the theoretical basis and applicability of their method. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these questions. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that ROCK has similar complexity to the original model, suggesting that it is unlikely due to the addition of multiple layers. It explicitly requests inference timings to support the claim. Additionally, it identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. The reviewer suggests comparing the full model (DNS) with models where one task is dropped out (DS, NS, DN) to address this issue. These suggestions provide clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 88-89, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the claim that ROCK has similar complexity to the original model, noting the addition of multiple layers and suggesting the need for inference timings to support the claim. Additionally, it identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. The suggestion to compare the full model with models where one task is dropped out provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the complexity of the ROCK model compared to the original model, suggesting that the claim is unlikely due to the addition of multiple layers. The reviewer supports this claim by pointing out the specific layers added and requests inference timings to substantiate the claim. Additionally, the comment identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance. The suggestion to compare the full model with models where one task is dropped out provides a clear direction for improvement. While the comment provides some reasoning and a suggestion for further analysis, it could be strengthened by including specific examples or references to support the claim about the model complexity. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the paper, specifically addressing the claim that the ROCK model has similar complexity to the original model. It points out the addition of multiple layers and suggests that inference timings should be provided to support this claim. Additionally, the comment identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. It offers a specific suggestion for improvement by comparing the full model with models where one task is dropped out. This feedback is clear, actionable, and provides the authors with a concrete path to enhance their draft by addressing both the complexity claim and the experimental design. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the joint probability P(y_1, y_2, ..., | y_{<i}, X) is calculated when the part is not autoregressive. It explicitly suggests adding the equation to the paper for clarity. This feedback provides a clear and direct action for the authors to take, which is to include the equation in their draft. The suggestion is specific and actionable, giving the authors a concrete task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the calculation of the joint probability P(y_1, y_2, ..., | y_{<i}, X) and suggests adding the equation to the paper for clarity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for clarification. It does not contain any subjective opinions, judgments, or claims that require verification. The question is factual and seeks clarification, while the suggestion is a request for additional information. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the calculation of the joint probability P(y_1, y_2, ..., | y_{<i}, X) when the part is not autoregressive. It suggests adding the equation to the paper for clarity. This feedback is clear and actionable, as it identifies a specific area where the paper lacks detail and provides a direct suggestion for improvement. By addressing this point, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it explained why this clarification is important or how it could impact the understanding of the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues or what specific aspects should be discussed. The authors can infer that they need to expand their discussion on dataset diversity and quality, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not specify which part of the paper should address these issues, making it weakly grounded. The authors can infer that it relates to the dataset discussion or experimental setup sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as the diversity and quality of the dataset and the model\\'s behavior on real-world datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that could be improved, it does not provide specific examples or references to support the claim that these aspects are lacking. The authors are left to infer the importance of these issues, making the comment somewhat verifiable. Therefore, the feedback is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s discussion regarding the diversity and quality of the dataset, particularly in relation to rare conditions and imaging variations. It also raises concerns about the model\\'s performance on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it points out areas that need further exploration and discussion, which could enhance the paper\\'s comprehensiveness and applicability. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how other studies have tackled similar problems. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reproducibility of the results due to the lack of promised code for training and testing. It implies that the authors should provide the code to ensure reproducibility, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it does not specify how the authors should proceed or what steps are necessary to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility in the paper, specifically mentioning the lack of promised code for training and testing. However, it does not specify which part of the paper discusses the model components or the training stages, making it weakly grounded. The comment is specific in identifying the issue of reproducibility and the need for code, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model\\'s training requires multiple stages and that the lack of promised code for training and testing makes the results non-reproducible. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the lack of code impacts reproducibility. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the implications of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the reproducibility of the results due to the lack of promised code for training and testing. It highlights that the provided training details about data and hyperparameters do not guarantee reproducibility, which is a significant concern for the validity and impact of the research. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or providing alternative methods for ensuring reproducibility. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical area but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the reproducibility of the results due to the lack of promised code for training and testing. It implies that the authors should provide the code to ensure reproducibility, but it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how the authors should proceed to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of reproducibility, specifically mentioning the lack of promised code for training and testing. However, it does not specify which part of the paper discusses the model components or the training stages, making it weakly grounded. The comment is specific in identifying the issue of reproducibility and the need for code, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model\\'s training requires multiple stages and that the lack of promised code for training and testing makes the results non-reproducible. However, the comment does not provide specific examples or references to support this claim, nor does it explain how the lack of code impacts reproducibility. This lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the implications of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the reproducibility of the results due to the lack of promised code for training and testing. It highlights that the provided training details about data and hyperparameters do not guarantee reproducibility, which is a significant concern for the validity and impact of the research. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of code or providing alternative methods for ensuring reproducibility. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a critical area but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of critical setup information, specifically the total number of agents available in Flow\u2019s default configuration. While it identifies a gap in the information provided, it does not explicitly instruct the authors to include this information or suggest how to present it. The action is implicit, as the authors can infer that they need to add this information, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of critical setup information, specifically the total number of agents available in Flow\u2019s default configuration. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the missing information, but without clear grounding, the authors may struggle to pinpoint where to add this detail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that critical setup information is missing, specifically the total number of agents available in Flow\u2019s default configuration. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this information or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting that critical setup information, such as the total number of agents available in Flow\u2019s default configuration, is missing. This feedback is valuable as it highlights a crucial piece of information that could significantly impact the understanding and reproducibility of the study. However, the comment lacks depth and does not provide suggestions on how to incorporate this information or why it is important. While it points out a clear area for improvement, it does not offer actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific gap in the paper, noting that critical setup information, such as the total number of agents available in Flow\u2019s default configuration, is missing. While it highlights the need for this information, it does not provide explicit instructions on how to include it or where it should be added. The action is implicit and somewhat vague, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\u2019s default configuration. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the missing information, but without clear grounding, the authors may struggle to pinpoint where to add this detail. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that critical setup information is missing, specifically the total number of agents available in Flow\u2019s default configuration. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this information or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\u2019s default configuration. This feedback is valuable as it highlights a crucial piece of information that could significantly impact the understanding and reproducibility of the study. However, the comment lacks depth and does not provide suggestions on how to incorporate this information or why it is important. While it points out a clear area for improvement, it does not offer actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific gap in the paper, noting the absence of critical setup information, such as the total number of agents available in Flow\u2019s default configuration. While it highlights the need for this information, it does not provide explicit instructions on how to include it or where it should be added. The action is implicit, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable, as it points out a critical area"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this concern or improve their claim. As a result, the comment lacks any actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made in, nor does it provide specific examples or references to those works. This lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and what specific issues need to be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point challenges the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. The reviewer provides a logical reasoning by pointing out the existence of other works in the field, which supports the claim that the paper\\'s claim is not as novel as it might seem. However, the comment lacks specific references or examples to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. While it identifies a potential issue with the novelty claim, it does not provide specific examples or references to those works, nor does it offer suggestions on how the authors might address this critique. The comment lacks actionable feedback and does not guide the authors on how to improve their draft, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this concern or improve their claim. As a result, the comment lacks any actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. However, it does not specify which part of the paper this claim is made in, nor does it provide specific examples or references to those works. This lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and what specific issues need to be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point challenges the claim that the paper presents the 'first deep generative model for unsupervised scene-graph discovery,' suggesting that there are many works that infer structures in an unsupervised way. The reviewer provides a logical reasoning by pointing out the existence of other works in the field, which supports the claim that the paper's claim is not as novel as it might seem. However, the comment lacks specific references or examples to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the claim that the paper presents the \"first deep generative model for unsupervised scene-graph discovery,\" suggesting that there are many works that infer structures in an unsupervised way. While it identifies a potential issue with the novelty claim, it does not provide specific examples or references to those works, nor does it offer suggestions on how the authors might address this critique. The comment lacks actionable feedback and does not"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the ablation study, namely that it does not address the effect of different numbers of projectors on distillation when feature dimensions are different. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue or what specific experiments should be conducted to investigate this effect. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments to explore the effect of different numbers of projectors on distillation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of analysis on the effect of different numbers of projectors on distillation when feature dimensions are different. This provides clear guidance on what the authors need to address in their study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when feature dimensions are different. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific gap in the ablation study, noting that it does not address the effect of different numbers of projectors on distillation when feature dimensions are different. This feedback is clear and actionable, as it directs the authors to conduct additional experiments or analyses to explore this aspect. By highlighting this omission, the comment provides valuable guidance for improving the comprehensiveness and depth of the study. However, it could be more helpful if it offered suggestions on how to conduct these additional analyses or what specific results to expect. Overall, the comment is mostly helpful as it points out a critical area for improvement and offers some direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories (chair, airplane, car). It specifically recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment provides a clear direction for additional experiments, it does not specify which datasets or shapes should be considered or how to design these experiments. The action is explicit but somewhat vague in terms of execution details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories mentioned. It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The suggestion is specific, as it provides clear guidance on what additional experiments should be conducted to enhance the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on diverse datasets would better demonstrate the generalization capabilities of the model. While the comment provides a logical reasoning for why more experiments are needed, it lacks specific examples or references to support the claim. The suggestion is based on a general observation that more complex shapes should be evaluated, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on diverse datasets to demonstrate the generalization capabilities of the model. It specifically suggests evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. This feedback is valuable as it offers a concrete direction for enhancing the experimental validation of the model, which can significantly strengthen the paper. However, the comment could be more helpful if it included specific examples of datasets or shapes that should be considered. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but lack detailed instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. This provides some grounding as it refers to specific methods, but it does not explicitly mention which part of the paper this suggestion pertains to, such as a particular section or experiment. The comment is specific in detailing the importance of understanding the implications of low computational requirements and the potential implications of low compute restrictions during test time. However, without explicit references to sections or experiments, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. The comment highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While it provides a general direction for improvement, it does not offer concrete evidence or references to support the necessity of this comparison. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. The comment provides a clear and actionable suggestion for the authors to consider, which could significantly enhance the comprehensiveness and relevance of their work. However, it could be more helpful if it offered specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks. It provides a concrete action for the authors to take by recommending they provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. This feedback is clear and provides specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. This feedback gives the authors a clear direction on how to improve their draft by offering a specific example of a comparison to include. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks in ResNet. The reviewer suggests providing more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. While the comment identifies a potential issue with the fairness of the comparison, it lacks specific examples or references to support the claim. The suggestion to include a comparison with ShuffleNetv2 is a logical step, but the comment could be strengthened by providing more detailed reasoning or evidence to substantiate the unfairness of the current comparison. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between DetNAS and ResNet, noting that ShuffleNetv2 blocks are more efficient than the Residual blocks in ResNet. It provides a specific suggestion for improvement by recommending that the authors provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. This feedback is clear and actionable, offering a concrete way for the authors to enhance the comprehensiveness and validity of their comparisons. By addressing this point, the authors can strengthen their analysis and provide a more robust evaluation of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It suggests that this limitation is not as general as the two papers mentioned in point (3), which can work with any finite-dimensional representation. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to make the approach more general. The action is implicit and vague, as the authors need to infer that they should consider expanding the representations to be more general, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the input and output spaces/representations, which are restricted to certain representations. It compares this limitation to other papers mentioned in point (3), which can work with any finite-dimensional representation. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation of the current approach and how it compares to other works, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer compares this limitation to other papers that can work with any finite-dimensional representation. However, the comment does not provide specific examples or references to the mentioned papers or detailed reasoning to support the claim that the current approach is not as general as the others. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper regarding the input and output spaces/representations, noting that they are restricted to certain representations such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It compares this limitation to other papers that can work with any finite-dimensional representation, suggesting that the current approach is not as general. This feedback is somewhat helpful as it points out a potential area for improvement in terms of generalizability. However, the comment could be more helpful if it provided suggestions on how to address this limitation or examples of how other papers handle more general representations. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the input and output spaces/representations, noting that they are restricted to specific representations such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It compares this limitation to other papers that can work with any finite-dimensional representation. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest ways to make the approach more general. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the input and output spaces/representations, which are restricted to certain representations. It compares this limitation to other papers that can work with any finite-dimensional representation. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation of the current approach and how it compares to other works, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It compares this limitation to other papers that can work with any finite-dimensional representation, suggesting that the current approach is not as general. However, the comment lacks specific examples or references to the mentioned papers or detailed reasoning to support the claim that the current approach is not general. This makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is somewhat verifiable, as it provides a general comparison but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks concrete actions or detailed advice on how to improve the practical usability of the system. As a result, the authors are left without a clear understanding of what steps to take to enhance the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the complexity of practical applications in image editing tasks, particularly the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention which part of the paper discusses these complexities, making it weakly grounded. The comment is specific in detailing the potential issues with practical usability, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of practical applications in image editing tasks, particularly regarding the need to specify a source prompt, blend word, and various conditions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in practical applications of the system, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This feedback highlights a potential limitation that could restrict the practical usability of the system for typical users seeking simpler image adjustments. However, the comment does not provide specific suggestions or guidance on how the authors might address this complexity or improve the practical usability of their system. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks concrete actions or detailed advice, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the complexity of practical applications in image editing tasks, particularly the need to specify a source prompt, blend word, and various conditions. However, it does not explicitly mention which part of the paper discusses these complexities, making it weakly grounded. The comment is specific in detailing the potential issues with practical usability, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of practical applications in image editing tasks, specifically mentioning the need to specify a source prompt, blend word, and various conditions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential complexity in practical applications of the system, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This highlights a potential limitation that could restrict the practical usability of the system for typical users seeking simpler image adjustments. However, the comment does not provide specific suggestions or guidance on how the authors might address this complexity or improve the practical usability of their system. While it points out an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, it does not provide specific guidance or suggestions on how the authors could enhance the significance of their contributions or how to effectively compare their technique with existing literature. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the significance of the paper\\'s contributions and the lack of comparison with traditional classification or manifold learning literature. However, it does not specify which part of the paper should be revised or what specific aspects need to be addressed. The authors cannot confidently determine which sections or elements are being discussed, making it weakly grounded. The comment is specific in identifying the lack of significance and comparison, but without grounding, it remains difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the contributions of the paper are not significant and lacks comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the significance of the paper\\'s contributions and the lack of comparison with traditional classification or manifold learning literature. However, it does not provide specific suggestions or guidance on how the authors might enhance the significance of their contributions or how to effectively compare their technique with existing literature. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale by explaining that larger datasets could provide more accurate estimates but would require more time to compute. The reviewer also references two external works, [1] and [2], which could be used to support the discussion. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer the need for a discussion and have a clear idea of what to include. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale for why this discussion is important, mentioning that larger datasets could provide more accurate estimates but would require more time to compute. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a discussion on the impact of the few-shot dataset, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary, referencing two external works. The claim is supported by logical reasoning, as it explains that larger datasets could provide more accurate estimates but would require more time to compute. The references to external works provide additional support, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced works, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides a rationale by explaining that larger datasets could provide more accurate estimates but would require more time to compute. The comment also references two external works, [1] and [2], which could be used to support the discussion. This feedback is clear and actionable, as it identifies a specific area for improvement and provides a logical basis for why this discussion is important. By including this discussion, the authors can enhance their paper by offering a more comprehensive analysis of the impact of the few-shot dataset. Therefore, the comment is mostly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation and experimental verification regarding why it is beneficial to keep representations in the same hidden space. However, it does not provide explicit guidance on how the authors should address this issue or what specific experiments or analyses are needed to demonstrate this. The action is implicit and somewhat vague, as the authors can infer that they need to provide more explanation and experimental evidence, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of explanation and experimental verification regarding why it is beneficial to keep representations in the same hidden space. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014explanation and experimental verification\u2014providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not provided an explanation or experimental verification for keeping representations in the same hidden space. However, it does not offer any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of explanation and experimental verification regarding why it is beneficial to keep representations in the same hidden space. This is a relevant point that could impact the understanding and credibility of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular experiments or analyses to conduct. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of sufficient novelty in the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). While it identifies a potential issue with the novelty of the approach, it does not provide explicit guidance on how the authors might address this concern. The comment lacks concrete suggestions or actionable steps for the authors to take to enhance the novelty of their methodologies. As a result, the authors are left without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the methodologies introduced in the paper, specifically Longitudinal Representation Learning and its extension from Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of significant advancement beyond existing methods, which limits the paper\\'s contribution to the NLP community. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodologies, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). The reviewer supports this claim by referencing existing works, which provides a logical basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or examples of how the approach fails to offer significant advancement. Despite this, the reference to existing works and the logical reasoning make the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a lack of sufficient novelty in the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). This feedback highlights a potential issue with the paper\\'s contribution to the field, which is crucial for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty of their methodologies or differentiate their work from existing approaches. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of sufficient novelty in the methodologies presented in the paper, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). While it identifies a potential issue with the novelty of the approach, it does not provide explicit guidance or suggestions on how the authors might address this concern or enhance the novelty of their methodologies. The comment lacks actionable steps or concrete advice, leaving the authors without a clear understanding of what changes are needed to improve the draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the methodologies introduced in the paper, specifically Longitudinal Representation Learning and its extension from Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it points out the lack of significant advancement beyond existing methods, which limits the paper\\'s contribution to the NLP community. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodologies, specifically mentioning the use of Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster R-CNN (Ren et al., 2015). The reviewer supports this claim by referencing existing works, which provides a logical basis for the assertion. However, the comment could be strengthened by providing more detailed comparisons or examples of how the approach fails to offer significant advancement. Despite this, the reference to existing works and the logical reasoning make the claim mostly verifiable. Therefore, the comment is rated as"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate these approaches or why they are relevant. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the oversight of various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, it does not specify which part of the paper this oversight is related to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of keeping \\\\Delta t fixed and mentioning S5 as an example, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, the comment does not provide specific examples or references to these approaches, making it difficult for the authors to understand the basis of the claim. Without detailed information or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant oversight in the paper, noting that it overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed. It provides a specific example, S5, which avoids the issue by computing the input-output via a parallel scan. However, the comment lacks depth and does not offer actionable suggestions or guidance on how the authors might incorporate these approaches or address the oversight in their work. Without specific recommendations or detailed feedback, the authors may find it challenging to effectively improve their draft based on this comment. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate these approaches or why they are relevant. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the oversight of various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, it does not specify which part of the paper this oversight is related to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of keeping \\\\Delta t fixed and mentioning S5 as an example, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed, such as S5. However, it does not provide specific examples or references to these approaches, making it difficult for the authors to understand the basis of the claim. Without detailed information or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant oversight in the paper, noting that it overlooks various SSM-based approaches that address the issue of keeping \\\\Delta t fixed. It provides a specific example, S5, which avoids the issue by computing the input-output via a parallel scan. However, the comment lacks depth and does not offer actionable suggestions or guidance on how the authors might incorporate these approaches or address the oversight in their work. Without specific recommendations or detailed feedback, the authors may find it challenging to effectively improve their draft based on this comment. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the misrepresentation of 3 as the underlying data generating mechanism, the need to use causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to unclear graph considerations. While the comment highlights specific areas for improvement, it does not provide explicit instructions or concrete guidance on how to address these issues. The authors are left to infer the necessary changes, such as revising the text to accurately reflect the underlying data generating mechanism and clarifying the definition of independence. Therefore, the comment is somewhat actionable, as it provides some direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the presentation of 3 as the underlying data generating mechanism and the difficulty in understanding definition 4 due to unclear graph considerations. Additionally, it suggests using causal graphs instead of the label inference process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims about the paper, including that 3 is not the underlying data generating mechanism and that it would be more standard to discuss causal graphs rather than the label inference process. The comment also critiques the difficulty in understanding definition 4 due to unclear graph considerations. While the reviewer provides some reasoning and suggestions for improvement, such as the use of causal graphs, the claim lacks specific examples or references to substantiate the assertion about the underlying data generating mechanism. Additionally, the comment on definition 4 is somewhat vague, as it does not provide detailed guidance on what specific graphs should be considered. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the paper, including the misrepresentation of 3 as the underlying data generating mechanism, the need to use causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to unclear graph considerations. While the comment highlights these areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer the necessary changes, such as revising the text to accurately reflect the underlying data generating mechanism and clarifying the definition of independence. While the feedback is somewhat helpful in pointing out areas of concern, it could be more actionable and comprehensive to be fully beneficial. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. While the comment implies that the authors should provide more examples to support their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The suggestion to include more examples is specific, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement. It does not contain any subjective opinions, claims, or suggestions that require verification. The question is factual and seeks clarification, while the suggestion is a request for additional examples to support the dual-free approach. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. While the comment identifies a potential area for improvement by questioning the feasibility of evaluating the gradient, it lacks specific guidance or suggestions on how to address this issue or where to include additional examples. The feedback is somewhat helpful as it prompts the authors to consider the practicality of their approach and suggests a direction for improvement, but it could be more comprehensive with detailed guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation regarding the selection of a probability for the appearance of an unobservable data point at step 3 of Algorithm 1. It explicitly requests an explanation for why the selection is made from [0, Pcj(0)]. This feedback provides a clear and direct action for the authors to take, which is to include an explanation in their draft. The comment is explicit and concrete, offering a specific area for improvement that the authors can address directly. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for the selection of a probability for the appearance of an unobservable data point. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of explanation for the selection of a probability for the appearance of an unobservable data point at step 3 of Algorithm 1. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors lack explanation, namely the selection of a probability for the appearance of an unobservable data point at step 3 of Algorithm 1. By pointing out this omission, the comment provides a clear and actionable suggestion for improvement. It encourages the authors to include an explanation for their choice, which could enhance the clarity and understanding of their methodology. However, the comment could be more helpful if it offered additional guidance or examples on how to provide this explanation. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions, as these terms are referenced throughout the paper. While the comment implies that the authors should clarify these concepts, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it does not specify how the authors should present this information or what aspects need clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (line 128 and line 168), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. However, the comment does not provide any specific reasoning or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This is a relevant suggestion that could enhance the clarity and understanding of the paper for readers. However, the comment does not offer specific guidance on how the authors might achieve this or what aspects of the definition would be most beneficial. While it points out a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the AIG-generation task is not convincing and recommends providing more background for readers unfamiliar with logic synthesis. Additionally, it suggests benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). These suggestions are clear and provide concrete steps for the authors to improve their draft. The comment is explicit and offers detailed guidance, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task and suggests providing more background for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the AIG-generation task is discussed. The comment is specific in suggesting what additional information is needed and how to improve the paper\\'s clarity and verifiability. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests providing more background for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets to enhance the paper\\'s credibility. The comment provides a logical reasoning for the need for additional background and benchmarking, which supports the claim. However, it lacks specific references or examples of existing datasets that could be used for benchmarking, which would strengthen the verifiability. Therefore, the comment is categorized as 4: Mostly Verifiable, as it provides a reasonable basis for the claim but could be further strengthened with additional details or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the AIG-generation task, noting that it is not convincing and suggesting that more background should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the paper\\'s credibility. This feedback is clear and actionable, offering concrete steps for the authors to improve the clarity and verifiability of their work. By addressing these points, the authors can significantly enhance their draft. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that some statements in the paper lack detail and analysis. However, it does not specify which statements are lacking detail or provide any guidance on how the authors might address this issue. Without explicit instructions or examples, the authors are left without a clear understanding of what needs to be improved or how to enhance the detail and analysis in their paper. As a result, the comment is vague and lacks actionable guidance, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a general issue with the paper, stating that some statements lack detail and analysis. However, it does not specify which statements are lacking detail or provide specific examples, making it difficult for the authors to pinpoint the exact parts of the paper that need improvement. Without explicit references to sections, figures, or specific statements, the authors cannot confidently determine the areas that need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some statements in the paper lack detail and analysis. However, it does not provide specific examples or reasoning to support this claim, making it difficult for the authors to understand which statements are lacking detail or how to address the issue. Without detailed evidence or references, the claim remains vague and unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a general issue with the paper, noting that some statements lack detail and analysis. However, it does not specify which statements are lacking detail or provide any guidance on how the authors might address this issue. Without specific examples or actionable feedback, the authors are left without a clear understanding of what needs to be improved or how to enhance the detail and analysis in their paper. This lack of specificity and guidance makes the comment unhelpful, as it does not provide the authors with a clear path to improve their draft. Therefore, the comment is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their generative model with other models like VAE and provide an analysis of how the unique features of diffusion models, such as diffusion timesteps, affect feature learning. While the comment implies that such a comparison and analysis would be beneficial, it does not explicitly instruct the authors to perform these comparisons or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the generative model with other models like VAE and analyzing how the unique features of diffusion models, such as diffusion timesteps, affect feature learning. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to analyze the differences between diffusion models and other generative models, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison with other generative models, such as VAE, would be more informative. It highlights the unique features of diffusion models, such as diffusion timesteps, and argues that an analysis of these differences could significantly enhance the paper. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a general idea but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could be improved by comparing the generative model with other models like VAE and analyzing how the unique features of diffusion models, such as diffusion timesteps, affect feature learning. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and understanding of their model. By comparing with other models and analyzing the unique features, the authors can gain valuable insights into the strengths and limitations of their approach. However, the comment could be more helpful if it included specific examples or references to similar analyses. Overall, the feedback is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions the complementarity of the self-supervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. Second, it points out that ICoL is proposed to mitigate memory issues and allow more negative instances, but there are no corresponding experiments to demonstrate the influence of the number of negatives. The reviewer provides specific examples and references (TAS-B) to support their claims, which gives the authors clear guidance on what needs to be addressed. However, the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. While the actions are implied, the comment is concrete in its suggestions, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 4\" and \"ICoL,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the combination of self-supervised tasks ICT and DaPI, noting the lack of complementarity and the insignificant effectiveness of DaPI. Additionally, it critiques the proposed ICoL for not providing experiments on the influence of the number of negatives, referencing TAS-B as a relevant example. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims. The first claim is that the combination of self-supervised tasks ICT and DaPI is not complementary, and the effectiveness of DaPI is not significant despite doubling GPU memory usage. This claim is somewhat verifiable as it provides a specific observation about the effectiveness of DaPI, but it lacks detailed reasoning or evidence to fully substantiate the claim. The second claim is that ICoL is proposed to mitigate memory issues but lacks corresponding experiments to demonstrate the influence of the number of negatives. This claim is also somewhat verifiable, as it highlights a gap in the experimental validation of ICoL. However, both claims could benefit from more detailed reasoning or references to support the observations. Therefore, the review point is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on two key points. First, it questions the complementarity of the self-supervised tasks ICT and DaPI in Table 4, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. This observation prompts the authors to reconsider the choice of tasks or provide a more detailed analysis of their effectiveness. Second, the comment critiques the proposed ICoL for not providing experiments to demonstrate the influence of the number of negatives, which is crucial for understanding its impact on performance. The reviewer references TAS-B as an example of the importance of negative quality over quantity. This feedback is clear and actionable, offering the authors specific areas to address and improve their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 3 is unclear regarding the difference between the three plots on the same row and suggests that a caption should be added to clarify this. This feedback provides a clear and direct action for the authors to take, which is to add a caption to the figure. The suggestion is concrete, as it specifies what needs to be done to improve the clarity of the figure. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the caption regarding the difference between the three plots on the same row. The comment suggests adding a caption to clarify this, providing a clear direction for improvement. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is unclear regarding the difference between the three plots on the same row and suggests adding a caption to clarify this. However, the comment does not provide any specific examples or detailed reasoning to support why the current caption is insufficient or how the addition of a caption would improve clarity. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is unclear what the difference is between the three plots on the same row. It suggests that adding a caption could help clarify this distinction. This feedback is clear and actionable, providing the authors with a concrete step to improve the clarity and communicability of their figure. By addressing this issue, the authors can enhance the reader\\'s understanding of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a deeper exploration of GPSE\\'s computational complexity, particularly when compared to complex hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should conduct a more detailed analysis of computational complexity, it does not provide specific guidance on how to approach this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a deeper exploration of GPSE\\'s computational complexity, particularly when compared to complex hand-crafted PSEs and other encoding strategies. However, it does not specify which part of the paper should address this issue, making it weakly grounded. The comment is specific in its suggestion to delve deeper into computational complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint where this analysis should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper exploration of GPSE\\'s computational complexity, particularly when compared to complex hand-crafted PSEs and other encoding strategies. However, the comment does not provide specific examples, references, or detailed reasoning to support why this is a significant issue or how it affects the paper. Without such evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from a deeper exploration of GPSE\\'s computational complexity, particularly when compared to complex hand-crafted PSEs and other encoding strategies. This feedback is actionable as it provides a specific direction for the authors to enhance their analysis and understanding of computational complexity. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the reporting of results on the VQA dataset, noting that the results should be reported on the test-standard split rather than the test-dev split. It references the guidelines from the VQA dataset authors to support this claim. The comment implies that the authors should correct this discrepancy, but it does not explicitly instruct them to do so. The action is concrete, as it specifies the correct action to take, but it is inferred from the comment. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reporting of results on the VQA dataset, noting that numbers should be reported on the test-standard split rather than the test-dev split. The comment provides a clear rationale for this correction, referencing the guidelines from the VQA dataset authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset should be reported on the test-standard split rather than the test-dev split, citing guidelines from the VQA dataset authors. This claim is supported by a reference to the guidelines, providing a clear rationale for the assertion. The mention of the test-standard split and the test-dev split, along with the reference to the guidelines, offers sufficient evidence to validate the claim. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results on the VQA dataset, noting that the results should be reported on the test-standard split rather than the test-dev split. It references the guidelines from the VQA dataset authors, providing a clear and actionable suggestion for improvement. By pointing out this discrepancy, the comment helps the authors ensure that their results are reported in a manner consistent with best practices. However, while the comment is mostly helpful, it could be more detailed by explaining why this discrepancy is important or how it might affect the interpretation of the results. Overall, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose the parameters $\\beta$, $\\alpha$, and $\\eta$ to guarantee a certain decision-making loss level while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to address this issue. The authors are left to infer that they need to find a way to control the term $T_i \\beta$, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with controlling the term $T_i \\\\beta$, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address the issue. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment lacks specific guidance or actionable steps for the authors to follow, such as recommending methods or strategies for controlling the trade-off. While it identifies an area for improvement, the feedback is incomplete and does not provide detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to address this issue. The authors are left to infer that they need to find a way to control the term $T_i \\\\beta$, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to manage the trade-off is specific, but without explicit references or detailed guidance, the authors may find it challenging to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss while optimizing Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address the issue. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$)"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited applicability of the methods presented to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, implying that the authors should consider this limitation. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what steps to take to improve the applicability of the methods. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper to more structured layers like convolutions, specifically mentioning the comparison with MON. However, it does not explicitly mention which part of the paper discusses these applications, making it weakly grounded. The comment is specific in questioning the applicability of the methods to non-fully connected architectures, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the methods presented to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. The reviewer questions whether the methods are ready to be extended to non-fully connected architectures, suggesting that the performance trails that of MON. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the methods are not ready for extension. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, suggesting that the performance trails that of MON. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. The feedback is somewhat helpful as it points out a potential area for improvement but does not provide detailed advice or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, implying that the authors should consider this limitation. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their methods. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper to more structured layers like convolutions, specifically mentioning the comparison with MON. However, it does not explicitly mention which part of the paper discusses these applications, making it weakly grounded. The comment is specific in questioning the applicability of the methods to non-fully connected architectures, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. The comment questions whether the methods are ready to be extended to non-fully connected architectures, suggesting that the performance trails that of MON. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the methods are not ready for extension. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, suggesting that the"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses uncertainty about how to evaluate the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It provides a list of potential metrics that the authors might consider for their next benchmark. While the comment implies that the authors should explore these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these metrics and potentially implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about evaluating the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. It provides a list of potential metrics that the authors might consider for their next benchmark. However, the comment does not specify which part of the paper this evaluation is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting potential metrics for evaluation, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the evaluation of the refactoring process and suggests that using a pass rate for unit tests alone is insufficient. However, it does not provide any specific reasoning or evidence to support why this is the case. The suggestion of potential metrics for evaluation is not based on a claim but rather an observation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation of the refactoring process, specifically noting that using a pass rate for unit tests alone may be insufficient. It provides a list of potential metrics that the authors might consider for their next benchmark, which is a valuable suggestion for improving the evaluation process. However, the comment could be more helpful if it explained why these metrics are relevant or how they could be applied. Overall, the feedback is somewhat helpful as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this concern or improve the sufficiency of their contribution. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements of the paper, the authors cannot confidently determine which part needs attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the main contribution are insufficient or how the authors might address this issue. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. While it identifies a potential issue with the novelty of the contribution, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this concern or enhance the sufficiency of their contribution. As a result, the comment is not helpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this concern or improve the sufficiency of their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Additionally, the comment lacks specificity regarding what aspects of the main contribution are insufficient or how the authors might address this issue. Without clear references or detailed guidance, the authors cannot effectively respond to this feedback. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, the comment lacks supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not provide any specific feedback or suggestions on how the authors might address this concern or enhance the sufficiency of their contribution. Without actionable advice or detailed guidance, the authors are left without a clear path to improve their draft. The comment lacks specificity and depth, making it unhelpful for the authors. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the main contribution of the work is not significant because the Wiener deconvolution has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this concern or improve the sufficiency of their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward."}
{"generated_text": "{'actionability_rationale': 'The review point identifies several weaknesses in the connection between spin glasses and the proposed regularization term, specifically questioning how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. While the comment highlights specific areas that need clarification, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to provide more detailed explanations or evidence to support the connection, but the lack of concrete steps makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, including the connection to spin glasses, the role of regularization in escaping local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the connection between spin glasses and the regularization term, questioning the effectiveness of the connection and the implications for the proposed scheme. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the connection is weak. Without explicit evidence or detailed explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by questioning the connection between spin glasses and the regularization term. It highlights three specific areas that need clarification: how the regularization helps escape local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. This feedback is clear and actionable, providing the authors with specific points to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to strengthen the connection or provided examples of how to address these issues. Overall, the comment is mostly helpful as it directs the authors to critical areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the self-training scheme is a direct application and appreciates the exploration in the paper. However, it also notes that the contribution in this area is relatively limited. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might enhance the contribution or address this limitation. The feedback lacks actionable details, leaving the authors uncertain about how to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme, which is a specific aspect of the paper. However, it does not explicitly mention which section of the paper discusses this scheme, making it weakly grounded. The comment does specify that the contribution in this area is relatively limited, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application and that the contribution in this area is relatively limited. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the contribution is limited. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the exploration of the self-training scheme but notes that the contribution in this area is relatively limited. While it identifies a potential weakness, it does not provide specific suggestions or guidance on how the authors might enhance the contribution or address this limitation. The feedback lacks actionable insights or detailed advice, making it difficult for the authors to effectively improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an issue but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results shown in the paper are of low resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This feedback is explicit and provides a clear action for the authors to take, which is to include these zoomed-in regions to enhance the quality assessment. The suggestion is concrete, as it specifies what should be included to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are of low resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or figures discussed in the paper. The comment is specific in its suggestion to include zoomed-in regions to improve the quality assessment. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results shown in the paper are of low resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This is a subjective claim as it is an opinion about the quality of the results. However, it lacks specific examples or detailed reasoning to support why the results are considered low-resolution or how the inclusion of zoomed-in regions would improve the quality assessment. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in the paper, noting that they are of low resolution. It provides a clear and actionable suggestion by recommending the inclusion of zoomed-in regions of the rendered focal stack or all-in-focus images to allow for a more detailed inspection of the quality. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and impact of their results, making it highly helpful. However, the comment could be more helpful if it explained why the inclusion of these zoomed-in regions is important or how it would benefit the readers. Overall, the comment is mostly helpful, as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes, which may be a concern for real-world applications with limited computational resources, and the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks, limiting the method\\'s applicability. While the comment identifies potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The feedback is somewhat actionable because it points out specific areas of concern but lacks concrete steps for improvement. Therefore, it is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific concerns regarding the comparative inference method, including the increase in inference cost due to multiple forward passes and the requirement for validation data for post-hoc calibration. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns and potential limitations of the method, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. Additionally, it mentions that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method\\'s applicability. While the comment provides logical reasoning and identifies potential issues, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors would need to further explore the implications and potential solutions themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant concerns regarding the comparative inference method. It points out that the method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications with limited computational resources. Additionally, it highlights the requirement for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks, limiting the method\\'s applicability. This feedback is clear and actionable, as it provides specific areas for the authors to consider when evaluating the practicality and applicability of their method. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided alternative approaches. Overall, the comment is mostly helpful, as it effectively directs the authors\\' attention to critical aspects that need further consideration and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if exploding gradients are a problem, the authors should perform gradient clipping with a high value for the gradient norm to avoid NaNs appearing. It also questions the use of simply reinitializing the model as a solution, suggesting it is \"hacky.\" While the comment implies that gradient clipping is a better approach, it does not explicitly instruct the authors to implement this change. The action is implicit but concrete, as the authors can infer that they should consider gradient clipping as a solution. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the approach of simply reinitializing the model to avoid NaNs and suggests using gradient clipping with a high value for the gradient norm as a more appropriate solution. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach of simply reinitializing the model to avoid NaNs, suggesting that gradient clipping with a high value for the gradient norm might be a better solution. While the comment provides a logical reasoning for considering gradient clipping, it lacks specific examples or references to support the claim that gradient clipping is a more effective solution. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the approach of simply reinitializing the model to avoid NaNs, suggesting that gradient clipping with a high value for the gradient norm might be a more effective solution. This feedback is clear and actionable, providing the authors with a specific suggestion for improving their methodology. By addressing this issue, the authors can enhance the robustness and reliability of their results. However, the comment could be more helpful if it provided additional context or examples of how gradient clipping could be implemented. Overall, the comment is mostly helpful as it directs the authors toward a potential improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests a more detailed explanation of the term \"common pattern.\" This is a clear and direct action for the authors to take, as it specifies exactly what additional information is needed. The comment provides a specific area for improvement, making it highly actionable. The authors know exactly what needs to be done to address the feedback, which is to provide a more detailed explanation of the term \"common pattern.\"', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the term \"common pattern,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies what needs to be addressed, namely a more detailed explanation of the term \"common pattern.\" This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the term \"common pattern,\" asking for a more detailed explanation. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"common pattern\" and requests a more detailed explanation. This feedback is clear and actionable, as it directly points out a potential weakness in the paper that could be clarified to improve its clarity and understanding. By addressing this issue, the authors can enhance the comprehensibility of their work, making the comment mostly helpful. However, it could be further improved by providing a suggestion on how to define or explain the term more effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting additional experiments or analyses to test generalizability. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about generalizability to datasets from other sources, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why the model might not generalize to other sources. As a result, the claim is considered unverifiable, as it does not provide sufficient information for the authors to address the concern effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model, specifically noting that all five downstream datasets are related to Reddit. It raises a concern about whether the model could effectively generalize to datasets from other sources, such as Twitter or Facebook. This feedback is somewhat helpful as it highlights an important consideration for the authors to address, namely the potential limitations of their model\\'s generalizability. However, the comment lacks specific suggestions or guidance on how the authors might explore or address this issue, such as recommending additional experiments or analyses. Therefore, the comment is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that all five downstream datasets are related to Reddit and raises a concern about the generalizability of the pre-trained model to datasets from other sources, such as Twitter or Facebook. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might investigate or test the generalizability of their model to different sources. Without specific suggestions or steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about generalizability to datasets from other sources, but it lacks detailed guidance on how the authors might address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations to justify why the model might not generalize to other sources. As a result, the claim is considered unverifiable, as it does not provide sufficient information for the authors to address the concern effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the generalizability of the pre-trained model, noting that all five downstream datasets are related to Reddit. It raises a concern about whether the model could effectively generalize to datasets from other sources, such as Twitter or Facebook. This feedback is somewhat helpful as it highlights an important consideration for the authors to address, namely the potential limitations of their model\\'s generalizability. However, the comment lacks specific suggestions or guidance on how the authors might explore or address this issue, such as recommending additional experiments or analyses to test generalizability. Without detailed guidance, the authors are left with a general insight but without a clear path for improvement. Therefore, the comment is"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the generated dataset due to the potential for LLMs to hallucinate. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting methods for quality checking or improving the dataset. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the quality of the generated dataset due to the potential for LLMs to hallucinate. However, it does not specify which part of the paper discusses the dataset or the quality checks, making it weakly grounded. The comment is specific in its concern about the dataset quality and the potential for hallucination, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for LLMs to hallucinate and asks how the authors ensure the quality of the generated dataset. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim or suggest how the authors might address the issue. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential for LLMs to hallucinate, which is a common issue in natural language processing. It prompts the authors to consider how they ensure the quality of the generated dataset. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without additional details or examples, the authors are left without a clear path to improve their dataset quality. Therefore, the comment is somewhat helpful, as it identifies an important area for consideration but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the meaningfulness of the comparison across the four models, suggesting that the fine-tuned model might perform best due to its training process. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve the comparison. The comment lacks actionable details, such as recommending specific adjustments to the experimental setup or suggesting alternative models for comparison. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the comparison across four models, specifically mentioning the wav2vec model being fine-tuned and the other three models being trained from scratch. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the comparison across models and suggests that the fine-tuned model might perform best due to its training process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the meaningfulness of the comparison across four models, specifically noting that the wav2vec model is fine-tuned while the others are trained from scratch. The reviewer suggests that this might lead to an unfair advantage for the fine-tuned model. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or references leaves the claim somewhat verifiable, as it provides a logical inference but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the meaningfulness of the comparison across four models, specifically noting that only the wav2vec model is fine-tuned while the others are trained from scratch. This observation suggests that the comparison might be biased, as it is easy to predict that the fine-tuned model would perform best. However, the comment does not provide specific suggestions or guidance on how the authors could address this issue or improve the comparison. While it identifies a potential weakness, it lacks actionable advice or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and could benefit from more examples, like Figure 2. While the comment implies that the authors should include more examples to clarify the content, it does not explicitly instruct them to do so or provide specific guidance on which sections or topics need additional examples. The action is implicit and somewhat vague, as the authors need to infer that they should add more examples and determine which parts of the paper would benefit from them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and could benefit from more examples, like Figure 2. However, it does not specify which part of the paper is dense or where additional examples would be most helpful. This lack of explicit reference to specific sections or figures makes it difficult for the authors to pinpoint the exact areas that need improvement. While the authors might have an idea of where the density lies, the comment is not fully grounded. It is specific in suggesting more examples, but without clear grounding, it is rated as weakly grounded and not specific.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is dense, even compared to other pure-math ML papers, and suggests that more examples like Figure 2 would help. However, the comment lacks specific reasoning or evidence to support why the paper is dense or how additional examples would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is well-written but notes that it feels dense, even compared to other pure-math ML papers. It suggests that more examples, like Figure 2, would help clarify the content. While the comment identifies a potential issue with the paper\\'s density and provides a specific suggestion for improvement, it lacks depth and does not offer detailed guidance on how to address the density issue or where additional examples might be most beneficial. The feedback is somewhat helpful as it points out a specific area for improvement but does not fully support the authors in implementing the suggested changes. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difference in the level of intuition provided in sections 4.1 and 4.2. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the level of intuition in section 4.1. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"4.2 starts by providing high-level intuition while 4.1 does not,\" which allows the authors to accurately identify the specific sections being addressed. This provides full grounding. However, the comment does not specify what needs to be addressed in terms of improving the level of intuition or providing more detailed intuition in section 4.1. This makes the comment specific in terms of identifying the sections but under-specific in terms of what needs to be improved. Therefore, the comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point makes a subjective observation about the level of intuition provided in sections 4.1 and 4.2. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and factual, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a discrepancy in the level of intuition provided in sections 4.1 and 4.2. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the level of intuition in section 4.1. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more discussions related to Figure (e)(j)(o) in Figure 3, which are the obtained permutation matrices. While the comment implies that additional context or explanation is needed, it does not explicitly instruct the authors to do so or provide specific guidance on what aspects of the permutation matrices should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should expand the discussion but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the need for more discussions related to the obtained permutation matrices in Figure (e)(j)(o). This provides clear guidance on what the authors need to focus on, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more discussions should be introduced regarding Figure (e)(j)(o) in Figure 3, which are the obtained permutation matrices. However, the comment does not provide any specific reasoning or evidence to support why these discussions are necessary or how they would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more discussions should be introduced regarding the obtained permutation matrices in Figure 3, specifically mentioning Figure (e)(j)(o). While it identifies a potential area for improvement, the comment lacks specificity and does not provide detailed guidance on what aspects of the permutation matrices should be discussed or how they relate to the overall paper. Without additional context or suggestions, the authors may find it challenging to determine the exact improvements needed. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While the comment highlights an area that needs clarification, it does not provide explicit instructions or suggestions for the authors to follow. The action is implicit, as the authors can infer that they need to provide more information about the crowd workers, but it lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification regarding the recruitment and training of crowd workers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, which fits the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. This is a relevant and important aspect to consider, as it pertains to the methodology and potential biases in the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a critical area for clarification, it lacks actionable feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While it highlights an area that needs clarification, it does not provide explicit instructions or suggestions for the authors to follow. The action is implicit, as the authors can infer that they need to provide more information about the crowd workers, but it lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for information about the crowd workers, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification regarding the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual in nature, seeking additional information to better understand the methodology used in the study. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. This is a relevant and important aspect to consider, as it pertains to the methodology and potential biases in the study. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a critical area for clarification, it lacks actionable feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. While it highlights an area that needs clarification, it does not provide explicit instructions or suggestions for the authors to follow. The action is implicit, as the authors can infer that they need to provide more information about the crowd workers, but it lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable, as it points out a relevant area for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the crowd workers, specifically asking who they were, how they were recruited, and how they were trained. However, it does not specify which part of the paper this question pert"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It implies that the authors should consider the importance of human evaluations and raises questions about the validity and robustness of their conclusions. However, the comment does not provide explicit guidance or concrete suggestions on how the authors should address this issue or improve their evaluation methods. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weakly correlated human evaluations, specifically mentioning the correlation between automatic metrics and human evaluations. It highlights the importance of human evaluations in assessing the quality of the results. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the concern about the validity and robustness of conclusions due to weak correlations, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak correlation between automatic metrics and human evaluations suggests that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it provides a logical reasoning based on the observed correlation, which could lead to questions about the validity and robustness of the conclusions. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the weak correlation between automatic metrics and human evaluations. It highlights the potential limitations of using automatic metrics to evaluate the quality of simplifications, suggesting that human evaluations are more important. This feedback is valuable as it points out a critical area for improvement and raises important questions about the validity and robustness of the conclusions drawn from the study. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as proposing alternative evaluation methods or ways to enhance the human evaluation process. Overall, the comment is somewhat helpful as it directs the authors\\' attention to a crucial aspect of their work that needs further exploration and improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific about the \"Chain of Reasoning\" section, particularly regarding line 276. This provides a clear and direct action for the authors to take, which is to provide additional details or clarification in that specific part of the paper. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and a specific line number (276), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more detail or clarification in that section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for more specificity regarding the \"Chain of Reasoning\" section, particularly line 276. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a request for clarification and does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the \"Chain of Reasoning\" section, particularly line 276. By asking for more specificity, the comment provides a clear direction for the authors to enhance the clarity and comprehensiveness of their reasoning. This feedback is actionable and encourages the authors to provide additional details or explanations that would help readers better understand the logical progression of their argument. However, the comment could be more helpful if it offered suggestions on what specific aspects of the reasoning should be clarified or expanded upon. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, referencing the common metric of minADE or minMSD, which is computed by fixing a budget of samples. While the comment implies that the authors should include such a metric, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this metric and understand how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ability to perform \"hypothetical inference\" or planning, referencing a specific example from the paper where the authors demonstrated using their graphical model and likelihood function to condition on goal states of one agent and plan latent variables to infer how other agents might respond. This provides full grounding as it explicitly mentions the specific part of the paper being addressed. The comment is also specific, as it suggests the inclusion of a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that there should be a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. However, it does not provide specific examples or detailed reasoning on why these metrics are necessary or how they would improve the analysis. The claim is somewhat verifiable as it points out a potential area for improvement but lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting the inclusion of a sample quality metric on the CARLA data. It references common metrics like minADE or minMSD, which are computed by fixing a budget of samples. This feedback is clear and actionable, providing the authors with a concrete suggestion for enhancing their analysis. By addressing this point, the authors can improve the robustness and reliability of their results. However, the comment could be more helpful if it offered additional guidance on how to implement or interpret the metric. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the assumption of having every constraint and its corresponding discriminator. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this assumption is incorrect, how it could be addressed, or if it needs to be clarified in the paper. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of having every constraint and its corresponding discriminator. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide details on why this assumption might be problematic or how it could be addressed. Without clear grounding and specific guidance, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption of having every constraint and its corresponding discriminator. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the assumption of having every constraint and its corresponding discriminator. While it identifies a potential area of confusion or assumption in the paper, it does not provide any specific guidance or suggestions for improvement. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address the issue or enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss or even include Wasserstein GAN (WGAN) as a baseline method, given that it is the first instance of using Optimal Transport (OT) in GANs. While the comment implies that the authors should consider adding WGAN to their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate WGAN into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing or adding Wasserstein GAN (WGAN) as a baseline method, referencing the Wasserstein GAN paper. This provides full grounding as it explicitly mentions the specific paper and method being discussed. The comment is also specific, as it clearly specifies what needs to be addressed: discussing or adding WGAN as a baseline method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) and the Wasserstein Distance in GANs was first introduced in the Wasserstein GAN paper (WGAN). This claim is somewhat verifiable as it references a specific paper (WGAN) that introduced the concept, providing a logical basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples on why discussing or adding WGAN as a baseline method would be beneficial. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as it provides a starting point but requires further elaboration for full clarity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific historical context regarding the use of Optimal Transport (OT) and the Wasserstein Distance in GANs, noting that this was first introduced in the Wasserstein GAN paper (WGAN). It suggests that the authors might find it beneficial to discuss or even include WGAN as a baseline method in their work. This feedback is clear and actionable, as it provides a specific historical reference and a suggestion for improvement that could enhance the context and relevance of the paper. However, the comment could be more helpful if it offered additional guidance on how to integrate WGAN into the discussion or analysis. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It recommends discussing these methods and provides specific references to existing works. Additionally, the comment notes that the paper\\'s preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. While the comment provides specific references and suggestions for improvement, it does not explicitly instruct the authors on how to incorporate these references or address the issues with clarity and organization. The action is implicit but concrete, as the authors can infer the need to include the suggested references and improve the paper\\'s clarity. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references to existing works, which helps ground the comment by allowing the authors to identify the relevant sections of the paper. However, the comment does not specify which part of the paper should include this discussion or how it should be integrated. While the authors can infer that it relates to the literature review or related work sections, the lack of explicit guidance makes the comment weakly grounded. The suggestion to discuss these methods is specific, but the lack of detailed guidance on implementation makes it somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion of related work on MCMC in discrete spaces and provides specific references to existing works that apply Langevin MCMC to sample discrete sequences. This claim is supported by the references provided, which give the authors a clear understanding of the existing literature that should be included. The comment also notes that the paper\\'s preliminary results and issues with clarity and organization make it more suitable for a workshop. While the references provide a strong basis for the claim, the comment could be strengthened by explaining how the absence of these references impacts the paper\\'s contribution or by providing more detailed feedback on the organization and clarity issues. Overall, the comment is mostly verifiable due to the references provided, but it could be further strengthened with additional reasoning or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of related work on MCMC in discrete spaces. It provides specific references to existing works that apply Langevin MCMC to sample discrete sequences, which the authors should consider including in their paper. Additionally, the comment acknowledges the paper\\'s preliminary results and issues with clarity and organization, suggesting that it may be more suitable for presentation at a workshop. This feedback is clear and actionable, offering the authors a concrete path to improve their draft by incorporating relevant literature and addressing the identified issues. However, the comment could be more helpful if it provided specific suggestions on how to enhance the clarity and organization of the paper. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references to existing works, which helps ground the comment. Additionally, the comment notes that the paper\\'s preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. While the comment identifies specific areas for improvement and provides references, it does not explicitly instruct the authors on how to incorporate these references or address the issues with clarity and organization. The action is implicit but concrete, as the authors can infer the need to include the suggested references and improve the paper\\'s clarity. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references to existing works, which helps ground the comment by allowing the authors to identify the relevant sections of the paper. However, the comment does not specify which part of the paper should include this discussion or how it should be integrated. While the suggestion to discuss these methods is specific, the lack of explicit guidance on implementation makes the comment somewhat specific. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks discussion of related work on MCMC in discrete spaces and provides specific references to existing works that apply Langevin MCMC to sample discrete sequences. This provides a clear and verifiable"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should clarify the methods used, compare them, or provide additional details. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where these methods are discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. Additionally, the comment lacks specificity as it does not provide details on what aspects of the methods are different or how they might impact the results. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the methods used by DS-FedDRO and FedDRO to estimate $g$. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the methods used by DS-FedDRO and FedDRO to estimate $g$. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their methodology. The comment lacks depth and actionable feedback, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there should be a discussion about the difference between (6) in \"Nicekl Kiela\" and (l). However, it does not provide any explicit guidance on what aspects of the difference should be discussed or how this discussion should be structured. The action is implicit and lacks concrete details, leaving the authors uncertain about how to address the suggestion effectively. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not specify which part of the paper this discussion should be included in. The authors might infer that it relates to a specific section or reference, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the difference should be discussed or how this discussion would benefit the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any context, reasoning, or evidence to support why this discussion is necessary or how it would improve the paper. Without additional information or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any further context, explanation, or guidance on why this discussion is necessary or how it would benefit the paper. Without additional details or suggestions, the authors are left without actionable feedback on how to address this issue. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that there should be a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any explicit guidance on what aspects of the difference should be discussed or how this discussion should be structured. The action is implicit and lacks concrete details, making it difficult for the authors to determine how to address the suggestion effectively. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not specify which part of the paper this discussion should be included in. The authors might infer that it relates to a specific section or reference, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the difference should be discussed or how this discussion would benefit the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any context, reasoning, or evidence to support why this discussion is necessary or how it would improve the paper. Without additional information or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there should be a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any context, reasoning, or guidance on why this discussion is necessary or how it would benefit the paper. Without additional details or suggestions, the authors are left without actionable feedback on how to address this issue. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that there should be a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not provide any explicit guidance on what aspects of the difference should be discussed or how this discussion should be structured. The action is implicit and lacks concrete details, making it difficult for the authors to determine how to address the suggestion effectively. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a discussion about the difference between (6) in \"Nicekl Kiela\" and (l), but it does not specify"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of variance analysis in the experiments and notes that the experiments were not conducted multiple times. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific methods for variance analysis or recommending the number of times the experiments should be repeated. The action is implicit and vague, leaving the authors uncertain about how to implement the suggested improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of variance analysis in the experiments and notes that the experiments were not conducted multiple times. However, it does not specify which part of the paper discusses the experiments or where the variance analysis should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where the experiments are discussed, the comment lacks full grounding. It is specific about the issue of variance analysis and the need for multiple runs, but without explicit references, it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and lacks variance analysis for the results. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiments, noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is valuable as it highlights a potential weakness in the experimental design that could affect the reliability and robustness of the findings. However, the comment does not provide guidance on how the authors might address this issue, such as suggesting methods for variance analysis or recommending the number of times the experiments should be repeated. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the real-world applicability of the experiments, specifically mentioning the lack of consideration for factors like differing dataset qualities and temporal drifts in data distributions. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to consider these factors in their experiments or discuss them in the paper, but the comment lacks concrete suggestions or steps on how to implement this. Therefore, the comment is somewhat actionable, as it points out a potential area for improvement but does not offer detailed guidance on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a gap in the paper regarding the real-world applicability of the experiments, specifically mentioning the lack of consideration for factors like differing dataset qualities and temporal drifts in data distributions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the gap between the experiments and real-world scenarios, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not account for factors like differing dataset qualities and temporal drifts in data distributions, which are characteristic of real-world data. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the extent of the issue or how to address it. The absence of detailed reasoning or evidence results in the comment being unverifiable, as it does not provide sufficient support for the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the applicability of the experiments to real-world datasets. It highlights the inherent differences between the experimental setup and the goal of achieving label efficiency with a human in the loop, such as differing dataset qualities and temporal drifts in data distributions. This feedback is valuable as it points out a critical area that the authors need to address to ensure the relevance and applicability of their work. However, the comment could be more helpful if it provided specific suggestions on how to account for these factors or how to bridge the gap between the experiments and real-world scenarios. Overall, the comment is somewhat helpful as it directs the authors to an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds as sufficient. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the communication cost in their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this information is presented in, making it weakly grounded. The comment is specific in pointing out that the communication cost is not particularly low or noteworthy, given the comparison with other federated Q-learning algorithms. However, it lacks detailed guidance on how the authors might address this issue or improve their communication cost. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds as sufficient. The comment provides a logical reasoning by comparing the communication cost with that of other algorithms, which supports the claim. However, it lacks specific references or examples to fully substantiate the comparison, making the claim somewhat verifiable. The authors would need to further explore the literature or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. This feedback highlights a potential weakness in the paper\\'s contribution, as it suggests that the communication cost may not be as innovative or efficient as initially perceived. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their communication cost. While it identifies a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds as sufficient. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue or improve their communication cost. Without specific guidance or suggestions, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this information is presented in, making it weakly grounded. The comment is specific in pointing out that the communication cost is not particularly low or noteworthy, given the comparison with other federated Q-learning algorithms. However, it lacks detailed guidance on how the authors might address this issue or improve their communication cost. Without specific suggestions or references, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated O(H) communication rounds as sufficient. The comment provides a logical reasoning by comparing the communication cost with that of other algorithms, which supports the claim. However, it lacks specific references or examples to fully substantiate the comparison, making the claim somewhat verifiable. The authors would need to further explore the literature or provide additional context to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. There is no guidance on what specific adaptations or changes the authors should make to their paper. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main idea of using an ensemble of neural networks, noting that it is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. The authors might infer that it relates to the methodology or discussion sections, but this inference is not direct. The comment is specific in identifying the lack of adaptation to the homomorphic encryption domain, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is \"trivial and very common in machine learning literature\" and that the paper lacks specific adaptation to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. This feedback highlights a gap in the paper\\'s contribution and suggests that the authors should consider providing more novel or specific adaptations to differentiate their work. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve their draft. While it points out a relevant area for improvement, it does not offer actionable steps or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. There is no guidance on what specific adaptations or changes the authors should make to their paper. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main idea of using an ensemble of neural networks, noting that it is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. The authors might infer that it relates to the methodology or discussion sections, but this inference is not direct. The comment is specific in identifying the lack of adaptation to the homomorphic encryption domain, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. This feedback highlights a gap in the paper\\'s contribution and suggests that the authors should consider providing more novel or specific adaptations to differentiate their work. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve their draft. While it points out a relevant area for improvement, it does not offer actionable steps or"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide more detailed explanations or analyses, but it does not specify what kind of information or analysis is needed. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. This provides clear guidance on what the authors need to address in their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the paper regarding why and how the new model works better than the previous state-of-the-art, MH. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The comment lacks specific reasoning or detailed explanation, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the paper\\'s explanation of why and how the new model works better than the previous state-of-the-art, MH. This feedback is valuable as it points out a gap in the paper\\'s discussion, prompting the authors to provide more detailed explanations or analyses. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending specific sections or analyses to include. Overall, the comment is somewhat helpful as it highlights an important area for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reasonableness of the formula used in the Adjective Projection part. It suggests an alternative approach, specifically recommending that the authors calculate the difference between the similarity of the object with \"large\" and \"small\" embeddings instead of using the similarity between the object embedding and the difference between the \"large\" and \"small\" embeddings. This feedback provides a clear and concrete suggestion for improvement, allowing the authors to understand exactly what needs to be changed and how to implement the suggested approach. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the specific section being addressed. It is also specific because it clearly specifies the issue with the formula, suggesting an alternative approach to estimate whether the object is large or small. The comment provides detailed guidance on how to improve the method, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasonableness of a formula used in the Adjective Projection part of the paper. It suggests an alternative approach, recommending that the authors calculate the difference between the similarity of the object with \"large\" and \"small\" embeddings instead of using the similarity between the object embedding and the difference between the \"large\" and \"small\" embeddings. While the comment provides a logical reasoning for the alternative approach, it lacks specific references or detailed examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formula used in the Adjective Projection part of the paper. It suggests an alternative approach, recommending that the authors calculate the difference between the similarity of the object with \"large\" and \"small\" embeddings instead of using the similarity between the object embedding and the difference between the \"large\" and \"small\" embeddings. This feedback is clear and actionable, providing the authors with a specific and logical suggestion for improvement. By following this advice, the authors can enhance the accuracy and clarity of their method. However, the comment could be more helpful if it included additional context or examples to further justify the alternative approach. Overall, the comment is mostly helpful, as it effectively guides the authors toward a potential enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of the equation \\sigma_k = sigmoid(\\sigma_k) in line 121 and suggests that the authors elaborate on the issues mentioned. While the comment identifies a specific area of confusion, it does not provide explicit instructions on how to address it. The suggestion to elaborate on the issues is vague and lacks concrete guidance on what aspects need further explanation. The authors can infer that they should clarify the equation, but the comment does not specify how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of the equation \\sigma_k = sigmoid(\\sigma_k) and suggesting that the authors elaborate on the issues mentioned. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements and questions about the meaning of an equation in the paper. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in line 121, questioning the meaning of the equation \\sigma_k = sigmoid(\\sigma_k). This is a clear and actionable point that can help the authors clarify their notation and improve the readability of their draft. Additionally, the comment expresses interest in the proposed method's ability to capture long-range context information for computer vision tasks, which is a positive observation. However, the comment could be more helpful if it provided additional context or suggestions on how to elaborate on the issues mentioned. Overall, the comment is mostly helpful as it directs the authors to clarify a specific point and highlights the potential interest in their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This feedback provides a clear and explicit action for the authors to take, which is to include a discussion and comparison with these works. The suggestion is concrete, as it specifies the type of comparison and references specific works, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing and comparing the work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, related work section, or results discussion. The authors might infer that it relates to the discussion of any-resolution generation, but this inference is not direct. The comment is specific in its suggestion to include comparisons with recent works, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This claim is somewhat verifiable as it provides references to specific works that could be used for comparison. However, the comment lacks detailed reasoning or explanation on why these works are relevant or how they would enhance the discussion. The authors would need to further explore and understand the context of these references to fully grasp the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This feedback is clear and actionable, as it provides specific references that the authors can use to enhance their discussion and comparison. By including these references, the authors can strengthen their paper by situating their work within the context of recent advancements in the field. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these references into the discussion or what specific aspects to focus on when comparing to these works. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This feedback provides a clear and explicit action for the authors to take, which is to include a discussion and comparison with these works. The suggestion is concrete, as it specifies the type of comparison and references specific works, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests discussing and comparing the work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. However, it does not specify which part of the paper this suggestion pertains to, such as the introduction, related work section, or results discussion. The authors might infer that it relates to the discussion of any-resolution generation, but this inference is not direct. The comment is specific in its suggestion to include comparisons with recent works, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests discussing and comparing the work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This claim is somewhat verifiable as it provides references to specific works that could be used for comparison. However, the comment lacks detailed reasoning or explanation on why these works are relevant or how they would enhance the discussion. The authors would need to further explore and understand the context of these references to fully grasp the suggestion. Therefore, the comment is rated as somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2] as examples. This feedback is clear and actionable, as it provides specific references that the authors can use to enhance their discussion and comparison. By"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential for overfitting in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. It explicitly requests that the authors discuss limitations, such as theoretical assumptions and implementation considerations. Additionally, it questions the relative improvement of ODER over RED alternatives and asks for a comparison of training times. These suggestions provide clear and concrete actions for the authors to take, making the comment highly actionable. The authors know exactly what needs to be addressed and how to improve their draft by following the reviewer\\'s guidance.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details several issues, including the potential for overfitting in the CT experiment due to the small test set size, the insufficient description of limitations in Section 6, and the need for discussion on theoretical assumptions, implementation considerations, and the relative improvement of ODER over RED alternatives. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the potential for overfitting in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. The reviewer provides a specific reference to a paper (https://doi.org/10.1002/mrm.28235) that discusses overfitting in similar contexts, which supports the claim. Additionally, the comment questions the sufficiency of Section 6 and suggests areas for improvement, such as discussing theoretical assumptions and implementation considerations. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to specific limitations that need to be addressed. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the CT experiment, specifically the small test set size, which could lead to overfitting. It also points out that Section 6 does not sufficiently describe the limitations of the work, suggesting that the authors should discuss theoretical assumptions, implementation considerations, and other relevant limitations. Additionally, the comment questions the relative improvement of ODER over RED alternatives and asks for a comparison of training times. This feedback is clear and actionable, providing the authors with specific areas to address and improve in their draft. By addressing these points, the authors can enhance the comprehensiveness and rigor of their work. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the text, noting that the bound on the 2-Wasserstein is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This feedback is explicit and provides a clear action for the authors to correct the error. The comment is concrete, as it specifies exactly what needs to be changed and where in the text the correction should be made. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line numbers (216 and 217), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect statement of the bound on the 2-Wasserstein, noting that it should be the bound on the 2-Wasserstein squared. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual correction regarding the statement of a bound on the 2-Wasserstein distance, noting that it should be the bound on the 2-Wasserstein squared. This is a straightforward correction of a mathematical expression, and the comment does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the text regarding the bound on the 2-Wasserstein distance, noting that it is incorrectly stated as $O(\\\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This feedback is clear and actionable, as it directly points out a mistake that needs to be corrected. By addressing this error, the authors can improve the accuracy and clarity of their draft. However, the comment could be more helpful if it provided additional context or suggested how this correction might impact the overall argument or results. Despite this, the comment is mostly helpful as it provides a specific and actionable piece of feedback. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, specifically IEConv, CDConv, and ProNet. It references several external works, including [1] Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures, [2] Learning from Protein Structure with Geometric Vector Perceptrons, [3] Equivariant Graph Neural Networks for 3D Macromolecular Structure, [4] Protein Representation Learning by Geometric Structure Pretraining, [5] Learning Hierarchical Protein Representations via Complete 3D Graph Networks, and [6] Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins. While the comment highlights a potential area for comparison, it does not provide explicit guidance or suggestions on how the authors should address this question or differentiate their method from the referenced works. The action is implicit and vague, as the authors need to infer that they should compare their method with these references and provide a clear explanation of the differences. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, specifically IEConv, CDConv, and ProNet. It references several external works, including [1] Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures, [2] Learning from Protein Structure with Geometric Vector Perceptrons, [3] Equivariant Graph Neural Networks for 3D Macromolecular Structure, [4] Protein Representation Learning by Geometric Structure Pretraining, [5] Learning Hierarchical Protein Representations via Complete 3D Graph Networks, and [6] Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the comparison section or the methodology. The comment is specific in detailing the comparison with other methods, providing references to external works. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, specifically IEConv, CDConv, and ProNet. It references several external works, including [1] Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures, [2] Learning from Protein Structure with Geometric Vector Perceptrons, [3] Equivariant Graph Neural Networks for 3D Macromolecular Structure, [4] Protein Representation Learning by Geometric Structure Pretraining, [5] Learning Hierarchical Protein Representations via Complete 3D Graph Networks, and [6] Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins. By providing specific references to these works, the comment offers a comprehensive basis for comparison, making the claim fully verifiable. The authors can easily understand the context and rationale behind the question, allowing them to address the critique effectively. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, specifically IEConv, CDConv, and ProNet. It references several external works, providing a comprehensive list of comparisons that the authors can consider. This feedback is somewhat helpful as it prompts the authors to clarify the unique contributions of their method and differentiate it from existing approaches. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the question or highlight the differences. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, specifically IEConv, CDConv, and ProNet. It references several external works, including [1] Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures, [2] Learning from Protein Structure with Geometric Vector Perceptrons, [3] Equivariant Graph Neural Networks for 3D Macromolecular Structure, [4] Protein Representation Learning by Geometric Structure Pretraining, [5] Learning Hierarchical Protein Representations via Complete 3D Graph Networks, and [6] Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins. While the comment highlights a potential area for comparison, it does not provide explicit guidance or suggestions on how the authors should address this question or differentiate their method from the referenced works. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2',"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper does not read well and needs more careful proofreading. However, it does not provide specific guidance on what aspects of the writing are unclear or need improvement, nor does it suggest how the authors might address these issues. Without detailed feedback or actionable steps, the authors are left without a clear understanding of what needs to be done to improve the readability of the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper does not read well and needs more careful proofreading. However, it does not specify which sections or parts of the paper are particularly problematic, nor does it provide any specific examples or details about what needs to be improved. Without explicit references to sections or specific issues, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity in terms of what aspects of the writing are unclear or need improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not read well and needs more careful proofreading. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand which parts of the paper need improvement or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper does not read well and needs more careful proofreading. However, it lacks specificity and does not provide any guidance on what aspects of the writing are unclear or need improvement. Without actionable feedback or examples, the authors are left without a clear understanding of how to address the issue. This limits the usefulness of the comment, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several specific actions for the authors to take. It requests an analysis of the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, which is crucial for understanding the synthetic task. It also points out the lack of mention and explanation of the trade-off parameter (Theta) and suggests a comparison with a baseline that uses attention from the previous question. These suggestions are explicit and provide clear guidance on what the authors need to address to improve their draft. The comment is concrete in its requests, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the distribution of addressing coefficients (Betas) and the trade-off parameter (Theta), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as analyzing the distribution of addressing coefficients with and without bias towards sequential addressing, and questioning the value and selection of the trade-off parameter (Theta). Additionally, it suggests a comparison with a baseline that uses attention from the previous question. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing is crucial for understanding the synthetic task. It also questions the value and selection of the trade-off parameter (Theta) and suggests a comparison with a baseline that uses attention from the previous question. While the comment provides a logical reasoning for the importance of these analyses, it lacks specific examples or references to support the claim fully. The suggestion for a comparison with a baseline is also not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification and examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It highlights the importance of analyzing the distribution of addressing coefficients (Betas) with and without bias towards sequential addressing, which is crucial for understanding the synthetic task. Additionally, it points out the lack of mention and explanation of the trade-off parameter (Theta) and suggests a comparison with a baseline that uses attention from the previous question. These suggestions are clear and provide specific areas for the authors to focus on, making the comment highly helpful. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct these analyses or comparisons. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer also expresses a personal opinion that the mathematical presentation is unnecessary and does not contribute to making the paper more interesting. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the draft. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"proposition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of the proposition, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The comment further specifies that the proposition does not contribute to making NC a complexity measure in statistical learning sense. This provides clear guidance on what needs to be addressed or reconsidered in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer also expresses a personal opinion that the mathematical presentation is unnecessary and does not contribute to the paper\\'s interest. However, the comment lacks specific examples or references to support the claim that the mathematical presentation is unnecessary or decorative. This makes the claim somewhat verifiable, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for the mathematical presentation. The reviewer also expresses a personal opinion that the mathematical presentation is unnecessary and does not contribute to the paper\\'s interest. Additionally, the comment questions whether the proposition makes NC a complexity measure in statistical learning sense. While the comment identifies a potential issue with the paper\\'s presentation, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the draft. The feedback is somewhat helpful as it points out areas for consideration but does not provide detailed advice or actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of defense techniques, specifically mentioning that the evaluation of defenses relying on input perturbation is essential for a comprehensive understanding of the attacks. It provides references to specific works by Doan et al. that discuss learnable, imperceptible, and robust backdoor attacks. While the comment identifies a gap in the evaluation, it does not explicitly instruct the authors to include these defenses or provide detailed guidance on how to incorporate them into their evaluation. The action is implicit and somewhat vague, as the authors can infer that they need to expand their evaluation but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a limitation in the evaluation of defense techniques, specifically mentioning the need to evaluate defenses relying on input perturbation in backdooring classification. It provides references to specific works by Doan et al. that discuss learnable, imperceptible, and robust backdoor attacks. However, the comment does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the evaluation of defense techniques, providing clear guidance on the types of defenses to consider. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of defense techniques is limited, particularly in the context of backdooring classification. It suggests that evaluating defenses relying on input perturbation is essential for a comprehensive understanding of the attacks. The comment supports this claim by referencing specific works by Doan et al., which discuss learnable, imperceptible, and robust backdoor attacks. This provides a clear and specific reference to relevant literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed analysis or examples of how these defenses are relevant to the proposed method. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of defense techniques, specifically highlighting the need to evaluate defenses relying on input perturbation in backdooring classification. It provides references to specific works by Doan et al. that discuss learnable, imperceptible, and robust backdoor attacks. This feedback is valuable as it guides the authors to expand their evaluation, which could enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered specific suggestions on how to incorporate these defenses into the evaluation or discussed the potential impact of these defenses on the proposed method. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. Additionally, it recommends that the context and evidence-based methods be more thoroughly presented. While the comment provides explicit actions for the authors to take, it lacks concrete details on how to achieve these improvements or specific examples of what should be included. The authors are given a clear direction but may need to infer the exact steps to implement the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests improvements to the related work section, specifically mentioning the need for a more focused section that includes descriptions of similar datasets for non-English or underrepresented languages. It also notes that the context and evidence-based methods are presented shallowly. However, the comment does not specify which part of the related work section is being addressed, making it weakly grounded. The suggestion is specific in terms of what needs to be improved, but without explicit references to sections, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could be more focused and includes a specific request for descriptions of similar datasets for non-English or underrepresented languages. It also notes that the context and evidence-based methods are presented shallowly. While the comment provides a clear suggestion for improvement, it lacks specific examples or references to support the claim that the related work section is too broad or shallow. This makes the claim somewhat verifiable, as the authors would need to infer the extent of the issues based on the general guidance provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the related work section, suggesting that it should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. Additionally, it recommends that the context and evidence-based methods be more thoroughly presented. This feedback is clear and constructive, offering the authors a clear direction for improving their draft by addressing gaps in their literature review. However, the comment could be more helpful if it provided examples of how to achieve these improvements or specific references to consider. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations. It highlights a potential inconsistency in the authors\\' claim that BN can be folded into convolutions before ReLU, given that the same mean, var, scale, and offset are shared within the same conv feature map. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their argument. The action is implicit and vague, as the authors are left to infer that they need to clarify their argument or provide additional evidence. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations, particularly in relation to the experiment in Table 2. The comment clearly specifies what needs to be addressed, namely the consistency of the authors\\' claim about BN folding and the implications of the shared mean, var, scale, and offset within the same conv feature map. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations. It points out a potential inconsistency in the authors\\' claim that BN can be folded into convolutions before ReLU, given that the same mean, var, scale, and offset are shared within the same conv feature map. This feedback is somewhat helpful as it identifies a specific area where the authors\\' argument may need clarification or correction. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their argument. To be more helpful, the comment could provide additional context or suggest ways to resolve the inconsistency. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of large-scale experiments in the paper, noting that the models used in the experiments section are quite small. It suggests that including experiments with varying network sizes would help demonstrate whether the results from the small-scale experiments extend to larger scale experiments. While the comment implies that the authors should conduct these additional experiments, it does not provide specific guidance on how to design or execute these experiments. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and provides specific details about the models used in the MNIST and SVHN experiments, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of large-scale experiments and the need for experiments that vary the size of the network to demonstrate the scalability of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments conducted in the paper are limited in scale, specifically mentioning the small number of hidden neurons and the single convolutional layer with 40 channels. The reviewer suggests that including experiments with varying network sizes would help demonstrate the scalability of the results. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that larger-scale experiments are necessary. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that the experiments conducted are limited in scale, particularly in terms of the size of the networks used. It suggests that including experiments with varying network sizes would help demonstrate whether the results from the small-scale experiments extend to larger scale experiments. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the robustness and generalizability of their findings. By addressing this suggestion, the authors can significantly improve the validity and applicability of their results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore this scenario, conduct a comparison, or provide additional analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address this question. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison with prior work should be addressed. Without clear grounding or detailed guidance, the authors cannot effectively determine what needs to be revised or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the behavior of the problem when W is the identity matrix and how it compares with prior work. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. While it identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might address this question or what aspects of the comparison should be emphasized. The comment provides some insight into a possible direction for further investigation but does not offer actionable feedback or detailed suggestions for improvement. Therefore, it is somewhat helpful, as it prompts the authors to consider a specific aspect of their work but does not fully guide them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. There is no guidance on whether the authors should consider including more general problems or how to achieve this expansion. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this issue is addressed, the comment lacks full grounding. It is specific in identifying the limitation but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work focuses primarily on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the work, specifically noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This feedback highlights an area where the authors might need to expand their work to enhance its applicability. However, the comment lacks specific suggestions or guidance on how the authors could address this limitation or expand the scope of their work. Without actionable advice or detailed recommendations, the comment provides only a vague indication of where the paper could be improved, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that learning both low- and high-frequency information in balance is not novel and mentions several related works that have been published. It suggests that the authors should analyze and compare their work to these related works. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects of the related works should be compared. The action is implicit and somewhat vague, as the authors need to infer that they should analyze and compare their work to the mentioned related works, but they are not given clear instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of learning both low- and high-frequency information in balance, suggesting that it is not novel and references several related works. However, it does not specify which part of the paper this critique pertains to, such as the introduction or related work section. The authors can infer that it relates to the discussion of novelty, but this inference is not direct. The comment is specific in identifying the related works and suggesting an analysis, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that learning both low- and high-frequency information in balance is not novel and references several related works to support this claim. The comment provides specific references to existing works, such as [1] to [4], which allows the authors to understand the context and potential impact of their work. This detailed reference to prior work provides a strong basis for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the paper\\'s approach to learning both low- and high-frequency information in balance. It provides a detailed critique by referencing several related works that have explored similar concepts, such as uniformly learning various frequency domains through random masking. The comment suggests that the authors should analyze and compare their work to these related works, which is a clear and actionable suggestion for improvement. By referencing specific works, the comment offers a concrete path for the authors to enhance their draft by situating their contribution within the existing literature. However, the comment could be more helpful if it provided additional guidance on how to effectively analyze and compare the works mentioned. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear direction for enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any explicit instructions or guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and lacks concrete details, leaving the authors uncertain about how to implement the suggested comparison. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the recommendation to compare the compression bandwidth of PC+IDF with IDF, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any reasoning, evidence, or references to support why this comparison is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison to be made in Section 5, recommending that the compression bandwidth of PC+IDF be compared with IDF. This feedback is somewhat helpful as it provides a clear direction for the authors to enhance their analysis by comparing different methods. However, the comment lacks depth and does not offer additional guidance or suggestions on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could include more detailed reasoning or examples of how this comparison could impact the paper\\'s conclusions or findings. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. While the comment explicitly states the action of renaming the models, it does not provide detailed guidance on why these names are misleading or how the proposed names address the issue. The suggestion is concrete in terms of what needs to be done, but the lack of explanation for the current names' misleading nature makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the model names, suggesting that they are misleading and proposing alternative names. However, it does not specify which part of the paper these model names are mentioned in, making it weakly grounded. The comment is specific in its suggestion for alternative names, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names. However, the comment does not provide any reasoning or evidence to support why these names are misleading or why the proposed names are more appropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model names, suggesting that they are misleading. It proposes alternative names that might be more descriptive and easier to understand. This feedback is clear and actionable, as it provides a concrete suggestion for improving the clarity and communicability of the model names. However, the comment could be more helpful if it explained why the current names are misleading or how the proposed names address this issue. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improvement, but it could be more comprehensive with additional context or explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of acronym \"AR\" for \"artificial intelligence\" and mentions its repeated use in line 055. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this is a mistake, a stylistic choice, or if it needs to be changed. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the acronym \"AR\" and references line 055, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of acronym and its repeated use, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of acronym \"AR\" for \"artificial intelligence\" and mentions its repeated use in line 055. However, it does not provide any reasoning or evidence to support why this choice is problematic or why it should be changed. The comment lacks specific justification or examples, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a specific issue with the use of the acronym \"AR\" for \"artificial intelligence\" and mentions its repeated use in line 055. While it identifies a potential inconsistency or confusion in terminology, it does not provide any further context or suggestions on how to address this issue. The comment lacks depth and actionable guidance, leaving the authors with a general observation but no clear direction for improvement. Therefore, it is rated as barely helpful, as it highlights a potential problem but does not offer constructive feedback for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the motivation for the gating design in the paper and notes that the gating mechanism is not a new concept in multi-task learning (MTL). However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how the authors might clarify the motivation or differentiate their approach from existing work. As a result, the comment lacks actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a new concept in MTL. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its critique of the gating mechanism, it is not grounded in the paper, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a new concept in MTL. However, the comment does not provide specific examples or references to support the claim that the gating mechanism is not novel. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a key issue with the paper, which is the lack of clarity in the motivation behind the gating design for multi-task learning (MTL). It points out that the gating mechanism is not a new concept in MTL, which could be a significant concern for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or differentiate their approach from existing work. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a new concept in MTL. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how the authors might clarify the motivation or differentiate their approach from existing work. As a result, the comment lacks actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of task-specific features to task-shared features. It questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a new concept in MTL. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its critique of the gating mechanism, it is not grounded in the paper, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point questions the motivation behind the gating design for multi-task learning (MTL) and notes that the gating mechanism is not a new concept in MTL. However, the comment lacks specific examples or references to support the claim that the gating mechanism is not novel. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, which is the lack of clarity in the motivation behind the gating design for multi-task learning (MTL). It notes that the gating mechanism is not a new concept in MTL, which could be a significant concern for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might clarify the motivation or differentiate their approach from existing work. While it highlights an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practicality of their approach. The comment lacks actionable details, such as recommending alternative assumptions or methods to mitigate these limitations. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical scenarios in which learning to defer is preferable and details how it is expected to behave. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the issue of strong assumptions required for training, such as the availability of ground truth and DM\\'s decisions for each DM of interest. This provides some guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to the assumptions or how they impact the practicality of the approach. This makes the claim somewhat verifiable, as the authors would need to infer the specific issues and provide additional context to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. This feedback highlights an important area for consideration and improvement in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or mitigate the assumptions required for training. While it points out a critical issue, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practicality of their approach. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to enhance their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the issue of strong assumptions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide explicit evidence or references to substantiate the assertion about the assumptions needed for training. This makes it difficult for the authors to fully understand and address the issue. As a result, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary details for full verification. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', \"helpfulness_rationale\": \"The review comment identifies a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental part is less convincing due to the choice of weak baselines, specifically mentioning the LR and SVM approaches. However, it does not provide explicit guidance on how to improve the experimental setup or suggest alternative baselines that could be used. The action is implicit, as the authors can infer that they need to strengthen their experimental results by using more robust baselines, but it lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the experimental part of the paper, specifically mentioning the use of LR and SVM baselines as too weak compared to deep learning approaches. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment, making it weakly grounded. The comment is specific in identifying the issue with the choice of baselines, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the choice of weak baselines, specifically mentioning LR and SVM approaches. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why these baselines are considered weak or why they are insufficient for the experimental evaluation. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary details to help the authors understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental part of the paper, noting that the choice of baselines, specifically LR and SVM, are considered weak compared to deep learning approaches. This feedback highlights a potential weakness in the experimental setup that could impact the credibility of the results. However, the comment lacks actionable suggestions or guidance on how the authors might strengthen their experimental design or choose more robust baselines. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight into a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of discussion on the communication cost in both the theorem and the experiment sections, which is crucial for understanding the contribution of the GLASU algorithm. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include a discussion on communication cost, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it highlights a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"GLASU algorithm\" and the sections on \"theorem\" and \"experiment,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion on the communication cost in both the theorem and experiment sections, thereby highlighting what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This claim is somewhat verifiable as it highlights a gap in the paper\\'s discussion, but it lacks specific examples or references to support the assertion that the communication cost is not addressed. The authors would need to further investigate to fully understand the claim and its implications. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out that the motivation of the GLASU algorithm, which is to save communication, is not supported by the discussion of the communication cost in either the theorem or the experiment sections. This feedback is valuable as it highlights a significant omission that could undermine the paper\\'s contribution. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific metrics or methods to measure communication cost. Overall, the comment is somewhat helpful as it directs the authors to a critical area needing attention but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the contributions of the paper should be explicitly stated. This provides a clear and direct action for the authors to take, which is to identify and highlight the contributions of their work. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this should be addressed in. This makes it weakly grounded, as the authors cannot confidently determine which sections need to be revised. However, the comment is specific in its request for explicit contributions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contributions of the paper should be explicitly stated. While this is a valid point, the comment lacks specificity and does not provide guidance on how the authors might identify and articulate their contributions more effectively. Without actionable advice or examples, the authors may struggle to understand how to implement this suggestion. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not offer detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the work is unclear and suggests that the explanation should be justified experimentally or theoretically. While the comment implies that the authors should provide more evidence or justification for their claims, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional justification but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work and the explanation provided in the paper, specifically mentioning the statement \"different densities directly will cause semantic conflicts.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the explanation should be justified experimentally or theoretically, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work is unclear and that the explanation is not convincing. It suggests that the statement \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. While the comment identifies a potential issue with the clarity of the motivation and explanation, it lacks specific examples or references to support the claim. The suggestion to justify the statement experimentally or theoretically provides some direction, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the claim is somewhat verifiable, as it provides a basis for improvement but requires further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation and explanation in the paper. It points out that the authors mention a potential issue with \"different densities directly causing semantic conflicts,\" but this is not adequately justified. The comment suggests that this should be addressed experimentally or theoretically, providing a clear direction for improvement. However, it lacks specific suggestions on how to justify the claim or what experiments or theoretical approaches could be used. While the feedback is somewhat helpful in identifying an area for improvement, it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it asks whether the three transformer modules are trained iteratively or in an end-to-end manner, which implies that the authors should clarify this aspect of their approach. Second, it questions the necessity of repeating the visualization in Figure 5, suggesting that it may be redundant if it does not demonstrate new points. While the comment provides explicit questions, it lacks concrete guidance on how to address these issues or what specific changes should be made. The authors are left with a general understanding of what needs clarification but without detailed instructions on how to implement the changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the three transformer modules are trained iteratively or in an end-to-end manner and suggesting that the repeated visualization in Figure 5 may not be necessary if it does not demonstrate new points. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the training method of the transformer modules and the necessity of repeating the visualization in Figure 5. The comment provides a logical basis for its claims by pointing out the similarity between Figure 5 and Figure 1, suggesting that the latter may be redundant if it does not demonstrate new points. However, the comment lacks specific examples or references to support the claim about the training method, making it somewhat verifiable. The authors would need to infer the reasoning behind the claim, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important points. First, it questions the training method of the transformer modules, asking whether they are trained iteratively or in an end-to-end manner. This is a critical aspect of the proposed approach that needs clarification. Second, it critiques the repetition of the visualization in Figure 5, suggesting that it may not be necessary if it does not demonstrate new points. These observations provide the authors with actionable feedback on areas that need clarification and potential redundancy in their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of what new points could be demonstrated. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take, including improving the precision and clarity of the writing and distinguishing the unique contributions of ParamReL from infoDiffusion. It suggests specific areas for improvement, such as clarifying the parameters of BFNs versus BFN-produced distributions. The comment also provides a clear direction for strengthening the paper by explicitly outlining the unique contributions of ParamReL. The feedback is concrete and actionable, giving the authors a clear path to follow for improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific areas for improvement, such as the writing and the proposed method\\'s relation to infoDiffusion. It provides clear guidance on what needs to be addressed, including the need for greater precision and clarity in the writing and the need to distinguish the unique contributions of ParamReL from infoDiffusion. This level of detail allows the authors to accurately identify the parts of the paper that require attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the writing would benefit from greater precision and clarity, and it provides specific examples of areas needing improvement. The comment also suggests that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The reviewer requests that the authors explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This feedback is mostly verifiable as it provides logical reasoning and specific examples to support the claim, but it could be strengthened with additional references or detailed comparisons to infoDiffusion. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on improving the precision and clarity of the writing, which is crucial for enhancing the overall quality of the paper. It highlights a particular area of concern, the distinction between \"parameters of BFNs\" and \"parameters of BFN-produced distributions,\" and suggests that the authors clarify this distinction. Additionally, the comment points out that the proposed method is closely related to infoDiffusion and recommends that the authors explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion. This feedback is clear and provides concrete suggestions for improvement, making it highly helpful for the authors to enhance their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify their focus on a situation where the gradient of the sum is not the sum of the individual gradients, as this is not communicated in the text. It also recommends discussing this setting in less space, as it is a common issue in all ERM approaches. The comment provides a clear action for the authors to take, which is to clarify and discuss this aspect more effectively. However, it does not specify how to achieve this or provide detailed guidance on what aspects to emphasize. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 60-74 and the beginning of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is the lack of communication about the focus on a situation where the gradient of the sum is not the sum of the individual gradients. The comment suggests that this setting is shared in all ERM approaches and could be discussed in less space, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors want to focus on a situation where the gradient of the sum is not the sum of the individual gradients, but this is not communicated in the text. The reviewer suggests that this setting is shared in all ERM approaches and could be discussed in less space. However, the comment lacks specific examples or references to support the claim that this setting is indeed shared across all ERM approaches. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some support but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the authors\\' focus in the discussion, particularly in lines 60-74 of Section 2. It points out that the authors seem to be emphasizing a situation where the gradient of the sum is not the sum of the individual gradients, but this is not explicitly communicated in the text. The comment suggests that this setting is common in all ERM approaches and could be discussed in less space, which is a valuable observation. However, the comment lacks actionable guidance on how the authors might clarify this point or improve the discussion. While it highlights an area for improvement, it does not provide detailed suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the proposed question-rewrite strategy, specifically questioning whether it covers a sufficiently large number of questions. It provides details on the number of invalid questions and the percentage attributed to unresolved coreference. However, the comment does not offer explicit guidance or suggestions on how the authors might address these concerns or improve their strategy. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to these issues. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"question-rewrite strategy\" and references \"Table 4 in the appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by detailing the concerns about the coverage of the strategy, the number of invalid questions, and the percentage attributed to unresolved coreference. The comment further provides specific details about the proposed method, such as the number of questions rewritten and the effect on model performance. This level of detail makes the comment specific and actionable, fitting the criteria for a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the proposed question-rewrite strategy, specifically questioning its coverage and effectiveness. It provides specific details, such as the percentage of invalid questions and the attribution to unresolved coreference. However, the comment lacks detailed reasoning or evidence to support the claim that the method does not cover a sufficiently large number of questions. While it provides some context, it does not offer a comprehensive justification or references to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional explanation or evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern with the proposed question-rewrite strategy, specifically questioning its coverage and effectiveness. It provides detailed reasoning by highlighting the percentage of invalid questions and the attribution to unresolved coreference. The comment also points out that the proposed method rewrites only a small number of questions, which may not have a significant impact. This feedback is clear and actionable, as it directs the authors to consider the limitations of their strategy and potentially explore alternative approaches to improve coverage and effectiveness. However, the comment could be more helpful if it suggested specific ways to address these issues or provided examples of how to enhance the strategy. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It asks for clarification on the benefit of using L2 distance. While the comment implies that the authors should justify or explain the choice of L2 distance, it does not provide explicit instructions or concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a rationale for their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in equation (4) and asks for clarification on the benefit of using it in the context of optimal transport (OT), where earth mover\\'s distance is more common. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). The reviewer provides a logical reasoning by pointing out the prevalence of earth mover\\'s distance in OT and asks for clarification on the benefit of using L2 distance. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It prompts the authors to justify or explain the benefit of using L2 distance in their context. This feedback is clear and actionable, as it encourages the authors to provide a rationale for their methodological choice, which could enhance the clarity and robustness of their paper. However, the comment could be more helpful if it offered suggestions on how to address the question or provided additional context on why L2 distance might be preferable in certain situations. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and provides a clear direction for enhancing their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a question about the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It asks for clarification on the benefit of using L2 distance. While the comment implies that the authors should provide an explanation or justification for their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of the benefit of L2 distance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). The comment asks for clarification on the benefit of using L2 distance, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). The reviewer provides a logical reasoning by pointing out the prevalence of earth mover\\'s distance in OT and asks for clarification on the benefit of using L2 distance. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in optimal transport (OT). It prompts the authors to justify or explain the benefit of using L2 distance in their context. This feedback is clear and actionable, as it directs the authors to consider and address the potential advantages or limitations of their methodological choice. By"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment implies that the authors should provide a more comprehensive comparison, it does not explicitly instruct them to do so or specify which other offline RL algorithms should be included in the discussion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their comparison to other algorithms. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. However, it does not specify which sections or parts of the paper are being addressed, making it weakly grounded. The comment is specific in its request for a broader discussion on algorithm comparison, but without explicit references to sections, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the description of the related work is scattered throughout the paper and requests a broader discussion on how the algorithm compares to other offline RL algorithms. While the comment identifies a potential issue with the organization of the related work section, it lacks specific examples or references to support the claim that the discussion is scattered or incomplete. The suggestion for a broader comparison is logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the organization of the related work section, noting that it is scattered throughout the paper. It suggests that while some relevant papers are included, a broader discussion on how the algorithm compares to other offline RL algorithms would be beneficial. This feedback is clear and actionable, as it directs the authors to improve the organization and comprehensiveness of their related work section. However, the comment could be more helpful if it provided specific examples of other offline RL algorithms that should be included in the comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution changes if all increments are available at the same time. While it implies that the authors should consider this scenario, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this scenario and potentially discuss its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all increments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of having all increments available at the same time on the final solution. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of having all increments available at the same time on the final solution. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the impact of having all increments available at the same time on the final solution. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how to address this question or what implications it might have for the paper. The comment lacks depth and actionable feedback, leaving the authors with a vague inquiry rather than concrete steps to improve their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the convoluted nature of using multiple different feature spaces, specifically mentioning the use of the 25 feature space of Mitchell et al. and the full/pruned glove model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the approach or address the potential circularity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific technique used in the paper, which involves the use of multiple feature spaces, including the 25 feature space of Mitchell et al. and the full/pruned glove model. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment also specifies the issue by describing the technique as \"convoluted\" and potentially \"circular,\" providing clear guidance on what aspect of the methodology is problematic. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technique of using multiple different feature spaces is convoluted and potentially circular. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the methodology, specifically the use of multiple different feature spaces, such as the 25 feature space of Mitchell et al. and the full/pruned glove model. It describes the technique as \"convoluted\" and potentially \"circular,\" suggesting that the approach may not be straightforward or may introduce unnecessary complexity. However, the comment does not provide specific suggestions or guidance on how the authors might simplify or improve their methodology. While it highlights a potential weakness, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and to include their FLOPs and parameter sizes in Table 7. It also questions why the results of OFA with progressive shrink are not used in the table. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be added or changed in the table. The explicit nature of the suggestions and the detailed guidance on how to implement them make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and specifies the inclusion of FLOPs and parameter sizes. The comment also questions why the results of OFA with progressive shrink are not used in the table, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that comparisons with other works using the MobileNetV3 search space should be included in Table 7, and questions why the results of OFA with progressive shrink are not used in the table. While the comment identifies a potential gap in the presentation of results, it does not provide specific examples or references to support the claim that these comparisons are necessary. The reasoning is somewhat vague, as it lacks detailed justification or evidence to fully substantiate the need for these comparisons. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper, namely the inclusion of comparisons with other works using the MobileNetV3 search space in Table 7. It provides a clear and actionable suggestion by recommending the inclusion of FLOPs and parameter sizes from these works, which could enhance the comprehensiveness and relevance of the results presented. Additionally, the comment questions why the results of OFA with progressive shrink are not used in the table, prompting the authors to consider this aspect as well. While the feedback is detailed and provides a clear direction for improvement, it could be more helpful if it included specific examples or references to similar works. Overall, the comment offers valuable guidance for enhancing the paper, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is necessary and undesirable, in addition to referencing existing work. While the comment implies that the authors should provide this discussion, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to structure or present this discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a discussion on why fixing hallucinations is necessary and undesirable, in addition to referencing existing work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to address the issue of hallucinations, but without clear grounding, the authors may struggle to identify the exact section where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on why fixing hallucinations is necessary and undesirable, in addition to referencing existing work. However, the comment does not provide any specific reasoning or examples to support why this discussion is important or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on why fixing hallucinations is necessary and undesirable, in addition to referencing existing work. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the importance of explaining the significance of fixing hallucinations. However, the comment lacks specific guidance on how to structure this discussion or what aspects should be emphasized. To be more helpful, the comment could provide examples or references to existing work that address this issue, offering a clearer path for the authors to follow. Therefore, the comment is rated as somewhat helpful, as it provides some direction but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the clarity of the text regarding the terms \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate,\" which are mentioned before the null hypothesis is clearly stated. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify the order of these terms and the null hypothesis, but it lacks specific instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 50-54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the order of terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" before the null hypothesis is clearly stated. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or explanation, the authors may find it challenging to understand the exact issue and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the clarity of the text regarding the terms \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate,\" which are mentioned before the null hypothesis is clearly stated. This feedback is somewhat helpful as it points out a specific area where the authors need to improve the clarity of their explanation. However, the comment lacks depth and does not provide suggestions on how to restructure the text to improve clarity or what specific changes should be made. To be more helpful, the comment could include specific examples or guidance on how to reorganize the text to ensure better understanding. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and the regularization process. It explicitly asks the authors to address how they solve this issue. This direct question provides a clear action for the authors to take, which is to provide a solution or explanation for the uncertainty. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It asks how the authors address this issue, which implies a need for clarification or improvement in the methodology section. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of inherent uncertainty and the need for a solution, but without explicit grounding, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It asks how the authors address this issue, which implies a need for clarification or improvement. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the inherent uncertainty. This lack of detailed evidence or justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It poses a question about how the authors address this issue, which is a relevant and important consideration for the reliability of the model. However, the comment does not provide specific suggestions or guidance on how to mitigate this uncertainty or improve the model's reliability. While it identifies a critical area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It explicitly asks the authors to address this issue, providing a clear and direct action for them to take. The question prompts the authors to provide a solution or explanation for the uncertainty, which is a concrete and actionable step. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It asks how the authors address this issue, which implies a need for clarification or improvement in the methodology section. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of inherent uncertainty and the need for a solution, but without explicit grounding, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It asks how the authors address this issue, which implies a need for clarification or improvement. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the inherent uncertainty. This lack of detailed evidence or justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic nature of the process and regularization. It poses a question about how the authors address this issue, which is a relevant and important consideration for the reliability of the model. However, the comment does not provide specific suggestions or guidance on how to mitigate this uncertainty or improve the model's reliability. While it identifies a critical area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the inherent uncertainty"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of SFAM scorers, which correlate well with human judgments on semantics-relevant styles but not on linguistics-relevant styles. It suggests that this discrepancy might lead to the LISA being more content-focused rather than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the LISA's performance on linguistics-relevant styles. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the performance of SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on styles that are more linguistics-relevant (e.g., simplification, linguistic acceptability) compared to those that are more semantics-relevant (e.g., sentiment, emotion). This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses these scorers or the LISA embedding, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles, such as simplification and linguistic acceptability. This discrepancy is suggested to make the LISA more content-focused rather than style-focused. The comment provides a logical reasoning based on the observed correlation patterns, which supports the claim. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on styles that are more linguistics-relevant (e.g., simplification, linguistic acceptability) compared to those that are more semantics-relevant (e.g., sentiment, emotion). This observation is important as it questions the focus of the LISA framework. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve the performance of the scorers on linguistics-relevant styles. While it points out a potential weakness, it lacks depth and specificity in terms of actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy in the performance of SFAM scorers, which correlate well with human judgments on semantics-relevant styles but not on linguistics-relevant styles. It suggests that this discrepancy might lead to the LISA being more content-focused rather than style-focused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the performance of the scorers on linguistics-relevant styles. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the performance of SFAM scorers, which are fundamental components of the LISA embedding. It highlights a discrepancy in their correlation with human judgments on styles that are more linguistics-relevant (e.g., simplification, linguistic acceptability) compared to those that are more semantics-relevant (e.g., sentiment, emotion). This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses these scorers or the LISA embedding, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on more linguistics-relevant styles (e.g., simplification, linguistic acceptability) compared to semantics-relevant styles (e.g., sentiment, emotion). This discrepancy is suggested to make the LISA more content-focused rather than style-focused. The comment provides a logical reasoning based on the observed correlation patterns, which supports the claim. However, it lacks specific examples or references to substantiate the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their experiments on additional real-world datasets, specifically mentioning DexYCB with more recent hand-object pose estimation pipelines. This feedback provides a clear and explicit action for the authors to take, as it specifies the datasets and methodologies to consider. The comment also offers concrete guidance on how to implement the suggested evaluation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB with more recent hand-object pose estimation pipelines. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or results. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting a particular dataset and methodology for evaluation, but without explicit grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB with more recent hand-object pose estimation pipelines. However, the comment does not provide any reasoning or evidence to support why these datasets or methodologies are necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB with more recent hand-object pose estimation pipelines. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness and applicability of their experimental results. By recommending a particular dataset and methodology, the comment offers a concrete way for the authors to improve their draft. However, it could be more helpful if it included further details on why these datasets are relevant or how they might impact the results. Overall, the comment is mostly helpful, as it provides valuable guidance for enhancing the experimental validation of the work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explicit explanation regarding the design of sequential models and how the attention model is updated, which is crucial for understanding the rationale of the proposed work. While the comment identifies specific areas that need clarification, it does not provide explicit instructions or concrete suggestions on how the authors should address these gaps. The action is implicit, as the authors need to infer that they should provide more detailed explanations, but it is vague because it lacks specific guidance on what to include or how to present this information. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation regarding the design of sequential models and how the attention model is updated, which is critical for understanding the rationale of the proposed work. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these components are discussed, the comment lacks full grounding. It is specific in identifying the need for more detailed explanations but does not provide concrete guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation regarding the design of sequential models and how the attention model is updated, which is critical for understanding the rationale of the proposed work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or evidence renders the claim unverifiable, as it does not provide sufficient support for the authors to improve their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of explicit explanation regarding the design of sequential models and how the attention model is updated. This feedback highlights an important area that needs clarification to enhance the understanding of the rationale behind the proposed work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional sections or examples to include. While it points out a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors make the entire code accessible if the paper is accepted. This is an explicit action that provides clear guidance on what the authors should do to improve their draft. The suggestion is concrete, as it specifies the action of making the code accessible. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests making the entire code accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the code is discussed. This lack of explicit reference makes it weakly grounded. The comment is specific in its suggestion to make the code accessible, but without grounding, it is challenging for the authors to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should make the entire code accessible if the paper is accepted. However, it does not provide any reasoning, evidence, or examples to support why this would be beneficial or necessary. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should make the entire code accessible if the paper is accepted. This feedback is clear and actionable, as it provides a specific step for the authors to take to enhance the transparency and reproducibility of their work. By making the code accessible, the authors can facilitate the review process and potentially increase the impact of their research. However, the comment could be more helpful if it explained why making the code accessible is beneficial or provided examples of how it could be done. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a concrete action by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is clear and provides specific guidance on how to improve the clarity of the explanations, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"hybrid architecture\" and the specific processes of \"spike-driven token selection\" and \"intra- and inter-stage feature fusion,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarity of the explanations and the inclusion of pseudo-code or flow diagrams to enhance understanding. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The suggestion to include pseudo-code or flow diagrams is a logical recommendation but lacks specific justification or examples to demonstrate the need for these additions. As a result, the claim is unverifiable due to the absence of supporting evidence or reasoning.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the clarity of the explanations for specific processes such as spike-driven token selection and intra- and inter-stage feature fusion. It provides a clear and actionable suggestion by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader\\'s understanding of the model\\'s operation. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided examples of how these additions might be structured or if it discussed the potential benefits of such enhancements. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement that could significantly enhance the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is an incremental improvement over existing AutoAugment, but the performance improvements are not significant when compared to recent methods. It specifically mentions that the resnet-50 model is only 0.3 better than a reference method and notes the large standard deviation, which raises doubts about the method\\'s generalizability. While the comment highlights areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve their method. The feedback is somewhat vague, leaving the authors to infer potential actions, such as conducting further experiments or refining the method to enhance its performance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s performance improvements compared to existing methods, specifically mentioning the comparison with AutoAugment and recent methods on ImageNet. It highlights the small performance improvements and the large standard deviation, which raises doubts about the method\\'s generalizability. However, the comment does not specify which part of the paper discusses these comparisons or improvements, making it weakly grounded. The comment is specific in detailing the issues with performance and generalizability, but without clear grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over existing AutoAugment, but the performance improvements are not significant when compared to recent methods. It provides a specific example by mentioning that resnet-50 is only 0.3 better than a reference method and notes the large standard deviation, which raises doubts about the method\\'s generalizability. While the comment provides some evidence through the comparison with a specific method, it lacks detailed references or further elaboration to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires additional information for full verification. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key issue with the proposed method, noting that it is an incremental improvement over existing AutoAugment and that the performance improvements are not significant when compared to recent methods. It provides a specific example by mentioning the performance of resnet-50 on ImageNet, highlighting that it is only 0.3 better than a reference method. Additionally, the comment points out the large standard deviation, which raises doubts about the method\\'s generalizability. While the comment effectively identifies areas for improvement, it lacks detailed suggestions or guidance on how the authors might address these issues or enhance their method. The feedback is somewhat helpful as it provides insight into potential weaknesses but could be more actionable with specific recommendations for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the comparison section, noting that it lacks references to existing prior arts and that a simple search reveals significant performance gaps between the proposed method and the latest methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include references to prior arts and conduct a more thorough comparison, but the comment does not specify which prior arts to include or how to structure the comparison. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the comparison section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of references to existing prior arts and the need for a more thorough comparison with the latest methods. The comment provides specific guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is weak without references to existing prior arts and that a simple search reveals significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific examples or references to the prior arts or the latest methods being compared. This lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of references to existing prior arts in the comparison section. It suggests that a simple search could reveal significant performance gaps between the proposed method and the latest methods. This feedback is clear and actionable, as it directs the authors to include references to prior arts and conduct a more thorough comparison. However, the comment could be more helpful if it provided specific examples of prior arts or methods to include in the comparison. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for enhancing the paper\\'s rigor and relevance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a quantification of the diversity of the data gathered, even though they argue for its importance. It implies that a simple statistic, such as a types vs. token count, would be sufficient. While the action is explicit, it is somewhat vague because it does not specify exactly how the quantification should be presented or what specific metrics should be used. The authors know they need to provide a quantification, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of quantification for the diversity of the data gathered, which is an important aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that a simple statistic, such as a types vs. token count, would be useful for quantifying diversity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but provide no quantification, which is easily remedied. The reviewer suggests that even a simple statistic, like a types vs. token count, would be beneficial. This claim is somewhat verifiable as it provides a logical reasoning for the need for quantification, but it lacks specific examples or references to support the assertion that such a statistic would be useful. The comment suggests a potential improvement but does not fully substantiate the claim with detailed evidence or examples, leaving some gaps in the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting that the authors argue for the diversity of the data gathered but fail to provide any quantification. It suggests that even a simple statistic, such as a types vs. token count, would be beneficial for supporting the argument. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance their analysis and provide more robust evidence for their claims. However, the comment could be more helpful if it offered additional guidance on how to present this quantification or suggested other metrics that could be used. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should provide a quantification of the diversity of the data gathered, even though they argue for its importance. It implies that a simple statistic, such as a types vs. token count, would be useful. While the action is explicit, it is somewhat vague because it does not specify exactly how the quantification should be presented or what specific metrics should be used. The authors know they need to provide a quantification, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of quantification for the diversity of the data gathered, which is an important aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that even a simple statistic, such as a types vs. token count, would be useful for quantifying diversity. This provides clear guidance on what could be improved. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors argue for the diversity of the data gathered but provide no quantification, which is easily remedied. The reviewer suggests that even a simple statistic, such as a types vs. token count, would be beneficial for supporting the argument. This claim is somewhat verifiable as it provides a logical reasoning for the need for quantification, but it lacks specific examples or references to support the assertion that such a statistic would be useful. The comment suggests a potential improvement but does not fully substantiate the claim with detailed evidence or examples, leaving some gaps in the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, noting that the authors argue for the diversity of the data gathered but fail to provide any quantification. It suggests that even a simple statistic, such as a types vs. token count, would be beneficial for supporting the argument. This feedback is clear and actionable, as it directs the authors to a specific area where they can enhance their"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to have created a more diverse set of positive instance pairs, but it lacks sufficient evidence or comparison with earlier works. The comment explicitly identifies the need for a measure of diversity and a comparison with existing works. However, it does not provide specific guidance on how to implement these suggestions or what measures to use. While the action is clear\u2014adding a measure of diversity and comparing with earlier works\u2014it lacks concrete details on how to execute these steps. Therefore, the comment is somewhat actionable, as it identifies the need for specific actions but does not provide detailed guidance on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim made in the paper about creating a more diverse set of positive instance pairs. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of a measure of diversity and the absence of a comparison with earlier works regarding diversity. This provides clear guidance on what needs to be addressed, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of creating a more diverse set of positive instance pairs is not sufficiently backed. The reviewer supports this claim by pointing out the lack of a measure of diversity and the absence of a comparison with earlier works regarding diversity. However, the comment does not provide specific examples or references to earlier works, which would strengthen the claim. This makes the claim somewhat verifiable, as it highlights a gap in the paper\\'s evidence but lacks detailed support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of evidence or comparison to support the claim of creating a more diverse set of positive instance pairs. It highlights the need for a measure of diversity and a comparison with earlier works regarding diversity. This feedback is clear and actionable, as it provides the authors with a concrete direction for improvement by suggesting specific elements to include in their analysis. However, the comment could be more helpful if it offered examples of measures of diversity or guidance on how to compare with earlier works. Overall, the comment is mostly helpful as it effectively directs the authors toward enhancing the robustness of their claims, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors\\' approach compares to or aligns with other inputs, such as structured information, and mentions that AUCROC appears high in other models in the literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects they should consider when comparing their approach to others. As a result, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of the authors\\' approach with other inputs, such as structured information, and mentions that AUCROC appears high in other models in the literature. However, it does not specify which part of the paper this question pertains to, such as a specific section or result, making it weakly grounded. The comment is specific in its inquiry about the comparison with structured information and the high AUCROC, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the comparison of the authors\\' approach with other inputs, such as structured information. It also mentions that AUCROC appears high in other models in the literature. However, the comment does not contain any claims or opinions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of the authors\\' approach with other inputs, such as structured information, and mentions that AUCROC appears high in other models in the literature. While it identifies a potential area for improvement or comparison, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to address this issue. Without detailed feedback or examples, the authors may find it challenging to determine how to incorporate this feedback into their draft. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should state the objective function in experiments, specifically mentioning the use of Monte Carlo estimates for expectations. It also questions the use of a reverse inequality sign in Eq. 7 and the gap definition below. Additionally, the reviewer notes that some parts of Section 3, particularly Section 3.2, are technical and may not help the audience understand the main method in Section 4. The reviewer suggests leaving more space in Section 4 to explain the training procedure. While the comment provides specific suggestions for improving the clarity of the objective function and the training procedure, it does not explicitly instruct the authors to make these changes. The actions are implicit but concrete, as the authors can infer what needs to be done and have a clear idea of how to implement it. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 7,\" \"the gap definition below,\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as questioning the use of a reverse inequality sign and suggesting that some parts of Section 3 are too technical and could be clarified in Section 4. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several observations and suggestions for improvement. It questions the use of a reverse inequality sign in Eq. 7 and the gap definition, suggesting that the expected loss is represented by \"v.\" However, the comment does not provide a clear explanation or justification for why this is an issue or how it affects the understanding of the paper. Additionally, it suggests that some parts of Section 3 are too technical and recommends leaving more space in Section 4 to explain the training procedure. While the suggestions are logical, they lack detailed reasoning or evidence to fully support the claims. Therefore, the comment is somewhat verifiable, as it provides some guidance but requires more detailed justification or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improving the clarity and comprehensiveness of the paper. It specifically recommends stating the objective function in experiments, which is a clear and direct suggestion for improvement. Additionally, it questions the use of a reverse inequality sign in Eq. 7 and the gap definition, prompting the authors to review and possibly correct these elements. The comment also notes that some parts of Section 3 are too technical and suggests leaving more space in Section 4 to explain the training procedure, which could enhance the audience's understanding. While the feedback is mostly helpful, it could be more comprehensive by providing specific examples or detailed explanations of how to improve the technical sections. Overall, the comment offers valuable insights and suggestions that can guide the authors in enhancing their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). While it implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3, top right plot,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by asking for an explanation of why the Disc. reward for SPACE and f-PCPO is going down in the Grid. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the downward trend in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). While it identifies an area that requires further explanation, it does not provide any suggestions or guidance on how the authors might address this issue or improve their explanation. The comment highlights a potential weakness in the paper but lacks actionable feedback, making it somewhat helpful. The authors are given a direction to explore but not fully supported in how to proceed. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of key implementation details, specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. While the comment identifies a specific area that needs attention, it does not provide explicit instructions on how to address this issue or what specific details should be included. The action is implicit, as the authors can infer that they need to provide this information, but it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of key implementation details, specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this information should be included in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this information could be relevant, the comment lacks full grounding. It is specific in identifying the missing details but does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"key implementation details are missing,\" specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the missing implementation details regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it directs the authors to include this information in their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to present this information effectively. Overall, the comment is mostly helpful as it highlights a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that while the use of DDIM Inversion for data preprocessing is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer recommends exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback provides a clear and explicit action for the authors to take, which is to investigate and improve the motion guidance strategy. The suggestion is concrete, as it specifies the area of focus and the potential improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"section on data preprocessing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the approach involving DDIM Inversion, explaining that while it reduces training time, it does not simplify the overall complexity. The comment further suggests exploring improvements to the motion guidance strategy to enhance training efficiency. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of DDIM Inversion for data preprocessing is effective in reducing training time but does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the approach does not simplify complexity. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the data preprocessing section. It points out that while the use of DDIM Inversion is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, as it provides a concrete direction for the authors to consider in refining their approach. By suggesting a specific area for improvement, the comment offers valuable guidance that can help the authors enhance the effectiveness and efficiency of their methodology. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might lead to difficulties in predicting rarer phrases and that this could exacerbate the heavy tail problem. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly address these issues, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might lead to difficulties in predicting rarer phrases and exacerbate the heavy tail problem. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing relation phrases or chunking, but this inference is not direct. The comment is specific in detailing the potential issue of heavy tail in relation phrases and the implications of chunking. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might lead to difficulties in predicting rarer phrases and exacerbate the heavy tail problem. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to infer the potential issues without concrete evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might lead to difficulties in predicting rarer phrases and exacerbate the heavy tail problem. This feedback is valuable as it prompts the authors to consider the implications of their approach and encourages them to explore potential solutions or improvements. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful as it directs the authors to an important area for consideration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides a clear direction for addressing the issue, it does not specify how to implement these solutions or provide detailed guidance on the best approach. The action is explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the best method to achieve it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for more robust approaches in dynamic regions, such as the Bonn dataset where moving objects can occupy over 50% of the image. The comment suggests potential solutions, such as masking out dynamic regions or re-running relative pose estimation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. The reviewer suggests potential solutions, such as masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment provides a logical reasoning for the need for robustness in dynamic regions, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors would need to further explore the suggestions to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, providing the authors with specific directions on how to improve the robustness of their approach in dynamic scenes. However, the comment could be more helpful if it included additional details or examples on how to implement these solutions effectively. Overall, the comment is mostly helpful as it offers valuable insights and suggestions for enhancing the robustness of the approach, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only compare the models proposed by the authors and lack comparisons with other methods. While it identifies a gap in the experimental design, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include comparisons with other methods, but it does not specify which methods to consider or how to integrate these comparisons into the paper. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting that they only compare the models proposed by the authors and lack comparisons with other methods. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for additional comparisons, but without clear grounding, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only compare the models proposed by the authors and lack comparisons with other methods. This is a factual observation rather than a subjective claim or suggestion. It does not require verification or evidence, as it is a straightforward statement of fact. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments only compare the models proposed by the authors and lack comparisons with other methods. This feedback is clear and actionable, as it highlights a gap in the paper that the authors can address by including comparisons with other methods. However, the comment could be more helpful if it provided suggestions on which specific methods to compare or how to integrate these comparisons into the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor inconsistency in Table 3 and 4, where the models labeled as \"math specialists\" have an asterisk, but the MAVIS models themselves do not. The reviewer suggests that the MAVIS models should also be considered \"math specialists\" and should have an asterisk. This feedback is explicit and provides a clear action for the authors to take, which is to ensure consistency in labeling the MAVIS models as \"math specialists\" with an asterisk. The comment is concrete, as it specifies exactly what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular inconsistency in the labeling of models as \"math specialists\" and suggests that the MAVIS models should also be labeled as such. This provides clear guidance on what needs to be addressed in the tables. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the labeling of models in Tables 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor inconsistency in the labeling of models in Tables 3 and 4. It points out that while models labeled as \"math specialists\" have an asterisk, the MAVIS models themselves do not. The reviewer suggests that the MAVIS models should also be considered \"math specialists\" and should have an asterisk. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the consistency and clarity of their presentation. However, the comment could be more helpful if it explained why this labeling is important or how it affects the interpretation of the results. Despite this, the feedback is mostly helpful as it guides the authors toward a straightforward improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It implies that the work provides few insights into a non-parametric method for text classification. However, the comment does not offer explicit guidance or suggestions on how the authors could enhance the technical novelty or provide more insights. The action is implicit and vague, leaving the authors uncertain about how to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what specific insights or contributions the work lacks. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to the widespread study of KNN-based methods in LM and MT. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide enough information for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It implies that the work provides few insights into a non-parametric method for text classification. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors could enhance the technical novelty or address the limitations. Without detailed guidance or examples, the authors are left with a general critique that does not effectively support their efforts to improve the draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overstates the enhancement of the Information Maximization (IM) for most existing RL algorithms and lacks a comparison with the latest work, particularly non-pixel-based approaches. While the comment identifies a potential issue with the paper\\'s claims, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to update their claims and include a comparison with more recent work, but the comment does not offer specific suggestions or examples of what to include. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the paper emphasizes the extensive enhancement of the Information Maximization (IM) for most existing RL algorithms. It points out that the most recent description of the mainstream RL algorithms in related work is SAC in 2018, suggesting that the claim is overstated and lacks a comparison with the latest work, especially non-pixel-based approaches. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a comparison with recent work and the lack of a comparison with non-pixel-based approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the enhancement of the Information Maximization (IM) for most existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. The comment provides a logical reasoning by pointing out the outdated reference to SAC in 2018 and suggesting that the paper should include a comparison with more recent work. However, the comment lacks specific examples or references to recent work, making it somewhat verifiable. The authors would need to make an effort to identify and incorporate the latest work into their discussion, but the lack of detailed references or examples makes the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that the Information Maximization (IM) has been extensively enhanced for most existing RL algorithms. It points out that the most recent description of the mainstream RL algorithms in related work is SAC in 2018, suggesting that the claim is overstated and lacks a comparison with the latest work, especially non-pixel-based approaches. This feedback is somewhat helpful as it highlights a gap in the paper\\'s discussion and suggests that the authors should include a more comprehensive comparison with recent work. However, the comment could be more helpful if it provided specific examples or references to recent work that should be included. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper overstates the enhancement of the Information Maximization (IM) for most existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to update their claims and include a comparison with more recent work, but the comment lacks specific suggestions or examples. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the paper emphasizes the extensive enhancement of the Information Maximization (IM) for most existing RL algorithms. It points out that the most recent description of the mainstream RL algorithms in related work is SAC in 2018, suggesting that the claim is overstated and lacks a comparison with the latest work, especially non-pixel-based approaches. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a comparison with recent work and the lack of a comparison with non-pixel-based approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the enhancement of the Information Maximization (IM) for most existing RL algorithms and lacks a comparison with the latest work, especially non-pixel-based approaches. The comment provides a logical reasoning by pointing out the outdated reference to SAC in 2018 and suggesting that the paper should include a comparison with more recent work. However, the comment lacks specific examples or references to recent work, making it somewhat verifiable. The authors would need to make an effort to identify and incorporate the latest work into their discussion, but the lack"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests expanding the background discussion in Section 2 by incorporating further background knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position of the work within the state-of-the-art (SoA). The comment provides a clear and concrete action for the authors to take, specifying the areas to expand and the type of references to include. This level of detail makes the action explicit and actionable, allowing the authors to know exactly what changes to make to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and \"related work,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be expanded, including the background discussion on adversarial examples and threat models, and suggests referencing relevant surveys to clarify the threat model and position within the state-of-the-art. This level of detail provides clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion in Section 2 with further background knowledge on adversarial examples and threat models. It recommends referencing relevant surveys to clarify the threat model and position within the state-of-the-art. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to surveys that could be used. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and implement the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the background discussion in Section 2 by incorporating further background knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position within the state-of-the-art (SoA). This feedback is valuable as it guides the authors on how to enhance the clarity and depth of their work, making it highly helpful. By following this advice, the authors can significantly improve the comprehensibility and impact of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the importance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or clarify the importance of their approach. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of the proposed multiple-span answer setting in real-world applications. However, it does not specify which part of the paper discusses this setting, making it weakly grounded. The comment is specific in questioning the relevance of the proposed setting, but without clear grounding, the authors may struggle to identify the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the importance of the proposed multiple-span answer setting in real-world applications. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance and importance of the proposed multiple-span answer setting in real-world applications. While it identifies a potential area of confusion or lack of clarity, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide any explanation or reasoning for why this might be beneficial or how it could improve the paper. The action is implied but lacks concrete guidance on how to implement it, making it vague and difficult for the authors to know exactly what steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Testsets\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to mix in the train set examples with hypernyms and non-hypernyms, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide any reasoning or evidence to support why this might be beneficial or necessary. The comment lacks specific justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests an alternative approach to the current methodology by proposing to mix train set examples with hypernyms and non-hypernyms. This suggestion could potentially enhance the diversity and complexity of the training data, which might improve the model\\'s performance or generalizability. However, the comment does not provide any further explanation or justification for why this approach might be beneficial, nor does it offer specific guidance on how to implement this change. While the suggestion is somewhat helpful, it lacks depth and actionable advice, making it only somewhat helpful for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide any explanation or reasoning for why this might be beneficial or how it could improve the paper. The action is implied but lacks concrete guidance on how to implement it, making it vague and difficult for the authors to know exactly what steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Testsets\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to mix in the train set examples with hypernyms and non-hypernyms, providing clear guidance on what needs to be addressed. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide any reasoning or evidence to support why this might be beneficial or necessary. The comment lacks specific justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests an alternative approach to the current methodology by proposing to mix train set examples with hypernyms and non-hypernyms. This suggestion could potentially enhance the diversity and complexity of the training data, which might improve the model\\'s performance or generalizability. However, the comment does not provide any further explanation or justification for why this approach might be beneficial, nor does it offer specific guidance on how to implement this change. While the suggestion is somewhat helpful, it lacks depth and actionable advice, making it only somewhat helpful for the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests mixing train set examples with hypernyms and non-hypernyms, but it does not provide any explanation or reasoning for why this might be beneficial or how it could improve the paper. The action is implied but lacks concrete guidance on how to implement it, making it vague and difficult for the authors to know exactly what steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Testsets\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to mix in the train set examples with hypernyms and non-hypernyms, providing clear guidance on what needs to be addressed. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to provide the results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results presented for AdpCLR_pre in Table 1. This is a clear and direct action, specifying exactly what needs to be done to improve the draft. The authors know exactly how to address the feedback, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing the results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results presented for AdpCLR_pre. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for results for the AdpCLR_full approach for the ResNet-50 architecture. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, requesting the authors to provide additional results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results presented for AdpCLR_pre in Table 1. This feedback is specific and directly addresses a gap in the paper, guiding the authors on how to enhance the completeness and comprehensiveness of their results section. By following this suggestion, the authors can improve the transparency and robustness of their experimental findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not provide any explicit or implicit action for the authors to take. It lacks guidance on whether this question should lead to further exploration, clarification, or potential changes in the paper. Without any actionable advice or suggestions, the authors are left without a clear direction on how to address this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the similarity between these concepts, but without explicit references to sections or parts of the paper, the authors may struggle to identify the exact context of the question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it identifies a potential area of confusion or overlap, it does not provide any further context, analysis, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance for the authors to address the issue. As a result, it is not helpful at all, as it does not assist the authors in improving their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiment results are suspicious, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. This suggests that the authors should investigate and address this issue. However, the comment does not provide explicit guidance on how to verify or correct the suspicious results, nor does it offer specific steps or suggestions for improvement. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the results and possibly correct them, but without detailed guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular issue with the experiment results, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2-hop EG into 3-hop EG. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning Tables 16 and 17. However, it does not provide any reasoning or evidence to support why these results are suspicious or how they should be corrected. The lack of detailed explanation or examples makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment results, noting that Tables 16 and 17 share the same result despite changing the 2-hop EG into 3-hop EG. This observation highlights a potential inconsistency or error in the experimental setup or analysis. However, the comment lacks depth and does not provide guidance on how the authors might investigate or resolve this issue. While it points out a problem, it does not offer actionable steps or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results show some advantages of the proposed algorithms but that these advantages are not very significant. It also mentions that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to improve the significance of the results or enhance the competitiveness of the algorithms. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results, indicating that they show some advantages of the proposed algorithms but are not very significant. It also mentions that the algorithms are still competitive with state-of-the-art algorithms. However, the comment does not specify which part of the paper these results are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of significance in the results and the competitiveness of the algorithms, but it does not provide detailed guidance on how to improve these aspects. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but are not very significant. However, the comment does not provide any supporting evidence, examples, or detailed reasoning to substantiate this claim. Without specific data or analysis, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the experimental results show some advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the algorithms are still competitive with state-of-the-art algorithms. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the significance of their results or improve the competitiveness of their algorithms. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to LLM (Language Learning Models) overconfidence. However, it does not provide explicit guidance on how the authors should address this concern or improve the protocol. The comment lacks specific suggestions or actions for the authors to take, leaving them without clear direction on how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the per-sentence assessment protocol, which is a specific aspect of the paper. This provides full grounding as the authors can identify the part of the paper being discussed. The comment also specifies the issue by mentioning the potential for LLM (Language Learning Models) overconfidence, which could lead to the protocol favoring incorrect predictions. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to LLM (Language Learning Models) overconfidence, which could lead to the protocol favoring incorrect predictions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the per-sentence assessment protocol, specifically noting that it may be prone to LLM (Language Learning Models) overconfidence. This feedback highlights a critical area for improvement, as it suggests that the protocol might favor incorrect predictions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the protocol. While it points out a potential weakness, it does not provide actionable steps or examples for the authors to consider. Therefore, the comment is somewhat helpful, as it offers insight into a potential problem but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the non-semantic diversity modeling, specifically asking why it reflects only non-semantic diversity and not semantic diversity. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could take to clarify or improve their explanation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$, specifically asking why this approach ensures smooth non-semantic diversity modeling but not semantic diversity. This provides clear guidance on what aspect of the explanation needs clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the non-semantic diversity modeling, specifically asking why minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity but not semantic diversity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this question or explain why the authors might need to clarify this aspect. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the non-semantic diversity modeling, asking why minimizing $L_{smo}$ with the aid of sampled $\\\\tilde{z}_{proj}$ ensures smooth non-semantic diversity but not semantic diversity. This question prompts the authors to clarify their explanation and potentially revisit their methodology or results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. While the comment implies that the authors should consider this question, it does not provide explicit guidance or suggestions on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this possibility further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental results section, but this inference is not direct. The comment is specific in its inquiry about the potential causes of the results, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experimental results. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. This question prompts the authors to consider the robustness and generalizability of their findings, which is an important aspect of evaluating the validity of their experimental results. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or further investigate the issue. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of description regarding the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any explicit or implicit action for the authors to take. The comment simply points out a potential omission without suggesting how the authors should address it, such as by adding a description or clarifying the section where this estimation is discussed. As a result, the authors are left without guidance on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions the estimation of $\\\\mu_t^a$ and questions its absence in the algorithm, which allows the authors to identify the specific part of the paper being addressed. However, it does not specify where this estimation should be described or what aspects of the estimation are missing. This makes the comment weakly grounded, as the authors can infer the relevant section but not with full confidence. The comment is specific in pointing out the lack of description, but it lacks detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the absence of a description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of description regarding the estimation of $\\\\mu_t^a$ in the algorithm. This is a clear and actionable point that highlights a gap in the paper\\'s explanation, which could be addressed by providing additional details or clarifying the section where this estimation is discussed. However, the comment does not offer suggestions on how to improve the description or what specific information should be included. While it points out a critical omission, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a discussion of the computational costs associated with training the proposed method, which involves complex components like modified Gromov-Hausdorff distances and hypergraph structures. While the comment implies that this discussion is necessary, it does not explicitly instruct the authors to add this discussion or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should address the computational costs but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures. It also notes that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment does not specify which part of the paper discusses these components or where the discussion of computational costs should be included. While the authors can infer that it relates to the methodology section, the lack of explicit references makes it weakly grounded. The comment is specific in detailing what needs to be addressed regarding computational costs, making it specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is complex due to the use of modified Gromov-Hausdorff distances and hypergraph structures, which likely increases the time complexity. The reviewer supports this claim by referencing the theoretical analysis of time complexity and the discussion of inference efficiency in Appendix B. However, the comment could be strengthened by providing more detailed reasoning or examples of how these components contribute to increased complexity. While the claim is mostly verifiable, it lacks comprehensive evidence or specific examples, making it somewhat verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the complexity of the proposed method, specifically mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is clear and actionable, as it directs the authors to include a discussion of computational costs, which could enhance the paper\\'s comprehensiveness and practicality. However, the comment could be more helpful if it provided specific suggestions on how to conduct this discussion or examples of similar analyses. Overall, the comment is mostly helpful as it identifies a relevant area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the originality of the proposed method in the context of LLMs and notes that it builds upon existing strategies. It also points out that the paper does not effectively distinguish its method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or improve the clarity of their contributions. The action is implicit and vague, as the authors are left to infer that they need to clarify the uniqueness of their approach, but without specific suggestions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the originality and distinctiveness of the proposed method within the context of LLMs, specifically mentioning the comparison with existing contrastive decoding techniques. However, it does not specify which part of the paper discusses the method or its comparison, making it weakly grounded. The comment is specific in identifying the issue of not distinguishing the proposed method from existing strategies, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs, despite effectively building upon existing strategies. The reviewer supports this claim by noting that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment lacks specific examples or references to existing contrastive decoding techniques, which would provide more detailed justification for the claim. This makes the claim somewhat verifiable, as it provides a logical basis but requires additional evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality and distinctiveness of the proposed method within the context of LLMs. It notes that the method may not represent a groundbreaking innovation, despite effectively building upon existing strategies. The comment highlights a lack of clarity in distinguishing the proposed method from existing contrastive decoding techniques, which could leave readers without a clear understanding of the unique contributions and advantages of the new approach. While the comment points out a significant area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the clarity of their contributions. This limits the comment\\'s helpfulness, making it somewhat helpful as it provides insight into a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the originality and distinctiveness of the proposed method within the context of LLMs. It notes that the method may not represent a groundbreaking innovation, despite effectively building upon existing strategies, and that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the originality and distinctiveness of the proposed method within the context of LLMs, noting that it may not represent a groundbreaking innovation despite effectively building upon existing strategies. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the need for clearer differentiation and understanding of the proposed method, but without explicit references or detailed guidance, it lacks full specificity. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs, despite effectively building upon existing strategies. The reviewer supports this claim by noting that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment lacks specific examples or references to existing contrastive decoding techniques, which would provide more detailed justification for the claim. This makes the claim somewhat verifiable, as it provides a logical basis but requires additional evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the originality and distinctiveness of the proposed method within the context of LLMs. It notes that the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit or implicit suggestions on how the authors might improve the figure to make it more intuitive. Without specific guidance or examples of what changes could be made, the authors are left without a clear understanding of how to address the issue. As a result, the comment lacks actionable guidance, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the tabular representation of node agent interactions is not intuitive. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is not intuitive. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. While it points out a potential problem, it lacks depth and does not provide suggestions or guidance on how the authors might improve the figure to make it more intuitive. Without actionable feedback or examples, the authors are left with a general observation that does not significantly aid in improving their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions that imply potential actions for the authors to consider. First, it suggests that other frameworks besides PU might be appropriate as baselines, particularly in the context of prioritizing learning on examples with less irreducible uncertainty. Second, it questions how the use of the PU loss impacts calibration and the importance of uncertainty estimation for downstream use cases of AI text detectors. While the questions imply actions, they are not explicitly stated, and the authors would need to infer the need for further exploration or analysis. The comment provides some guidance but lacks concrete details on how to implement these suggestions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two separate points. The first point questions whether other frameworks besides PU might be more appropriate as baselines, suggesting the consideration of noise-aware losses. The second point discusses the impact of the PU loss on calibration and the importance of uncertainty estimation for downstream use cases. However, the comment does not specify which part of the paper these points relate to, making it weakly grounded. It is specific in suggesting alternative frameworks and discussing the importance of uncertainty estimation, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions regarding the use of the PU loss and its impact on calibration, as well as the importance of uncertainty estimation for downstream use cases. The comment suggests that other frameworks besides PU might be more appropriate as baselines, particularly in the context of prioritizing learning on examples with less irreducible uncertainty. However, it does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of alternative frameworks and the importance of uncertainty estimation, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions that could significantly impact the paper\\'s analysis and conclusions. First, it questions whether other frameworks besides PU might be more appropriate as baselines, particularly in the context of prioritizing learning on examples with less irreducible uncertainty. This suggestion encourages the authors to consider alternative approaches that could enhance the robustness of their findings. Second, the comment explores the impact of the PU loss on calibration and the importance of uncertainty estimation for downstream use cases of AI text detectors. These questions provide valuable insights and prompts for the authors to reconsider their methodology and its implications. However, the comment could be more helpful if it offered specific suggestions or examples of alternative frameworks or methods to consider. Overall, the feedback is mostly helpful as it directs the authors toward important areas for exploration and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their characterization. The feedback lacks actionable details, leaving the authors uncertain about what changes, if any, are needed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. However, it does not specify which part of the introduction this characterization is found, making it weakly grounded. The comment is specific in its critique of the characterization, providing a clear explanation of the distinction between TL and fine-tuning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. The reviewer provides a logical explanation and a clear distinction between TL and fine-tuning, which supports the claim. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the argument. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. While the comment identifies a potential mischaracterization, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their characterization. The feedback lacks actionable advice or examples, making it somewhat helpful as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their characterization. The feedback lacks actionable details, leaving the authors uncertain about what changes, if any, are needed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. However, it does not specify which part of the introduction this characterization is found, making it weakly grounded. The comment is specific in its critique of the characterization, providing a clear explanation of the distinction between TL and fine-tuning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. The reviewer provides a logical explanation and a clear distinction between TL and fine-tuning, which supports the claim. However, the comment could be strengthened by referencing specific literature or examples to further substantiate the argument. While the reasoning is sound, the lack of detailed references or examples makes the claim mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefiting another task, and that fine-tuning is a sequential approach. While the comment identifies a potential mischaracterization, it does not provide"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is considered important. However, it does not provide any guidance on how to address this issue or what specific limitations should be included. The action is clear but lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a missing element in the paper, specifically the absence of a \"Limitation\" section. However, it does not specify which part of the paper should include this section or what specific limitations should be addressed. This lack of detail makes it difficult for the authors to pinpoint where to make improvements. The comment is not grounded because it does not reference a specific section or part of the paper, and it is not specific in detailing what needs to be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation\" section, which is considered important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a missing element in the paper, specifically the absence of a \"Limitation\" section. While it points out an important omission, it does not provide any guidance or suggestions on what specific limitations should be addressed or how to incorporate this section into the paper. This lack of detail and actionable feedback limits the usefulness of the comment for the authors, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific areas where the paper could be improved, including detailed explanations in Section 2.1 on the theory behind diffusion models, a clearer explanation of CLIP guidance in Section 2.2, and a more detailed discussion of works by Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it notes that captions of figures are often not explanatory. While the comment does not explicitly instruct the authors to make these changes, the actions are clear and concrete, as the authors can directly address each point by providing more detailed explanations or clearer captions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"Section 2.1,\" \"Section 2.2,\" and \"Section 3.2,\" allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed in each section, such as the need for more detailed explanations in Section 2.1 and the lack of explanation for works by Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it points out issues with figure captions, providing specific examples (Figures 3, 4, 7, 8). This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies several areas where the paper could be improved, such as needing more detailed explanations in Section 2.1 on the theory behind diffusion models, a clearer explanation of CLIP guidance in Section 2.2, and a more detailed discussion of works by Choi et al. (2021) and Meng et al. (2021) in Section 3.2. Additionally, it notes that captions of figures are often not explanatory. While the comment provides specific areas for improvement, it does not offer detailed reasoning or examples to support these claims, making it somewhat verifiable. The authors would need to infer the specific issues and how to address them, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed list of specific areas where the paper could be improved, offering clear and actionable feedback. It identifies the need for more detailed explanations in Section 2.1 on the theory behind diffusion models, in Section 2.2 regarding CLIP guidance, and in Section 3.2 regarding the works of Choi et al. (2021) and Meng et al. (2021). Additionally, it points out issues with figure captions, suggesting that they are often not explanatory. This feedback is highly helpful as it provides the authors with concrete steps to enhance the clarity and depth of their paper, making it easier for them to improve the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This feedback is explicit and provides a clear action for the authors to take, which is to modify the title to include the term \"tensor completion.\" The suggestion is concrete, as it specifies exactly what needs to be done to improve the title. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, it does not specify which part of the paper discusses the tensor completion application, making it weakly grounded. The comment is specific in its suggestion to include the term \"tensor completion\" in the title, but without grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, the comment does not provide any supporting evidence or reasoning to justify why this term is crucial for the title. Without additional context or explanation, the authors may find it challenging to understand the significance of including \"tensor completion\" in the title. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This feedback is clear and actionable, as it provides a specific suggestion for improving the title to better reflect the content of the paper. By including \"tensor completion\" in the title, the authors can more accurately convey the focus of their work. However, the comment could be more helpful if it explained why this term is important or how it affects the reader\\'s understanding of the paper. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed method to other prior methods and implement a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. The reviewer explicitly states that this would make the paper more persuasive. While the action is clear, it lacks specific guidance on how to implement these comparisons or what specific aspects to focus on. The authors know they need to include additional comparisons, but the comment does not provide detailed instructions on how to execute this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of comparison to prior methods, specifically suggesting that the authors should implement a simple baseline like character frequencies to provide a more comprehensive empirical evaluation. This feedback is specific in its suggestion to include a comparison, which helps the authors understand what needs to be addressed. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as the results or discussion sections. The authors can infer that it relates to the evaluation or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their proposed method to prior methods and suggests implementing a simple baseline like character frequencies to provide a more comprehensive empirical evaluation. The reviewer supports this claim by reasoning that the current evaluation, which focuses solely on statistically significant linear regressions, is insufficient. The suggestion to include a simple baseline is logical and provides a clear rationale for why such a comparison would enhance the paper. However, the comment could be strengthened by providing specific examples of prior methods or references to similar studies that have used such comparisons. Despite this, the overall claim is well-supported, making it mostly verifiable. Therefore, the feedback is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the authors have not attempted to compare their proposed method to any prior methods. It suggests that the authors should implement a simple baseline, such as character frequencies, to provide a more comprehensive empirical evaluation. This feedback is clear and actionable, offering a specific and constructive suggestion for improvement. By including a comparison to a simple baseline, the authors can enhance the persuasiveness of their work. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in reducing computational load in real applications. It explains that different tokens activate different channels, making it difficult to apply a uniform activation pattern across all tokens. The reviewer suggests that the method relies on precomputed PPL and activation patterns that may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this limitation or improve the method to achieve better computational efficiency. The action is implicit and somewhat vague, as the authors are left to infer potential solutions or modifications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the practicality of reducing computational load in the proposed method. It highlights a potential challenge in applying a uniform activation pattern across all tokens due to the activation of different channels for different tokens. The comment also mentions the reliance on precomputed PPL and activation patterns, which may not generalize well, potentially requiring all tokens to activate all channels. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the potential limitations and challenges, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the practicality of reducing computational load in the proposed method. It explains that different tokens activate different channels, making it difficult to apply a uniform activation pattern across all tokens. The reviewer supports this claim by noting that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens. The comment provides a logical reasoning for the potential issue, but it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed method regarding its practicality in reducing computational load. It highlights a challenge in applying a uniform activation pattern across all tokens due to the activation of different channels for different tokens. The reviewer points out that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. This feedback is somewhat helpful as it provides insight into a potential weakness in the method\\'s applicability and suggests an area for improvement. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provide alternative approaches to enhance the method\\'s practicality. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential limitation in the proposed method regarding its practicality in reducing computational load. It highlights a challenge in applying a uniform activation pattern across all tokens due to the activation of different channels for different tokens. The reviewer notes that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. While the comment points out a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the method to achieve better computational efficiency. The action is implicit and somewhat vague, as the authors are left to infer potential solutions or modifications. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the practicality of reducing computational load in the proposed method. It highlights a potential challenge in applying a uniform activation pattern across all tokens due to the activation of different channels for different tokens. The reviewer notes that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique activation pattern. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the potential limitations and challenges, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the practicality of reducing computational load in the proposed method. It highlights a potential challenge in applying a uniform activation pattern across all tokens due to the activation of different channels for different tokens. The reviewer supports this claim by noting that the method relies on precomputed PPL and activation patterns"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the core motivation of the paper, specifically noting that the abstract does not effectively convey the main problem to be solved. The reviewer points out that the statements in the abstract are stacked and do not capture the main problem. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to make the motivation clearer. The action is implicit and vague, as the authors are left to infer that they need to restructure the abstract to better present the core motivation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the clarity of the core motivation in the paper, specifically mentioning the abstract. It highlights the issue with stacked statements that do not effectively capture the main problem to be solved. However, the comment does not specify which part of the abstract or the paper should be revised to improve clarity. While the authors can infer that it relates to the abstract, the lack of explicit grounding makes it difficult for them to pinpoint the exact sections needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, citing the abstract as an example. The reviewer provides a logical reasoning by pointing out the stacked statements in the abstract, which make it difficult to understand the main problem being addressed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues from the abstract, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the paper\\'s core motivation. It points out that the abstract does not effectively convey the main problem being addressed, despite mentioning challenges in demarcating task boundaries and proposing new benchmarks, metrics, and gating techniques. The comment highlights the need for a clearer presentation of the core motivation, which is crucial for understanding the paper\\'s contribution. However, the feedback lacks specific suggestions or guidance on how to improve the clarity of the core motivation, such as recommending ways to restructure the abstract or provide more detailed explanations. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of clarity in the core motivation of the paper, specifically noting that the abstract does not effectively convey the main problem to be solved. The reviewer points out the stacked statements in the abstract, which make it difficult to understand the core motivation. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve clarity. The action is implicit and lacks concrete details, making it barely actionable. Authors are left to infer that they need to restructure the abstract to better present the core motivation, but without specific instructions, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the clarity of the core motivation in the paper, specifically mentioning the abstract as an example. It highlights the issue with stacked statements that do not effectively capture the main problem to be solved. However, the comment does not specify which part of the abstract or the paper should be revised to improve clarity. While the authors can infer that it relates to the abstract, the lack of explicit grounding makes it difficult for them to pinpoint the exact sections needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, citing the abstract as an example. The reviewer points out stacked statements that do not effectively capture the main problem to be solved. However, the comment lacks specific examples or detailed reasoning to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues from the abstract, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the paper\\'s core motivation, noting that the abstract does not effectively convey the main problem being addressed. It highlights the stacked statements in the abstract, which make it difficult to understand the core motivation. This feedback is valuable as it points out a critical area for improvement, but it lacks specific suggestions or guidance on how to enhance clarity. While it directs"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data and questions the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to provide examples to clarify the process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the sequence inference classifier used to filter data, which is a specific aspect of the paper. It raises concerns about the nature of the data that passes this filter and suggests that the task of filtering data using the task description is different from the original MNLI distribution. The comment also requests examples of the filtered data to better understand the process. This provides full grounding as it explicitly mentions the sequence inference classifier and the task of filtering data. It is also specific because it details what needs to be addressed regarding the nature of the filtered data and the task description. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for examples provides a direction for improvement but does not offer enough justification or evidence to fully verify the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern about the sequence inference classifier used to filter data, noting that it is unclear what kind of data passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. This feedback is clear and actionable, as it directs the authors to provide examples of the filtered data, which would help clarify the methodology and improve the transparency of the study. However, the comment could be more helpful if it offered suggestions on how to present these examples or discussed the implications of the observed differences. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises concerns about the sequence inference classifier used to filter data, noting that it is unclear what kind of data passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment implies that the authors should provide examples of the filtered data, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to provide examples to clarify the process. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the sequence inference classifier used to filter data, which is a specific aspect of the paper. It raises concerns about the nature of the data that passes this filter and questions whether the task of filtering data using the task description is different from the original MNLI distribution. The reviewer suggests that examples of the filtered data would be helpful to better understand the process. This provides full grounding as it explicitly mentions the sequence inference classifier and the task of filtering data. It is also specific because it details what needs to be addressed regarding the nature of the filtered data and the task description. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for examples provides a direction for improvement but does not offer enough justification or evidence to fully verify the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but requires more detailed support to be fully substantiated.', 'verifiability_label': '3"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the application experiments, including potential biases due to the reliance on a single model and a small dataset. It suggests that the authors need to conduct comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, it points out specific issues with the paper, such as chaotic equation numbering and the lack of indentation in Algorithm 1. While the comment provides explicit actions for the authors to take, such as conducting comprehensive experiments and addressing formatting issues, it lacks detailed guidance on how to implement these changes. The authors know what needs to be done but may need additional support to execute the suggestions effectively. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"application experiments\" and the specific issues with the reliance on a single model and a small dataset. It also provides specific examples, such as the chaotic equation numbering and the lack of indentation in Algorithm 1, which allows the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be addressed, such as conducting comprehensive experiments and improving the formatting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the reliance on a single model and a small dataset. The reviewer supports this claim by noting that the experiment results are difficult to be convincing without comprehensive experiments. The comment also highlights specific issues with the paper, such as chaotic equation numbering and the lack of indentation in Algorithm 1. While the comment provides some reasoning and examples, it could be strengthened by referencing specific studies or methodologies that demonstrate the importance of comprehensive experiments. Overall, the claim is mostly verifiable, as it provides a logical basis for the critique but lacks detailed references or examples to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the application experiments, noting that the reliance on a single model and a small dataset may introduce biases. It highlights the difficulty in convincing readers of the effectiveness of the proposed methods without comprehensive experiments. The comment provides specific suggestions for improvement, such as conducting more extensive experiments and addressing issues with equation numbering and Algorithm 1 formatting. While the feedback is somewhat helpful, it could be more comprehensive by offering additional guidance on how to conduct more comprehensive experiments or by suggesting specific areas for improvement in the paper\\'s structure, argumentation, and language clarity. Overall, the comment provides valuable insights but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider practical applications of catastrophic forgetting and provide commentary on real tasks with available data. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate practical applications into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical applications of catastrophic forgetting, suggesting that the experiments in the paper are conducted on datasets that are not real-world tasks. It implies that the authors should comment on the relevance of their model to real tasks with available data. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to address the practical applications of the model, but without explicit grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments in the paper are conducted on datasets that are not real-world tasks, implying that the authors should comment on the relevance of their model to practical applications. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to comment on real tasks with available data is a logical one, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent concern about the practical relevance of the experiments conducted in the paper, specifically regarding catastrophic forgetting. It suggests that the authors should comment on the applicability of their model to real-world tasks with available data. This feedback is valuable as it prompts the authors to consider the broader implications of their work and encourages them to address the practical significance of their findings. However, the comment could be more helpful if it provided specific examples or guidance on how to identify and discuss relevant real-world tasks. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that may have been overlooked, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of selecting m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. While the reviewer expresses confusion about the process, they do not provide explicit guidance or suggestions for improvement. The comment lacks concrete actions or detailed instructions on how the authors might address this issue or clarify the process. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. This question implies that the authors should clarify this aspect of their methodology. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the selection process, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the selection of m\\' in the CAL-MIR method. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking whether it is done exhaustively over all loss minimizer subsets. This question highlights a potential area of confusion or complexity in the methodology, prompting the authors to clarify or simplify the process. However, the comment does not provide specific suggestions or guidance on how to address this issue, nor does it offer alternative approaches or improvements. While it identifies a point of confusion, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for clarification but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider other backdoor detection methods that are input data-free, such as those based on weight matrix statistics or matrix factorization, in their analysis of algorithm performance. While the comment implies that these methods should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as it does not provide specific guidance on how to integrate these methods into the analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods, such as those based on weight matrix statistics or matrix factorization, which should be taken into account in the analysis of algorithm performance. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input data-free, such as those based on weight matrix statistics or matrix factorization. This claim is somewhat verifiable as it provides a logical reasoning for including these methods, which could enhance the analysis of algorithm performance. However, the comment lacks specific references or examples of these methods, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the \"Robustness\" section of the paper, suggesting that the authors should consider other backdoor detection methods that are input data-free. It provides a clear and actionable suggestion by recommending the inclusion of methods like weight matrix statistics or matrix factorization, which could enhance the analysis of algorithm performance. This feedback is valuable as it guides the authors on how to expand their analysis and potentially improve the robustness of their findings. However, the comment could be more helpful if it provided additional context or examples of these methods. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies two areas that need improvement: the completeness of the relation works section and the need to describe the view of the knowledge graph in the problem definition methodology. The first part of the comment is clear and direct, instructing the authors to address the incompleteness of the relation works section. The second part is also explicit, as it specifies what needs to be described regarding the view of the knowledge graph. Both parts provide clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section\" and the \"problem definition methodology,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the completeness of the relation works section and the need to describe the view of the knowledge graph in the problem definition methodology. This provides clear guidance on what the authors need to focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works section\" is incomplete and that the authors need to describe which view of the knowledge graph is part of the assumption. However, the comment does not provide specific examples or references to support why this information is missing or how it impacts the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of incompleteness in the paper, namely the \"relation works section,\" and provides a clear and actionable suggestion for improvement. It specifies that the authors need to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is clear and provides a direct path for the authors to enhance the clarity and completeness of their work. However, it could be more helpful if it offered additional guidance or examples on how to effectively present this information. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement and provides a clear direction for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the focus of the paper, suggesting that the contribution is more about regression than black box optimization. It implies that the authors should clarify this point in their proposal and provide the accuracy of their method on the regression task compared to strong baselines. While the comment explicitly states that the authors should address this issue, it does not provide specific guidance on how to present this information or which baselines to consider. The action is explicit but somewhat vague, as it lacks detailed instructions on how to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the metric used, specifically mentioning the optimality gap and the contribution of regression. It suggests that the authors should clarify whether their contribution is more about regression or black box optimization and provides a specific suggestion to compare the accuracy of their method on the regression task with strong baselines. This feedback is fully grounded as it explicitly mentions the problem setup and the metric used, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific, as it provides a clear suggestion for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the focus of the paper, suggesting that the contribution is more about regression than black box optimization, and that the optimality gap is not part of the proposal. The reviewer provides a logical reasoning by pointing out that the optimization is a downstream task and should be consistent regardless of the regression mechanism. However, the comment lacks specific examples or references to support the claim that the contribution is more about regression than black box optimization. This makes the claim somewhat verifiable, as it provides a reasonable argument but requires further elaboration or evidence to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the focus of the paper, suggesting that the contribution is more about regression than black box optimization, and that the optimality gap is not part of the proposal. It provides a specific suggestion for improvement by recommending that the authors clarify their contribution and provide the accuracy of their method on the regression task compared to strong baselines. This feedback is clear and actionable, offering a concrete direction for the authors to enhance the clarity and focus of their paper. However, it could be more helpful if it included specific examples of strong baselines or detailed guidance on how to present the results. Overall, the comment is mostly helpful as it identifies a potential issue and provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update derivation for the intrinsic reward parameters (Eq.7-10). While it identifies an area that requires improvement, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The comment implies that the authors should provide more detailed justification or derivation, but it lacks concrete steps or suggestions for implementation. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"technical design\" and references specific equations (Eq.7-10), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of theoretical support for the design and the need for more justification regarding the update derivation for the intrinsic reward parameters. However, while it identifies the need for more justification, it does not provide specific suggestions on how to improve this aspect. Therefore, the comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support and that the update derivation for the intrinsic reward parameters is hardly convincing. However, it does not provide specific examples or detailed reasoning to substantiate these claims. The mention of Sorg et al. 2010 provides some context, but it does not fully address the lack of theoretical support or the convincing nature of the update derivation. The claim is somewhat verifiable as it highlights a potential issue but lacks comprehensive evidence or detailed explanation, making it challenging for the authors to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the technical design, specifically the lack of theoretical support for the update derivation of the intrinsic reward parameters. It points out that while the design is acknowledged, the justification for the update derivation is not convincing. This feedback is valuable as it highlights a critical area that requires further development or clarification. However, the comment could be more helpful if it provided specific suggestions or examples on how to strengthen the theoretical support or justify the update derivation. Overall, the comment is somewhat helpful as it directs the authors to a critical area for improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their claim. It lacks actionable details, such as recommending alternative approaches or providing examples of adaptive methods that do not rely on a single parameter. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique of the adaptivity claim and provides a clear rationale for why it does not align with adaptive methods like AdaGrad. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. The reviewer provides a logical reasoning by comparing it to adaptive methods like AdaGrad. However, the comment lacks specific examples or references to support the claim that the adaptive variance reduction property is not adaptive, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. The reviewer provides a logical reasoning by comparing it to adaptive methods like AdaGrad. This feedback is somewhat helpful as it identifies a potential weakness in the authors\\' claim and offers a perspective for improvement. However, it lacks specific suggestions or guidance on how the authors might address this issue or clarify their claim. While it prompts the authors to reconsider their claim, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their claim. It lacks actionable details, such as recommending alternative approaches or providing examples of adaptive methods that do not rely on a single parameter. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique of the adaptivity claim and provides a clear rationale for why it does not align with adaptive methods like AdaGrad. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. The reviewer provides a logical reasoning by comparing it to adaptive methods like AdaGrad. However, the comment lacks specific examples or references to support the claim that the adaptive variance reduction property is not adaptive. This makes it somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on choosing a \"small enough\" beta parameter, which does not align with the adaptivity claim. The reviewer provides a logical reasoning by comparing it to adaptive methods like AdaGrad. This feedback is somewhat helpful as it identifies a"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the unclear value of different augmentation techniques and notes that DINOv2 is often the best-performing model. It suggests further investigation into why DINOv2 is consistently effective and how to improve it. While the comment implies that the authors should explore these aspects, it does not provide explicit instructions or concrete steps on how to conduct this investigation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the unclear value of different augmentation techniques and mentions DINOv2 as the best-performing model most of the time. However, it does not specify which part of the paper discusses these techniques or where the issue of unclear value is most prominent. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in suggesting further investigation into why DINOv2 is effective and how to improve it, the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the value of different augmentation techniques is unclear and that DINOv2 is often the best-performing model. However, it does not provide specific examples or detailed reasoning to support these claims. The suggestion to further investigate why DINOv2 is effective and how to improve it is vague and lacks concrete evidence or references. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the unclear value of different augmentation techniques. It notes that while different techniques may have varying effects on different models, DINOv2 consistently performs well. The comment suggests further investigation into why DINOv2 is effective and how to improve it. This feedback is somewhat helpful as it points out an area for improvement and provides a direction for further exploration. However, it lacks specific suggestions or guidance on how to conduct this investigation, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. The reviewer implies that a change in the acronym might be necessary to avoid confusion. However, the comment does not explicitly instruct the authors to make the change or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should change the acronym but are not given specific instructions on how to implement this change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a potential issue with the acronym used for \"follow the top perturbed leader,\" noting that it might be unfortunate due to its similarity to the common usage of FTL as \"Follow the Leader\" in the literature. However, it does not specify which part of the paper this acronym is used in, making it weakly grounded. The comment is specific in identifying the issue with the acronym, but without clear grounding, the authors may struggle to pinpoint where the change is needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. This claim is somewhat verifiable as it provides a logical reasoning for the issue, but it lacks specific references or examples from the literature to fully substantiate the claim. The authors would need to verify the common usage of FTL in the literature themselves to fully understand and address the concern. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym used for \"follow the top perturbed leader,\" noting that it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. This feedback is clear and actionable, as it suggests that the authors might consider changing the acronym to avoid confusion. However, the comment does not provide specific guidance on how to choose a new acronym or why the current one is problematic, which could enhance its helpfulness. Overall, the comment is mostly helpful as it directs the authors to an important consideration for their work, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. The reviewer implies that a change in the acronym might be necessary to avoid confusion. However, the comment does not explicitly instruct the authors to make the change or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should change the acronym but are not given specific instructions on how to implement this change. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a potential issue with the acronym used for \"follow the top perturbed leader,\" noting that it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. However, it does not specify which part of the paper this acronym is used in, making it weakly grounded. The comment is specific in identifying the issue with the acronym, but without clear grounding, the authors may struggle to pinpoint where the change is needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. This claim is somewhat verifiable as it provides a logical reasoning for the issue, but it lacks specific references or examples from the literature to fully substantiate the claim. The authors would need to verify the common usage of FTL in the literature themselves to fully understand and address the concern. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym used for \"follow the top perturbed leader,\" noting that it conflicts with the common usage of FTL as \"Follow the Leader\" in the literature. This feedback is clear and actionable, as it suggests that the authors might consider changing the acronym to avoid confusion. However, the comment does not provide specific guidance on how to choose a new acronym or why the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the selection of attacks in Table 1 is arbitrary and suggests that the authors should consider using state-of-the-art attacks like MIDIFGSM. It also recommends mentioning the number of iterations for these attacks and their hyper-parameters. The comment provides clear and concrete actions for the authors to take, specifying exactly what needs to be addressed and how to implement the changes. This level of detail ensures that the authors know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the selection of attacks, suggesting that the current choices are arbitrary and recommending the use of state-of-the-art attacks like MIDIFGSM. Additionally, it specifies the need to mention the number of iterations and hyper-parameters for these attacks. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that the authors should consider using state-of-the-art attacks like MIDIFGSM. The reviewer provides a specific reference to a survey paper that offers an extensive analysis of attacks, which supports the claim. This reference provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed comparisons or examples of why MIDIFGSM is considered state-of-the-art, which would enhance the verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the selection of attacks in Table 1. It points out that the current selection seems arbitrary and suggests considering state-of-the-art attacks like MIDIFGSM, which is a relevant and up-to-date choice. The comment also recommends mentioning the number of iterations and hyper-parameters for these attacks, which is crucial for reproducibility and clarity. This feedback is clear and constructive, offering the authors a direct path to improve their draft by expanding the analysis and providing more detailed information. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the method\\'s applicability to other pre-training methods. The comment lacks actionable guidance, leaving the authors without a clear path to follow in order to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the limitations and conclusion sections of the paper, allowing the authors to identify the parts of the paper being addressed. However, it does not specify what specific aspects of the method or pre-training methods are being discussed, nor does it provide details on how the method might not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). Without explicit references or detailed feedback, the authors may struggle to understand the exact issues or improvements needed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a limitation of the method, noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it highlights an area where the method's applicability might be restricted. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore the method\\'s performance with different pre-training methods. Without actionable advice, the authors may find it challenging to fully utilize this feedback for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the qualitative analysis section, specifically regarding the determination of input sentences, the fine-tuning process, and the attribution values in Figure 1. It explicitly asks for clarification on how the input sentences were chosen and whether they occurred during fine-tuning. Additionally, it inquires about the normalization of vector norms and the effectiveness of the attribution map for input examples that failed classification. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer the necessary actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions and concerns about the qualitative analysis, including the determination of input sentences, the fine-tuning process, normalization of vector norms, and the effectiveness of the attribution map for input examples that failed classification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the qualitative analysis section. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires clarification: the qualitative analysis. It raises questions about the determination of input sentences for qualitative analysis, the fine-tuning process, and the attribution values in Figure 1. The comment also inquires about the normalization of vector norms and the effectiveness of the attribution map for input examples that failed classification. This feedback is clear and actionable, as it prompts the authors to provide additional details and explanations that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of what kind of information would be beneficial. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft by identifying specific areas for clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a clear and explicit suggestion for the authors to include examples of practical applications where specific types of tensors need to be equivariant. It also instructs the authors to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is concrete, as it specifies exactly what the authors should do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples and clarify the advantages, but without explicit grounding, the authors may struggle to identify the exact section where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any specific examples or references to support the claim that these applications are necessary or how they would validate the advantages. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to include examples of practical applications where specific types of tensors need to be equivariant. It also instructs the authors to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is valuable as it guides the authors on how to enhance the practical relevance and understanding of their work. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to present these applications and their implications. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it notes that the methods like ERM, cRT, and LWS are not referenced properly. It also points out that Section 3.2.3 does not fully align with the table. While the comment highlights areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the methods and ensure alignment between the table and the section, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the tables, noting that the methods like ERM, cRT, and LWS are not referenced properly and that Section 3.2.3 does not fully align with the table. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with the tables, such as the unclear representation of methods like ERM, cRT, and LWS, and the lack of alignment between Section 3.2.3 and the table. However, the comment does not provide detailed reasoning or examples to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of specific examples or detailed justification limits the verifiability of the claim. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it notes that the methods like ERM, cRT, and LWS are not referenced properly. Additionally, it points out that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it directs the authors to clarify the methods and ensure alignment between the table and the section. By addressing these issues, the authors can improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided suggestions on how to improve the alignment or offered examples of how to properly reference the methods. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific comments for the authors to address. The first comment asks for more details on whether the model is suitable for sarcastic/non-sarcastic utterances, suggesting that the authors should provide additional information for further analysis. The second comment questions the utility of eye-movement data for sarcastic/non-sarcastic sentiment classification beyond textual features and requests more explanations. Both comments are explicit and provide concrete actions for the authors to take, making the feedback highly actionable. The authors know exactly what additional information or explanations are needed to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as providing more details on the model\\'s suitability for sarcastic/non-sarcastic utterances and explaining the utility of eye-movement data for sarcastic/non-sarcastic sentiment classification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification and additional information. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two areas for improvement in the paper. It suggests that the authors should provide more details on whether their model is suitable for sarcastic/non-sarcastic utterances and why eye-movement data would be useful for sarcastic/non-sarcastic sentiment classification beyond textual features. These questions are clear and direct, offering the authors concrete steps to enhance their analysis and improve the clarity of their work. However, the comment could be more helpful if it included additional context or suggestions on how to address these points. Overall, the feedback is mostly helpful as it guides the authors toward specific improvements, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are few, noting that the paper only conducts experiments on two small-scale/resolution datasets. It also mentions that the tables are unprofessional, specifically pointing out that \"DDIM is sampler method instead of model.\" While the comment identifies issues with the experimental setup and presentation, it does not provide explicit guidance on how to address these issues. The authors can infer that they need to conduct more experiments or improve the presentation of their results, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table1 and table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental results, noting that there are only two small-scale/resolution datasets used and that the tables are unprofessional, with \"DDIM\" incorrectly labeled as a sampler method instead of a model. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results are few and that the tables are unprofessional, specifically mentioning that \"DDIM is sampler method instead of model.\" However, the comment lacks detailed reasoning or evidence to support these claims. It does not provide specific examples or comparisons to illustrate the issues with the experimental setup or the tables. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the limited number of experimental results and the unprofessional presentation of the tables. It points out that the experiments are conducted only on two small-scale/resolution datasets, which may limit the generalizability of the findings. Additionally, it notes that the tables are unprofessional, specifically mentioning that \"DDIM is sampler method instead of model.\" While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed steps or examples to follow. Therefore, the comment is somewhat helpful, as it provides some insight but not enough actionable advice to fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experimental results are few, noting that the paper only conducts experiments on two small-scale/resolution datasets. It also mentions that the tables are unprofessional, specifically pointing out that \"DDIM is sampler method instead of model.\" While the comment identifies specific issues, it does not provide explicit guidance on how to address these problems. The authors can infer that they need to conduct more experiments or improve the presentation of their results, but the comment lacks concrete steps or suggestions. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table1 and table2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the experimental results, noting that there are only two small-scale/resolution datasets used and that the tables are unprofessional, with \"DDIM\" incorrectly labeled as a sampler method instead of a model. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the experimental results are few and that the tables are unprofessional, specifically mentioning that 'DDIM is sampler method instead of model.' However, the comment lacks detailed reasoning or evidence to support these claims. It does not provide specific examples or comparisons to illustrate the issues with the experimental setup or the tables. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited number of experimental results and the unprofessional presentation of the tables. It notes that the experiments are conducted only on two small-scale/resolution datasets, which may limit the generalizability of the findings. Additionally, it points out that the tables are unprofessional, specifically mentioning that \"DDIM is sampler method instead of model.\" While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more clarification about why the proposed method is important, specifically questioning whether it is merely adjusting the variance level of DPSGD and its impact on utility and privacy. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so or provide concrete guidance on how to present this information. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the importance of their method and its implications for utility and privacy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more clarification is needed about the importance of the proposed method, specifically questioning whether it is merely adjusting the variance level of DPSGD and its impact on utility and privacy. However, it does not specify which part of the paper this clarification should address, making it weakly grounded. The comment is specific in its request for clarification on the importance and implications of the method, but without clear grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the importance of the proposed method, suggesting that it merely adjusts the variance level of DPSGD and may impact utility but not privacy. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a need for more clarification regarding the importance of the proposed method, specifically questioning whether it merely adjusts the variance level of DPSGD and its impact on utility and privacy. While the comment highlights an area that requires further explanation, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s presentation but does not provide detailed advice on how to improve it. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. The comment provides a clear and specific action for the authors to take, which is to conduct a larger-scale experiment and include a longer-horizon example. This guidance is explicit and concrete, giving the authors a clear path to follow for improving their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a larger-scale experiment and a longer-horizon example, but without explicit grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, the comment does not provide specific reasoning or evidence to support why a bigger-scale experiment or longer-horizon example would be beneficial. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the empirical results, suggesting that they are illustrative rather than demonstrative. It provides a specific suggestion for improvement by recommending a bigger-scale experiment, particularly with a longer-horizon example. This feedback is clear and actionable, offering the authors a concrete direction to enhance their work by expanding the scope of their experiments. However, the comment could be more helpful if it provided additional context or examples of how a longer-horizon example could be beneficial. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that Equation (13) does not have a closed-form solution in general and requests additional details about how it is solved in experiments and on computational complexity. This feedback provides a clear and direct action for the authors to take, which is to include more information about the solution process and computational complexity. The comment is specific and provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of a closed-form solution and the need for details on how it is solved in experiments and on computational complexity. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general, which is a factual statement. However, it does not provide any supporting evidence, reasoning, or references to justify why this is the case. The comment suggests that additional details about how the equation is solved in experiments and on computational complexity would be helpful, but without specific examples or references, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13), noting that it does not have a closed-form solution in general. It suggests that providing details on how the equation is solved in experiments and on computational complexity would be beneficial. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of similar approaches. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of discussion on the choice of \"proximity\" and its relationship to the tasks proposed in the paper. It suggests that the authors should analyze which tasks have reasonable proximity metrics and demonstrate failure on those that do not. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or concrete steps on how to perform it. The action is implicit and somewhat vague, as the authors need to infer the specific tasks to analyze and how to demonstrate failure. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the choice of \"proximity\" and its relationship to the tasks proposed in the paper. It highlights a specific issue with the correlation between proximity in fingertip Cartesian positions and the solution space, and provides an example of a complicated maze where this correlation breaks down. The comment also suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that do not. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results sections where proximity is mentioned. The comment is specific in detailing the issue and the potential improvements, making it somewhat actionable. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the choice of \"proximity\" and its relationship to the tasks proposed. It provides a logical reasoning by explaining that proximity on fingertip Cartesian positions is strongly correlated with proximity in the solution space for some tasks, but not for others, such as complicated mazes or robotic tasks with obstacles and collisions. The reviewer suggests that analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that do not would improve the paper. While the reasoning is logical, it lacks specific examples or references to support the claim fully. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the choice of \"proximity\" and its relationship to the tasks proposed. It highlights a critical issue by explaining that proximity on fingertip Cartesian positions is strongly correlated with proximity in the solution space for some tasks, but not for others, such as complicated mazes or robotic tasks with obstacles and collisions. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that do not. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it offered additional guidance on how to conduct this analysis or provided examples of how to demonstrate failure. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. It also directs the authors to \"See Questions for details,\" implying that the questions mentioned in the comment provide specific guidance on what needs to be addressed. While the comment does not provide detailed instructions on which specific implementation details are missing, it clearly indicates that the authors need to provide more information. The action is explicit but somewhat vague, as the authors know they need to add more details but may not be entirely sure of what exactly is required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, which is a specific issue. However, it does not specify which parts of the paper are affected by this issue, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in detailing what is missing, such as implementation details necessary for reproducibility. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to identify the exact details that are missing. The comment also refers to \"Questions for details,\" which suggests that additional information is needed but does not provide that information within the review itself. As a result, the claim is somewhat verifiable, as it highlights a potential issue but lacks detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of implementation details in the experiments. It highlights that readers may find it challenging to fully understand or reproduce the results without these details. The comment is somewhat helpful as it points out a critical area for improvement, but it lacks specific guidance or suggestions on what implementation details are missing or how they should be provided. To be more helpful, the comment could specify which details are crucial or provide examples of what information is needed. Overall, the feedback is somewhat helpful as it directs the authors to a critical area for enhancement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of the comparison between SSUL and the paper, noting that the use of different detectors for object proposal generation may introduce bias. It suggests two potential improvements: using Mask2Former for SSUL or adopting an unsupervised method for generating object proposals without additional data or a heavy model. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for these changes and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the comparison between SSUL and the paper, noting the use of different detectors for object proposal generation. It highlights the potential unfairness in the comparison due to differences in data and model size. The comment suggests two potential improvements: using Mask2Former for SSUL or adopting an unsupervised method for generating object proposals. However, it does not specify which part of the paper discusses these comparisons, making it weakly grounded. The comment is specific in detailing the issue and potential solutions, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between SSUL and the paper, noting the use of different detectors for object proposal generation. It points out that the use of a pretrained Mask2Former introduces an unfair comparison due to differences in data and model size. The reviewer suggests that SSUL should also adopt Mask2Former or an unsupervised method for generating object proposals. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between SSUL and the paper, noting the use of different detectors for object proposal generation. It points out that the use of a pretrained Mask2Former introduces an unfair comparison due to differences in data and model size. The comment suggests two potential improvements: using Mask2Former for SSUL or adopting an unsupervised method for generating object proposals without additional data or a heavy model. This feedback is clear and actionable, providing the authors with specific suggestions for enhancing the fairness and robustness of their comparison. However, it could be more helpful if it included specific examples or references to support the suggested improvements. Overall, the comment is mostly helpful, as it guides the authors toward addressing a critical aspect of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights potential issues with the validation of the proposed approach, specifically regarding the metrics used for evaluation. It points out that the style accuracy is based on a style classifier, which may be accurate but does not necessarily reflect the performance of the algorithm. Additionally, it raises concerns about the verification of the transfer result based on a stylized input. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes. The feedback is somewhat actionable because it points out potential problems but lacks detailed instructions on how to resolve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the validation of the proposed approach through the metrics used, specifically mentioning the style accuracy based on a style classifier and the verification of the transfer result based on a stylized input. However, it does not explicitly mention which part of the paper discusses these metrics or experiments, making it weakly grounded. The comment is specific in detailing the issues with the metrics and the potential lack of verification, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the validation of the proposed approach, specifically regarding the metrics used. It questions the accuracy of the style classifier and the potential difficulty in verifying the transfer result based on a stylized input. While the comment identifies potential issues, it lacks specific examples or references to support these claims. The reasoning is somewhat logical, but the absence of detailed evidence or examples makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the validation of the proposed approach, specifically regarding the metrics used in the experiments. It points out that the style accuracy is based on a style classifier, which may not fully capture the performance of the algorithm. Additionally, it raises concerns about the verification of the transfer result based on a stylized input. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these issues or improve the validation process. The feedback is somewhat helpful as it provides insight into potential weaknesses but does not offer detailed, actionable advice for the authors to enhance their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the validation of the proposed approach, specifically regarding the metrics used in the experiments. It points out that the style accuracy is based on a style classifier, which may not fully capture the performance of the algorithm, and raises concerns about the verification of the transfer result based on a stylized input. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the validation process. The feedback is somewhat actionable because it highlights areas for improvement but lacks detailed instructions on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the validation of the proposed approach, specifically mentioning the metrics used, such as style accuracy based on a style classifier and the verification of the transfer result based on a stylized input. However, it does not explicitly mention which part of the paper discusses these metrics or experiments, making it weakly grounded. The comment is specific in detailing the issues with the validation process, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the validation of the proposed approach, specifically regarding the metrics used, such as style accuracy based on a style classifier and the verification of the transfer result based on a stylized input. While the comment identifies potential issues, it lacks specific examples or detailed reasoning to fully substantiate the claims. The reasoning is somewhat logical, but the absence of concrete evidence or references makes it challenging for the authors to fully understand and address the concerns. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the validation of the proposed approach, specifically regarding the metrics used in the experiments. It points out that the style accuracy is based on a style classifier, which may not fully capture the performance of the algorithm, and raises concerns about the verification of the transfer result based on a stylized input. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance the validation process. The feedback provides some insight"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of how individual preferences are generated and interpreted in the paper. It suggests that the authors clarify whether \"preference\" refers to rules/policies learned from experiences or something else. While the comment identifies an area that needs clarification, it does not provide explicit instructions on how to address this issue or what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the concept of \"preference,\" but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s argument about taking individual preferences into account when simulating agents, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarifying how these preferences are generated on an individual level, such as how certain agents are more risk-averse than others. The comment provides a clear direction for the authors to address the lack of clarity in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how individual preferences are generated and interpreted in the paper. It questions whether the authors have adequately explained how certain agents are more risk-averse than others, suggesting that the interpretation of \"preference\" may be limited to rules or policies learned from experiences. The comment highlights a lack of clarity in the paper, but it does not provide specific examples or references to support the claim. This makes the comment somewhat verifiable, as it identifies an area of potential confusion but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the interpretation of \"preference\" in the paper. It questions how individual preferences are generated and whether the authors have adequately clarified this aspect. By pointing out this ambiguity, the comment provides the authors with a clear direction to improve the clarity of their argument. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to clarify the concept of \"preference.\" Overall, the feedback is somewhat helpful as it highlights a critical area for improvement but lacks detailed guidance on how to implement the suggested clarification. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of clarity regarding how individual preferences are generated and interpreted in the paper. It suggests that the authors clarify whether \"preference\" refers to rules or policies learned from experiences or something else. While the comment points out an area that needs clarification, it does not provide explicit instructions on how the authors should address this issue or what specific details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the concept of \"preference,\" but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s argument about taking individual preferences into account when simulating agents, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of clarifying how these preferences are generated on an individual level, such as how certain agents are more risk-averse than others. The comment provides a clear direction for the authors to address the lack of clarity in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how individual preferences are generated and interpreted in the paper. It questions whether the authors have adequately explained how certain agents are more risk-averse than others, suggesting that the interpretation of \"preference\" may be limited to rules or policies learned from experiences. The comment highlights a potential area of confusion but does not provide specific examples or references to support the claim. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors can infer the need for clarification but may not be entirely sure of the exact issues to address. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the interpretation of \"preference\" in the paper. It questions how individual preferences are generated and whether the authors have adequately clarified this aspect, suggesting that the"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several questions about Figure 4, specifically asking for clarification on the meaning of \"1-200 frames,\" how the values are computed, and why the precision and recall change with trajectory length. It also inquires about the term \"action repeat.\" While the comment identifies specific areas of confusion, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify these points in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions about the meaning of \"1-200 frames,\" how values are computed, and why precision and recall change with trajectory length. Additionally, it inquires about the term \"action repeat.\" This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific aspects of Figure 4, such as the meaning of \"1-200 frames\" and how values are computed. It also inquires about the change in precision and recall with trajectory length and the term \"action repeat.\" These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas of confusion in Figure 4, questioning the meaning of \"1-200 frames,\" how values are computed, and why precision and recall change with trajectory length. It also inquires about the term \"action repeat.\" This feedback is clear and actionable, as it prompts the authors to clarify these aspects in their draft, which could significantly improve the clarity and understanding of their work. However, the comment could be more helpful if it provided suggestions on how to present this information more effectively or offered examples of how to address these issues. Overall, the comment is mostly helpful, as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some design decisions, such as the number of initial ground truth examples and the number of labeled examples, seem arbitrary. It suggests that the authors should provide justification for these decisions, especially in light of the cost-effectiveness motivation. The reviewer also mentions an alternative scenario, comparing LLaMAA and finetuning with equivalent costs, which could be explored. While the comment implies that the authors should provide justification for their design choices, it does not explicitly instruct them to do so. The suggestion to compare LLaMAA and finetuning is a concrete idea, but the overall action is inferred and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific design decisions, such as the number of initial ground truth examples and the number of labeled examples, which are mentioned as arbitrary. It suggests that the authors should provide justification for these decisions, especially in the context of cost-effectiveness. The comment also mentions an alternative scenario, comparing LLaMAA and finetuning with equivalent costs. However, it does not specify which part of the paper these design decisions are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the design decisions and the alternative scenario, providing clear guidance for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the arbitrariness of certain design decisions, such as the number of initial ground truth examples and labeled examples. It suggests that these decisions should be justified, especially in light of the cost-effectiveness motivation. The reviewer proposes an alternative scenario, comparing LLaMAA and finetuning with equivalent costs, to provide a more satisfying explanation. While the comment raises a valid concern about the arbitrariness of design choices, it lacks specific examples or references to support the claim. The suggestion for an alternative scenario provides some direction, but the overall justification is somewhat vague. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a logical basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, especially in the context of cost-effectiveness. The reviewer proposes an alternative scenario, comparing LLaMAA and finetuning with equivalent costs, which could provide a more satisfying explanation. By suggesting that the authors provide justification for their design choices, the comment offers a clear and actionable direction for improvement. However, it could be more helpful if it included specific suggestions on how to justify these decisions or what aspects of the design should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a logical framework for addressing the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. The reviewer expresses confusion about the complexity of the approach. However, the comment does not provide explicit guidance or suggestions for improvement, nor does it indicate specific actions the authors should take to address the confusion. The feedback lacks actionable details, leaving the authors uncertain about how to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation behind using a graph structured model to capture global dependencies in sentences, contrasting it with existing sequence models. It also questions the complexity of the approach. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the approach and its complexity, providing clear guidance on what the authors might need to clarify or explain further. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. The reviewer also questions the complexity of the approach, as the encoder and decoder are based on Transformer, which can already draw global dependencies. However, the comment lacks specific examples or references to support the claim that the approach is complex or unnecessary. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also questions the complexity of the approach, as the encoder and decoder are based on Transformer, which can already draw global dependencies. While the comment identifies a potential area of confusion, it lacks specific suggestions or guidance on how the authors might clarify or simplify their approach. The feedback highlights an important point but does not provide actionable advice for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also questions the complexity of the approach, as the encoder and decoder are based on Transformer, which can already draw global dependencies. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns or improve their draft. Without specific actions or detailed feedback, the authors are left without a clear understanding of how to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, contrasting it with existing sequence models that typically focus on local dependencies. It also questions the complexity of the approach, noting that the encoder and decoder are based on Transformer, which can already draw global dependencies. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the approach's complexity and its contrast with existing models, providing clear guidance on what the authors might need to clarify or explain further. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also questions the complexity of the approach, as the encoder and decoder are based on Transformer, which can already draw global dependencies. However, the comment lacks specific examples or references to support the claim that the approach is complex or unnecessary. This makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also questions the complexity of the approach, as the encoder and decoder are based on Transformer, which can already draw global dependencies. While the comment identifies a potential area of confusion, it lacks specific suggestions or guidance on how the authors might"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of how different methods work. Additionally, it highlights the lack of implementation details in the main paper, which makes reproducing the results challenging. The comment explicitly states that the authors should provide videos and clarifies the need for more implementation details. However, it does not specify which implementation details are missing or how to address them. While the actions are clear, the lack of detailed guidance on implementation details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which could enhance the understanding of the methods. It also mentions the lack of implementation details in the main paper, which makes reproducing the results difficult. However, the comment does not specify which part of the paper lacks these details or how they should be addressed. While it provides some guidance on what could be improved, it lacks full grounding as it does not explicitly mention specific sections or figures. The comment is specific in its suggestions but not fully grounded, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of the methods. It also notes that some implementation details are lacking, making it difficult to reproduce the results. The claim about the lack of implementation details is somewhat verifiable as it points out a specific area where the paper could be improved. However, the comment lacks detailed examples or references to specific implementation details that are missing, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two actionable suggestions. First, it suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of the methods. This is a clear and specific recommendation that could significantly improve the paper\\'s clarity and impact. Second, it highlights the lack of implementation details in the main paper, which makes reproducing the results difficult. This feedback is also clear and actionable, as it points out a specific area where the authors can improve the reproducibility of their work. However, the comment could be more helpful if it provided examples of the missing implementation details or suggested ways to address them. Overall, the comment is mostly helpful, as it offers valuable guidance for enhancing the paper\\'s clarity and reproducibility.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that it does not account for the effect of the order of layers with the same parameters in the network. It also points out a potential issue with Figure 1, where the layer representation is unclear. The reviewer implies that the authors should conduct more experiments and theoretical analyses to address these concerns. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these additional experiments or analyses. The action is implicit and somewhat vague, as the authors know they need to address the approximation and figure labeling issues but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the approximation in Equation 11, noting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. Additionally, it points out a potential issue with Figure 1, where the layer representation is unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that it does not account for the effect of the order of layers with the same parameters in the network. It also points out a potential issue with Figure 1, where the layer representation is unclear. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the approximation is incomplete. The suggestion to conduct more experiments and theoretical analyses is logical but not fully supported by the current comment. Therefore, the claim is somewhat verifiable, as it provides a basis for improvement but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the approximation in Equation 11, questioning whether it adequately accounts for the effect of the order of layers with the same parameters in the network. It also points out a potential issue with Figure 1, where the layer representation is unclear. The comment suggests that the authors should conduct more experiments and theoretical analyses to address these concerns. While the feedback identifies areas for improvement, it lacks detailed guidance or specific suggestions on how to conduct these additional experiments or analyses. This limits the comment\\'s helpfulness, as it provides some insight but does not fully empower the authors to make significant improvements to their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that it does not account for the effect of the order of layers with the same parameters in the network. It also points out a potential issue with Figure 1, where the layer representation is unclear. The comment implies that the authors should conduct more experiments and theoretical analyses to address these concerns. While the comment identifies specific areas for improvement, it lacks explicit instructions or detailed guidance on how to conduct these additional experiments or analyses. The action is implicit and somewhat vague, as the authors know they need to address the approximation and figure labeling issues but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the approximation in Equation 11, noting that it only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. Additionally, it points out a potential issue with Figure 1, where the layer representation is unclear. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approximation in Equation 11, questioning whether it accounts for the effect of the order of layers with the same parameters in the network. It also points out a potential issue with Figure 1, where the layer representation is unclear. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the approximation is incomplete. The suggestion to conduct more experiments and theoretical analyses is logical but not fully supported by the current"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the offline-to-online learning adaptation is incremental and that existing offline RL benchmarks are based on simulation environments and rule-based reward functions. It implies that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and lacks concrete details, making it vague and difficult for the authors to know exactly what steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the incremental nature of addressing offline-to-online learning adaption and mentions that existing offline RL benchmarks are based on simulation environments and rule-based reward functions. However, it does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how the authors might address this issue or improve their approach. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the offline-to-online learning adaptation is incremental and that existing offline RL benchmarks are based on simulation environments and rule-based reward functions. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the assertion. The lack of detailed reasoning or evidence renders the claim unverifiable, as it does not provide sufficient support for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the offline-to-online learning adaptation is incremental and notes that existing offline RL benchmarks are based on simulation environments and rule-based reward functions. It suggests that implementing online fine-tuning on top of existing benchmarks is feasible. However, the comment lacks specific guidance or actionable advice on how the authors might address this issue or improve their approach. Without detailed suggestions or examples, the authors may find it challenging to determine how to enhance their work based on this feedback. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 6 provides contradicting evidence regarding the utility of emotion-awareness for synthetic text detection. It highlights specific examples, such as AT and GAS, where the results do not support the claim that emotion-awareness is beneficial. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the analysis or presentation of the results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to resolve the contradiction. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of contradicting evidence, such as AT and GAS, and explains why these results suggest that emotion-awareness might not be useful for synthetic text detection. The comment clearly specifies what needs to be addressed, namely the inconsistencies in the results and the potential implications for the claim about emotion-awareness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 provides contradicting evidence regarding the utility of emotion-awareness for synthetic text detection. It provides specific examples, such as AT and GAS, where the results do not support the claim that emotion-awareness is beneficial. This makes the claim somewhat verifiable, as it offers logical reasoning and specific examples to support the assertion. However, the comment could be strengthened by providing more detailed explanations or references to further substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper by pointing out contradicting evidence in Table 6 regarding the utility of emotion-awareness for synthetic text detection. It provides specific examples, such as AT and GAS, where the results do not support the claim that emotion-awareness is beneficial. This feedback is valuable as it highlights a critical inconsistency that the authors need to address. However, the comment could be more helpful if it offered suggestions on how to resolve this contradiction or provided additional context to better understand the implications of these findings. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention but lacks detailed guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It explicitly recommends testing with various models, such as Vision Transformers (ViT), and includes references to specific papers. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions. The comment provides clear and concrete actions for the authors to take, specifying what additional experiments and results should be included. This level of detail and specificity makes the feedback highly actionable, as it gives the authors a clear path forward for improving their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments to address the research question and demonstrates the method\\'s generalizability. It specifically mentions testing with various models, such as Vision Transformers (ViT), and references two papers for guidance. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or the discussion of generalizability. The suggestion is specific, as it provides clear guidance on what additional experiments and results should be included. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It provides specific references to relevant papers, such as \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" and \"Learning Transferable Visual Models From Natural Language Supervision,\" which can help the authors understand the context and potential benefits of these experiments. The suggestion to include results under more complex input noise models, such as multiplicative distortions, is also supported by references to specific types of distortions. This level of detail and reference to external works provides a strong basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning on why these specific experiments are beneficial or by including examples of how they might be conducted. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting additional experiments to address the research question and demonstrate the method\\'s generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and references two relevant papers for guidance. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, which would provide a more comprehensive evaluation. This feedback is detailed and constructive, offering specific directions for enhancing the experimental section of the paper. By addressing these points, the authors can significantly improve the robustness and comprehensiveness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the D.2 appendix mentions two human annotators, while the author responses indicate that the number should be four. This provides a clear and direct action for the authors to take, which is to correct the discrepancy in the number of annotators mentioned in the appendix. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the D.2 appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy in the number of human annotators mentioned in the appendix compared to what is indicated in the author responses. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the D.2 appendix mentions two human annotators, while the author responses indicate that the number should be four. This is a factual statement that does not require verification, as it is a matter of fact based on the information provided. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the number of human annotators mentioned in the D.2 appendix compared to what is indicated in the author responses. By pointing out this inconsistency, the comment provides a clear and actionable feedback that the authors can address to ensure accuracy and consistency in their documentation. This guidance is specific and helps the authors correct a potential error in their draft, making the comment mostly helpful. However, it could be more helpful if it included suggestions on how to resolve the discrepancy or why it is important to correct it. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would have improved the authors\\' understanding of the value of the proposed approach. However, it does not provide specific guidance on how to enhance the motivation or what aspects of the encoder and decoder structure should be clarified. The action is implicit and vague, as the authors are left to infer and determine the specific improvements needed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, it does not specify which part of the paper this motivation should be included in, nor does it provide details on what aspects of the encoder and decoder structure need clarification. Without explicit references to sections or specific elements, the authors cannot confidently determine which part of the paper needs attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would help in understanding the value of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would help the authors better understand the value of the proposed approach. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the motivation or what aspects of the encoder and decoder structure need clarification. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited novelty of the explored loss functions and the absence of black-box evaluation. It also suggests that the paper should consider extending the analysis to targeted attacks. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The authors are left to infer that they need to explore new loss functions, conduct black-box evaluations, and consider targeted attacks, but without detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific concerns regarding the novelty of the explored loss functions, the absence of black-box evaluation, and the limited scope of the attacks considered (only untargeted attacks). It provides clear guidance on what needs to be addressed, such as exploring new loss functions and considering targeted attacks. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions, suggesting that they are not new and are merely \"plug and play\" additions. The reviewer supports this claim by referencing the use of JS divergence, masked CE loss, and masked spherical loss in the context of segmentation attacks. However, the comment lacks specific references or detailed examples to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several key concerns regarding the novelty of the explored loss functions and the limitations of the evaluation approach. It points out that the loss functions used are not new and suggests that the paper lacks a comprehensive evaluation, specifically mentioning the absence of black-box evaluations and the limited scope of attacks considered (only untargeted attacks). The comment provides clear and actionable feedback by recommending the exploration of new loss functions and the inclusion of targeted attacks to enhance the analysis. However, it could be more helpful if it offered specific suggestions on how to implement these changes or provided examples of alternative loss functions. Overall, the comment is mostly helpful as it directs the authors to address critical areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies several concerns, including the limited novelty of the explored loss functions, the absence of black-box evaluations, and the limited scope of attacks considered (only untargeted attacks). While the comment highlights these issues, it does not provide explicit guidance or suggestions on how the authors should address them. The authors are left to infer that they need to explore new loss functions, conduct black-box evaluations, and consider targeted attacks, but without detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides some direction but lacks concrete details.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific concerns, including the novelty of the explored loss functions, the absence of black-box evaluations, and the limited scope of attacks considered (only untargeted attacks). It provides clear guidance on what needs to be addressed, such as exploring new loss functions and considering targeted attacks. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions and the limitations of the evaluation approach. It claims that the loss functions are not new and are merely \"plug and play\" additions. The reviewer supports this claim by referencing the use of JS divergence, masked CE loss, and masked spherical loss in the context of segmentation attacks. However, the comment lacks specific references or detailed examples to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence makes the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several critical areas for improvement in the paper, including the novelty of the explored loss functions, the absence of black-box evaluations, and the limited scope of attacks considered (only untargeted attacks). By pointing out these limitations, the comment provides clear and actionable feedback that can guide the authors in enhancing the novelty and"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. While the comment implies that the authors should conduct a direct comparison and provide results for CIFAR100, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to include these comparisons and results. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"CIFAR10\" and \"CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by noting that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. Additionally, it requests results for CIFAR100. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment lacks specific examples or references to support the claim that the results are not impressive or to justify the need for a direct comparison. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches. It suggests that a direct comparison with other methods is necessary and requests results for CIFAR100. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, it could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while it is known that hyperbolic space is well suited for hierarchical datasets, the experiments do not clearly demonstrate this. However, it does not provide any explicit guidance or suggestions on how the authors could improve their experiments to better showcase this suitability. The comment lacks specific instructions or concrete steps for the authors to take, leaving them uncertain about how to address the issue. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a known property of hyperbolic space being well suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. However, it does not specify which experiments or sections of the paper should be revised to better demonstrate this suitability. Without explicit references to specific parts of the paper, the authors cannot confidently determine which sections need attention. Additionally, the comment lacks specificity in detailing what aspects of the experiments should be improved to better showcase the suitability of hyperbolic space for hierarchical datasets. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"it is known that hyperbolic space is well suited for hierarchical datasets,\" but it does not provide any supporting evidence or references to substantiate this claim. The comment also states that \"none of the experiments clearly demonstrate this,\" but it lacks specific examples or detailed reasoning to support the assertion that the experiments are insufficient. Without additional context or justification, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a known property of hyperbolic space being well suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. While it highlights an area for improvement, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors could enhance their experiments to better showcase this suitability. Without detailed feedback or concrete steps, the authors may struggle to address the issue effectively. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what specific aspects they should focus on to clarify the strengths of MixBoost. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the strengths of MixBoost, but without clear grounding, the authors may struggle to identify the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the main strengths of MixBoost. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or enhance the clarity of their work. As a result, the comment is not helpful at all, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the surprising nature of the statement \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that proper hyperparameter tuning is essential in ML. It also points out a potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The suggestions are somewhat vague, as the authors are left to infer the exact changes needed to improve the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (243 and 245), allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the statement \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that the wording is hard to understand. Additionally, it points out the potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the surprising nature of a statement regarding hyperparameter tuning and suggests that the wording is unclear. It also points out a potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. While the comment identifies specific areas for improvement, it lacks detailed reasoning or evidence to fully substantiate the claims. The suggestion to train on the complete train+val set is a logical improvement, but the comment could be strengthened by providing more context or examples to support the claim about the surprising nature of the statement. Therefore, the comment is somewhat verifiable, as it provides some reasoning but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a surprising statement in the paper regarding the use of the test set for hyperparameter tuning, suggesting that this is an unusual approach compared to previous works. It acknowledges the importance of proper hyperparameter tuning in machine learning but notes that the wording of the statement is unclear. Additionally, the comment points out a potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. This feedback is somewhat helpful as it highlights a specific area for improvement in terms of clarity and methodology. However, it could be more helpful if it provided additional guidance or examples on how to address the issue with the wording or suggested ways to present the information more clearly. Overall, the comment provides some actionable insights but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a surprising statement regarding the use of the test set for hyperparameter tuning and suggests that proper hyperparameter tuning is essential in machine learning. It also points out a potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The suggestions are somewhat vague, leaving the authors to infer the necessary actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions line numbers (243 and 245), allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the statement \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that the wording is unclear. Additionally, it points out the potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the surprising nature of a statement regarding the use of the test set for hyperparameter tuning, suggesting that this is an unusual approach compared to previous works. It acknowledges the importance of proper hyperparameter tuning in machine learning but notes that the wording of the statement is unclear. Additionally, it points out a potential issue with the \"smaller training set\" and offers a suggestion to train the network with optimal parameters on the complete train+val set. While the comment identifies specific areas for"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. The reviewer provides a specific suggestion to hint at how the authors tokenize the parameters and use DDPM to predict actual parameters. This feedback is explicit and provides concrete guidance on how the authors can improve their writing by offering more detailed explanations. The suggestion is clear and actionable, giving the authors a specific direction to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. It lacks detailed elaboration on the actual implementation. The reviewer provides a specific suggestion to hint at how the authors tokenize the parameters and use DDPM to predict actual parameters. However, the comment does not explicitly mention which part of the introduction is obscure or lacks detail, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction is obscure and lacks detail, suggesting that the authors should provide more information on how they tokenize parameters and use DDPM to predict actual parameters. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to support the claim that the introduction is unclear. The suggestion to provide more information is a logical step, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing of the paper, noting that the introduction is obscure and lacks detailed elaboration on the actual implementation. It provides a clear and actionable suggestion by recommending that the authors provide more information on how they tokenize parameters and use DDPM to predict actual parameters. This feedback is valuable as it guides the authors on how to improve the clarity and depth of their writing, making it mostly helpful. However, it could be more helpful if it included specific examples or detailed guidance on how to enhance the introduction. Overall, the comment is mostly helpful, as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is not good but does not provide any specific details or examples of what aspects of the presentation are problematic. It lacks actionable guidance on how the authors might improve their presentation. Without explicit suggestions or concrete examples, the authors are left without a clear understanding of what changes are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the presentation refers to, making it difficult for the authors to identify the exact area needing improvement. Additionally, the comment lacks specificity, as it does not provide any details on what aspects of the presentation are not good or what improvements are needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a subjective statement expressing dissatisfaction with the presentation but lacks any supporting evidence, reasoning, or examples to justify why the presentation is not good. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is vague and lacks specificity, making it unhelpful to the authors. It simply states that the presentation is not good without providing any details or examples of what aspects are problematic or how they might be improved. This lack of actionable feedback does not assist the authors in enhancing their draft, leaving them without guidance on where to focus their efforts for improvement. Therefore, the comment is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific omission in the related work section, mentioning that the authors fail to include the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is explicit and provides a clear action for the authors to take, which is to include this work in their related work section. The comment is concrete, as it directly instructs the authors on what needs to be added to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the related work section, namely the work by Rieck et al. [2], which discusses the correlation of topological complexity with generalization ability. This provides clear guidance on what needs to be added to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors miss the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. However, the comment does not provide any supporting evidence, reasoning, or references to the specific aspects of the work that should be included. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary details to help the authors understand why this omission is significant or how to address it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific omission in the related work section, pointing out that the authors fail to mention the work by Rieck et al. [2] when discussing the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it directs the authors to include this relevant work in their literature review. By addressing this omission, the authors can enhance the comprehensiveness and accuracy of their paper. However, the comment could be more helpful if it provided additional context or explained why this work is particularly relevant. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the usefulness of the exploration parameter gamma, suggesting that since only upper-bounds on the pseudo-regret are provided, gamma might be considered useless. It proposes that a remark on high-probability upper-bounds and the role of gamma would be interesting. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment provides a clear direction for improvement by suggesting a specific area for further exploration and questioning the applicability of the analysis, it does not explicitly instruct the authors on how to address these points. The action is implicit but concrete, as the authors can infer the need for additional analysis and remarks. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the exploration parameter gamma, questioning its usefulness and suggesting a remark on high-probability upper-bounds and the role of gamma. Additionally, it raises a question about whether the analysis can be extended to high-probability bounds on the regret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the usefulness of the exploration parameter gamma, suggesting that since only upper-bounds on the pseudo-regret are provided, gamma might be considered useless. The reviewer proposes that a remark on high-probability upper-bounds and the role of gamma would be interesting. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment raises valid points, it lacks specific examples or references to support the claim about the uselessness of gamma or the potential extension to high-probability bounds. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the usefulness of the exploration parameter gamma, questioning whether it is meaningful given the provision of only upper-bounds on the pseudo-regret. It suggests that a remark on high-probability upper-bounds and the role of gamma would be interesting, and it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. This feedback is clear and actionable, as it directs the authors to consider the implications of their analysis and suggests potential areas for further exploration. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights and prompts the authors to expand their analysis, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either add a restatement of the definition of LCA relaxation from Wang et al. in the body of the paper or include a description in the appendix. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to address the issue. The comment is specific and provides concrete guidance on how to implement the suggested changes, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for the LCA relaxation, and suggests a solution by recommending the addition of a restatement from Wang et al. or a description in the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LCA relaxation was referenced but never defined in the paper. This is a factual statement that does not require verification. It is a request for clarification or addition of information, not an opinion or suggestion that requires justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the LCA relaxation was referenced but never defined. It provides a clear and actionable suggestion by recommending that the authors either add a restatement of the definition from Wang et al. in the body of the paper or include a description in the appendix. This feedback is valuable as it guides the authors on how to improve the clarity and completeness of their work, ensuring that readers can better understand the concepts discussed. The comment is specific and actionable, making it mostly helpful for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more information on how validation and test splits influence model training could enhance the reproducibility of the dataset. While the comment implies that additional details are needed, it does not explicitly instruct the authors to provide this information or specify how to do so. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to provide more details on validation and test splits, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more information on how validation and test splits influence model training could enhance reproducibility. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the implications of the suggestion themselves. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more information on how validation and test splits influence model training could enhance the reproducibility of the dataset. This feedback is clear and actionable, as it provides a concrete direction for the authors to improve their draft by including additional details on the validation and test splits. However, the comment could be more helpful if it offered specific suggestions or examples of how to present this information. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the scope of the regularization techniques used to address overfitting, specifically questioning why the authors limit their focus to dropout. It suggests considering other regularization techniques like L2 regularization, data augmentation, and adding noise, and asks about the impact of using ZeroLiers alongside these techniques. While the comment implies that the authors should consider a broader range of regularization techniques, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore additional regularization techniques and their interactions with ZeroLiers. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of regularization techniques used to address overfitting, specifically questioning why the authors limit their focus to dropout. It suggests considering other techniques like L2 regularization, data augmentation, and adding noise, and asks about the impact of using ZeroLiers alongside these techniques. However, the comment does not specify which part of the paper discusses regularization techniques or overfitting, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in its suggestion to consider additional regularization techniques and their interactions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scope of regularization techniques used to address overfitting, specifically questioning why the authors limit their focus to dropout. It suggests considering other techniques like L2 regularization, data augmentation, and adding noise, and asks about the impact of using ZeroLiers alongside these techniques. While the comment highlights a potential limitation in the scope of the study, it does not provide specific examples or references to support the claim that these techniques are commonly used in practice. The suggestion to consider additional techniques is logical, but the comment lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the question but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the scope of regularization techniques used to address overfitting, specifically questioning why the authors limit their focus to dropout. It suggests considering other techniques like L2 regularization, data augmentation, and adding noise, and asks about the impact of using ZeroLiers alongside these techniques. This feedback is valuable as it prompts the authors to broaden their exploration of regularization methods, which could lead to a more comprehensive understanding of overfitting and its mitigation. However, the comment could be more helpful if it provided specific suggestions or examples of how to incorporate these additional techniques or discussed the potential benefits and drawbacks of using ZeroLiers in combination with them. Overall, the comment is somewhat helpful as it identifies an area for further exploration but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about generalizing Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that the authors discuss this generalization in the section about consistency. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to implement the generalization. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific assumption, Assumption A (overlap), and questions its generalization from a tabular setting to a function approximation setting. It explicitly mentions the section about consistency, providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the generalization of the assumption. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that the authors discuss this generalization in the section about consistency. However, the comment does not provide any specific reasoning, examples, or references to support why this generalization is necessary or how it could be addressed. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this generalization themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the generalization of Assumption A (overlap) from a tabular setting to a function approximation setting. It suggests that the authors discuss this generalization in the section about consistency, which is a relevant point for the paper. However, the comment does not provide detailed guidance or suggestions on how to address this issue or what aspects of the generalization should be discussed. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that Table 1 should be one column wide, and figures 3, 5, and 6 would benefit from being two column wide. Additionally, it advises that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the width of these elements, suggesting that they should be adjusted to improve readability. The comment further provides a clear suggestion for improvement by recommending that the paper be straightened up, indicating that the content could be better organized. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 1 should be one column wide and that figures 3, 5, and 6 would benefit from a two-column width. It also mentions that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. While the comment provides some reasoning for the suggestions, such as the need for better organization, it lacks specific examples or detailed explanations to fully substantiate the claims. The authors may need to infer the exact issues and improvements needed, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the presentation and organization of the paper. It suggests that Table 1 should be one column wide, which could improve its readability, and recommends that figures 3, 5, and 6 be two column wide for better visibility. Additionally, the comment notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This feedback is clear and provides concrete steps for the authors to enhance the clarity and organization of their draft, making it highly helpful. However, it could be further improved by offering more detailed guidance on how to straighten up the content or by suggesting specific areas that need clarification. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific action to test the effectiveness of perturbed images by creating additional image-question-answer triplets for the Text-DPO baseline. It implies that the authors should experiment with perturbed images to determine if they are the primary factor contributing to the performance improvement. While the action is not explicitly stated, the comment provides a clear and concrete suggestion for an experiment that the authors can conduct to test their hypothesis. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"repeat Text-DPO baseline\" and the specific action of creating additional image-question-answer triplets with perturbed images. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear suggestion for testing the effectiveness of perturbed images by creating new triplet pairs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a specific action to test the effectiveness of perturbed images by creating additional image-question-answer triplets. The reviewer implies that the perturbations themselves are the primary factor contributing to the performance improvement rather than the DPO objective. While the comment provides a logical reasoning, it lacks specific examples or references to support the claim that perturbations are the key factor. This makes the claim somewhat verifiable, as it provides a reasonable hypothesis but requires further elaboration or evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for testing the effectiveness of perturbed images by creating additional image-question-answer triplets. This feedback is actionable and offers a clear path for the authors to explore the impact of perturbations on their method. By suggesting a particular experiment, the comment helps the authors identify a potential area for improvement and innovation. However, it could be more helpful if it included additional guidance on how to interpret the results or what specific outcomes to expect from this experiment. Overall, the comment is mostly helpful as it directs the authors toward a meaningful experiment to conduct, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential assumption in the paper that there is no difference in expertise between Alice and Bob, and suggests that this assumption may not hold in real-world tasks. It points out that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to incorporate this consideration into their analysis. The action is implicit and vague, as the authors are left to infer that they need to explore and address this assumption, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption made in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the potential for non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges a specific assumption made in the paper, questioning the validity of assuming no difference in expertise between Alice and Bob. The reviewer provides a logical reasoning by pointing out that real-world tasks in human-AI collaboration often involve varying levels of expertise, which could lead to non-linear interactions between success-rate and speed-up. This reasoning is supported by a common-sense observation and a general understanding of human-AI collaboration dynamics, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise between the human and the AI. This feedback is somewhat helpful as it points out a limitation in the paper\\'s assumptions and suggests that the authors consider the implications of expertise differences in human-AI collaboration. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to incorporate expertise differences into the analysis. Overall, the comment offers some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise between the human and the AI. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest ways to incorporate this consideration into their analysis. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights the potential for non-linear interactions between success-rate and speed-up due to varying levels of expertise between the human and the AI. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges a specific assumption in the paper, questioning the validity of assuming no difference in expertise between Alice and Bob. The reviewer provides a logical reasoning by pointing out that real-world tasks in human-AI collaboration often involve varying levels of expertise, which could lead to non-linear interactions between success-rate and speed-up. This reasoning is supported by a common-sense observation and a general understanding of human-AI collaboration dynamics, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential assumption in the paper regarding the expertise of Alice and Bob, suggesting that this assumption may not hold in real-world tasks. It highlights"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalizability of the mitigation strategies, specifically mentioning the possibility of data leakage. It suggests that these strategies might be dataset-specific and not applicable more generally. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve the generalizability of their framework. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the mitigation strategies being dataset-specific and not generally applicable. It highlights the concern that these strategies might limit the framework\\'s applicability to other LLMs and datasets. However, it does not specify which part of the paper discusses these strategies, making it weakly grounded. The comment is specific in identifying the issue of generalizability and the potential limitations of the framework. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies are dataset-specific and may not be applicable more generally. This claim is somewhat verifiable as it provides a logical reasoning that the strategies might be limited in their generalizability due to their dataset-specific nature. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the mitigation strategies discussed in the paper, noting that they might be dataset-specific and not generally applicable. This observation is relevant as it highlights a potential weakness in the framework\\'s applicability to other datasets or language models (LLMs). However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their framework. While it points out an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper is not sufficiently clear in some aspects and provides a list of questions to address. However, it does not explicitly instruct the authors on how to improve clarity or what specific changes to make. The comment implies that the weaknesses could be fixed, but it lacks concrete guidance on how to achieve this. The action is implicit and somewhat vague, as the authors know they need to improve clarity but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment indicates that the paper is not sufficiently clear and provides a list of questions to address. However, it does not specify which parts of the paper are unclear or which questions are being referred to, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of specific references or detailed guidance on what needs to be clarified renders the comment weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not sufficiently clear, but it does not provide specific examples or detailed reasoning to support this claim. The mention of \"questions\" implies that the reviewer has specific concerns, but these are not elaborated upon. Without concrete examples or references, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is not sufficiently clear and provides a list of questions to address. However, it does not specify which parts of the paper are unclear or what specific issues need to be resolved. The mention of \"the weaknesses could be fixed until the final paper submission\" suggests that the authors should address these issues, but without detailed guidance, the feedback remains vague and lacks actionable steps. This limits the usefulness of the comment for the authors, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details about the task conditions and the task itself. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. By asking these questions, the reviewer prompts the authors to clarify and potentially expand on these aspects of their work. This feedback is valuable as it encourages the authors to provide more detailed information, which could enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered specific suggestions on how to address these questions or provided examples of how to improve the clarity of the information. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, it does not provide any explicit or implicit suggestions on how the authors should address these issues or what specific steps they should take to incorporate these aspects into their work. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights specific areas where the paper could be improved, such as addressing problems like memory to register and personalize to user characteristics, reasoning over common sense, and facts in open domain dialogue. However, it does not specify which part of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in identifying the areas for improvement but not fully grounded, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the lack of addressing certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. This feedback is somewhat helpful as it points out a gap in the paper\\'s coverage, allowing the authors to consider expanding their work to include these important aspects. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address these issues, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the concern about the bias in the dataset. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical distribution data but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the concern about the bias in the dataset. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing the issue of bias and the potential impact of Arxiv papers, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. The reviewer suggests that the authors should provide this information to address the concern about bias in the dataset. The comment also questions the inclusion of Arxiv papers, suggesting that they are not peer-reviewed and may not be considered formal publications. The reviewer provides an intuition that the bias might be due to Arxiv papers and expresses reservations about including them in the study. However, the comment lacks specific examples or references to support the claim about Arxiv papers being \"junk\" or not considered severe writing. This makes the claim somewhat verifiable, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the potential bias in the dataset. The comment also questions the inclusion of Arxiv papers, expressing reservations about their quality and peer-review status. This feedback is somewhat helpful as it identifies a potential issue with the dataset and suggests a specific area for improvement. However, it lacks detailed guidance on how the authors might address this concern or provide statistical distribution data. Therefore, the comment is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the concern about the bias in the dataset. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include statistical distribution data but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the concern about the bias in the dataset. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing the issue of bias and the potential impact of Arxiv papers, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address the concern about the bias in the dataset. The reviewer also questions the inclusion of Arxiv papers, expressing reservations about their quality and peer-review status. However, the comment lacks specific examples or references to support the claim about Arxiv papers being \"junk\" or not considered severe writing. This makes the claim somewhat verifiable, as it provides some reasoning but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to address"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. While the comment implies that the authors should shift their focus, it does not provide specific guidance on how to achieve this or what aspects of the framework should be emphasized. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework rather than the applications. However, it does not specify which part of the paper this feedback pertains to, such as sections discussing the framework or applications. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing attention. Additionally, the comment lacks specificity regarding what aspects of the framework or problem should be emphasized. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than the applications. However, it does not provide any supporting evidence, reasoning, or examples to justify why this shift in focus would be beneficial or necessary. Without such justification, the claim remains unverifiable, as it lacks the necessary details for the authors to understand and address the suggestion effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending much space on applications. While it identifies a potential imbalance in the paper\\'s content, it lacks specificity and does not provide guidance on how the authors might achieve this balance or what specific aspects of the framework should be emphasized. Without actionable advice or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their work further or what specific aspects need additional attention. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the marginally above acceptance threshold of the work and mentions that the authors have adequately addressed the limitations and potential negative societal impact. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the areas of limitations and societal impact that have been addressed, but without clear grounding, the authors may struggle to pinpoint where these aspects are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact of their work. While it provides some positive feedback, it lacks specific details or constructive suggestions for improvement. The comment does not offer actionable advice or guidance on how the authors might enhance their work further, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as barely helpful, as it provides some recognition but does not effectively support the authors in making meaningful enhancements to their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the simplicity of the current dataset, suggesting that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to the potential for future studies to follow a similar path to the GSM8K dataset. However, the comment does not provide explicit guidance or suggestions on how the authors could address these concerns or enhance the research impact of their work. The feedback lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the simplicity of the current dataset and suggests that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also mentions the potential for future studies to follow a similar path to the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology or results sections. While the authors might infer that it relates to the dataset description or discussion, the lack of explicit grounding makes it difficult to pinpoint the exact section needing attention. The comment is specific in detailing the potential limitations of the dataset and the implications for future research, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current dataset is simple and could be solved by a straightforward method involving natural language translation and code or search libraries. It also suggests that the paper may have limited research impact due to the potential for future studies to follow a similar path to the GSM8K dataset. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim about the dataset\\'s simplicity or the potential impact on future research. Therefore, the comment is categorized as \"2: Borderline Verifiable,\" as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the simplicity of the current dataset, suggesting that it could be solved by a straightforward method involving natural language translation and code or search libraries. It also implies that the paper may have limited research impact due to the potential for future studies to follow a similar path to the GSM8K dataset. However, the comment lacks specific suggestions or actionable feedback on how the authors could address these concerns or enhance the research impact of their work. Without detailed guidance or constructive advice, the authors are left with a general understanding of the issue but no clear path to improvement. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising a statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. It also points out that the proposed measure does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. While the comment implies that the authors should revise the statement and address the limitations, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary revisions and improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. The comment further elaborates on the lack of a stronger theoretical connection to generalization and experimental performance compared to competing measures. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of discussing the limitations of the proposed measure, particularly in light of the presentation\\'s claim that it does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. The reviewer provides a detailed explanation of their concern, which is based on the presentation\\'s content. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reviewer\\'s reasoning to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the fairness of discussing the limitations of the proposed measure. It points out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental superiority. This feedback is clear and actionable, as it directs the authors to revisit and possibly revise their claims about the measure\\'s limitations. However, the comment could be more helpful if it provided suggestions on how to address these limitations or improve the discussion. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. It points out that the proposed measure does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. While the comment implies that the authors should revise the statement and address these limitations, it does not provide explicit guidance on how to revise the statement or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the necessary revisions and improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. The comment elaborates on the lack of a stronger theoretical connection to generalization and experimental performance compared to competing measures. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of discussing the limitations of the proposed measure, particularly in light of the presentation\\'s claim that it does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. The reviewer provides a detailed explanation of their concern, which is based on the presentation\\'s content. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reviewer\\'s reasoning to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, questioning the fairness of discussing the limitations of the proposed measure. It points out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental superiority. This feedback is clear and actionable, as it directs the authors to"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include these results, how to incorporate them, or what specific LLMs should be considered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the lack of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these results should be included. The authors might infer that it relates to the results section or the discussion of benchmarking, but this inference is not direct. The comment is specific in identifying the absence of results for fine-tuned LLMs, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source LLMs is \"quite important\" for a domain-specific benchmark. However, the comment does not provide any specific reasoning, examples, or references to support why these results are crucial or how their absence impacts the benchmark. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper, namely the absence of results for fine-tuned open-source Large Language Models (LLMs) in the context of a domain-specific benchmark. This is a relevant observation that could impact the comprehensiveness and relevance of the study. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or why it is important. Without actionable feedback or detailed reasoning, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer sufficient guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the training process of the regression model, specifically asking for clarification on the input and output, as well as the parameter space for the ridge regression model. It also inquires about the potential impact of the number of parameters on model performance. While the questions imply that the authors should provide more detailed information about the training process and model parameters, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the training process of the regression model, specifically asking for clarification on the input and output, as well as the parameter space for the ridge regression model. It also inquires about the potential impact of the number of parameters on model performance. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The questions are specific in terms of what information is needed, but without explicit references to sections or figures, the authors may struggle to pinpoint where to address these concerns. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the training process of the regression model, including the input and output, as well as the parameter space for the ridge regression model. It also inquires about the potential impact of the number of parameters on model performance. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the training process of the regression model, including the input and output, as well as the parameter space for the ridge regression model. It also inquires about the potential impact of the number of parameters on model performance. These questions are relevant and could help the authors clarify and improve their methodology section. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending additional experiments or analyses. While it prompts the authors to consider important aspects of their methodology, it lacks actionable feedback that would enable them to make concrete improvements. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies an issue with the notation in equation 6 and related equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g. This feedback provides a clear and direct action for the authors to take, which is to correct the notation in the equations. The comment is specific and actionable, as it specifies what needs to be changed and why, giving the authors a clear path forward. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g. This provides clear guidance on what needs to be addressed in the equations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, as it is an operator between a scalar and a tensor, not just between two scalars. This claim is supported by logical reasoning, as it provides a clear explanation of the mathematical operation involved. However, the comment could be strengthened by providing a reference or example to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks full evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation in equations 6 and related equations. It identifies a potential error in the operator notation, suggesting that the operator should be the multiplication of the underlying vector space and not \\cross_g. This feedback is clear and directly addresses a technical issue in the paper, offering a concrete way for the authors to improve the accuracy and clarity of their mathematical expressions. By correcting this notation, the authors can enhance the rigor and precision of their work. Therefore, the comment is highly helpful, as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of the proposed model. It specifies two areas where additional experiments are needed: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This provides clear and concrete guidance on what needs to be added to the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the ablation experiments, providing clear guidance on the areas that require further exploration. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs and the role of reweighting after selection. However, the comment does not provide specific examples or references to support why these ablation experiments are necessary or how they would improve the paper. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these experiments themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors add more ablation experiments to demonstrate the effectiveness of their proposed model. It specifies two areas where additional experiments are needed: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This guidance is specific and offers a concrete path for the authors to enhance their draft, making the comment highly helpful. By addressing these suggestions, the authors can significantly improve the robustness and clarity of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental results could be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. While the comment provides a clear direction for improvement, it does not specify which specific datasets or tasks should be considered or how the authors should incorporate these adaptive mechanisms into their work. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental results could be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. However, the comment does not specify which part of the paper these suggestions pertain to, such as the experimental section or specific results. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements to the experimental setup and referencing related works, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works as baseline approaches for comparison. The comment provides a logical reasoning for the suggestion, as using more complex datasets and adaptive mechanisms could enhance the robustness and applicability of the results. However, it lacks specific examples or references to the adaptive mechanisms mentioned, which would strengthen the justification. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could be more robust with additional supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experimental results by suggesting that the datasets used in the experiments have a limited number of dimensions. It recommends expanding the datasets to include more complex datasets with thousands of dimensions and deep learning tasks, such as image datasets. Additionally, the comment suggests considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. This feedback is clear and actionable, providing the authors with specific directions for enhancing the complexity and relevance of their experimental setup. However, the comment could be more helpful if it included specific examples or guidance on how to implement these suggestions. Overall, the comment is mostly helpful, as it offers valuable insights and actionable steps for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the experimental results could be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions or which datasets or tasks to focus on. The action is implicit but concrete, as it outlines a specific area for enhancement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests expanding the experimental datasets to include more complex datasets with thousands of dimensions and deep learning tasks, such as image datasets. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. However, the comment does not specify which part of the paper these suggestions pertain to, such as the experimental section or specific results. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting improvements to the experimental setup and referencing related works, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental results could be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). It also points out that the results from Table 4 do not show the advantage of using PRESENCE. While the comment identifies issues with the experimental results, it does not provide explicit guidance on how to address these concerns or improve the results. The authors can infer that they need to provide more convincing evidence or clarify the importance of reweighting, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the experiment results, particularly the relationship between temperature $\\\\tau$ and downstream performance, and questions the importance of reweighting using a positive or negative $\\\\tau$. Additionally, it points out the lack of advantage shown in Table 4. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experiment results, specifically questioning the justification for using PRESENCE and the importance of reweighting using a positive or negative temperature ($\\\\tau$). The reviewer provides a logical reasoning by pointing out that using a positive or negative $\\\\tau$ can yield improvement over no reweighting, which raises questions about the necessity of reweighting. However, the comment lacks specific examples or references to support these claims, making it somewhat verifiable. The authors would need to further explore and address these concerns to fully understand and respond to the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific concerns with the experiment results, particularly regarding the relationship between temperature $\\\\tau$ and downstream performance shown in Figure 5. It questions the necessity of using PRESENCE and the importance of reweighting using a positive or negative $\\\\tau$. Additionally, it points out that the results from Table 4 do not demonstrate the advantage of using PRESENCE. This feedback is clear and actionable, as it highlights areas where the authors can improve their experimental analysis and results. By addressing these concerns, the authors can strengthen their paper and provide more convincing evidence for the effectiveness of PRESENCE. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or what steps they should consider to investigate the reason behind the performance gain. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular observation regarding the results for k=1 being better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. This provides clear guidance on what aspect of the results needs further exploration or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide detailed analysis or examples to substantiate the assertion that the performance gain is not solely due to Eq.10. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of results in Table 2, specifically noting that the results for k=1 are better than the baselines. It suggests that this might indicate a reason other than applying Eq.10. However, the comment lacks specific guidance or suggestions on how the authors should address this observation or investigate the underlying cause of the performance gain. Without actionable feedback or detailed advice, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its lack of justification compared to alternative approaches. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific alternatives or improvements. The feedback is vague and does not offer concrete steps for the authors to take, leaving them uncertain about how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method, specifically mentioning the choice of mixed-integer programming and its lack of justification compared to alternative approaches. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection where these choices are discussed. This makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in its critique of the method\\'s grounding, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its lack of justification compared to alternative approaches. However, the comment does not provide specific examples or references to support why this choice is not justified or how it compares to alternative approaches. This lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the choice of mixed-integer programming is not fully justified and its advantages over alternative approaches are unclear. This feedback is valuable as it highlights a critical area for improvement in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending alternative approaches or providing a detailed justification for the choice of mixed-integer programming. While it points out a weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate issues. The first part notes that the notation in Equation 1 is confusing due to the use of \"c\" instead of \"o.\" This is an explicit action for the authors to correct the notation, making it clear and actionable. The second part points out that \"Pedersen et al 2007\" is missing from the reference section, which is also an explicit and clear action for the authors to take. Both parts of the comment provide specific guidance on what needs to be addressed, making the review point highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the confusion in notation due to the use of \"c\" instead of \"o\" in Equation 1, and the missing reference to \"Pedersen et al 2007\" in the reference section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate claims. The first claim is that the notation in Equation 1 is confusing due to the use of \"c\" instead of \"o.\" This is a factual observation and does not require verification. The second claim is that \"Pedersen et al 2007\" is missing from the reference section. This is also a factual statement, as it points out a specific omission in the reference list. Both claims are factual and do not require verification, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues that need attention: the confusion in notation in Equation 1 due to the use of \"c\" instead of \"o,\" and the omission of \"Pedersen et al 2007\" from the reference section. These are clear and actionable points that provide the authors with specific guidance on how to improve their draft. By addressing these issues, the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it offered suggestions on how to resolve the notation issue or provided context for the missing reference. Overall, the feedback is mostly helpful as it directs the authors to important areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second contribution of the paper, which is the proposal to combine SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. It also notes that the architecture in Figure 5 is similar to the proposed architecture in MEGA. The reviewer suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects should be discussed or ablated. The action is implicit and somewhat vague, as the authors can infer that they need to discuss and differentiate their work from existing proposals, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second contribution of the paper, the proposal to combine SSMs with Attention, and references specific works (MEGA and Block-state Transformer) that have proposed similar ideas. It also provides a specific example of the architecture in Figure 5, which is similar to the proposed architecture in MEGA. The comment is specific in suggesting that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposal to combine SSMs with Attention is not new and has been proposed before in MEGA and Block-state Transformer. The reviewer supports this claim by referencing specific works (MEGA and Block-state Transformer) that have proposed similar ideas. Additionally, the comment notes that the architecture in Figure 5 is similar to the proposed architecture in MEGA, suggesting that the similarities and differences between S++ and this work should be discussed. This provides a clear and specific reference to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of the similarities and differences between the proposed work and the referenced works, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper\\'s second contribution, which is the proposal to combine SSMs with Attention. It points out that this idea has been proposed before in MEGA and Block-state Transformer, and suggests that the authors discuss and ablate the similarities and differences between their work and these existing proposals. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s contribution and provides a direction for improvement by encouraging the authors to differentiate their work from existing literature. However, the comment could be more helpful if it offered specific suggestions on how to discuss and ablate the similarities and differences. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the second contribution of the paper, which is the proposal to combine SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. It also notes that the architecture in Figure 5 is similar to the proposed architecture in MEGA. The reviewer suggests that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific aspects should be discussed or ablated. The action is implicit and somewhat vague, as the authors can infer that they need to discuss and differentiate their work from existing proposals, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second contribution of the paper, which is the proposal to combine SSMs with Attention, and references specific works (MEGA and Block-state Transformer) that have proposed similar ideas. It also provides a specific example of the architecture in Figure 5, which is similar to the proposed architecture in MEGA. The comment is specific in suggesting that the similarities and differences between S++ and this work should be discussed thoroughly and ablated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposal to combine SSMs with Attention is not new and has been proposed before in MEGA and Block"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the reason for reporting results on knowledge transfer only on a few select environments. While it implies that the authors should provide a rationale or explanation for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their decision. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for reporting results on knowledge transfer only on a few select environments. This provides clear guidance on what aspect of the paper needs further explanation or justification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the reason for reporting results on knowledge transfer only on a few select environments. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the reason for reporting results on knowledge transfer only on a few select environments. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their reporting. The comment lacks depth and actionable feedback, leaving the authors with a vague inquiry rather than concrete steps to enhance their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the lack of specific ablation experiments, which could lead to confusion regarding the performance improvement attributed to the pre-trained weights rather than the proposed method. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should conduct ablation experiments to clarify the contribution of the proposed method. However, the comment lacks concrete details on what specific ablation experiments should be performed or how to structure them. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of ablation experiments in the paper, which could lead to confusion about the performance improvement attributed to pre-trained weights rather than the proposed method. However, it does not specify which part of the paper should include these ablation experiments or where the authors should add them. While the authors might infer that it relates to the results or discussion sections, the comment lacks explicit grounding. It is specific in identifying the need for ablation experiments but does not provide detailed guidance on how to implement them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance improvement could be attributed to the pre-trained weights rather than the proposed method, suggesting that the absence of detailed ablation comparisons leads to confusion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to conduct ablation experiments is a logical response to address the issue, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, namely the lack of ablation experiments to demonstrate the contribution of the proposed method. It highlights a potential concern that the performance improvement could be attributed to pre-trained weights rather than the method itself, which could lead to confusion. The comment is clear and actionable, as it provides a specific area for improvement by suggesting the inclusion of detailed ablation comparisons. However, it could be more helpful if it offered guidance on how to structure these experiments or what specific comparisons should be made. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a major concern regarding the limitation of the lemmatizer, specifically that it strips suffixes from words that are already lemmas but end with a suffix substring. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the lemmatizer, which is the stripping of suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about real-world texts with evolving vocabularies, providing a clear indication of what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the described limitation of the lemmatizer is a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the significance of this limitation or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a relevant concern, especially for real-world texts with evolving vocabularies. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights an important area for consideration, it does not offer actionable feedback or constructive advice, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the comparison in Table 2, where pre-trained DGCNN is used for semantic segmentation for each completion method. It suggests that the comparison of the segmentation metric is not meaningful because the segmentation of those methods + DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the comparison. The action is implicit and vague, as the authors are left to infer that they need to reconsider the comparison or find a more meaningful way to present it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of segmentation metrics, noting that the comparison is not meaningful due to the use of pre-trained DGCNN for semantic segmentation. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of segmentation metrics in Table 2 is not meaningful because the use of pre-trained DGCNN for semantic segmentation makes the comparison less relevant. The comment provides a logical reasoning by suggesting that the comparison is not meaningful due to the additional step of using DGCNN. However, it lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore the implications of using pre-trained DGCNN to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the comparison presented in Table 2, noting that the use of pre-trained DGCNN for semantic segmentation makes the comparison of segmentation metrics less meaningful. It highlights that the comparison is not meaningful because the segmentation of the methods + DGCNN is worse than the proposed method. This feedback is clear and actionable, as it points out a potential flaw in the experimental setup that could affect the interpretation of results. However, the comment could be more helpful if it suggested alternative approaches or metrics that could be used to make the comparison more meaningful. Overall, the comment is mostly helpful as it provides valuable insight into the limitations of the current comparison and prompts the authors to consider alternative methods for evaluation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is challenging to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to improve their work. As a result, the comment lacks any actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that it is difficult to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the rules or data are being discussed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of their work is being addressed. Additionally, the comment lacks specificity regarding what needs to be improved or how the authors might address the issue. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is difficult to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the assertion or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it is challenging to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. Without actionable feedback or detailed advice, the comment lacks the necessary depth and clarity to be helpful for the authors. Therefore, it is rated as barely helpful, as it identifies a potential area of concern but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with dynamic sparse training-based and other sparsity-based methods. While the action is implied, it is clear and specific, providing a concrete direction for the authors to enhance their draft. The comment does not leave any ambiguity about what needs to be added or how to implement the comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a comparison with dynamic sparse training-based and other sparsity-based methods is missing. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its request for a comparison, but without clear grounding, the authors may struggle to identify the exact section where this addition should be made. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper lacks a comparison with dynamic sparse training-based and other sparsity-based methods. While this is a valid point, the comment does not provide specific guidance or examples of how such a comparison could be conducted or what aspects should be considered. Without detailed suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reasoning presented in the paper regarding the intractability of $p_\\\\theta(y|x)$. It questions the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$. The reviewer provides a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable. However, the comment does not offer any explicit or implicit suggestions for how the authors might address this issue or improve their explanation. There is no guidance on how to clarify or correct the reasoning presented in the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly refers to a specific statement in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the reasoning presented, questioning the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$. The reviewer provides a counterexample to illustrate this point, making the comment detailed and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reasoning presented in the paper regarding the intractability of $p_\\\\theta(y|x)$. It provides a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable. This critique is based on logical reasoning and a specific example, which provides a clear and detailed explanation of the issue. However, the comment could be strengthened by referencing specific sections or equations in the paper where this issue is discussed, which would enhance its verifiability. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a critical point about the reasoning presented in the paper regarding the intractability of certain probabilities. It questions the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$. The reviewer provides a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable. This feedback is valuable as it challenges the authors to reconsider their assumptions and potentially revise their analysis. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or clarify their reasoning. Overall, the comment is mostly helpful as it prompts the authors to reevaluate their assumptions and provides a direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the irreproducibility of the study due to the inaccessible datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might make the datasets accessible or what steps they could take to ensure reproducibility. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the irreproducibility of the study due to the inaccessible datasets outside of the associated groups. However, it does not specify which part of the paper discusses the datasets or how the authors could address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what needs to be done to make the datasets accessible. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is irreproducible due to the inaccessible datasets outside of the associated groups. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the study\\'s reproducibility due to the inaccessible datasets outside of the associated groups. This is a critical concern for the validity and impact of the research, as reproducibility is a cornerstone of scientific research. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue, such as recommending ways to make the datasets accessible or suggesting alternative approaches to ensure reproducibility. Without detailed feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the presence of a missing equation before the statement \"where p is the firing rate\" in Section 3.4.1. While it explicitly asks for clarification, it does not provide any guidance on how to address the issue or what the missing equation might be. The authors are left to infer that they need to identify and include the missing equation, but without further details, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the potential missing equation before the statement \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed in this section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the presence of a missing equation before a specific statement in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for clarification regarding the presence of a missing equation before a specific statement in the paper. It identifies a potential gap in the text, prompting the authors to ensure that all necessary equations are included. While the comment highlights an important aspect that needs attention, it lacks depth and does not provide specific guidance on how to address the issue or what the missing equation might be. This limits its helpfulness, as it provides only a basic level of feedback. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation of sentiment word detection and correction is lacking, and it suggests that experiments should be conducted to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback provides a clear and direct action for the authors to take, specifying what needs to be added to the evaluation section. The comment is explicit and concrete, offering a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation of sentiment word detection and correction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of sentiment word detection and correction is lacking, given that the key ideas of SWRM involve these aspects. The reviewer suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the necessity of these experiments. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the evaluation of the paper, specifically the lack of evaluation for sentiment word detection and correction. It highlights that the key ideas of SWRM involve these aspects and suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing this gap, the authors can enhance the comprehensiveness and rigor of their evaluation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results of KMLM-XLM-R_{large}(ours) in all the result tables. It implies that the authors may have omitted reporting all the performance of KMLM-large without providing a logical reasoning for this omission. However, the comment does not explicitly instruct the authors to include these results or provide a specific reason for their absence. The action is implicit and somewhat vague, as the authors need to infer that they should report these results and understand why they were omitted. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the reporting of the results of KMLM-XLM-R_{large}(ours) in all the result tables. The comment highlights a potential omission in the paper, providing clear guidance on what needs to be included. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the completeness of the results reported in the paper, specifically asking about the results of KMLM-XLM-R_{large}(ours) in all the result tables. However, it does not provide any supporting evidence, reasoning, or examples to justify why these results are missing or why they are important. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the completeness of the results reported in the paper, particularly regarding the results of KMLM-XLM-R_{large}(ours) in all the result tables. It implies that the authors may have omitted reporting all the performance of KMLM-large without providing a logical reasoning for this omission. While the comment identifies a potential issue, it lacks detailed guidance or suggestions on how the authors might address this concern or why it is important to include these results. The feedback is somewhat helpful as it points out a gap in the paper, but it could be more actionable and comprehensive to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the completeness of the results reported in the paper, specifically questioning the absence of results for KMLM-XLM-R_{large}(ours) in all the result tables. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as whether they should include these results or provide a logical reasoning for their exclusion. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the reporting of the results of KMLM-XLM-R_{large}(ours) in all the result tables. The comment highlights a potential omission in the paper, providing clear guidance on what needs to be included. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the completeness of the results reported in the paper, specifically asking about the results of KMLM-XLM-R_{large}(ours) in all the result tables. However, it does not provide any supporting evidence, reasoning, or examples to justify why these results are missing or why they are important. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the completeness of the results reported in the paper, particularly regarding the results of KMLM-XLM-R_{large}(ours) in all the result tables. It implies that the authors may have omitted reporting all the performance of KMLM-large without providing a logical reasoning for this omission. While the comment identifies a potential issue, it lacks detailed guidance or suggestions on how the authors might address this concern or why it is important to include these results. The feedback is somewhat helpful as it points out a gap in the paper, but it could be more actionable and comprehensive to be fully beneficial for the authors. Therefore, it is rated as somewhat helpful.', 'help"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the reliability of the claims due to the underperformance of in-context learning baselines compared to the backbone. It suggests that the large variance in results or the uncareful design of the baselines might be responsible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific explanations are needed. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the results, noting that many in-context learning baselines underperform the backbone in many items. It suggests that this might be due to large variance in results or uncareful design of the baselines. However, the comment does not specify which items or experiments are affected, making it weakly grounded. The comment is specific in identifying the issue of underperformance and suggesting the need for more explanations to support the reliability of claims. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"there are mysterious results\" and suggests that \"many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items.\" The reviewer attributes this underperformance to large variance in results or uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the issue or how to address it. The absence of concrete evidence or references leaves the claim somewhat verifiable, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results, noting that many in-context learning baselines underperform the backbone in many items. It suggests that this underperformance might be due to large variance in results or uncareful design of the baselines. The comment implies that more explanations are needed to support the reliability of the claims. While it highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or provide additional explanations. The feedback is somewhat helpful as it points out a potential weakness but does not offer detailed advice on how to resolve it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the reliability of the claims due to the underperformance of in-context learning baselines compared to the backbone. It suggests that the large variance in results or the uncareful design of the baselines might be responsible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific explanations are needed to support the reliability of their claims. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the results, noting that many in-context learning baselines underperform the backbone in many items. It suggests that this underperformance might be due to large variance in results or uncareful design of the baselines. However, the comment does not specify which items or experiments are affected, making it weakly grounded. The suggestion to provide more explanations to support the reliability of claims is specific, but without explicit references to the parts of the paper that need further explanation, the comment remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are mysterious results where in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone in many items. The reviewer suggests that this underperformance might be due to large variance in results or uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the issue or how to address it. The absence of concrete evidence or references leaves the claim somewhat verifiable, as it requires more detailed justification to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results, noting that many in-context learning baselines underperform the backbone in many items. It suggests that this underperformance might be due to large variance in results or uncareful design of the baselines."}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the key innovation of GFNSeqEditor, specifically regarding how it produces novel sequences with improved properties. It explicitly suggests that the paper should better articulate the novel techniques or insights that lead to these improvements. This feedback provides a clear and direct action for the authors to take, namely to clarify the key innovation and its contributions. The comment is specific in its request for additional explanation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"key innovation\" and the \"GFNSeqEditor,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of ambiguity in the claim about the key innovation and suggests that the paper should better articulate the novel techniques or insights leading to the claimed improvements. This provides clear guidance on what needs to be addressed to enhance the reader\\'s understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the key innovation of GFNSeqEditor, specifically in its ability to produce novel sequences with improved properties. The reviewer suggests that the paper should better articulate the novel techniques or insights that lead to these improvements. While the comment identifies a gap in the paper\\'s clarity, it does not provide specific examples or references to support the claim. The reasoning is logical, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the paper\\'s key innovation, specifically regarding the claim that GFNSeqEditor can produce novel sequences with improved properties. It highlights the need for better articulation of the novel techniques or insights that lead to these improvements, which is essential for enhancing the reader\\'s understanding of the method\\'s unique value. This feedback is clear and actionable, providing the authors with a specific area to focus on to improve the clarity and impact of their work. However, it could be more helpful if it offered suggestions on how to articulate these novel aspects or provided examples of how to enhance clarity. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment. While the action is explicit, it lacks concrete guidance on what specific experiment should be performed or how to measure the faithfulness of the approach. The comment provides a clear direction but lacks detailed instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the faithfulness of the proposed approach and suggests that the authors should demonstrate their claim about the method being less at risk to biases with a simple experiment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to use a simple experiment to demonstrate the faithfulness, providing clear guidance on what the authors need to do to address the concern. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment. However, it does not provide any specific reasoning or evidence to support why this demonstration is necessary or how it would be beneficial. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement regarding the faithfulness of the proposed approach. It suggests that the authors should demonstrate their claim about the method being less at risk to biases with a simple experiment. This feedback is clear and actionable, providing a concrete step for the authors to take to strengthen their argument. However, the comment could be more helpful if it offered additional guidance on what type of experiment would be most effective or how to measure the faithfulness of the approach. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method for its inability to operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. The comment suggests that this limitation is not the best \"motivation\" for the proposed method. However, it does not provide explicit guidance on how the authors could improve the motivation or address this limitation. The action is implicit and vague, as the authors are left to infer that they need to find a better way to motivate their method, but without specific suggestions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques a specific sentence in the manuscript, \"Most real-world applications are continuous in nature and are quite difficult to discretize or solve with discrete state-action spaces,\" suggesting that it is not the best \"motivation\" for the proposed method. However, it does not specify which part of the manuscript this sentence is located in, making it weakly grounded. The comment is specific in identifying the issue with the proposed method's limitation in operating with state-action spaces, which is a clear suggestion for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method for its inability to operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. The comment suggests that this limitation is not the best \"motivation\" for the proposed method. However, the comment lacks specific examples or references to support the claim that the method's limitation is a significant issue. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it can only operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. This feedback is clear and actionable, as it highlights a critical area where the authors need to address the applicability of their method. By pointing out this limitation, the comment provides a clear direction for improvement, encouraging the authors to consider broader applicability or alternative approaches. However, the comment could be more helpful if it offered suggestions on how to address this limitation or provided examples of how other methods might overcome similar challenges. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment critiques the proposed method for its inability to operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. It suggests that this limitation is not the best \"motivation\" for the proposed method. However, the comment does not provide explicit guidance on how the authors could improve the motivation or address this limitation. The action is implicit and lacks concrete details, making it barely actionable. Authors may infer that they need to find a better way to motivate their method, but the comment does not offer specific suggestions on how to do so.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques a specific sentence in the manuscript, \"Most real-world applications are continuous in nature and are quite difficult to discretize or solve with discrete state-action spaces,\" suggesting that it is not the best \"motivation\" for the proposed method. However, it does not specify which part of the manuscript this sentence is located in, making it weakly grounded. The comment is specific in identifying the issue with the proposed method's limitation in operating with state-action spaces, which is a clear suggestion for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method for its inability to operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. The comment suggests that this limitation is not the best \"motivation\" for the proposed method. However, the comment lacks specific examples or references to support the claim that the method's limitation is a significant issue. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it can only operate with state-action spaces, which is a limitation in real-world applications that are continuous in nature. This feedback is clear and actionable, as it highlights a critical area where the authors need to address the applicability of their method. By"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the experimental results and the presentation of the main results in Table 1. It suggests that the results are not competitive with state-of-the-art (SOTA) methods and that the presentation is unclear due to differences in backbones compared to prior methods. The reviewer also recommends moving the baseline to the ablation study and only showing the proposed method. While the comment provides explicit actions for improvement, it lacks concrete details on how to achieve these changes, such as specific benchmarks to compare against or detailed guidance on how to present the results more clearly. The authors know they need to address the issues but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiment results\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the results being not competitive and the presentation of the main results being unclear due to differences in backbones compared to prior methods. Additionally, it provides a specific suggestion to move the baseline to the ablation study and only show the proposed method. This level of detail and specificity makes the comment fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment results are not competitive with state-of-the-art (SOTA) methods and that the presentation of the main results in Table 1 is unclear due to differences in backbones compared to prior methods. The comment suggests moving the baseline to the ablation study and only showing the proposed method. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim about the lack of competitiveness. The suggestion to move the baseline is a logical improvement, but without further explanation, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the experimental results and the presentation of the main results in Table 1. It points out that the results are not competitive with state-of-the-art (SOTA) methods and that the presentation is unclear due to differences in backbones compared to prior methods. The reviewer suggests moving the baseline to the ablation study and only showing the proposed method. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and competitiveness of their results. However, the comment could be more helpful if it offered additional suggestions or examples on how to enhance the presentation of the results. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback provides a clear and explicit action for the authors to take, which is to clarify the copyright scenario in their manuscript. The comment also offers a specific area for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or conclusion sections where copyright issues might be addressed. The comment is specific in its request for clarification, providing a clear direction for the authors to improve their manuscript. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This is a request for clarification rather than a claim or suggestion that requires justification. Therefore, it fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the manuscript, suggesting that the copyright scenario could be clarified. It provides a clear and actionable suggestion by asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is valuable as it directs the authors to a critical aspect of their work that needs clarification, potentially impacting the legal and ethical implications of their research. However, the comment could be more helpful if it offered additional guidance or examples on how to address this issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed advice.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of domain-specific and domain-agnostic information. While it identifies a gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide a theoretical explanation or justification, but it does not specify what kind of explanation or analysis is needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the theoretical justification and intuitive explanation of the behavior of low-rank and high-rank adapters in terms of domain-specific and domain-agnostic information. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing\u2014a theoretical justification or intuitive explanation\u2014and suggests that experimental observation alone is insufficient. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters in terms of domain-specific and domain-agnostic information. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the theoretical justification and intuitive explanation of the behavior of low-rank and high-rank adapters in terms of domain-specific and domain-agnostic information. It highlights that the current explanation relies solely on experimental observation, which is not sufficient for a comprehensive understanding. This feedback is valuable as it points out a critical area that needs further exploration and explanation. However, the comment could be more helpful if it provided suggestions on how the authors might address this gap, such as proposing theoretical frameworks or methodologies to explore these concepts. Overall, the comment is somewhat helpful as it directs the authors to an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the validity of the statement regarding local models and their relationship to decision boundaries. It asks why this is true and why we can\\'t measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" While the comment highlights a potential area of confusion or lack of clarity, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify or provide additional explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the statement regarding local models and their relationship to decision boundaries, and it asks for clarification on why this is true and why differences in probabilities cannot be measured. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the statement regarding local models and decision boundaries. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the validity of a statement regarding local models and their relationship to decision boundaries. It asks why this is true and why differences in probabilities cannot be measured, such as \"if feature 1 were higher, the model would be less confident in class y.\" This feedback is somewhat helpful as it prompts the authors to clarify or provide additional explanation for a potentially confusing statement. However, it lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Therefore, the comment is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and suggests including results on classic datasets like CIFAR-10 and CIFAR-100. This feedback is explicit in its action, as it directly instructs the authors to expand their experimental evaluation to include these classic datasets. The suggestion is concrete, as it specifies the datasets to include, providing clear guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ImageNet\" and \"CIFAR-10 and CIFAR-100,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of results on classic datasets like CIFAR-10 and CIFAR-100. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet, without including results on classic datasets like CIFAR-10 and CIFAR-100. This is a factual statement about the content of the paper, not an opinion or suggestion. It does not contain any subjective claims or judgments that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental evaluation, noting that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This feedback is clear and actionable, as it highlights a gap in the experimental setup that the authors can address to enhance the comprehensiveness and relevance of their results. By suggesting the inclusion of additional datasets, the comment provides a concrete direction for improvement, making it mostly helpful. However, it could be more helpful if it offered additional context or reasoning on why these datasets are important or how their inclusion would benefit the study. Nonetheless, the feedback is valuable in guiding the authors toward a more robust experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion in Figure 1 regarding the softmax layer, which is not clearly shown despite being mentioned in the text description. It compares this to the clarity of the figure in the original DinoSR paper. While the comment identifies a specific issue with the figure, it does not provide explicit guidance on how to resolve it. The authors can infer that they need to clarify the figure, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the confusion regarding the softmax layer and its absence in the figure, which is not clearly shown despite being mentioned in the text description. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite being mentioned in the text description. The reviewer compares this to the clarity of the figure in the original DinoSR paper. While the comment highlights a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to the original DinoSR paper provides some context, but the comment could be strengthened with more detailed comparisons or explanations. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that the softmax layer is not clearly shown despite being mentioned in the text description. It compares this to the clarity of the figure in the original DinoSR paper. This feedback is clear and actionable, as it points out a potential confusion in the figure that could be addressed to improve the clarity and accuracy of the presentation. By highlighting this issue, the authors can take steps to enhance the comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to improve the figure or clarified the text description to align with the figure. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more related work on causal inference, specifically mentioning examples of such works. While the comment implies that the authors should review and discuss these works, it does not provide explicit instructions or detailed guidance on which specific works to include or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer which related works to consider and how to incorporate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should review related work on causal inference and mentions specific examples of such works. However, it does not specify which part of the paper this suggestion pertains to, such as the literature review section or the introduction. The authors can infer that it relates to the discussion of related work, but this inference is not direct. The comment is specific in suggesting related works to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more related work on causal inference and mentions specific examples of such works. However, it does not provide any justification or reasoning for why these specific works are relevant or how they would enhance the paper. The claim lacks supporting evidence or detailed explanation, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more related work on causal inference, specifically mentioning examples of such works. This feedback is somewhat helpful as it points out a potential gap in the literature review section, prompting the authors to consider additional relevant works. However, the comment lacks specificity and does not provide detailed guidance on which specific works to include or how they would enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to effectively address the feedback. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that sections 3.1 and 3.2 could have been avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. It also points out that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This feedback provides a clear and concrete action for the authors to take, which is to conduct ablation studies to justify their decision. The comment is explicit and provides specific guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to avoid using sections 3.1 and 3.2 if the authors used the LLM2Vec encoder, which is already cited in the paper. The comment further specifies that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3.1 and 3.2 could have been avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. The reviewer suggests that the reasoning for not adopting this approach is unclear and recommends validating the decision with ablation studies. While the comment provides a logical argument for reconsidering the sections, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to conduct ablation studies is a step towards validation but is not explicitly referenced or explained. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification and examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the use of the LLM2Vec encoder in sections 3.1 and 3.2. It highlights that the authors could have avoided these sections if they had used this encoder, which is already cited in the paper. The comment also points out that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This feedback is specific and constructive, offering a concrete way for the authors to enhance their draft by providing additional justification for their choices. However, it could be more helpful if it included specific examples or guidance on how to conduct the ablation studies. Overall, the comment is mostly helpful as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. While it identifies a potential limitation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending the inclusion of real-world problems or suggesting specific types of real-world problems to consider. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and no real-world problems are considered. This provides some level of grounding as it refers to the experiments section, allowing the authors to identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what specific real-world problems should be included or how the inclusion of real-world problems would improve the experiments. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. This claim is somewhat verifiable as it highlights a potential limitation in the experimental setup. However, the comment lacks specific examples or references to real-world problems that could be included, which would strengthen the claim. The authors would need to infer which real-world problems could be relevant, making the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental setup, specifically noting that only synthetic objective functions are used for comparisons with existing baselines, without considering real-world problems. This feedback highlights an area where the authors could enhance the relevance and applicability of their work. However, the comment lacks specific suggestions or guidance on how to incorporate real-world problems or which types of real-world problems would be most beneficial to include. While it points out a weakness, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. While it identifies a potential limitation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending the inclusion of real-world problems or suggesting specific types of real-world problems to consider. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and no real-world problems are considered. This provides some level of grounding as it refers to the experiments section, allowing the authors to identify the part of the paper being discussed. However, the comment lacks specificity as it does not detail what specific real-world problems should be included or how the inclusion of real-world problems would improve the experiments. Without clear guidance or suggestions, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. This is a logical claim that can be supported by the authors providing evidence of the experiments conducted. However, the comment lacks specific examples or references to real-world problems that could be included, which would strengthen the claim. Without detailed examples or references, the authors may find it challenging to understand the full scope of the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support. This aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experiments, noting that only synthetic objective functions are used for comparisons with existing baselines, without considering real-world problems. This feedback highlights an area where the authors could enhance the relevance and applicability of their work. However, the comment lacks specific suggestions or guidance on how to incorporate real-world problems or which types of"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify the findings that distinguishing roles using explanation-focused cues is challenging. While the comment implies that such an analysis is necessary, it does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the paper, namely the challenge of distinguishing roles using explanation-focused cues. It suggests that this challenge might be due to LLMs relying more on language style than informational depth. The comment also recommends a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging, suggesting that LLMs may rely more on language style than informational depth. The comment provides a logical reasoning by linking the challenge to the reliance on language style, which is a common issue in natural language processing. However, it lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore this reasoning to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific challenge in the paper, which is the difficulty in distinguishing roles using explanation-focused cues. It suggests that this challenge might be due to LLMs relying more on language style than informational depth. The comment provides a constructive suggestion for improvement by recommending a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify these findings. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their analysis and understanding of the issue. However, it could be more helpful if it included specific examples or guidance on how to conduct the analysis. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper uses a significant number of acronyms, which can affect readability, and specifically mentions the acronym \"DU\" being used without a clear definition. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they should either define the acronyms or reduce their use, but the comment lacks concrete suggestions on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the use of acronyms in the paper, particularly mentioning the acronym \"DU\" without a clear definition. This provides some level of grounding as it allows the authors to identify the part of the paper being addressed, although it does not specify which sections or paragraphs are affected. The comment is specific in pointing out the lack of definition for \"DU,\" which is a clear issue that needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper uses a significant number of acronyms, which affects readability, and specifically mentions the acronym \"DU\" being used without a clear definition. This claim is somewhat verifiable as it provides a specific example of an acronym that lacks a definition, which could impact the paper\\'s readability. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as explaining how the use of acronyms affects readability or providing examples of other acronyms that are defined. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the heavy use of acronyms, which can affect readability. It provides a concrete example by mentioning the acronym \"DU\" being used without a clear definition. This feedback is actionable as it highlights a specific area for improvement, prompting the authors to either define the acronyms or reduce their use to enhance clarity. However, the comment could be more helpful if it suggested ways to balance the use of acronyms with their definitions or provided examples of how to improve readability. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, namely the heavy use of acronyms, which can affect readability. It points out that the acronym \"DU\" is mentioned without a clear definition. This feedback provides a clear action for the authors to take, which is to either define the acronyms or reduce their use to improve readability. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the heavy use of acronyms, which can affect readability. It provides a concrete example by mentioning the acronym \"DU\" being used without a clear definition. This allows the authors to accurately identify the part of the paper being addressed, providing full grounding. The comment is also specific because it clearly specifies what needs to be addressed, namely the need to define the acronym \"DU\" or reduce the use of acronyms to improve readability. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper uses a significant number of acronyms, which can affect readability, and specifically mentions the acronym \"DU\" being used without a clear definition. This claim is somewhat verifiable as it provides a specific example of an acronym that lacks a definition, which could impact the paper\\'s readability. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as explaining how the use of acronyms affects readability or providing examples of other acronyms that are defined. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the heavy use of acronyms, which can affect readability. It provides a concrete example by mentioning the acronym \"DU\" being used without a clear definition. This feedback is actionable as it directs the authors to address the issue of acronyms by either defining them or reducing their use to improve clarity. However, the comment could be more helpful if it provided additional guidance on how to balance the use of acronyms with their definitions or suggested ways to"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in section 2.3, specifically regarding the independence of the variance of the distribution p(q|s) and how it is estimated. It asks whether the variance is determined using the sample variance of the quality values in the training data and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. While the comment identifies specific areas of concern, it does not provide explicit instructions or suggestions for how the authors should address these questions. The authors are left to infer that they need to clarify or justify their assumptions about variance estimation, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for clarification but does not provide detailed instructions on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the estimation of variance, particularly regarding its independence and how it is determined. The comment specifies what needs to be addressed, such as whether the variance is estimated using the sample variance of quality values or if a complete covariance matrix is approximated. This provides clear guidance on what aspects of the paper need further clarification or explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the estimation of variance in section 2.3, specifically regarding its independence and how it is determined. The reviewer asks whether the variance is estimated using the sample variance of quality values in the training data and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. While the comment seeks clarification on specific aspects of the methodology, it does not contain an opinion, judgment, or suggestion that requires verification. It is a request for information, making it a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises specific questions about the estimation of variance in section 2.3, particularly regarding its independence and how it is determined. It asks whether the variance is estimated using the sample variance of quality values in the training data and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. This feedback is somewhat helpful as it identifies areas of potential confusion or lack of clarity in the paper. However, it could be more helpful if it provided suggestions on how to address these questions or offered alternative approaches for estimating variance. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what the authors should do with this observation or how it relates to the overall paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the initial accuracy of the MIL-based baseline model compared to the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically for the NSCLC dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model compared to the converged models, specifically for the NSCLC dataset. While it identifies a potential area of interest or concern, it does not provide any further context, analysis, or suggestions for improvement. The comment lacks depth and actionable guidance, leaving the authors without a clear direction on how to address the issue or enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential area for exploration but does not offer meaningful feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While the action is explicit, it lacks concrete guidance on which specific datasets to consider or how to evaluate the generalization across them. The authors are given a clear direction to expand their analysis, but the lack of detailed instructions on execution makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology section or the results section. This makes it difficult for the authors to pinpoint where this suggestion should be addressed. While the comment is specific in its suggestion to consider other datasets, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method. However, it does not provide any specific reasoning or evidence to support why other datasets are necessary or how they would enhance the generalization of the method. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is somewhat helpful as it identifies a potential limitation in the current focus on the MuAViC dataset and provides a direction for expanding the analysis. However, the comment lacks specific guidance on which datasets to consider or how to evaluate the generalization across them. To be more helpful, the comment could include suggestions for alternative datasets or methodologies for assessing generalization. Overall, the feedback offers some insight but could be more comprehensive and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the Bayes-optimality of the systems and suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. While the comment implies that the authors should provide a more comprehensive analysis and include alternative hypotheses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis and include alternative hypotheses. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the Bayes-optimality of the systems and suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion to establish alternative hypotheses and design experiments to discriminate between them, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the Bayes-optimality of the systems and suggests that more work is needed to establish alternative hypotheses and design experiments to discriminate between them. The comment implies that the current analysis is confirmatory and lacks a comprehensive exploration of alternative hypotheses. However, it does not provide specific examples or references to support the claim that the analysis is confirmatory or lacks depth. The reasoning is based on the reviewer\\'s perception of the paper\\'s focus, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the Bayes-optimality of the systems discussed in the paper, particularly on the relatively straightforward problems investigated. It suggests that more work is needed at the beginning of the paper to establish alternative hypotheses and design experiments to discriminate between them. This feedback is valuable as it points out a potential gap in the paper\\'s analysis and encourages the authors to broaden their exploration of alternative hypotheses. However, the comment could be more helpful if it provided specific suggestions on how to establish these alternative hypotheses or design the experiments. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a question about the Bayes-optimality of the systems discussed in the paper and suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. While the comment implies that the authors should provide a more comprehensive analysis and include alternative hypotheses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis and include alternative hypotheses. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the Bayes-optimality of the systems discussed in the paper and suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion to establish alternative hypotheses and design experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the Bayes-optimality of the systems discussed in the paper and suggests that more work is needed to establish alternative hypotheses and design experiments to discriminate between them. The comment implies that the current analysis is confirmatory and lacks a comprehensive exploration of alternative hypotheses. However, it does not provide specific examples or references to support the claim that the analysis is confirmatory or lacks depth. The reasoning is based on the reviewer\\'s perception of the paper\\'s focus, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the Bayes-optimality of the systems discussed in the paper, particularly on the relatively straightforward problems investigated. It suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. This feedback is valuable as it points out a potential gap in the paper\\'s analysis and encourages the authors to broaden their exploration of alternative hypotheses."}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add confidence intervals to the reported values in Table 1, which provides results for the performance of different fairness improvement techniques. This feedback is clear and specific, giving the authors a direct action to take to improve their draft. The comment provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being very close, making it difficult to draw conclusions. The comment suggests adding confidence intervals to provide a more robust analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to address this issue. While the comment identifies a potential problem, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to add confidence intervals is a logical step to improve the analysis, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that the reported values are very close, making it difficult to draw conclusions. It provides a clear and actionable suggestion by recommending the addition of confidence intervals to provide a more robust analysis. This feedback is valuable as it guides the authors on how to improve the clarity and reliability of their results, making the comment mostly helpful. However, it could be more helpful if it explained why confidence intervals are important or how they would enhance the analysis. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some choices are not justified or clear, but it does not provide specific examples or details about which choices are in question. It also does not offer guidance on how the authors might address these issues or what specific changes they should make. The comment is vague and lacks explicit instructions, leaving the authors uncertain about what actions to take. Since the comment does not provide concrete steps or suggestions for improvement, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment indicates that some choices are not justified or clear, but it does not specify which choices are in question or provide details on what aspects are unclear. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment does not provide any guidance on how to address these issues, leaving the authors without a clear understanding of what needs to be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some choices are not justified or clear, but it does not provide any specific examples or reasoning to support this claim. The comment lacks detailed evidence or references to substantiate the assertion, making it difficult for the authors to understand which choices are in question or why they are unclear. Without specific examples or explanations, the claim remains unverifiable, as it does not provide enough information for the authors to address the issue effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of justification or clarity in some choices made in the paper, but it does not specify which choices are in question or provide examples. Additionally, it does not offer suggestions or guidance on how the authors might address these issues or improve their draft. Without specific feedback or actionable advice, the comment does not provide the authors with a clear path to enhance their work. Therefore, it is rated as barely helpful, as it highlights a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that make pruning laborious. It highlights the challenge of tuning these parameters due to their impact on both FLOPs and accuracy, which can lead to multiple solutions with the same FLOPs. The reviewer suggests that the paper lacks clarity on how the grid search is conducted and requests detailed discussions on this issue for reproducibility. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these concerns or what specific details should be included in the discussions. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed information about the grid search process, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameter tuning, specifically mentioning the presence of two hyperparameters that make pruning laborious. It highlights the challenge of tuning these parameters due to their impact on both FLOPs and accuracy, which can lead to multiple solutions with the same FLOPs. The reviewer notes that the current presentation lacks clarity on how the grid search is conducted and requests detailed discussions regarding this issue for reproducibility. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where hyperparameters and grid search are discussed. The comment is specific in detailing the issue with hyperparameter tuning and the need for detailed discussions. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that make pruning laborious. It highlights the challenge of tuning these parameters due to their impact on both FLOPs and accuracy, which can lead to multiple solutions with the same FLOPs. The reviewer points out that the current presentation lacks clarity on how the grid search is conducted and requests detailed discussions regarding this issue for reproducibility. While the comment identifies a potential issue with the methodology, it lacks specific examples or references to support the claim about the complexity of tuning. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding hyperparameter tuning, noting that the paper has two hyperparameters that make pruning laborious. It highlights the challenge of tuning these parameters due to their impact on both FLOPs and accuracy, which can lead to multiple solutions with the same FLOPs. The reviewer points out that the current presentation lacks clarity on how the grid search is conducted and requests detailed discussions regarding this issue for reproducibility. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a detailed analysis of the hyperparameter tuning process. However, the comment could be more helpful if it offered suggestions on how to present this information or what specific aspects of the grid search should be discussed. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and reproducibility of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, and it questions the difference between known and unknown attacks. While the comment identifies a gap in the presentation, it does not explicitly instruct the authors to include these accuracies or clarify the distinction between known and unknown attacks. The action is implicit, as the authors can infer that they need to provide the missing information, but it lacks concrete guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: the accuracies of the target model using different defenses against the FGSM attack and the distinction between known and unknown attacks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, which makes it unclear whether known attacks differ from unknown attacks. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This omission makes it unclear whether known attacks differ from unknown attacks. The comment is clear and actionable, as it points out a gap in the presentation that the authors can address to improve the clarity and completeness of their results. However, it could be more helpful if it suggested ways to present this information or discussed the potential impact of this omission on the interpretation of the results. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. This provides a clear and direct action for the authors to take, making the comment highly actionable. The suggestion is specific and offers a concrete solution to improve the readability of the figures, giving the authors a clear path forward in addressing the issue.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not specify which figures are problematic, making it weakly grounded as the authors cannot confidently determine which parts of the paper are being addressed. The comment is specific in its suggestion to use a log-scale, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not provide any specific examples or reasoning to support why a log-scale would improve readability. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim borderline verifiable. The authors would need to infer the reasoning behind the recommendation, which adds to the complexity of addressing the feedback.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures in the paper, noting that they are difficult to read. It provides a clear and actionable suggestion by recommending the use of a log-scale for the y-axis to improve readability. This feedback is valuable as it offers a concrete step for the authors to enhance the clarity and effectiveness of their figures, which can significantly impact the overall quality and accessibility of the paper. However, the comment could be more helpful if it explained why a log-scale might be beneficial or provided examples of other figures that have successfully used this scale. Despite this, the feedback is mostly helpful as it directs the authors toward a specific improvement that can be easily implemented.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the validation of the proposed method, specifically noting that the claim about the usefulness of augmentation information for \"flowers and birds\" was not supported by experimental results. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. While the comment explicitly states the need for validation and provides specific examples of datasets, it does not offer detailed guidance on how to conduct the validation or what specific metrics to use. The action is clear but somewhat vague in terms of execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"case where \"augmentation information is useful\" as claimed by the authors,\" and it specifies the example cases of flowers and birds, which are mentioned in the Introduction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is the validation of the proposed method using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method was motivated by the usefulness of augmentation information for \"flowers and birds,\" as claimed in the Introduction, but this claim is not supported by experimental validation. The reviewer suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. While the comment provides a logical reasoning for the need for validation, it lacks specific examples or references to substantiate the claim. This makes the comment somewhat verifiable, as it highlights a gap in the validation process but does not provide detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the validation of the proposed method, specifically noting that the claim about the usefulness of augmentation information for \"flowers and birds\" was not supported by experimental results. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. This feedback is clear and actionable, providing the authors with a specific direction for improving their work by conducting additional experiments. However, the comment could be more helpful if it offered additional guidance on how to effectively use these datasets or what specific metrics to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim that opponents will evolve toward the Nash equilibrium and the lack of theoretical analyses or empirical evidence to support this claim. It points out that the empirical evaluations do not demonstrate convergence to Nash equilibrium. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific analyses or empirical evaluations to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to provide more evidence or analysis, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s claim about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of theoretical analyses and empirical evidence supporting this claim, and it questions whether GEMS converges to Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that opponents will evolve toward the Nash equilibrium. However, the comment does not provide specific examples or references to substantiate this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of theoretical analyses and empirical evidence to support the claim that opponents will evolve toward the Nash equilibrium. It questions whether GEMS converges to Nash equilibrium, which is a critical aspect of the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or empirical evaluations. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of theoretical analyses and empirical evidence supporting the claim that opponents will evolve toward the Nash equilibrium. It questions whether GEMS converges to Nash equilibrium, indicating a gap in the paper\\'s argument. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific analyses or empirical evaluations to conduct. The action is implicit and somewhat vague, as the authors can infer that they need to provide more evidence or analysis, but they are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s claim about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of theoretical analyses and empirical evidence supporting this claim, and it questions whether GEMS converges to Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that opponents will evolve toward the Nash equilibrium. However, it does not provide specific examples or references to substantiate this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of theoretical analyses and empirical evidence to support the claim that opponents will evolve toward the Nash equilibrium. It questions whether GEMS converges to Nash equilibrium, which is a critical aspect of the paper\\'s claims. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or empirical evaluations to conduct. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_r"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with Equation (1), including its unclear purpose, the definition of the optimization variable, and the unusual constraints notation. Each point provides a clear and explicit action for the authors to take: clarify the purpose of the equation, correct the definition of the optimization variable, and address the unusual constraints notation. These actions are concrete and provide specific guidance on how to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with Equation (1), including the unclear purpose, the definition of the optimization variable, and the unusual constraints notation. This provides clear guidance on what needs to be addressed in the equation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of observations and questions about Equation (1), which are factual statements rather than claims or opinions. They do not express subjective judgments or require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies several specific issues with Equation (1), providing clear and actionable feedback. It questions the purpose of the equation, suggesting that it might be mixing the definition of a loss function with an optimization problem. It also points out the unusual definition of the optimization variable \"x\" as being in R^n, which might be intended to be in R^k. Additionally, it notes the unusual constraints notation \"s.t. C(A, x)\". By addressing these points, the comment helps the authors clarify and improve the clarity of their equation, making it more effective. However, the comment could be more helpful if it provided suggestions on how to resolve these issues or offered alternative ways to present the equation. Overall, the feedback is mostly helpful as it provides clear guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the strange observation that including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse. The reviewer explicitly asks for more discussions or explanations on this phenomenon. While the comment does not provide specific guidance on what kind of discussions or explanations are needed, it clearly identifies an area that requires further elaboration. The action is explicit but somewhat vague, as the authors know they need to provide more context but may not be entirely sure of the exact details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the strange observation that including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse, and it requests more discussions or explanations on this phenomenon. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about a specific observation in the paper, noting that including the collected LIV-EN parallel data for fine-tuning results in a worse performance of the NMT system. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this observation is strange or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about an unexpected observation in the paper, where including the collected LIV-EN parallel data for fine-tuning results in a worse performance of the NMT system. It explicitly asks for more discussions or explanations on this phenomenon, which is a clear and actionable request for the authors to provide additional context or analysis. This feedback is valuable as it prompts the authors to address a potential weakness in their work and encourages them to clarify their findings. However, the comment could be more helpful if it suggested specific areas or methods for further exploration or analysis. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that requires clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" and notes that these conjectures lack adequate reasoning or references. However, it does not provide specific guidance on how the authors should address this issue or what additional reasoning or references are needed. The comment implies that the authors should provide more evidence or references to support their claims, but it does not offer concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding \"fine-tuning as exposure of existing capabilities in LMs,\" suggesting that the conjectures are unsubstantiated and lack adequate reasoning or references. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in identifying the issue with the unsubstantiated conjectures and the need for adequate reasoning or references. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs\" without adequate reasoning or references. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references or detailed explanations, making it difficult for the authors to understand and address the issue. As a result, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it lacks depth and does not provide specific examples or suggestions on how the authors might substantiate their claims or address the issue. Without actionable guidance or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial, given the use of FACodec. While the comment implies that the authors should consider adding NaturalSpeech 3 to their baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include NaturalSpeech 3 and understand how to integrate it into their study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks, given the use of FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where NaturalSpeech 3 should be included. This lack of explicit grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to include NaturalSpeech 3 as a baseline, but without clear grounding, it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial, given the use of FACodec. However, the comment does not provide any reasoning or evidence to support why NaturalSpeech 3 would be a more suitable baseline or how it would improve the study. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial, given the use of FACodec. This feedback is somewhat helpful as it provides a specific suggestion for improvement by recommending a particular baseline to consider. However, the comment lacks depth and does not explain why NaturalSpeech 3 would be a better choice or how it would enhance the study. To be more helpful, the comment could include additional reasoning or evidence supporting the suggestion. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experimental setting, specifically regarding the use of the first 4 weeks of data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to ensure fairness. The action is implicit and somewhat vague, as the authors are left to infer that they need to adjust their experimental setup to include the first 4 weeks of data for training. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the experimental setting, suggesting that the proposed method should use the first 4 weeks of data for training, while other methods should use them for inference. This provides a clear and specific issue regarding the fairness of the experimental setting. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental setting, specifically regarding the use of the first 4 weeks of data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current setting may not be fair. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed justification or evidence for why the current setting is unfair. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides a logical basis but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experimental setting, specifically regarding the use of the first 4 weeks of data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. This feedback is somewhat helpful as it identifies a potential issue with the experimental design that could affect the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their experimental setup. To be more helpful, the comment could provide additional context or propose alternative approaches to ensure fairness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the fairness of the experimental setting, specifically regarding the use of the first 4 weeks of data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to ensure fairness. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the experimental setting, suggesting that the proposed method should use the first 4 weeks of data for training, while other methods should use them for inference. This provides a clear and specific issue regarding the fairness of the experimental setting. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experimental setting, specifically regarding the use of the first 4 weeks of data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current setting may not be fair. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed justification or evidence for why the current setting is unfair. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides a logical basis but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the fairness of the experimental setting"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This is a clear and direct action, providing specific details on what needs to be included in the results section. The authors know exactly what additional information is required to enhance their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or a specific experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing what needs to be reported, but it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not provide any justification or reasoning for why this information is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This feedback is specific and offers a concrete way for the authors to enhance their paper by including additional data that could strengthen their findings. By addressing this suggestion, the authors can provide a more comprehensive analysis of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of sequential bias on the VisDial results. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should conduct an analysis, provide additional experiments, or discuss the implications of sequential bias in their results. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the same point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the impact of sequential bias on the VisDial results. This provides clear guidance on what aspect of the paper needs further explanation or analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of sequential bias on the VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the impact of sequential bias on the VisDial results. While it identifies a potential area for further exploration or clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the results might be affected by sequential bias. The comment lacks depth and actionable advice, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but not enough to be actionable.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. However, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy or improve their draft. The comment raises a concern but lacks actionable advice, leaving the authors uncertain about what steps to take to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results on the ImageNet-LT dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation that LTAP achieves a larger performance improvement for head classes than for tail classes, which contradicts the stated goal of strengthening parameter protection for tail classes. This provides clear guidance on what aspect of the results needs further clarification or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the ImageNet-LT dataset contradict the stated goal of LTAP, which is to strengthen parameter protection for tail classes. The comment provides a logical reasoning by comparing LTAP\\'s performance improvement for head classes versus tail classes, suggesting a discrepancy. However, it lacks specific examples or detailed analysis to fully substantiate the claim, making it somewhat verifiable. The authors would need to further investigate the experimental results to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results on the ImageNet-LT dataset and the stated goal of LTAP, which is to strengthen parameter protection for tail classes. It highlights that LTAP achieves a larger performance improvement for head classes than for tail classes, suggesting a contradiction. This feedback is valuable as it points out a potential weakness in the paper\\'s claims and encourages the authors to address this discrepancy. However, the comment could be more helpful if it provided suggestions on how to resolve this contradiction or further explored the implications of this finding. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reliance on LLM-based evaluation for reward computation, which may introduce biases or inconsistencies in the quality assessment of generated documentations. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete steps or recommendations for improvement, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the reward computation, which relies on LLM-based evaluation by prompting. This allows the authors to identify the relevant part of the paper, providing full grounding. The comment is specific as it details the potential issues with relying on LLMs for evaluation, such as introducing biases or inconsistencies in the quality assessment of generated documentations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. The claim is supported by logical reasoning, as it points out the potential for biases or inconsistencies in the quality assessment of generated documentations due to the reliance on LLMs. However, the comment lacks specific examples or references to external works that might substantiate the claim further. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires additional evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance on LLM-based evaluation for reward computation, which could introduce biases or inconsistencies in the quality assessment of generated documentations. This is a relevant and important point that the authors should consider. However, the comment lacks specific suggestions or guidance on how to address this concern, such as alternative evaluation methods or ways to mitigate potential biases. While it highlights a critical area for improvement, the feedback could be more actionable and comprehensive. Therefore, the comment is somewhat helpful, as it provides insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples to demonstrate the effectiveness of the described process and compare it to state-of-the-art (SOTA) performance from referenced papers. It also mentions that Equation 12 might contribute to this, but it is unclear. While the comment implies that the authors should clarify the effectiveness of their process, it does not provide specific guidance on how to do so or what aspects of the process need further clarification. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effectiveness of the described process is unclear and suggests using empirical examples and comparing to SOTA performance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the described process is surprising and suggests using empirical examples and comparing to SOTA performance. However, it does not provide specific examples or references to support the claim that the process is surprising or unclear. The mention of Equation 12 as possibly contributing to this issue is not elaborated upon, leaving the authors without clear guidance on how to address the concern. The lack of detailed justification or examples makes the claim borderline verifiable, as it provides some direction but requires more detailed support to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the effectiveness of the described process is surprising and suggests using empirical examples and comparing to state-of-the-art (SOTA) performance. It also mentions that Equation 12 might contribute to this, but it is unclear. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a method to enhance the clarity and substantiation of the paper\\'s claims. However, the comment could be more helpful if it provided specific guidance on how to use empirical examples or how to clarify Equation 12. Overall, the comment offers some direction but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem and provides a detailed explanation of why Assumption 1 limits the adversary\\'s ability to pick arbitrary samples. It explains that after removal, the remaining pairs still suffice for accurate recovery, given that m is proportional to k log n. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1\" and provides a detailed explanation of the problem\\'s difficulty, specifically addressing the issue of the adversary\\'s limitations. It also provides a specific example of how the assumption affects the problem, making it clear to the authors where the issue lies. The comment is specific in detailing the reasoning behind the difficulty of the problem, providing a clear path for the authors to address the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of why the assumption limits the adversary\\'s ability to pick arbitrary samples and how this affects the problem. The reviewer explains that after removal, the remaining pairs still suffice for accurate recovery, given a specific condition on m. This explanation is thorough and provides a logical reasoning for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of why the assumption limits the adversary\\'s ability to pick arbitrary samples and how this affects the problem. The reviewer explains that after removal, the remaining pairs still suffice for accurate recovery, given a specific condition on m. This feedback is clear and actionable, as it guides the authors to reconsider their assumptions and potentially revise their approach to address the identified issue. However, the comment could be more helpful if it offered suggestions on how to overcome this limitation or alternative approaches to consider. Overall, the comment is mostly helpful as it provides valuable insights and direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the difficulty of the problem and provides a detailed explanation of why Assumption 1 limits the adversary\\'s ability to pick arbitrary samples. It explains that after removal, the remaining pairs still suffice for accurate recovery, given a specific condition on m. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern or improve their draft. Without actionable guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 1\" and provides a detailed explanation of the problem\\'s difficulty, specifically addressing the issue of the adversary\\'s limitations. It explains why the assumption limits the adversary\\'s ability to pick arbitrary samples and provides a specific example of how the problem remains manageable after removal. This detailed explanation makes it clear to the authors where the issue lies and how it affects the problem. The comment is specific in detailing the reasoning behind the difficulty of the problem, providing a clear path for the authors to address the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of why the assumption limits the adversary\\'s ability to pick arbitrary samples and how this affects the problem. The reviewer explains that after removal, the remaining pairs still suffice for accurate recovery, given a specific condition on m. This detailed explanation provides a logical reasoning for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of why the assumption limits the adversary\\'s ability to pick arbitrary samples and how this affects the problem. The reviewer explains that after removal, the remaining pairs still suffice for accurate recovery, given a specific condition on m. This feedback is clear and actionable, as it guides the authors to reconsider their assumptions and potentially"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between Figure 1 and the last two columns of Table 1, specifically noting that NNGS increases as k increases in Figure 1, which contradicts the comparison in Table 1. However, the comment does not provide explicit guidance on how the authors should resolve this contradiction or suggest specific actions to address it. The authors are left to infer that they need to reconcile the findings in Figure 1 with those in Table 1, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the contradiction between the relationship illustrated in Figure 1 and the comparison in the last two columns of Table 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 1 illustrates a contradiction with the comparison in the last two columns of Table 1, specifically regarding the relationship between NNGS and the number of selected k-nearest neighbors. However, the comment does not provide specific details or examples to support this claim, such as exact values or comparisons between the figures and table. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific contradiction between Figure 1 and the last two columns of Table 1, noting that the relationship between NNGS and the number of selected k-nearest neighbors is illustrated in Figure 1, while the comparison in Table 1 suggests a different trend. This feedback is clear and actionable, as it points out a potential error or inconsistency that the authors need to address. By highlighting this contradiction, the reviewer provides a concrete step for the authors to take in revising their figures and tables to ensure consistency. However, the comment could be more helpful if it offered suggestions on how to resolve the contradiction or provided additional context for understanding the issue. Overall, the comment is mostly helpful, as it effectively directs the authors\\' attention to a critical area needing revision.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks and asks for clarification on the impact of a large number of tasks, specifically on the set of shared parameters. It also requests that the authors address the question regarding the effect of the number of tasks on the proposed approach. While the comment implies that the authors should provide additional analysis or discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question in their response. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. It also mentions the experiments, which provide results for a limited number of tasks (up to 20). The comment is specific in its inquiry about the effect of the number of tasks on the proposed approach. However, it does not explicitly mention which part of the paper this concern is based on, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, suggesting that it might pose a challenge similar to multitask learning. The reviewer asks for clarification on the impact of a large number of tasks, specifically on the set of shared parameters, and requests that the authors address this question. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the challenge posed by a large number of tasks. The request for clarification is clear, but the initial claim is not fully substantiated, making the comment somewhat verifiable. Therefore, the feedback is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, suggesting that it might pose a challenge similar to multitask learning. It asks for clarification on the impact of a large number of tasks, specifically on the set of shared parameters, and requests that the authors address this question. This feedback is somewhat helpful as it identifies a potential area of concern and prompts the authors to consider the scalability of their approach. However, it could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that the eyetracking data selection/filtering is perplexing, suggesting that everything is analyzed with some exclusions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the analysis. The comment lacks actionable details, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"eyetracking data selection/filtering,\" which implies that it is addressing a specific aspect of the paper related to data analysis. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it highlights the perplexity of the eyetracking data selection/filtering, suggesting that everything is analyzed with some exclusions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes a perceived issue with the eyetracking data selection/filtering, stating that \"it looks like everything is analyzed (e.g., regressions to earlier parts of the sentence) with some exclusions.\" However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the eyetracking data is perplexing or problematic. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the eyetracking data selection/filtering, noting that it appears everything is analyzed with some exclusions. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the credibility of the Appendix results for InitNO, noting that while InitNO reported improved text-image alignment on StableDiffusion-v1-4, Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the credibility of their results. Without specific suggestions or steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the credibility of the Appendix results for InitNO, specifically mentioning the comparison with Table 6. However, it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the credibility of the results, as it points out a discrepancy between the reported improvements in InitNO and the actual results shown in Table 6. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the credibility of Appendix results for InitNO is questionable, citing a discrepancy between the reported improvements in InitNO and the actual results shown in Table 6. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as explaining how the reported improvements are inconsistent with the data presented in Table 6. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the Appendix results for InitNO, noting a discrepancy between the reported improvements in text-image alignment and the actual results shown in Table 6. This feedback is somewhat helpful as it identifies a potential issue with the credibility of the results, prompting the authors to reconsider or clarify the data presented in the Appendix. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the credibility of their results. To be more helpful, the comment could provide additional context or suggest ways to verify the results or present the data more clearly. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the credibility of the Appendix results for InitNO, noting a discrepancy between the reported improvements in text-image alignment and the actual results shown in Table 6. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. Without specific guidance or suggestions on how to improve the credibility of the results or clarify the discrepancy, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the credibility of the Appendix results for InitNO, specifically mentioning the comparison with Table 6. However, it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the credibility of the results, as it points out a discrepancy between the reported improvements in InitNO and the actual results shown in Table 6. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the credibility of Appendix results for InitNO is questionable, citing a discrepancy between the reported improvements in text-image alignment and the actual results shown in Table 6. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the Appendix results for InitNO, noting a discrepancy between the reported improvements in text-image alignment and the actual results shown in Table 6. This feedback is somewhat helpful as it identifies a potential issue with the credibility of the results, prompting the authors to reconsider or clarify the data presented in the Appendix. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the credibility of their results. Without additional context or actionable advice, the authors are left with a general insight but no clear path forward. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the credibility"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could benefit from additional editing, particularly from a language-usage and type perspective. It also points out that the equations can become unwieldy due to the use of sub/superscripts and suggests considering dropping some of them for convenience. The comment provides explicit actions for the authors to take, such as editing the writing and potentially simplifying the equations. The feedback is clear and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the writing and equations in the paper, suggesting that the writing could benefit from additional editing and that the notation in the equations might be unwieldy. However, it does not specify which sections or equations are problematic, making it weakly grounded. The comment is specific in suggesting ways to improve the writing and equations, such as considering dropping sub/superscripts for convenience. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly from a language-usage and type perspective. It also notes that the equations can become unwieldy due to the use of sub/superscripts and suggests considering dropping some of them for convenience. While the comment provides some reasoning, it lacks specific examples or detailed explanations of where the writing is uneven or where the equations become unwieldy. This makes the claim somewhat verifiable, as the authors would need to make an effort to identify and address the issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement: the writing and the equations. It suggests that the writing could benefit from additional editing, particularly from a language-usage and type perspective, and provides a specific suggestion to consider dropping some sub/superscripts for convenience. This feedback is clear and actionable, offering the authors concrete steps to enhance the clarity and readability of their draft. However, the comment could be more helpful if it provided examples of where the writing is uneven or where the equations become unwieldy, which would further guide the authors in making improvements. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main issues. First, it suggests that the authors should explain the high cost of image acquisition and the type of manual collection used. This is an explicit suggestion with concrete details on what the authors need to address. Second, it points out a minor issue with the line number 79, suggesting that it contains two questions and asking for clarification on \"regulatory requirements\" mentioned on line 263. While the latter part is a minor comment, the first part provides clear and actionable guidance for the authors to improve their draft. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (79 and 263) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed: explaining the high cost of image acquisition and the type of manual collection used, as well as clarifying the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" This provides detailed feedback on how to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the dataset is small relative to the development cost and suggests that the authors should explain the cost and manual collection methods. This claim is somewhat verifiable as it highlights a potential issue but lacks specific details or references to support the assertion about the cost. The second part is a request for clarification on a minor grammatical issue and a question about regulatory requirements, which are not claims but rather requests for information. Therefore, the overall verifiability of the comment is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of actionable and non-actionable feedback. It highlights a specific issue with the dataset, noting that it is small relative to the development cost and suggesting that the authors explain the cost and manual collection methods. This is a clear and actionable suggestion that can help the authors improve their draft by justifying their dataset acquisition process. Additionally, the comment identifies a minor grammatical issue with the line number 79 and asks for clarification on \"regulatory requirements,\" which is also helpful. However, the comment could be more helpful if it provided additional context or suggestions on how to address the dataset size issue or the regulatory requirements. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point raises two main issues. First, it suggests that the authors should explain the high cost of image acquisition and the type of manual collection used, which is an explicit and concrete suggestion. Second, it points out a minor issue with the line number 79, suggesting that it contains two questions and asking for clarification on \"regulatory requirements.\" This part is also explicit and provides clear guidance on what needs to be addressed. Therefore, the comment is mostly actionable, as it provides specific and actionable feedback for the authors to improve their draft.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (79 and 263) in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear guidance on what needs to be addressed: explaining the high cost of image acquisition and the type of manual collection used, as well as clarifying the content of \"regulatory requirements\" and what is considered \"politically sensitive.\" This provides detailed feedback on how to improve the draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the dataset is small relative to the development cost and suggests that the authors should explain the cost and manual collection methods. This claim is somewhat verifiable as it highlights a potential issue but lacks specific details or references to support the assertion about the cost. The second part is a request for clarification on a minor grammatical issue and a question about regulatory requirements, which are not claims but rather requests for information. Therefore, the overall verifiability of the comment is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a mix of actionable and non-actionable feedback. It highlights a specific issue with the dataset, noting that it is small relative to the development cost and suggesting that the authors explain the cost and manual collection methods. This is a clear and actionable suggestion that can help the authors improve their draft by justifying their dataset"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the generation of the third column in Fig. 7, noting that the visualizations appear unnormalized. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should clarify the generation process, provide additional details, or make changes to the visualizations. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the third column of Fig. 7, noting that the visualizations appear unnormalized. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about the generation of the third column in Fig. 7, noting that the visualizations appear unnormalized. However, it does not provide any supporting evidence, reasoning, or examples to justify why the visualizations are unnormalized or how this affects the interpretation of the data. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses curiosity about the generation of the third column in Fig. 7, noting that the visualizations appear unnormalized. While it identifies a potential issue with the visual presentation, it lacks specific guidance or suggestions for improvement. The authors are left with a general observation but no actionable steps to address the concern. The feedback is somewhat helpful as it highlights an area of potential confusion or misinterpretation, but it does not provide detailed guidance on how to resolve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two main issues: the heuristic nature of the assignment entropy maximization objective and the lack of evaluation of its advantages in the ablation experiment. It also points out the absence of discussion on potential negative societal impacts. While the comment highlights areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should conduct a more thorough evaluation of the assignment entropy maximization and discuss potential societal impacts, but without specific instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"assignment entropy maximization\" objective and the \"ablation experiment\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the assignment entropy maximization objective, suggesting that the advantages of using it should be evaluated in the ablation experiment. Additionally, it points out the absence of discussion on potential negative societal impacts. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assignment entropy maximization objective is regarded as the objective to optimize the matching of the association graph and multi-task, but the investigation is heuristic. The comment suggests that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment and discuss potential negative societal impacts. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the heuristic nature of the investigation. The suggestion to evaluate the advantages of assignment entropy maximization is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement in the paper. First, it points out that the assignment entropy maximization objective is regarded as the objective to optimize the matching of the association graph and multi-task, but the investigation is heuristic. This suggests that the authors should provide a more rigorous evaluation of the benefits of using assignment entropy maximization. Second, the comment notes that the authors did not discuss potential negative societal impacts of their work, which is an important consideration for any research. While the comment highlights these areas for improvement, it lacks specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it provides direction for enhancing the paper, but it could be more actionable with detailed advice or examples.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two main areas for improvement: the heuristic nature of the assignment entropy maximization objective and the lack of evaluation of its advantages in the ablation experiment. It also points out the absence of discussion on potential negative societal impacts. While the comment highlights these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to conduct a more thorough evaluation of the assignment entropy maximization and discuss potential societal impacts, but without specific instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"assignment entropy maximization\" objective and the \"ablation experiment\" section, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the assignment entropy maximization objective, suggesting that the advantages of using it should be evaluated in the ablation experiment. Additionally, it points out the absence of discussion on potential negative societal impacts. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the assignment entropy maximization objective is regarded as the objective to optimize the matching of the association graph and multi-task, but the investigation is heuristic. It suggests that the authors should evaluate the advantages of using assignment entropy maximization in the ablation experiment and discuss potential negative societal impacts. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the heuristic nature of the investigation. The suggestion to evaluate the advantages of assignment entropy maximization is somewhat verifiable, as it provides a direction for improvement but lacks detailed justification. The absence of discussion on potential negative societal impacts is also noted, but without specific examples or references, it remains somewhat verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited number of baseline models in the experimental section. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. The comment lacks actionable guidance, such as recommending the inclusion of additional baseline models or suggesting specific models to consider. Without clear instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experimental section, noting that there is only one baseline model. However, it does not specify which part of the experimental section this issue pertains to, such as a particular table or section where the baseline models are discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in identifying the issue with the limited number of baseline models, it is not fully grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the validity or comprehensiveness of the study. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental section, noting that there is only one baseline model. This feedback is valuable as it highlights a potential limitation in the experimental setup that could affect the robustness and comprehensiveness of the study. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue, such as recommending additional baseline models or explaining the rationale behind the choice of the single baseline model. While it points out a critical area for improvement, the feedback could be more helpful with additional guidance or suggestions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of certain baselines and literature comparisons in the results section, specifically mentioning traditional quantization-aware training (QAT) methods like LSQ and LSQ+, as well as LLM-based QAT work and recent post-training quantization (PTQ) baselines like SpinQuant. The reviewer suggests that including these comparisons would be beneficial, particularly in understanding the trade-offs between using extra memory and relying on fine-tuning low-rank adapters. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to incorporate these comparisons or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors can infer the need for additional comparisons but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the comparisons, such as traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. The comment also provides a rationale for including these comparisons, suggesting that understanding the trade-offs between using extra memory and fine-tuning low-rank adapters is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain baselines and literature comparisons are missing, such as traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. The reviewer suggests that including these comparisons would be beneficial, particularly in understanding the trade-offs between using extra memory and relying on fine-tuning low-rank adapters. While the comment identifies specific areas for improvement, it lacks detailed justification or references to support the claim that these comparisons are necessary. The suggestion is somewhat verifiable, as it provides a logical rationale for the inclusion of these comparisons, but it could be strengthened with more explicit reasoning or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by pointing out the absence of certain baselines and literature comparisons, such as traditional quantization-aware training (QAT) methods like LSQ and LSQ+, other LLM-based QAT work, and recent post-training quantization (PTQ) baselines like SpinQuant. The reviewer suggests that including these comparisons would be beneficial, particularly in understanding the trade-offs between using extra memory and relying on fine-tuning low-rank adapters. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their results section. However, the comment could be more helpful if it offered additional insights or suggestions on how to present these comparisons effectively. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about defining attributes and requests more detailed instructions. While it explicitly asks for clarification on the definition of attributes and the differences between them, it does not provide specific guidance on how to address this issue. The authors are left to infer that they need to provide more detailed instructions, but the comment lacks concrete steps or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about defining attributes and requests more detailed instructions, which is a specific issue. However, it does not specify which part of the paper this question pertains to, such as a particular section or paragraph where the definition of attributes is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in its request for more detailed instructions on defining attributes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the definition of attributes and the differences between them. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the definition of attributes and requests more detailed instructions. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors might address this issue. Without actionable suggestions or examples, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it points out a potential weakness but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the theory in the paper\\'s ability to predict the robustness of models to adversarial perturbations. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their theory. There is no guidance on what specific aspects of the theory could be revised or how the authors might enhance its predictive capabilities. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the theory in the paper\\'s ability to predict the robustness of models to adversarial perturbations. However, it does not specify which part of the paper this theory is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the theory are insufficient or how it could be improved. Without clear grounding or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern about the theory in the paper\\'s ability to predict the robustness of models to adversarial perturbations. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks specific details or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to improve their work. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the theory presented in the paper, specifically questioning its ability to predict whether a model can be trained to be robust against adversarial perturbations. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve their theory. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes into play. While the comment highlights a lack of clarity, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify the definition of \"scenario\" and its relation to \"agnostic,\" but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes into play. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification on the definition of \"scenario\" and its relation to \"agnostic,\" providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and the inclusion of \"agnostic\" part. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes into play. While it identifies a potential area of confusion, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect. The comment highlights a need for clarification but does not offer actionable feedback or examples to help the authors address the issue. Therefore, it is somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the naming of the method as \"Maestro\" and notes that it is never introduced. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this naming should be changed, why it is confusing, or how it could be clarified. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the naming of the method as \"Maestro\" and notes that it is never introduced. However, it does not specify which part of the paper this naming issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the method is mentioned, the comment lacks full grounding. It is specific in questioning the naming choice but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the naming of the method as \"Maestro\" and notes that it is never introduced. However, it does not provide any supporting evidence, reasoning, or context to justify why this naming choice is confusing or inappropriate. Without additional explanation or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the naming of the method as \"Maestro\" and notes that it is never introduced. While it points out a potential issue with the naming, it does not provide any further context or suggestions on why this naming choice might be confusing or problematic. Without additional explanation or guidance, the authors are left without a clear understanding of how to address this issue or improve the naming convention. Therefore, the comment is barely helpful, as it identifies a potential problem but lacks depth and actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define what \"best\" means in the context of the paper, specifically regarding the \"best\" candidate. It provides a clear action by asking for clarification on whether \"best\" refers to candidates that are most relevant for prediction, those with the highest confidence scores, or other criteria. This feedback is direct and provides concrete guidance on how to improve the clarity of the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 5\" and \"the best candidate,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a definition of \"best\" within the context of the paper, including whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or other criteria. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the definition of \"best\" in the context of the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of ambiguity in the paper, namely the definition of \"best\" candidate on page 5. By asking for clarification on what \"best\" means within the context of the paper, the comment provides clear and actionable feedback. This guidance helps the authors to improve the clarity and precision of their terminology, which is crucial for understanding and interpreting the results. The comment is specific and directly addresses a potential source of confusion, offering a straightforward way for the authors to enhance the comprehensibility of their work. Therefore, it deserves a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some claims in the paper are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to make the claims more accurate. The feedback lacks concrete instructions or examples, leaving the authors uncertain about how to revise their claims effectively. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the claims made in the paper, particularly regarding the proposed method\\'s consideration of feed-forward layers. However, it does not specify which parts of the paper contain these over-claims, making it weakly grounded. The comment is specific in identifying the issue of over-claiming, but without explicit references to sections or figures, the authors may struggle to pinpoint where these issues occur. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some points are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the point.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claims made in the paper, noting that some points are over-claimed. It highlights a particular inconsistency, namely that the proposed method does not consider feed-forward layers but is described as if it does. This feedback is somewhat helpful as it points out a potential area for clarification or correction. However, it lacks depth and does not provide specific guidance on how the authors might address this issue or improve their claims. Without actionable advice or suggestions for revision, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the experimental design, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide explicit guidance on how the authors should address this issue or what changes are needed to improve the clarity of the experimental design. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"no variations\" and \"Up to 18 games\" finetuning methods, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the experimental design. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment lacks detailed reasoning or examples to support why these methods are unclearly motivated. Without specific evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental design, noting that the \"no variations\" and \"Up to 18 games\" finetuning methods are not clearly motivated. This feedback is somewhat helpful as it highlights a potential weakness in the paper that the authors need to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the experimental design. Without actionable advice or examples, the authors may find it challenging to effectively address the issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to evaluate their method performance under missing modality cases, specifically by testing the method on a dataset with different missing ratios. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment also references specific works, [A] and [B], which could provide additional guidance on how to approach this evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: evaluating the method performance under missing modality cases, such as testing sets with different missing ratios. The comment further references specific works, [A] and [B], which could provide additional guidance on how to approach this evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only the \"Miss-V\" and \"Miss-A\" results are shown in table 1/2, and it is necessary to evaluate the method performance under missing modality cases. The reviewer suggests testing the method on a dataset with different missing ratios. While the comment provides a logical reasoning for the need to expand the evaluation, it lacks specific examples or references to support the claim fully. The suggestion is somewhat verifiable, as it highlights a potential limitation in the current evaluation but does not provide detailed guidance on how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the evaluation of the method, noting that only the \"Miss-V\" and \"Miss-A\" results are shown in table 1/2. It highlights the need to evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. By referencing specific works, [A] and [B], the comment provides a clear direction for the authors to expand their evaluation. This feedback is actionable and offers a concrete suggestion for improvement, making it mostly helpful. However, it could be further improved by providing more detailed guidance on how to implement this evaluation or by suggesting specific metrics or approaches to consider. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. While the action is explicit, it lacks concrete guidance on how to conduct the ablation study or what specific aspects should be examined. The authors are informed of the need for an ablation study but are left without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an ablation study on the effect of using image features, but it does not specify which part of the paper this suggestion pertains to. The authors might infer that it relates to the experimental section or results, but this inference is not direct. The comment is specific in suggesting an ablation study on the effect of image features, but it lacks grounding as it does not clearly identify the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. However, the comment does not provide any specific reasoning or evidence to support why this ablation study is necessary or how it would benefit the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper. However, it lacks specificity and does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be examined. While it offers a direction for enhancing the paper, the comment could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what steps they should consider to test the approach in challenging settings. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as a particular experiment or section discussing the approach. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its inquiry about the approach\\'s performance in challenging settings, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might affect the approach. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. This feedback highlights an important aspect that the authors should consider when evaluating their approach, which could be a significant factor in determining its applicability and robustness. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or what additional experiments or analyses could be conducted to test the approach in challenging settings. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should conduct additional experiments, explore different settings, or provide more detailed analysis to address this concern. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as a particular experiment or section discussing the approach. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not direct. The comment is specific in its inquiry about the approach\\'s performance in challenging settings, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might affect the approach. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. This is a valid concern that the authors should consider, as it could impact the applicability and robustness of their approach. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or what additional experiments or analyses could be conducted to test the approach in challenging settings. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in making improvements.\", 'help"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed and that it cannot be claimed as non-identifiable due to insufficient data. However, the comment does not provide any explicit or implicit actions for the authors to take to correct this misunderstanding. It lacks guidance on how the authors should address this issue or what steps they should take to improve their understanding. As a result, the comment is unactionable, as it does not offer any actionable advice for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the authors\\' understanding of identifiability, which is a property of a model assuming infinite data can be observed. However, it does not specify which part of the paper this misunderstanding is discussed in, making it weakly grounded. The comment is specific in detailing what is wrong with the authors\\' understanding, providing a clear explanation of the correct concept of identifiability. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed. The reviewer provides a logical explanation by explaining that a model cannot be claimed as non-identifiable due to insufficient data. This reasoning is clear and supports the claim, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to further substantiate the argument. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the authors\\' understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed. The reviewer clarifies that a model cannot be claimed as non-identifiable due to insufficient data. This feedback is valuable as it provides a clear correction to a potential misunderstanding, helping the authors to improve their understanding of the concept. However, the comment could be more helpful if it offered specific examples or guidance on how to apply this understanding in the context of the paper. Overall, the comment is mostly helpful as it directs the authors toward a critical area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results section, specifically mentioning the comparison with a simple baseline. This provides some grounding as the authors can infer that it relates to the results section, but it does not specify which part of the results or which specific comparisons are being discussed. The comment is specific in pointing out the lack of benefit with respect to the simple baseline, but it does not provide detailed guidance on how to address this issue or improve the results. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results show no particular benefit with respect to the simple baseline. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the results, specifically noting that they show no particular benefit compared to a simple baseline. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues related to efficiency: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide more details on the time cost of the pre-training process and potentially explore ways to improve the inference speed. However, the lack of specific suggestions or concrete steps makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper related to efficiency, including the pre-training process and the inference speed. It explicitly mentions the use of a vocoder pre-trained on 60k-hour LibriLight and the incorporation of a diffusion-based vocoder for waveform refinement. This allows the authors to accurately identify the parts of the paper being addressed, providing full grounding. The comment also specifies what needs to be addressed, such as providing details on the time cost of the pre-training process and explaining the slower inference speed compared to DSP and WarpNet. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method requires a vocoder pre-trained on 60k-hour LibriLight and does not describe the time cost of this pre-training process. It also mentions that the inference process incorporates a diffusion-based vocoder, which results in slower inference speed compared to DSP and WarpNet. The claim is somewhat verifiable as it provides some reasoning about the efficiency concerns, but it lacks specific details or references to support the assertion about the time cost and the comparison with other methods. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas of concern regarding the efficiency of the proposed method. It points out that the method requires a vocoder pre-trained on a large dataset, which may not be described in terms of the time cost, such as GPU hours. Additionally, it notes that the inference process incorporates a diffusion-based vocoder, which could result in slower inference speed compared to other methods like DSP and WarpNet. While the comment highlights important considerations for efficiency, it lacks detailed suggestions or guidance on how the authors might address these issues or improve the efficiency of their method. The feedback is somewhat helpful as it provides insight into potential areas for improvement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two specific issues related to efficiency: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment implies that the authors should provide more details on the time cost of the pre-training process and potentially explore ways to improve the inference speed. While the feedback is somewhat actionable, it lacks concrete steps or examples, making it barely actionable. Therefore, the comment aligns with a score of 2.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper related to efficiency, including the pre-training process and the inference speed. It explicitly mentions the use of a vocoder pre-trained on 60k-hour LibriLight and the incorporation of a diffusion-based vocoder for waveform refinement, which allows the authors to accurately identify the parts of the paper being addressed, providing full grounding. The comment also specifies what needs to be addressed, such as providing details on the time cost of the pre-training process and explaining the slower inference speed compared to other methods. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method requires a vocoder pre-trained on 60k-hour LibriLight and does not describe the time cost of this pre-training process. It also mentions that the inference process incorporates a diffusion-based vocoder, which results in slower inference speed compared to DSP and WarpNet. The claim is somewhat verifiable as it provides some reasoning about the efficiency concerns, but it lacks specific details or references to support the assertion about the time cost and the comparison with other methods. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but it does not explore this generalization. This implies that the authors should consider exploring this generalization to strengthen the framework. However, the comment does not provide explicit guidance on how to explore this generalization or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should explore the generalization but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while this generalization is mentioned, it is not explored, which raises questions about the framework\\'s generalizability. This provides some level of specificity regarding what needs to be addressed. However, the comment does not explicitly mention which part of the paper discusses this generalization, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) but does not explore this generalization, which raises questions about the framework\\'s generalizability. However, the comment lacks specific examples or detailed reasoning to support why this generalization is important or how it could be explored. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that while the authors mention the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, they do not explore this generalization. This observation raises questions about the framework\\'s generalizability, which is a critical aspect of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might explore this generalization or improve the framework. While it highlights an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but it does not explore this generalization. This implies that the authors should consider exploring this generalization to strengthen the framework. However, the comment does not provide explicit guidance on how to explore this generalization or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should explore the generalization but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while this generalization is mentioned, it is not explored, which raises questions about the framework\\'s generalizability. This provides some level of specificity regarding what needs to be addressed. However, the comment does not explicitly mention which part of the paper discusses this generalization, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but it does not explore this generalization. This raises questions about the framework\\'s generalizability. However, the comment lacks specific examples or detailed reasoning to support why this generalization is important or how it could be explored. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that while the authors mention the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, they do not explore this generalization. This observation raises questions about the framework\\'s generalizability, which is a critical aspect of the paper. However, the comment does"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It specifies that this data can offer insights into the framework\\'s comparative performance throughout the recommendation process, allowing readers to assess its effectiveness more thoroughly. The comment provides a clear and concrete action for the authors to take, making it highly actionable. The authors know exactly what information to include and why it is important for their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It references a specific paper by Zhang et al. (2022) as an example of how such information can be presented. This provides full grounding, as the authors can accurately identify the part of the paper being addressed, which is the discussion or results section. The comment is also specific, as it clearly specifies what needs to be addressed by including success rate data at each conversation turn. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. It references a specific paper by Zhang et al. (2022) as an example of how such information can be presented. This reference provides a clear and relevant example of how the proposed approach could be evaluated, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests including information on the success rate at each conversation turn to provide a more comprehensive understanding of the proposed approach\\'s performance. This feedback is valuable as it offers a specific and actionable suggestion for enhancing the clarity and depth of the paper\\'s evaluation. By including this data, the authors can offer insights into the framework\\'s comparative performance throughout the recommendation process, allowing readers to assess its effectiveness more thoroughly. The comment is clear and provides a concrete way for the authors to improve their draft, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and difficult to read, particularly due to the frequent inclusion of numbered lists within paragraphs. It recommends that these lists be presented as actual lists instead of being integrated into the paragraphs, where appropriate. While the comment provides a clear suggestion for improvement, it does not specify which sections or paragraphs should be restructured. The action is explicit but lacks concrete guidance on implementation, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and difficult to read, particularly due to the frequent inclusion of numbered lists within paragraphs. It recommends presenting these lists as actual lists instead of being integrated into the paragraphs. However, the comment does not specify which sections or paragraphs are problematic, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is dense and difficult to read, particularly due to the frequent inclusion of numbered lists within paragraphs. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a general issue with the paper\\'s readability, specifically noting that it is dense and difficult to follow due to the frequent inclusion of numbered lists within paragraphs. It provides a specific suggestion for improvement by recommending that these lists be presented as actual lists instead of being integrated into the paragraphs, where appropriate. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and readability of their work. However, the comment could be more helpful if it specified which sections or paragraphs should be restructured. Overall, the comment is mostly helpful as it provides a valuable insight and actionable advice for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might also rely on spectral cues, albeit in a more indirect manner. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or explore the implications of this observation. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors may infer that it relates to the discussion or results sections where the classifier's performance is analyzed, but this inference is not direct. The comment is specific in its question about the underlying mechanisms of fake image detectors, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. This observation prompts the authors to consider the broader implications of their findings and encourages them to explore potential commonalities among different detection methods. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or further investigate the implications. While it stimulates critical thinking, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to analyze both satisfied and unsatisfied cases in the visualization results. It also mentions a specific context, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" which provides some context but does not specify how this relates to the visualization results. While the action is clear, the comment lacks detailed guidance on how to conduct the analysis or what specific aspects to focus on. The authors know they need to analyze the results, but the comment could be more concrete in suggesting how to approach this analysis. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"visualization results\" and references a specific context, \"Class-incremental learning for semantic segmentation re-using neither old data nor old labels,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the visualization results are \"terrible\" compared to the ground truth and requests an analysis of satisfied and unsatisfied cases. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" compared to the ground truth. However, it does not provide any supporting evidence, examples, or detailed reasoning to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the visualization results, stating that they are \"terrible\" compared to the ground truth. It suggests that the authors should analyze both satisfied and unsatisfied cases to better understand the performance of their method. While the comment highlights a critical area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects to focus on. This limits the usefulness of the feedback, as the authors are left with a general direction but without detailed instructions on how to implement it. Therefore, the comment is somewhat helpful, as it points out a relevant issue but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s reliance on previous work, suggesting that limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the paper\\'s reliance on previous work and its potential impact on the validity and effectiveness of TIW. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitations and issues in previous works that could affect the paper\\'s validity, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential limitations or issues in previous works that could affect the validity and effectiveness of TIW. However, it does not provide specific examples or references to these previous works, making it difficult for the authors to understand the basis of the claim. The comment lacks detailed reasoning or evidence to support the assertion, leaving it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential issue with the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address these concerns or improve their work. Without detailed suggestions or examples, the authors are left with a general understanding of the issue but no clear path forward. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of information during the partitioning step, specifically questioning whether any information unavailable to the policy is being used. It also suggests that if such information is used for clustering participants, it should be incorporated into the policy training. While the comment implies that the authors should clarify or address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information or clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the idea of selecting a policy out of many for each sub-group. It raises a question about whether any information unavailable to the policy is being used during the partitioning step and suggests that if such information is used, it should be incorporated into the policy training. This provides a clear and specific issue for the authors to address, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of information during the partitioning step, specifically questioning whether any information unavailable to the policy is being used. It suggests that if such information is used, it should be incorporated into the policy training. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that information is indeed being used in a way that could be improved. The reasoning is logical but lacks detailed evidence or examples, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the methodology, specifically regarding the use of information during the partitioning step. It questions whether any information unavailable to the policy is being used and suggests that if such information is used, it should be incorporated into the policy training. This feedback is valuable as it prompts the authors to clarify their methodology and potentially improve their approach by considering all relevant information. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or examples of how to incorporate the suggested information. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, specifically asking why the former is worse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they might need to take to improve their draft. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, prompting the authors to clarify or address this issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for an explanation regarding the rendering quality of NeRF compared to NeuS and Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, which is a relevant and specific point that could help the authors understand and address potential weaknesses in their work. However, the comment does not provide any guidance or suggestions on how the authors might investigate or improve this aspect of their research. While it identifies an area for further exploration, it lacks actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a bold assumption made in Section 3.7, questioning how it can be concluded from the proposed evaluation approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to strengthen their argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the bold assumption made in the section, specifically regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer highlights the lack of understanding of how this conclusion can be drawn from the proposed evaluation approach, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. The reviewer expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the assumption is bold or how it can be challenged. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It questions the validity of this assumption, particularly in light of the proposed evaluation approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a more robust evaluation. While it points out a potential weakness, it does not offer actionable feedback or constructive advice for improvement. Therefore, the comment is somewhat helpful, as it highlights an area for concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to strengthen their argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a bold assumption regarding the suitability of purely unsupervised large-scale pretraining for NLP applications and highlights the lack of understanding of how this conclusion can be drawn from the proposed evaluation approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It expresses confusion about how this conclusion can be drawn from the proposed evaluation approach. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the assumption is bold or how it can be challenged. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a bold assumption made in the manuscript regarding the suitability of purely unsupervised large-scale pretraining for NLP applications. It questions the validity of this assumption, particularly in light of the proposed evaluation approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a more robust evaluation. While it points out a potential weakness, it does not offer actionable feedback or constructive advice for improvement. Therefore, the comment is somewhat helpful, as it highlights an area for concern but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions a bold assumption made in the manuscript regarding the suitability of purely"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the related work section, specifically mentioning the omission of recent related work, including [A] and DCN [18], which are not discussed or included in Table 3. It also notes that [B] is relevant but not discussed in the context of performance. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to include these references and discuss their relevance, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"Related work 2.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as discussing recent related work including [A] and DCN [18], and mentioning [B] in the context of transductive label propagation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper misses discussing recent related work, specifically mentioning [A] and DCN [18], which are not included in the paper. The reviewer provides specific references to support their claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how these omissions impact the paper\\'s comprehensiveness or relevance. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved by discussing recent related work, including [A] and DCN [18], which are not included in the paper. It also notes that [B] is relevant but not discussed in the context of performance. This feedback is clear and actionable, as it provides the authors with specific references to include in their related work section, enhancing the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it offered suggestions on how to integrate these references or discussed their significance in the context of the paper. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft by addressing specific gaps in the literature review.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the operator should be the Hadamard product between the DAG and Attention, instead of the addition as shown in Figure 2. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is explicit and concrete, giving the authors a specific task to perform, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the operator used in the figure, which should be the Hadamard product between the DAG and Attention, instead of the addition as shown. This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction regarding the operator used in Figure 2, stating that it should be the Hadamard product between the DAG and Attention, instead of addition. This is a factual observation without any subjective claims or opinions. It does not require verification or evidence, as it is a matter of fact. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the operator used in Figure 2, recommending that it should be the Hadamard product between the DAG and Attention, instead of addition. This feedback is clear and directly addresses a potential error or inconsistency in the presentation, offering a straightforward way for the authors to improve the accuracy and clarity of their figure. By following this suggestion, the authors can enhance the precision of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the authors\\' response to concerns, particularly regarding the achievement of optimal rates for SOBA under additional smoothness assumptions. It also notes that limitations are only partially addressed and suggests that the non-standard finite sum assumption could be anticipated in the abstract. Additionally, it mentions a discrepancy between theoretical and practical updates of SABA that is briefly mentioned but not properly addressed. While the comment provides detailed feedback on specific aspects of the paper, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.7. 2022. Post authors\u2019 response,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the feedback on the authors\\' response, particularly regarding the achievement of optimal rates for SOBA under additional smoothness assumptions and the limitations addressed. The comment also highlights the need for the non-standard finite sum assumption to be anticipated in the abstract and the discrepancy between theoretical and practical updates of SABA. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides a detailed assessment of the authors\\' response, specifically addressing the concerns raised in the original review. It acknowledges the authors\\' efforts in addressing weaknesses, particularly in achieving optimal rates for SOBA under additional smoothness assumptions, which are considered realistic. The reviewer also notes that the limitations are only partially addressed, highlighting specific areas that could be improved, such as anticipating the non-standard finite sum assumption in the abstract and addressing the discrepancy between theoretical and practical updates of SABA. While the comment provides a comprehensive evaluation, it lacks specific references or detailed examples to fully substantiate the claims. Therefore, the comment is mostly verifiable, as it provides a strong basis for the claims but could benefit from additional supporting evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides detailed feedback on the authors\\' response to concerns raised in the original review. It acknowledges the authors\\' efforts in addressing weaknesses, particularly regarding the achievement of optimal rates for SOBA under additional smoothness assumptions, which are considered realistic. The reviewer also notes that the limitations are only partially addressed and suggests improvements, such as anticipating the non-standard finite sum assumption in the abstract and addressing the discrepancy between theoretical and practical updates of SABA. This feedback is specific and actionable, offering the authors clear guidance on how to enhance their draft. However, the comment could be more helpful if it provided additional suggestions or examples for addressing these issues. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim that UnKE\\'s cause-driven optimization preserves pre-trained knowledge and the experimental results, which show that UnKE\\'s ability to retain original knowledge is worse than the baseline. However, the comment does not provide specific guidance on how the authors should address this discrepancy or improve their claim. It lacks actionable steps, such as suggesting ways to strengthen the experimental design or analysis to better support the claim. Without explicit or implicit actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the claim that UnKE\\'s cause-driven optimization preserves pre-trained knowledge, noting that the experimental results show UnKE\\'s ability to retain original knowledge is worse than the baseline. The comment also references an external work, providing a specific example of a related study. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the paper\\'s claim that UnKE\\'s cause-driven optimization preserves pre-trained knowledge by presenting experimental results that contradict this claim. The reviewer references an external work, \"Rosati D, Gonzales R, Chen J, et al. Long-form evaluation of model editing [J]. arXiv preprint arXiv:2402.09394,\" which provides a specific example of a related study. This external reference supports the claim by offering a comparison with existing literature, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or analysis of the results, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s claim and the experimental results, specifically noting that UnKE\\'s ability to retain original knowledge is worse than the baseline. It references an external work, providing a specific example of a related study. This feedback is valuable as it highlights a potential weakness in the paper\\'s claims and suggests that the authors should address this discrepancy in their discussion or conclusions. However, the comment could be more helpful if it offered suggestions on how to resolve this issue or improve the paper\\'s claims. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. However, it does not provide explicit guidance on how the authors should improve the explanation or suggest specific changes to make it clearer. The action is implicit, as the authors can infer that they need to enhance the explanation, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the explanation of the intention of BWTP/GLBW, indicating that the details are in the appendix, making it difficult to understand at first glance. However, it does not specify which part of the paper this explanation is located in, leaving the authors to infer that it might be in the main text or appendix. The comment is specific in identifying the issue with the explanation but lacks grounding as it does not point to a specific section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. This feedback is somewhat helpful as it points out a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the explanation or make it more accessible. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. However, it does not provide explicit guidance on how the authors should improve the explanation or suggest specific changes to make it clearer. The action is implicit, as the authors can infer that they need to enhance the explanation, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the explanation of the intention of BWTP/GLBW, noting that many details are in the appendix, which makes it difficult to understand at first glance. However, it does not specify which part of the paper this explanation is located in, leaving the authors to infer that it might be in the main text or appendix. The comment is specific in identifying the issue with the explanation but lacks grounding as it does not point to a specific section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation of the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand at first glance. This feedback is somewhat helpful as it points out a potential area for improvement in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the explanation or make it more accessible. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the explanation of"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a proof that was omitted due to space constraints, either in the revision or as supplementary material. The action is clear and concrete, as it specifies what needs to be done to address the issue. The reviewer provides a direct and actionable suggestion, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the omission of a proof due to space constraints, and suggests a potential solution by including it in the revision or as supplementary material. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that a proof is omitted due to space constraints and recommends including it in the revision or as supplementary material. While the comment identifies a potential issue with the paper, it lacks specific reasoning or evidence to support why the proof is necessary or how its inclusion would improve the paper. The suggestion is vague and does not provide detailed justification or examples, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that a proof is omitted due to space constraints in Section 3. It provides a clear and actionable suggestion by recommending that the proof be included either in the revision or as supplementary material. This feedback is valuable as it helps the authors understand where their paper lacks detail and offers a straightforward way to address this omission. However, the comment could be more helpful if it explained why the proof is important or how its inclusion would enhance the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing specific experimental results or references would be more effective than simply stating that \"Since the NPPs lack any direct dependence on magnitudes\" is the reason why NPPs perform worse than ETAS.\" This feedback implies that the authors should include more detailed experimental evidence or references to support their claims. While the action is explicit, it lacks concrete guidance on how to present this evidence or which specific results or references to include. The authors are given a clear direction but may need to infer the exact details of how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests providing specific experimental results or references instead of relying on a general statement about the performance of NPPs. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result, making it weakly grounded. The comment is specific in its suggestion to provide more detailed evidence, but without clear grounding, the authors may struggle to identify the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing specific experimental results or references would be more effective than relying on a general statement about the performance of NPPs. However, the comment does not provide any specific examples or references to support this claim, nor does it explain why these details would be more effective. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that providing specific experimental results or references would be more effective than relying on a general statement about the performance of NPPs. This feedback is somewhat helpful as it identifies a potential improvement in the paper by recommending more detailed evidence to support the claims made. However, the comment lacks specificity and does not provide examples or guidance on how to present these results or references. Without actionable suggestions or detailed examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks depth and guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the implementation details, specifically mentioning that Equations 3 and 4 outline connectivity patterns but do not provide guidance on applying these connections to complex architectures like UNet, ResNet, and MobileNet. The reviewer notes that these details are not included in the Appendix, which raises serious problems for understanding the paper. While the comment identifies specific areas of confusion, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the implementation details and possibly include them in the main text or Appendix. However, the lack of concrete guidance on how to implement these changes makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Equations 3 and 4) and tables (Tables 1, 4, and 5), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of guidance on applying the connectivity patterns to complex architectures like UNet, ResNet, and MobileNet, and notes that these details are not included in the Appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically mentioning Equations 3 and 4 as examples. However, it does not provide detailed reasoning or examples to support why these equations are unclear or how they relate to the complex architectures like UNet, ResNet, and MobileNet. The lack of specific guidance or examples makes it difficult for the authors to understand and address the issue, rendering the claim borderline verifiable. The authors would need to make a significant effort to infer the exact nature of the problem, which is why the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the implementation details in the paper. It points out that Equations 3 and 4, which outline connectivity patterns between layers, do not provide specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet. This lack of detail makes it challenging for readers to understand and replicate the methodology. Additionally, the comment notes that these details are not included in the Appendix, which further complicates the paper\\'s comprehensibility. While the comment highlights a critical area for improvement, it could be more helpful by suggesting specific steps or examples on how to clarify the implementation details. Overall, the feedback is somewhat helpful as it directs the authors to a specific area needing improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the HTER label calculation, which relies on automatic scripts, and suggests that the authors should experiment with other languages and annotations to verify this scalability. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is explicit but somewhat vague, as it does not provide detailed guidance on how to conduct these experiments or what specific languages or annotations to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the calculation of HTER labels, which relies on automatic scripts, and raises a concern about scalability to other annotations like MQM or DA. It suggests that if the calculation is not scalable, the authors should experiment with other languages and annotations to verify scalability. However, the comment does not specify which part of the paper discusses the calculation of HTER labels or the experiments conducted, making it weakly grounded. The comment is specific in detailing the issue of scalability and the need for additional experiments, but without explicit grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the HTER label calculation, which relies on automatic scripts, to other annotations like MQM or DA. The reviewer suggests that if this is not the case, the authors should experiment with other languages and annotations to verify scalability. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the current limitations of the calculation. The suggestion to experiment with other languages and annotations is a logical step, but without detailed guidance or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the HTER label calculation, which relies on automatic scripts. It suggests that the authors should experiment with other languages and annotations to verify the scalability of their approach. This feedback is clear and actionable, as it provides a specific direction for the authors to explore to enhance the robustness and applicability of their method. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or which languages or annotations to prioritize. Overall, the comment is mostly helpful as it directs the authors toward a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how overall performance depends on $m$ in $G_m$. While it raises an important question, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore this dependency, conduct additional experiments, or provide a theoretical explanation. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the question. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how overall performance depends on $m$ in $G_m$. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to a section discussing performance metrics or experimental results, but this inference is not direct. The comment is specific in asking about the dependency of performance on $m$, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the dependence of overall performance on $m$ in $G_m$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how overall performance depends on the parameter $m$ in the context of $G_m$. While it identifies a potential area for further exploration or clarification, it does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the performance might be affected by changes in $m$. The comment lacks depth and actionable advice, making it somewhat helpful as it prompts the authors to consider a specific aspect of their work but does not fully guide them in doing so. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential theory-practice gap in the paper, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment implies that the authors should address this gap, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the theory-practice gap. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential theory-practice gap, specifically mentioning the difficulty in fitting sparse neural nets, as discussed in Farrell, Liang, and Misra ECTA 2021. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results sections where the theory-practice gap might be addressed. The comment is specific in detailing what needs to be addressed, namely, the key elements that allow Causal-Stonet to learn sparse neural nets. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that theoretical works on deep learning often do not reflect practice, specifically mentioning the difficulty in fitting sparse neural nets as discussed in a referenced paper. The comment suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the reference to the Farrell, Liang, and Misra ECTA 2021 paper provides some support, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. The authors would need to further explore the referenced paper to fully understand the context and implications. Therefore, the comment is somewhat verifiable, as it provides a starting point but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential theory-practice gap in the paper, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve the comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to address the theory-practice gap or provided examples of how to discuss these elements. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement but lacks detailed guidance on execution.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests several actions to address the issue of dense spacing in the manuscript. It recommends making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are concrete and provide specific guidance on how to improve the layout and readability of the paper. The authors are given clear instructions on what changes to make, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as \"Figures and tables,\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of dense spacing and suggests potential solutions, such as making tables smaller or relocating them to the Appendix, and reducing the size of certain figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is densely packed in terms of space, with figures and tables positioned closely to the text, which can make the paper seem cluttered and condensed. The reviewer suggests possible solutions, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. While the comment provides a logical reasoning for the issue, it lacks specific examples or references to support the claim or demonstrate the impact of the suggested changes. This makes the claim somewhat verifiable, as the authors would need to infer the extent of the problem and the effectiveness of the suggested solutions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that it appears densely packed with figures and tables closely positioned to the text, which can make the paper seem cluttered and condensed. It provides actionable suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are clear and provide the authors with concrete steps to enhance the readability and organization of their manuscript. While the comment could be more detailed by specifying which figures or tables should be considered for reduction, it still offers valuable guidance for improving the draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two distinct pieces of feedback. First, it suggests that the ReCPE method proposed in the article is too strategic and lacks a strong theoretical guarantee. This implies that the authors should strengthen their article by providing a more robust theoretical foundation for their method. Second, it points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7. Both pieces of feedback are explicit and provide clear actions for the authors to take. The first suggestion is concrete, as it specifies the need for a stronger theoretical basis, while the second is straightforward and actionable. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ReCPE method\" and the \"Note 2 on page 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the strategic nature of the ReCPE method and the lack of theoretical guarantee, suggesting that the authors could strengthen their article by addressing this issue. Additionally, it points out a minor spelling error in Note 2. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the ReCPE method is too strategic and lacks a strong theoretical guarantee. This claim is somewhat verifiable as it suggests that the method is intuitive and lacks a robust theoretical foundation, but it does not provide specific examples or references to support this claim. The second part is a minor comment about a spelling error in Note 2 on page 7, which is factual and does not require verification. Therefore, the overall comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that the ReCPE method proposed in the article is too strategic and lacks a strong theoretical guarantee. This feedback is actionable and encourages the authors to strengthen their article by providing a more robust theoretical foundation for their method. Second, it points out a minor spelling error in the phrase \"real word\" in Note 2 on page 7. While this is a minor correction, it highlights the importance of attention to detail in the manuscript. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides specific guidance, but it could be more comprehensive by offering suggestions on how to strengthen the theoretical foundation. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the method beyond NLU tasks to generation tasks. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should explore this application, how to approach it, or what specific aspects to consider. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method beyond NLU tasks to generation tasks. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion about the method\\'s limitations or potential applications. Without explicit references or detailed context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the method\\'s applicability to generation tasks should be considered or explored. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking whether the method can be applied to generation tasks beyond NLU tasks. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the method beyond NLU tasks to generation tasks. While it identifies a potential area for exploration, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of the method could be adapted for generation tasks. The comment lacks depth and actionable advice, making it somewhat helpful. The authors are given a direction to consider, but without detailed guidance, the feedback does not fully support their efforts to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a specific issue with the manuscript, pointing out that \"$N_d$ is not defined\" and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, which is to clarify the definition of $N_d$ and address the potential variation in observations per task. The comment is explicit and concrete, offering a straightforward way for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that \"$N_d$ is not defined\" and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"$N_d$ is not defined\" and suggests that it would be beneficial to explicitly state that there could be a different number of observations per task. This is a factual observation rather than a subjective claim or suggestion. It does not require verification or evidence, as it is a straightforward statement of fact. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, pointing out that \"$N_d$ is not defined\" and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback is clear and actionable, as it directly addresses a potential confusion in the manuscript and provides a specific suggestion for improvement. By clarifying the definition of $N_d$ and addressing the variation in observations per task, the authors can enhance the clarity and precision of their work. However, the comment could be more helpful if it provided additional context or examples of how this clarification could impact the analysis or results. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a formatting issue where the appendix is not cut from the main paper, and it specifies that the PDF provided for the main paper is a 14-page document. This comment implies that the authors should ensure the appendix is properly formatted and integrated into the main paper. However, it does not provide explicit instructions on how to achieve this, such as suggesting specific sections or formatting guidelines. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Appendix\" and specifies that it is not cut from the main paper, indicating that the PDF provided for the main paper is a 14-page document. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the formatting of the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the appendix is not cut from the main paper, and it specifies that the PDF provided for the main paper is a 14-page document. This statement is factual and descriptive, making it a normal statement without a claim or suggestion that requires verification. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment points out a formatting issue where the appendix is not properly integrated into the main paper, specifying that the PDF provided for the main paper is a 14-page document. This feedback is clear and actionable, as it directly informs the authors of a specific formatting error that needs to be addressed. By correcting this issue, the authors can ensure that their paper is presented in a professional and coherent manner. However, the comment could be more helpful if it provided additional guidance on how to integrate the appendix effectively or suggested specific sections where the appendix should be included. Overall, the comment is mostly helpful as it identifies a clear issue and provides some direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the main improvement in the proposed model, suggesting that it is primarily due to the ternary potential. It implies that without the ternary potential, the model does not outperform existing models for 2 modalities setup (except HieCoAtt). The reviewer explicitly asks the authors to provide more insight into this observation. While the action is clear\u2014exploring and explaining the role of the ternary potential\u2014the comment does not provide specific guidance on how to address this issue or what aspects to focus on. The authors are left with a general direction but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the main improvement in the proposed model coming from the ternary potential. The comment further suggests that without the ternary potential, the model does not outperform existing models for 2 modalities setup (except HieCoAtt), and it requests more insight into this observation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, as the model does not outperform existing models without it for 2 modalities setup (except HieCoAtt). The reviewer suggests that the authors provide more insight into this observation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that the ternary potential is the sole reason for the model\\'s improvement. This makes the claim somewhat verifiable, as the authors would need to further investigate and provide evidence to fully understand and address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed model, specifically that the main improvement comes from the ternary potential. It highlights that without this component, the model does not outperform existing models for 2 modalities setup (except HieCoAtt). The comment is clear in its suggestion that the authors should provide more insight into this observation. However, it lacks specific guidance or suggestions on how the authors might address this issue or further explore the role of the ternary potential. While it points out a critical area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proposed model, specifically that the main improvement comes from the ternary potential. It suggests that without this component, the model does not outperform existing models for 2 modalities setup (except HieCoAtt). The reviewer explicitly asks the authors to provide more insight into this observation. While the action is clear\u2014exploring and explaining the role of the ternary potential\u2014the comment lacks specific guidance on how to address this issue or what aspects to focus on. The authors are left with a general direction but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the main improvement in the proposed model coming from the ternary potential. The comment further suggests that without the ternary potential, the model does not outperform existing models for 2 modalities setup (except HieCoAtt), and it requests more insight into this observation. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, as the model does not outperform existing models without it for 2 modalities setup (except HieCoAtt). The reviewer suggests that the authors provide more insight into this observation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that the ternary potential is the sole reason for the model\\'s improvement. This makes the claim somewhat verifiable, as the authors would need to further investigate and provide evidence to fully understand and address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed model, specifically that the main improvement comes from the ternary potential. It"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide additional information in the tables to facilitate easier assessment of the degree of apples-to-applesness of the comparisons. Specifically, it recommends noting which methods use data augmentations, what architecture they use, and whether they perform episodic or joint training. This feedback is explicit and provides concrete guidance on what information should be added to the tables to enhance clarity and comparability. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the tables\" and provides specific suggestions for what information should be included to facilitate easier assessment of the comparisons. It specifies what needs to be addressed, such as noting which methods use data augmentations, what architecture they use, and whether they perform episodic or joint training. This level of detail provides clear guidance on how to improve the tables, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that providing additional information about the methods used in the tables, such as whether they use data augmentation, architecture, and training objectives, would enhance the clarity of the comparisons. While the comment makes a logical suggestion, it lacks specific examples or references to support the claim that this information is necessary. The reasoning is based on general knowledge about data augmentation and training practices, but without detailed examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the clarity and comparability of the results presented in the tables. It specifically recommends noting which methods use data augmentation, what architecture they employ, and whether they perform episodic or joint training. This feedback is valuable as it guides the authors on how to enhance the transparency and comprehensiveness of their results, making it highly helpful for improving the draft. However, the comment could be more helpful if it included specific examples of how this information could be presented or if it discussed the potential impact of this information on the interpretation of the results. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on more recent models and benchmarks to validate the claim. Additionally, it questions the relevance of the PTB benchmark and the potential performance of hyperpruning on more recent benchmarks and architectures. While the comment provides a clear direction for further investigation, it lacks specific guidance on how to conduct these tests or which benchmarks to use. The authors are given a general idea of what needs to be done but are left to infer the exact steps, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that hyperpruning methods would beat the state of the art, specifically mentioning the use of LSTM and LSH networks. It questions the relevance of these architectures for language modeling and suggests testing LSH on more recent models and benchmarks. Additionally, it raises concerns about the PTB benchmark being a small dataset and questions the performance of hyperpruning on more recent benchmarks and architectures. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed regarding the choice of architectures and benchmarks. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. The reviewer suggests testing LSH on more recent models and benchmarks to validate the claim. Additionally, it questions the relevance of the PTB benchmark and the potential performance of hyperpruning on more recent benchmarks and architectures. While the comment provides a logical basis for its claims, it lacks specific references or detailed examples to fully substantiate the argument. This makes the claim mostly verifiable, as it provides a reasonable basis for the critique but requires further elaboration to be fully convincing.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on more recent models and benchmarks to validate the claim. Additionally, it questions the relevance of the PTB benchmark and the potential performance of hyperpruning on more recent benchmarks and architectures. While the comment provides a clear direction for further investigation, it lacks specific guidance on how to conduct these tests or which benchmarks to use. The feedback is somewhat helpful as it highlights areas for improvement but could be more comprehensive with detailed suggestions or examples.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on more recent models and benchmarks to validate the claim. Additionally, it questions the relevance of the PTB benchmark and the potential performance of hyperpruning on more recent benchmarks and architectures. While the comment provides a clear direction for further investigation, it lacks specific guidance on how to conduct these tests or which benchmarks to use. The authors are given a general idea of what needs to be done but are left to infer the exact steps, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests testing LSH on more recent models and benchmarks to validate the claim. Additionally, it questions the relevance of the PTB benchmark and the potential performance of hyperpruning on more recent benchmarks and architectures. While the comment provides a clear direction for further investigation, it does not explicitly mention specific sections of the paper where these concerns are raised. The authors can infer that it relates to the methodology and results sections, but the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the choice of architectures and benchmarks, making it specific. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more experimental details, including the neural networks and hyperparameters used, should be included in the appendix. This provides a clear and direct action for the authors to take, as it specifies exactly what additional information needs to be added to improve the draft. The comment is concrete in its guidance, leaving no ambiguity about what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more experimental details, specifically neural networks and hyperparameters, should be included in the appendix. However, it does not specify which part of the paper these details should be added to, making it weakly grounded. The comment is specific in its suggestion to include more details, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, specifically neural networks and hyperparameters, should be included in the appendix. However, it does not provide any justification or reasoning for why these details are necessary or how they would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including these details. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more experimental details, specifically the neural networks and hyperparameters used, should be included in the appendix. This feedback is somewhat helpful as it identifies a specific area where the authors can provide additional information to enhance the transparency and reproducibility of their experimental setup. However, the comment lacks depth and does not provide specific guidance on how to present this information or why it is important. To be more helpful, the comment could include examples of how such details are typically presented or the benefits they might offer. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that section 5.1 does not provide useful information on why the new model is superior. However, it does not specify what specific information is missing or suggest how the authors should improve this section. The feedback lacks explicit guidance or concrete suggestions on what additional details or analyses should be included to make the section more informative. As a result, the authors are left without a clear understanding of how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 5.1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the section does not provide useful information on why the new model is superior. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"section 5.1 does not seem to provide useful info regarding why the new model is superior.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with section 5.1, noting that it does not provide useful information on why the new model is superior. This feedback is somewhat helpful as it highlights a gap in the paper that the authors need to address. However, it lacks depth and does not offer suggestions on how to improve the section or what specific information should be included to make it more informative. To be more helpful, the comment could provide examples of what kind of information would be useful or suggest ways to enhance the section. Therefore, the comment is rated as somewhat helpful, as it points out a problem but does not fully guide the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary to address this issue. However, the comment does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should make a comparison but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide details on how to conduct the comparison or what aspects should be considered. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs attention and how to address it. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. The reviewer implies that a comparison between the single-IMP and multi-IMP is necessary. However, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary to address this issue. However, the comment lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. While it identifies a potential area for improvement, it does not offer actionable steps or suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider checking human-factors literature on creating systems that effectively interact with people, as there are no specific ethical concerns mentioned regarding the proposed methods. While the comment implies that the authors should explore this literature, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should seek out this literature but without detailed instructions on how to apply this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of ethical concerns with the proposed methods and mentions the limitations listed under the weaknesses and suggestions section. The comment provides a clear direction for the authors to consider checking human-factors literature on creating systems that effectively interact with people. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no specific ethical concerns with the proposed methods and suggests that the authors should consider human-factors literature on creating systems that effectively interact with people. However, the comment does not provide any specific examples or references to support the claim about ethical concerns or the limitations of the proposed methods. The suggestion to check human-factors literature is a general recommendation without detailed justification or examples. This lack of specific evidence or reasoning makes the claim somewhat verifiable, as the authors would need to independently explore the suggested literature to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of specific ethical concerns with the proposed methods and suggests that the authors should consider checking human-factors literature on creating systems that effectively interact with people. This feedback is somewhat helpful as it points out a potential area for improvement in terms of ethical considerations and suggests a direction for the authors to explore. However, the comment could be more helpful if it provided specific examples or references to ethical concerns in similar contexts or detailed guidance on how to address these issues. Overall, the feedback offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include other datasets and compare with existing methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments conducted in the paper, specifically mentioning the use of the MNIST-fashion dataset. It raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets and suggests comparing it with other neural network pruning methods. However, the comment does not specify which part of the paper discusses the experiments or the model selection approach, making it weakly grounded. The comment is specific in its suggestion to explore scalability and compare with other methods, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It suggests comparing the approach with other neural network pruning methods. However, the comment does not provide specific examples or references to support the claim about scalability or comparisons with other methods. This lack of detailed justification makes it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It suggests that the authors should consider the applicability of their approach to other datasets and compare it with other neural network pruning methods. This feedback is actionable and provides a clear direction for the authors to expand their experiments and comparisons, which could significantly enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or which datasets or methods to consider. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear path for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several specific mathematical formulation issues and inconsistencies in the paper, providing explicit examples of where corrections are needed. It highlights errors in notation, such as the incorrect use of \"max\" instead of \"min\" on Line 345, and inconsistencies in index notation, such as the use of \"i\" for both objectives and time steps. Additionally, it points out the presence of an unexplained variable \"x'\" in the hypervolume formula on Line 225 and questions the use of a uniform distribution on Line 819. Each of these points provides clear guidance on what needs to be corrected, making the feedback highly actionable. The authors know exactly which lines to revise and how to address the issues, ensuring a direct path to improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 345,\" \"Line 347,\" \"Line 344,\" \"Line 374,\" \"Line 225,\" and \"Line 819,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with mathematical formulation and inconsistencies, such as the incorrect use of \"max\" instead of \"min,\" inconsistent index notation, and the presence of an unexplained variable \"x'.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific mathematical formulation issues and inconsistencies in the paper, providing explicit examples and references to lines where these issues occur. This level of detail allows the authors to easily understand and address the problems. The comment is fully verifiable as it provides clear evidence and examples to support the claims, ensuring that the authors can effectively improve their draft by making the necessary corrections. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies several specific mathematical formulation issues and inconsistencies in the paper. It provides explicit examples of where corrections are needed, such as the incorrect use of \"max\" instead of \"min\" on Line 345, the inconsistency in index notation on Line 344 and 374, and the presence of an unexplained variable \"x'\" in the hypervolume formula on Line 225. Additionally, it questions the use of a uniform distribution on Line 819. This level of detail and specificity empowers the authors to make precise corrections and improvements to their draft, ensuring a significant impact on the quality of the paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While the comment implies that such experiments would be beneficial, it does not explicitly instruct the authors to perform these experiments or provide guidance on how to design them. The action is implicit and somewhat vague, as the authors need to infer the need for these experiments and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to clarify the importance of the choice of particles, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. However, it does not provide any specific reasoning or evidence to support why this is important or how it would impact the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While this is a constructive suggestion, it lacks specificity and does not provide detailed guidance on how to design or interpret these experiments. The comment highlights a potential area for improvement but does not offer actionable steps or examples, leaving the authors with a general idea of what could be improved but without clear direction on how to implement it. Therefore, the comment is somewhat helpful, as it identifies a potential enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While the suggestion is explicit, it lacks concrete details on how to design and execute these experiments or what specific outcomes should be expected. The authors are given a clear action to take but are left without detailed guidance on how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, which is a relevant aspect of the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to clarify the importance of the choice of particles, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. However, it does not provide any specific reasoning or evidence to support why this is important or how it would impact the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While this is a constructive suggestion, it lacks specificity and does not provide detailed guidance on how to design or interpret these experiments. The comment highlights a potential area for improvement but does not offer actionable steps or examples, leaving the authors with a general idea of what could be improved but without clear direction on how to implement it. Therefore, the comment is somewhat helpful, as it identifies a potential enhancement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should conduct experiments to demonstrate the effect of using different numbers of particles. While the suggestion is explicit, it lacks concrete guidance on how to design or interpret these experiments. The authors are given a clear action to take but are left without detailed instructions on how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting experiments to demonstrate the effect of using different numbers of particles, which is a relevant aspect of the paper. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to clarify the importance of the choice of particles, providing clear guidance on what needs to be addressed. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. This provides a clear and direct action for the authors to take, which is to include a comparison of their methods using the covariance metric. The comment is specific and actionable, as it gives the authors a concrete task to perform to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in identifying the need for a comparison on plasticity evaluation metrics, but without explicit references to sections or figures, the authors may struggle to pinpoint where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. This feedback is clear and actionable, as it directs the authors to include a comparison that could enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it provided additional context or suggested how the comparison should be structured or presented. Overall, the comment is mostly helpful as it highlights a critical gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests better explanation for Table 5, specifically asking for clarification on the meaning of A, B, C, and D. It also suggests that there should be an explanation for why positive paths lead to monotonic solutions and under what scenarios. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be clarified and why. The explicit nature of the request and the detailed guidance on what to include make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests better explanation for the table, asking for clarification on the meaning of A, B, C, and D, as well as an explanation for why positive paths lead to monotonic solutions and under what scenarios. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests better explanation for Table 5, specifically asking for clarification on the meaning of A, B, C, and D, as well as an explanation for why positive paths lead to monotonic solutions and under what scenarios. This is a request for clarification and additional information, rather than an opinion or claim that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for better explanation in Table 5. It requests clarification on the meaning of A, B, C, and D, as well as an explanation for why positive paths lead to monotonic solutions and under what scenarios. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance the clarity and comprehensiveness of their work. By addressing these points, the authors can improve the reader\\'s understanding of their methodology and results. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of obtaining a single US accuracy, suggesting the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing Appendix Fig. F6, F7, F8, and F9. While the comment highlights potential issues and references specific figures, it does not provide explicit guidance or concrete steps for the authors to address these concerns. The authors are left to infer that they might need to explore alternative methods or provide more detailed explanations, but the lack of specific actions or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the practicality of obtaining a single US accuracy and questions the reliability of early predictions of US accuracy as predictors of DS accuracy. The comment further references Appendix Fig. F6, F7, F8, and F9, providing clear guidance on where the authors might need to address these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of obtaining a single US accuracy and questions the reliability of early predictions of US accuracy as predictors of DS accuracy. It references specific figures (Appendix Fig. F6, F7, F8, F9) to support the claim that the curve is saturated only towards the end. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the unreliability of early predictions. While the references to figures provide some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a practical concern about the time cost of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing specific figures (Appendix Fig. F6, F7, F8, F9) to support this point. This feedback is somewhat helpful as it identifies a potential issue with the methodology and provides a direction for further exploration. However, it could be more helpful if it offered specific suggestions or guidance on how to address these concerns or improve the methodology. Overall, the comment provides valuable insights but lacks detailed actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing specific figures. While the comment identifies potential issues, it does not provide explicit guidance or concrete steps for the authors to address these concerns. The authors are left to infer that they might need to explore alternative methods or provide more detailed explanations, but the lack of specific actions or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the practicality of obtaining a single US accuracy and questions the reliability of early predictions of US accuracy as predictors of DS accuracy. The comment further references Appendix Fig. F6, F7, F8, and F9, providing clear guidance on where the authors might need to address these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the practicality of obtaining a single US accuracy and questions the reliability of early predictions of US accuracy as predictors of DS accuracy. It references specific figures (Appendix Fig. F6, F7, F8, F9) to support the claim that the curve is saturated only towards the end, indicating that early predictions may not be reliable. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the unreliability of early predictions. While the references to figures provide some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a practical concern about the time cost of obtaining a single US accuracy and suggests the possibility of using a"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This provides a clear and direct action for the authors to take, specifying what needs to be done to improve their draft. The comment is concrete in terms of what is required and how to implement the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for ablation studies to isolate factors, but without clear grounding, it is challenging for the authors to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, the comment does not provide any specific reasoning or evidence to support why such studies are necessary or how they would improve the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This feedback is clear and actionable, providing a specific direction for the authors to enhance their analysis and understanding of the factors influencing the results. By conducting ablation studies, the authors can gain deeper insights into the performance of their method, which could lead to improvements in the paper. However, the comment could be more helpful if it provided examples of specific factors to consider or detailed guidance on how to design and execute these studies. Overall, the feedback is mostly helpful as it offers a clear path for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should investigate how the proposed attack performs against the mode connectivity-based defense proposed in the ICLR paper. While the comment implies that the authors should conduct this investigation, it does not provide explicit instructions or concrete steps on how to carry out this analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which provides a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. However, the comment does not explicitly mention which part of the current paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for a comparison with the mode connectivity-based defense, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which claims that Fine-Tuning is not the most effective approach to recover backdoor models unless sufficient clean data is available. The reviewer suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. While the reference provides some support for the claim, the comment lacks detailed reasoning or specific examples from the referenced paper to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a direction for further exploration but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and highlights a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. This feedback is somewhat helpful as it directs the authors to a relevant area for further exploration and comparison. However, it lacks specific guidance on how to conduct this investigation or what aspects to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in the ICLR paper. While the comment implies that the authors should conduct this investigation, it does not provide explicit instructions or concrete steps on how to carry out this analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which provides a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. However, the comment does not explicitly mention which part of the current paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for a comparison with the mode connectivity-based defense, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which claims that Fine-Tuning is not the most effective approach to recover backdoor models unless sufficient clean data is available. The reviewer suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. While the reference provides some support for the claim, the comment lacks detailed reasoning or specific examples from the referenced paper to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a direction for further exploration but requires additional evidence or explanation to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and highlights a claim about the effectiveness of Fine-Tuning in recovering backdoor models. It suggests that the authors should investigate how their proposed attack performs against the mode connectivity-based defense proposed in this paper. This"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' decision to exclude the codes during the review process makes the claims less transparent. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. There is no guidance on whether the authors should include the codes, how to present them, or what specific steps to take to enhance transparency. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' decision to exclude the codes during the review process, which impacts the transparency of the claims. However, it does not specify which part of the paper this decision is affecting, making it weakly grounded. The comment is specific in identifying the issue of transparency and the exclusion of codes, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' decision to exclude the codes during the review process makes the claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the transparency of the claims due to the exclusion of codes during the review process. However, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without detailed feedback or recommendations, the authors are left without a clear path to improve their draft. The comment highlights a concern but does not offer constructive advice, making it barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part, \"3) is not necessary,\" is vague and does not provide any guidance on what needs to be addressed or improved. The second part, \"I encourage the authors to validate the proposed approach in Waymax in the future,\" is explicit and provides a clear action for the authors to take. It suggests that the authors should test their approach in a larger dataset, specifically Waymax, which provides more traffic scenarios. This part of the comment is concrete and actionable, as it gives a specific direction for the authors to follow. However, the first part of the comment lacks actionability. Overall, the comment is mostly actionable due to the explicit and concrete suggestion in the second part, but the first part remains vague and unactionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper it addresses, making it difficult for the authors to identify the exact section being discussed. However, it is specific in suggesting that the authors validate their approach in Waymax, which provides more traffic scenarios compared to the current version. This provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts. The first part, \"3) is not necessary,\" is a subjective opinion that lacks any supporting evidence or reasoning. It does not provide any justification or explanation for why this is not necessary, making it unverifiable. The second part, \"I encourage the authors to validate the proposed approach in Waymax,\" is a suggestion for future work and does not contain a claim that requires verification. Therefore, the overall comment is unverifiable due to the first part, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for future work, encouraging the authors to validate their proposed approach in Waymax, which offers a larger dataset of traffic scenarios compared to the current version. This feedback is valuable as it directs the authors toward a specific direction for enhancing the applicability and robustness of their approach. However, the comment could be more helpful if it included additional details on why Waymax is a suitable choice or how the validation process should be conducted. Despite this, the feedback is mostly helpful as it offers a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works and that the main difference lies in the visual features. It also mentions the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA). The reviewer implies that the use of additional features may not bring significant insights to the community. However, the comment does not provide specific guidance or suggestions on how the authors could enhance the technical contribution or address the critique. The feedback lacks actionable details, leaving the authors uncertain about how to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the transformer-based TAPG method and its comparison with RTD-Net (ICCV2021). It highlights the main differences between the proposed method and RTD-Net, particularly in the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The comment also questions the novelty of the approach and suggests that the use of additional features may not bring significant insights to the community. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the technical contribution section, but this inference is not direct. The comment is specific in detailing the critique of the technical contribution and the potential lack of novelty. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not very significant, as the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). The reviewer highlights that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper also considers 3D pose and action features obtained by Laban Movement Analysis (LMA). The reviewer acknowledges that LMA has been proven effective in dance action recognition, suggesting that the use of additional features may not bring significant insights to the community. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim about the lack of significance. While the reviewer provides some logical reasoning, the absence of explicit examples or detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). It highlights that the main difference between RTD-Net and the proposed method lies in the visual features, and that the paper also considers 3D pose and action features obtained by Laban Movement Analysis (LMA). The reviewer acknowledges that LMA has been proven effective in dance action recognition, suggesting that the use of additional features may not bring significant insights to the community. While the comment identifies a potential limitation in the novelty of the technical contribution, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the significance of their work. The feedback is somewhat helpful as it provides some insight into the critique but does not offer actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. While the comment implies that additional experiments are needed, it does not provide specific guidance on which design choices to compare or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not specify which part of the paper discusses this implementation or where these comparisons should be made. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting additional comparisons but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, the comment does not provide specific examples or references to support the claim that these comparisons are necessary. Without detailed reasoning or evidence, the authors may find it challenging to understand the significance of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. This feedback is somewhat helpful as it identifies a specific area where additional experimentation could be beneficial. However, the comment lacks depth and does not provide specific guidance on which design choices to compare or how to structure these comparisons. To be more helpful, the comment could include suggestions on which design choices are particularly relevant or how to design the comparisons to yield meaningful insights. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Table 2 in the paper is incomplete and suggests that the authors should report additional baselines that outperform their results, even though these results are slightly weak. The comment provides a clear and specific action for the authors to take, which is to include these additional baselines in their table. This guidance is direct and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the table, which is that it is incomplete due to the omission of several baselines that outperform the results reported in the paper. The comment further suggests that these baselines are reported in the Re-BART paper and should be included for completeness, even though their results are slightly weak. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete because it hides several baselines that outperform the results reported. The reviewer supports this claim by referencing the Re-BART paper, which presumably contains these additional baselines. However, the comment lacks specific examples or detailed reasoning about why these baselines are important or how their inclusion would improve the paper. While the reference to the Re-BART paper provides some support, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the completeness of Table 2 in the paper, noting that it hides several baselines that outperform the results reported. It provides a clear and actionable suggestion by recommending that the authors include these additional baselines, even though their results are slightly weak. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and accuracy of their results, thereby improving the overall quality of the paper. However, the comment could be more helpful if it provided additional context or reasoning about why these baselines are important or how their inclusion would impact the paper. Despite this, the feedback is mostly helpful as it directs the authors toward a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It asks why other sequences were not considered and encourages the authors to discuss the performance on other sequences. While the comment implies that the authors should provide a more comprehensive evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include more sequences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It asks why other sequences were not considered and encourages the authors to discuss the performance on other sequences. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in its request for a more comprehensive evaluation, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It asks why other sequences were not considered and encourages the authors to discuss the performance on other sequences. However, the comment lacks specific reasoning or evidence to support why the current evaluation is insufficient or why other sequences should be included. The request for more thorough evaluations is logical, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the evaluation section, specifically questioning the choice of only three scenes from the HS-ERGB dataset for evaluation. It suggests that the authors should consider evaluating their method on other sequences to provide a more comprehensive analysis. This feedback is clear and actionable, as it directs the authors to expand their evaluation to include more sequences, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific guidance on how to select additional sequences or what criteria to use for evaluation. Overall, the comment is mostly helpful as it highlights an area for improvement and offers a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. However, it does not provide explicit guidance on how to address these issues. The comment suggests that there is room to use more bits without affecting computation time, but it does not offer specific advice on how to implement this. Similarly, it questions the interpretation of bit-embeddings and the lack of semantic relations for words with odd ranks, but it does not provide suggestions on how to address these concerns. The feedback lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the size of 44 bits and the counter-intuitive nature of predicting the rank of words. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the concerns about the bit size and the interpretation of bit-embeddings, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. The claim about the small size of 44 bits is somewhat verifiable as it suggests that there is room to use more bits without affecting computation time, but it lacks specific reasoning or examples to fully substantiate this claim. The second point about predicting the rank of words is more subjective and lacks supporting evidence or references to justify the counter-intuitive nature of this approach. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. It suggests that there is room to use more bits without affecting computation time and questions the interpretation of bit-embeddings, particularly regarding the lack of semantic relations for words with odd ranks. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback provides some insight into areas that need further exploration but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the concerns about the bit size and the interpretation of bit-embeddings, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. The claim about the small size of 44 bits is somewhat verifiable as it suggests that there is room to use more bits without affecting computation time, but it lacks specific reasoning or examples to fully substantiate this claim. The second point about predicting the rank of words is more subjective and lacks supporting evidence or references to justify the counter-intuitive nature of this approach. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two concerns: the small size of 44 bits and the counter-intuitive nature of predicting the rank of words. It suggests that there is room to use more bits without affecting computation time and questions the interpretation of bit-embeddings, particularly regarding the lack of semantic relations for words with odd ranks. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback provides some insight into areas that need further exploration but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. While the comment highlights a problem, it does not offer explicit guidance or suggestions on how the authors might address this issue. The action is implicit, as the authors need to infer that they should provide a solution for mitigation, but it is vague because it lacks specific details on what kind of mitigation might be effective. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, namely the requirement for human annotation to provide semantically meaningful information, which can be subjective. It mentions that this limitation is discussed in the appendix but lacks a solution for mitigation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a solution to mitigate the subjective nature of human annotation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires human annotation to provide semantically meaningful information, which can be subjective. The reviewer acknowledges that this limitation is mentioned in the appendix but notes that no solution for mitigation is provided. While the comment identifies a potential issue, it lacks specific examples or references to support the claim or suggest how the authors might address the limitation. This makes the claim somewhat verifiable, as it provides a general observation but lacks detailed evidence or guidance for improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness but lacks depth and actionable advice, leaving the authors with a general direction to consider but no concrete steps to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights a problem, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit, as the authors need to infer that they should provide a solution for mitigation, but it is vague because it lacks specific details on what kind of mitigation might be effective. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, namely the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a solution to mitigate the subjective nature of human annotation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires human annotation to provide semantically meaningful information, which can be subjective. It acknowledges that this limitation is mentioned in the appendix but notes the absence of a solution for mitigation. While the comment identifies a potential issue, it lacks specific examples or references to support the claim or suggest how the authors might address the limitation. This makes the claim somewhat verifiable, as it provides a general observation but lacks detailed evidence or guidance for improvement.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that this limitation is mentioned in the appendix but lacks a solution for mitigation. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness but lacks depth and actionable advice, leaving the authors with a general direction to consider but no concrete steps to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take, including \"Pretrain a CausalLM using this dataset (mixed with other datasets used by ObscuraCoder, except obfuscated ObscuraX)\" and \"Compare its performance against ObscuraCoder to conclusively attribute any improvements to the deobfuscation objective.\" These actions are clear and concrete, giving the authors specific steps to follow to improve their draft. The comment also suggests a method for comparison, which further enhances its actionability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific actions for the authors to take, such as pretraining a CausalLM using a mixed dataset and comparing its performance against ObscuraCoder. However, it does not specify which part of the paper these actions relate to, making it weakly grounded. The comment is specific in detailing what needs to be done to improve the paper, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests pretraining a CausalLM using a mixed dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any reasoning or evidence to support why this approach would be beneficial or how it would help in attributing improvements to the deobfuscation objective. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides clear and actionable suggestions for improving the paper. It explicitly instructs the authors to pretrain a CausalLM using a mixed dataset and compare its performance against ObscuraCoder. This guidance is specific and offers a concrete method for the authors to attribute any improvements to the deobfuscation objective. By following these steps, the authors can enhance their draft with a more robust evaluation and attribution of results. The comment is highly helpful as it provides clear and actionable feedback that can significantly improve the quality of the paper.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the geometric loss should be added to the reconstruction loss, rather than itself, as shown in lines 264-266. This provides a clear and direct action for the authors to take, which is to correct the equation. The comment is specific and actionable, as it specifies exactly what needs to be changed and where in the paper this correction should be made. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the loss equation shown in lines 264-266, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equation, suggesting that the geometric loss should be added to the reconstruction loss rather than itself. This provides clear guidance on what needs to be corrected. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the geometric loss should be added to the reconstruction loss, rather than itself, as shown in lines 264-266. This is a factual statement about the equation, which does not require verification or evidence. It is a matter of correcting a specific mathematical expression, and the comment does not express an opinion or suggestion that requires justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the loss equation presented in the paper, specifically noting that the geometric loss should be added to the reconstruction loss rather than itself. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their presentation. By addressing this issue, the authors can enhance the precision of their methodology, which is beneficial for the overall quality of the paper. However, the comment could be more helpful if it explained why this correction is important or how it impacts the results. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method of MLM (Masked Language Modeling) should also be employed in autoregressive language models, which are more prevalent in real-world applications. While the comment implies that the authors should consider this suggestion, it does not provide explicit guidance on how to implement this change or why it is important. The action is implicit and somewhat vague, as the authors need to infer that they should explore the application of MLM in autoregressive models. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method of MLM (Masked Language Modeling) should also be employed in autoregressive language models, which are more prevalent in real-world applications. However, it does not specify which part of the paper discusses MLM or autoregressive language models, making it weakly grounded. The comment is specific in suggesting that the method should be applied to autoregressive models, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method of Masked Language Modeling (MLM) should also be employed in autoregressive language models, which are more prevalent in real-world applications. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is important or necessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method of Masked Language Modeling (MLM) should also be employed in autoregressive language models, which are more prevalent in real-world applications. While this is a valid observation, the comment lacks specificity and does not provide actionable guidance on how the authors might implement this suggestion or why it is important. Without detailed reasoning or examples, the authors may find it challenging to understand the significance of this suggestion or how to incorporate it into their work. Therefore, the comment is somewhat helpful, as it identifies an area for potential improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that the GAN is difficult to optimize and use adversarial gradient updating, and it questions why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing or unclear, but without clear grounding, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support or evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. While the comment identifies important areas for improvement, it lacks specific suggestions or actionable steps for the authors to address these concerns. The feedback provides some insight into potential weaknesses but does not offer detailed guidance on how to improve the draft. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their method. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what is missing or unclear, but without clear grounding, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing gradient and model collapsing. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support or evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks clarity on how to avoid issues like the vanishing"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of models used for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. While the comment highlights a potential issue with the experimental design, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or justify their choice of models, but it is vague because it does not specify how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of models used for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. This question implies that the authors should clarify their experimental setup, but it does not explicitly mention which part of the paper this question pertains to. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the choice of models, but it lacks grounding as it does not specify the exact section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of models used for the ablation study. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of models used for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. This question highlights a potential inconsistency or lack of justification in the experimental setup, prompting the authors to clarify their rationale. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative models or explaining the reasons behind the choice of BART and BART+Longformer. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest how the authors should address this issue or improve their draft. As a result, the authors are left without any guidance on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the cursory analyses and the unfairness of writing it as a weakness, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, the comment does not provide specific examples or detailed reasoning to support the claim that the removal of the SciBERT report exacerbates this issue. The statement about the unfairness of writing it as a weakness is also not substantiated with evidence or examples. As a result, the claim is not fully verifiable due to the lack of supporting details or references, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment addresses a specific issue with the paper, noting that the removal of a previous report of SciBERT exacerbates an earlier problem where the analyses of the models were cursory and lacked deeper analyses. However, the comment acknowledges that it is unfair to write this as a weakness because the current paper does not mention it. While the comment identifies a potential issue, it lacks actionable suggestions or guidance on how the authors might address this problem or improve their analysis. Without specific recommendations or detailed feedback, the authors are left without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide enough depth or direction for the authors to effectively enhance their draft.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, it does not provide any explicit or implicit actions for the authors to take. The comment does not suggest how the authors should address this issue or improve their draft. As a result, the authors are left without any guidance on how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the cursory analyses and the unfairness of writing it as a weakness, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point discusses the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However, the comment does not provide specific examples or detailed reasoning to support the claim that the removal of the SciBERT report exacerbates this issue. The statement about the unfairness of writing it as a weakness is also not substantiated with evidence or examples. As a result, the claim is not fully verifiable due to the lack of supporting details or references, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment addresses a specific issue with the paper, noting the removal of a previous report of SciBERT and its impact on the earlier problem in v1, where the analyses of the models were cursory and lacked deeper analyses. However"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues: the origin of the connectivity graph $\\\\cal{G}_{F}$ and the clarity of the section on the source of patches and how they are mixed. While the comment highlights these areas as being unclear, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the source of the graph and the mixing process, but without concrete suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Functional connectivity encoder\" and \"connectivity graph $\\\\cal{G}_{F}$,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues, namely the unclear origin of the graph and the difficulty in discerning the source of patches and how they are mixed. This provides clear guidance on what needs to be clarified or improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the origin of the connectivity graph $\\\\cal{G}_{F}$ and the clarity of the section on the source of patches and how they are mixed. However, it does not provide any supporting evidence, reasoning, or examples to justify why these aspects are unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the unclear origin of the connectivity graph $\\\\cal{G}_{F}$ and the difficulty in discerning the source of patches and how they are mixed. By pointing out these areas of confusion, the comment provides the authors with clear and actionable feedback on where to focus their efforts to improve the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these aspects, such as recommending specific sections or methods to address the issues. Overall, the comment is mostly helpful as it directs the authors to areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that Figure 4(b) indicates faster training due to the proposed method, suggesting that it seems far-fetched given that all networks are trained for the same amount of epochs. It also recommends a longer discussion of related work. While the comment implies that the authors should address the validity of their claim and provide a more detailed discussion of related work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more robust explanation and discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and \"Pruning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that Figure 4(b) indicates faster training due to the proposed method, noting that all networks are trained for the same amount of epochs. Additionally, it suggests a longer discussion of related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of a claim regarding faster training in Figure 4(b) and suggests that it seems far-fetched given that all networks are trained for the same amount of epochs. The reviewer also recommends a longer discussion of related work. While the comment raises a logical concern about the claim, it lacks specific examples or references to support the assertion that the claim is far-fetched. The suggestion for a longer discussion of related work is a general recommendation without detailed justification. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim that Figure 4(b) indicates faster training due to the proposed method. It questions the validity of this claim, noting that all networks are trained for the same amount of epochs, which makes the assertion seem far-fetched. Additionally, the comment suggests that the paper would benefit from a longer discussion of related work. This feedback is clear and actionable, as it prompts the authors to reconsider their claims and provide a more robust discussion of related work. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or how to improve the discussion of related work. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises concerns about the validity of the claim that Figure 4(b) indicates faster training due to the proposed method. It questions the logic of this claim, noting that all networks are trained for the same amount of epochs. Additionally, it suggests that the paper would benefit from a longer discussion of related work. While the comment implies that the authors should address the validity of their claim and provide a more detailed discussion of related work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more robust explanation and discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and \"Pruning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that Figure 4(b) indicates faster training due to the proposed method, noting that all networks are trained for the same amount of epochs. Additionally, it suggests a longer discussion of related work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the validity of a claim regarding faster training in Figure 4(b) due to the proposed method, noting that all networks are trained for the same amount of epochs. It suggests that the claim seems far-fetched and recommends a longer discussion of related work. While the comment raises a logical concern, it lacks specific examples or references to support the assertion that the claim is far-fetched. The suggestion for a longer discussion of related work is a general recommendation without detailed justification. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or references to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim that Figure 4(b) indicates faster training due to the proposed method. It questions the validity of this claim, noting that all networks are"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the derivative of the Lagrangian, pointing out that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This provides a clear and direct action for the authors to correct the error in their draft. The comment is specific and actionable, as it specifies exactly what needs to be changed and why. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the derivative of the \"Lagrangian,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the derivative, noting that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This provides clear guidance on what needs to be corrected in the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the Lagrangian is incorrect, specifically stating that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}. This is a factual statement that does not require verification, as it is a mathematical assertion. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the mathematical derivation of the Lagrangian, pointing out that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This is a clear and actionable piece of feedback that directly addresses a potential weakness in the paper. By correcting this error, the authors can improve the accuracy and rigor of their work. The comment is specific and provides a direct suggestion for improvement, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction part of the paper is not clear and lacks background information about cognitive models. It implies that the authors should refine their writing to improve clarity. However, the comment does not provide specific guidance on what aspects of the writing need refinement or how to enhance clarity. The action is implicit and somewhat vague, as the authors know they need to improve the clarity but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction part of the paper lacks clarity and background information about cognitive models. However, it does not specify which sections of the introduction are unclear or missing background information, making it weakly grounded. The comment is specific in its critique of the introduction, as it points out the need for refinement in writing to improve clarity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not clear, specifically mentioning that the introduction lacks background information about cognitive models. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the introduction lacks background information about cognitive models. It suggests that the authors need to refine their writing to improve clarity. While the comment highlights a relevant area for improvement, it does not provide specific guidance or examples on how to enhance the introduction. This limits the usefulness of the feedback, as the authors are left with a general direction but without detailed suggestions for improvement. Therefore, the comment is somewhat helpful, as it points out a critical area for revision but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the performance of DFA on the NLP task, which is described as the \"most standard\" task. The reviewer notes that the abstract gives readers the impression that DFA performs at near-backprop levels on this task, unlike its performance on other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the clarity of their presentation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to effectively respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of DFA on the NLP task and notes that it lags behind backprop performance, suggesting that this is not sufficiently emphasized in the paper. It also mentions the abstract, which gives readers the impression that DFA performs at near-backprop levels on this task. However, the comment does not specify which part of the paper should be revised or how the authors should address this issue, making it weakly grounded. The comment is specific in identifying the discrepancy between DFA and backprop performance on the NLP task, but it lacks detailed guidance on how to improve the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that DFA performance on the NLP task lags behind backprop performance, suggesting that this is not sufficiently emphasized in the paper. The reviewer provides a logical reasoning by pointing out the discrepancy between the abstract\\'s impression of DFA\\'s performance and the actual results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact areas where the performance discrepancy is most pronounced, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the paper regarding the performance of DFA on the NLP task, which is described as the \"most standard\" task. It notes that the abstract gives readers the impression that DFA performs at near-backprop levels on this task, unlike its performance on other tasks. This feedback is somewhat helpful as it points out a potential misrepresentation in the paper, prompting the authors to clarify the performance of DFA on the NLP task. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or offered guidance on how to improve the clarity of the presentation. Overall, the comment provides some insight but lacks detailed actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the performance of DFA on the NLP task, which is described as the \"most standard\" task. It notes that the abstract gives readers the impression that DFA performs at near-backprop levels on this task, unlike its performance on other tasks. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the clarity of their presentation. The feedback lacks actionable steps, leaving the authors uncertain about how to effectively respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of DFA on the NLP task and notes that it lags behind backprop performance, suggesting that this is not sufficiently emphasized in the paper. It also mentions the abstract, which gives readers the impression that DFA performs at near-backprop levels on this task, unlike its performance on other tasks. However, the comment does not specify which part of the paper should be revised or how the authors should address this issue, making it weakly grounded. The comment is specific in identifying the discrepancy between DFA and backprop performance on the NLP task, but it lacks detailed guidance on how to improve the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that DFA performance on the NLP task lags behind backprop performance, suggesting that this is not sufficiently emphasized in the paper. The reviewer provides a logical reasoning by pointing out the discrepancy between the abstract\\'s impression of DFA\\'s performance and the actual results. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact areas where the performance discrepancy is most pronounced, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It specifically mentions SRW and FROT as examples that should be included as baselines. This feedback provides a clear and direct action for the authors to take, which is to include these methods as baselines in their work. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"dimensional reduction methods in optimal transport estimation\" and provides specific examples of SRW and FROT, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these methods as baselines. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation, and suggests including SRW and FROT as baselines. However, the comment does not provide specific reasoning or evidence to support why these methods are necessary or how they would improve the baseline. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks a robust baseline, particularly for dimensional reduction methods in optimal transport estimation. It suggests including SRW and FROT as baselines, which provides clear and actionable feedback for the authors to enhance the comprehensiveness and validity of their work. By highlighting this gap, the comment helps the authors improve their draft by offering a concrete direction for inclusion of additional baselines. However, the comment could be more helpful if it provided further context or reasoning on why these methods are important or how they would impact the results. Overall, the feedback is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take, nor does it suggest how they might address this issue. Without specific guidance or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not detail what aspects of the advantages and disadvantages should be discussed or how they should be addressed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a gap in the paper by noting that the advantages and disadvantages of transductive learning have not been discussed. This is a relevant observation that could help the authors improve their work by providing a more comprehensive analysis of the learning method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending particular aspects to discuss or how to structure this discussion. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the invariance of the contractivity should be stated formally. While the action is explicit, it lacks concrete guidance on how to achieve this formal statement or what specific aspects of the contractivity should be formalized. The authors are given a clear direction to address the comment but are left without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for a formal statement of the invariance of contractivity, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, which is a clear and actionable suggestion. However, it lacks specificity regarding what aspects of the contractivity should be formalized or how this would enhance the paper. While it provides a direction for improvement, the feedback could be more helpful if it included examples or detailed guidance on how to formalize the invariance. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the potential contribution of uncertainty saliency maps and questions the significance of their application without evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback lacks actionable steps, such as recommending specific evaluations or clarifications, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these maps or the evaluation, making it weakly grounded. The authors can infer that it relates to the sections discussing uncertainty saliency maps, but this inference is not direct. The comment is specific in its critique of the evaluation and the trustworthiness of the generated uncertainty/confidence, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim that the significance of uncertainty saliency maps is unclear without evaluation. It also disagrees with the assertion that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the potential contribution of uncertainty saliency maps, noting that without evaluation, their significance is unclear. It also questions the trustworthiness of uncertainty/confidence generated from the same mechanism that generated the explanation, suggesting that the explanation itself may be more trustworthy. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve the evaluation of their maps. While it identifies areas for improvement, the feedback lacks actionable steps or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. Without actionable steps or detailed feedback, the authors are left uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these maps or the evaluation, making it weakly grounded. The authors can infer that it relates to the sections discussing uncertainty saliency maps, but this inference is not direct. The comment is specific in its critique of the evaluation and the trustworthiness of the generated uncertainty/confidence, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also disagrees with the assertion that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises concerns about the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide specific suggestions or guidance on how the authors might address these concerns or improve their draft. Without actionable feedback or detailed advice,"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the diffusion model they should emphasize. As a result, the comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft in response to this feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the diffusion model are being questioned or what unique advantages it might offer. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or comparisons to other methods, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. This feedback prompts the authors to consider the distinctive contributions of their work and how they might differentiate it from existing methods. However, the comment does not provide specific guidance or suggestions on how to address this issue or what aspects of the diffusion model are particularly advantageous. While it identifies a relevant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view\\'s effect. While the comment implies that such a discussion or comparison would be beneficial, it does not explicitly instruct the authors to make these additions or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and comparison in the related work section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to enhance understanding of the multi-view\\'s effect. The authors might infer that it relates to the related work section, but this is not explicitly stated. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. The reviewer also suggests that the multi-view training is similar to task augmentation meta-learning methods. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a thoughtful observation about the multi-view latent attack\\'s potential impact on the model\\'s meta generalizability and its performance in the cross-domain setting. It suggests that a discussion or comparison in the related work section would enhance the understanding of the multi-view\\'s effect. This feedback is clear and actionable, as it directs the authors to include a discussion that could significantly improve the paper\\'s comprehensiveness and depth. However, the comment could be more helpful if it offered specific examples or references to related work for comparison. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view\\'s effect. While the comment implies that such an addition would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to conduct the discussion or comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and comparison in the related work section. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to enhance understanding of the multi-view\\'s effect. The authors might infer that it relates to the related work section, but this is not explicitly stated. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also suggests that the multi-view training is similar to task augmentation meta-learning methods. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a thoughtful observation about the potential impact of the multi-view latent attack on the model\\'s meta generalizability and its performance in the cross-domain setting. It suggests that a discussion or comparison in the related work section would enhance the understanding of the multi-view\\'s effect. This feedback is clear and actionable, as it directs the authors to include a discussion that could"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the impact of Age and FaceID features is not studied in the ablation, implying that the authors should conduct an ablation study to evaluate the impact of these features. However, the comment does not explicitly instruct the authors to perform this study or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include an ablation study and determine the specific steps themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of study on the impact of Age and FaceID features in the ablation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table where these features are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the absence of an ablation study on the impact of these features, but without clear grounding, it is challenging for the authors to pinpoint where to make the necessary changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation, which is a factual statement. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the absence of an ablation study on the impact of Age and FaceID features. This feedback is clear and actionable, as it directs the authors to conduct an ablation study to better understand the contribution of these features to the overall performance. However, the comment could be more helpful if it provided additional guidance on how to design and execute the ablation study or suggested specific metrics or methods to consider. Despite this, the feedback is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests moving the detailed discussion from Appendix to the main manuscript, indicating that the values in Table 2 and Fig. 5 are not adequately explained in the current manuscript. This provides a clear and direct action for the authors to take, making the comment highly actionable. The reviewer specifies the exact elements that need to be addressed, ensuring the authors know exactly what changes to make to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inclusion of detailed discussions in the Appendix and suggests moving them to the main manuscript. The comment clearly specifies what needs to be addressed, providing a clear path for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the inclusion of detailed discussions in the Appendix, suggesting that the values in Table 2 and Fig. 5 should be discussed in the main manuscript. However, the comment does not provide specific reasoning or examples to support why these discussions should be moved to the main text. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion, rendering the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript regarding the ablation study, noting that Table 2 and Fig. 5 were not mentioned in the main text. It questions the relevance of the detailed discussion in the Appendix and suggests moving it to the main manuscript. This feedback is clear and actionable, as it provides a specific recommendation for improving the organization and accessibility of the manuscript. By addressing this suggestion, the authors can enhance the clarity and flow of their work, making the comment mostly helpful. However, it could be further improved by explaining why the detailed discussion is important or how it impacts the overall narrative of the paper. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should include more LLM-related results in their paper, specifically mentioning the expectation to see results from llama-3-70B, Mistral-7B, and others. This feedback provides a clear and direct action for the authors to take, as it specifies which LLMs should be included in the experiments. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely more LLM-related results, and suggests particular LLMs (llama-3-70B, Mistral-7B, etc.) that the authors should include in their experiments. This provides clear guidance on what needs to be added to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more LLM-related results, specifically mentioning the expectation to see results from llama-3-70B, Mistral-7B, etc. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific LLMs are relevant or necessary. Without additional context or explanation, the authors may find it challenging to understand the basis of this expectation. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by pointing out that the paper should include more results related to large language models (LLMs). It specifically mentions the expectation to see results from LLMs like llama-3-70B and Mistral-7B, which the authors did not include in their experiments. This feedback is valuable as it directs the authors to expand their experimental scope and potentially enhance the relevance and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these results or discussed the potential benefits of including them. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) seems to outperform ReAct prompting, but it is closely related to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about how DFSDT will perform for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment highlights potential issues and areas for further exploration, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The feedback is vague and lacks concrete actions or recommendations, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and its relationship to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about how DFSDT will perform for other types of LLMs not in the category of LLaMA, GPT, or Claude. However, the comment does not specify which part of the paper discusses DFSDT or where the comparison with ReAct prompting is made, making it weakly grounded. The comment is specific in detailing the issues with DFSDT and its potential limitations, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to self-consistency + CoT and Tree-of-thoughts, and it questions how DFSDT will perform for other types of LLMs. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed \"Depth First Search-based Decision Tree\" (DFSDT), noting that it is closely related to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about how DFSDT will perform for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment highlights areas for improvement and questions the generalizability of the approach, it lacks specific suggestions or guidance on how the authors might address these concerns or expand the scope of their work. The feedback is somewhat helpful as it points out potential limitations, but it could be more actionable and comprehensive to be fully beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to self-consistency + CoT and Tree-of-thoughts, and it questions how DFSDT will perform for other types of LLMs not in the category of LLaMA, GPT, or Claude. While the comment identifies potential areas for improvement, it does not provide explicit guidance or suggestions on how the authors might address these concerns or expand the scope of their work. The feedback lacks actionable steps or concrete advice, making it unactionable. The authors are left without a clear understanding of what changes or additions are needed to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and its relationship to self-consistency + CoT and Tree-of-thoughts. It also raises a concern about how DFSDT will perform for other types of LLMs not in the category of LLaMA, GPT, or Claude. However, the comment does not specify which part of the paper discusses DFSDT or where the comparison with ReAct prompting is made, making it weakly grounded. The comment is specific in detailing the issues with DFSDT and its potential limitations, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to self-consistency + CoT and Tree-of-thoughts, and it questions how DFSDT will perform for other types of LLMs not in the category of LLaMA,"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the appropriateness of proposing an identical method without proper acknowledgment of previous work. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should acknowledge previous work, but it lacks concrete details on how to do so or what specific actions are needed. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the appropriateness of proposing an identical method without proper acknowledgment of previous work. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in its critique of the method's originality and the need for proper acknowledgment, but it lacks grounding. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method without proper acknowledgment of previous work. However, the comment does not provide specific examples or references to the existing work that the authors should acknowledge. This lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the appropriateness of proposing an identical method without proper acknowledgment of previous work. It highlights the importance of acknowledging contributions in a proper manner, which is a valid point. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve their draft. Without detailed suggestions or examples, the authors are left without a clear path to enhance their work. Therefore, the comment is somewhat helpful, as it identifies a potential issue but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC and suggests that MMV might be better due to a better backbone architecture. However, it does not provide explicit instructions or suggestions for the authors to address this question or explore the reasons behind the performance differences. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Since the action is implicit and lacks detailed instructions, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between XDC and MMV, mentioning their performance relative to their respective fully-supervised baselines. It raises a question about why MMV shows better performance than XDC and suggests that MMV might be better due to a better backbone architecture. However, the comment does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in detailing the performance comparison and the question about the better backbone architecture, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point presents a claim about the performance of XDC and MMV, comparing their results to their respective fully-supervised baselines. The reviewer questions why MMV does not exceed its fully-supervised baseline but shows better performance than XDC. While the comment raises a valid point about the performance comparison, it lacks specific evidence, detailed reasoning, or references to support the claim. The authors are left to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison between XDC and MMV, noting that MMV does not exceed its fully-supervised baseline but shows better performance than XDC. It suggests that MMV might be better due to a better backbone architecture. While the comment identifies a potential area for improvement and poses a relevant question, it lacks specific guidance or suggestions for the authors to address this issue. The feedback provides some insight but does not offer actionable steps or detailed analysis, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the writing is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer recommends narrowing the focus to a main idea or two and providing analyses to demonstrate why they work, rather than detailing a well-engineered system with numerous functions and considerations. This feedback is clear and provides concrete guidance on how the authors can improve their draft by focusing on a more concise and theoretical approach. The explicit nature of the suggestion and the detailed reasoning make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the writing style, suggesting it is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. It provides a specific suggestion to focus on a main idea or two and demonstrate why they work, rather than detailing a well-engineered system. However, the comment does not specify which sections of the paper are too verbose or lack focus, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer suggests narrowing the focus to a main idea or two and providing analyses to demonstrate their effectiveness. While the comment provides a logical reasoning for the critique, it lacks specific examples or references to support the claim that the paper is too implementation-focused. This makes the claim somewhat verifiable, as the authors would need to make an effort to understand and address the critique without detailed guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the writing style, noting that it is too verbose and lacks focus, resembling an implementation paper rather than a theoretical or general advancement. The reviewer suggests narrowing the focus to a main idea or two and providing analyses to demonstrate why they work, rather than detailing a well-engineered system with numerous functions and considerations. This feedback is clear and actionable, offering a specific direction for the authors to improve the clarity and focus of their writing. However, while it provides valuable guidance, it could be more helpful if it included examples or specific suggestions on how to achieve this focus. Overall, the comment is mostly helpful, as it effectively directs the authors toward a more concise and impactful presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for readers to understand and replicate the methodology. This feedback is clear and direct, giving the authors a specific action to take: to include code and supplementary documentation. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of code and supplementary documentation, which could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in suggesting that providing these resources would be beneficial, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where these resources should be included. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which could enhance clarity and reproducibility. However, the comment does not provide any specific examples or reasoning to support why these resources would be beneficial or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of code and supplementary documentation, which could enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for readers to understand and replicate the methodology. This feedback is clear and actionable, offering a concrete way for the authors to improve their draft by making it more accessible and reproducible. However, the comment could be more helpful if it provided specific examples of how the code or documentation could be structured or what aspects of the methodology could be clarified through these resources. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should discuss ensembles and uncertainty estimation, specifically mentioning that ensembles have been studied before in the context of offline RL on discrete Atari games. It also recommends empirically comparing the proposed method to random ensembles (REM) to incorporate value uncertainty in offline RL. While the comment provides a clear direction for the authors to include a discussion and empirical comparison, it does not specify which sections of the paper should be revised or how to conduct the comparison. The action is explicit but somewhat vague in terms of execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and references a specific study on ensembles in the context of offline RL on discrete Atari games. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests discussing and empirically comparing the proposed method to random ensembles (REM) to incorporate value uncertainty in offline RL. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles have been studied before in the context of offline RL on discrete Atari games, and that random ensembles (REM) significantly outperform DQN/naive ensembling in the offline setting. The reviewer suggests that this should be discussed and empirically compared to the proposed method. While the comment provides a reference to a previous study, it lacks specific details or examples that would fully substantiate the claim. The suggestion to empirically compare the proposed method to random ensembles is a logical step, but without detailed justification or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a relevant area for discussion and comparison in the paper, specifically ensembles and uncertainty estimation. It references a previous study that found random ensembles (REM) to significantly outperform DQN/naive ensembling in the offline setting on discrete Atari games. The comment suggests that this finding should be discussed and empirically compared to the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by incorporating a relevant comparison. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, it does not provide specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear critique, suggesting that the combination of two methods lacks novelty. This feedback gives the authors a clear direction on what aspect of their work needs further development or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed methodology, suggesting that the combination of two methods lacks originality. However, it does not provide specific examples or detailed feedback on how the authors might address this concern or enhance the novelty of their work. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the proposed approach, specifically noting that it appears that a different model needs to be fine-tuned for each target language. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the scalability of their approach. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to enhance the scalability of their method. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the proposed approach, specifically noting that it seems that a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding how the scalability issue could be addressed or improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the scalability of the proposed approach, specifically noting that it appears that a different model needs to be fine-tuned for each target language. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the proposed approach, specifically noting that it seems that a different model needs to be fine-tuned for each target language. While this observation highlights a potential limitation of the approach, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the scalability of their method. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details should be provided in Eq. 20 for readers unfamiliar with bAbI or question answering. It specifically asks whether \"valid words\" refer to possible answer words for the given story and question. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to provide this information. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not be entirely sure of the exact content to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing more details for readers unfamiliar with bAbI or question answering, and it clarifies that \"valid words\" refer to possible answer words for the given story and question. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details should be provided in Eq. 20 for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more details are necessary. This makes the comment somewhat verifiable, as it offers a reasonable suggestion but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more details for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question, which is a helpful suggestion for enhancing the clarity and accessibility of the paper. However, the comment could be more helpful if it provided additional guidance on how to present this information or examples of how to improve the explanation. Overall, the feedback is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on execution. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that more details should be provided in Eq. 20 for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to provide this information or specify what details should be included. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not be entirely sure of the exact content to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing more details for readers unfamiliar with bAbI or question answering, and it clarifies that \"valid words\" refer to possible answer words for the given story and question. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review comment suggests that more details should be provided in Eq. 20 for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more details are necessary. This makes the comment somewhat verifiable, as it offers a reasonable suggestion but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more details for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question, which is a helpful suggestion for enhancing the clarity and accessibility of the paper. However, the comment could be more helpful if it provided additional guidance on how to present this information or examples of how to improve the explanation. Overall, the feedback is somewhat helpful as it points out a specific area for improvement but lacks detailed guidance on execution. Therefore, it aligns"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the interested-region-based adversarial attacking is not a novel idea, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This comment provides a specific reference to an existing work, which could guide the authors in understanding the novelty of their approach. However, it does not offer explicit instructions or suggestions on how the authors should address this issue or incorporate this information into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should acknowledge the existing work and possibly differentiate their contribution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the novelty of the \"interested-region-based adversarial attacking\" technique. It explicitly mentions a reference, Yao et al. Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019, which allows the authors to accurately identify the part of the paper being addressed. The comment is specific in pointing out that the technique is not novel and provides a direct reference to existing work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"interested-region-based adversarial attacking\" is not a novel idea, referencing Yao et al. as an existing work. This claim is supported by a specific reference to an external source, which provides a clear and verifiable basis for the assertion. The mention of a specific paper and its publication details strengthens the justification, making the claim fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the \"interested-region-based adversarial attacking\" technique, pointing out that it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This feedback is valuable as it highlights a gap in the originality of the proposed method, which could impact the paper\\'s contribution and significance. However, the comment does not provide specific guidance on how the authors might address this issue or differentiate their work from the existing literature. While it raises an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the \"interested-region-based adversarial attacking\" technique is not novel, as it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This feedback highlights a potential issue with the novelty of the approach, but it does not provide explicit guidance on how the authors should address this concern or differentiate their work. The comment lacks actionable steps or suggestions for improvement, making it somewhat vague and unhelpful for the authors. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the novelty of the \"interested-region-based adversarial attacking\" technique. It explicitly mentions a reference, Yao et al. Trust Region Based Adversarial Attack on Neural Networks, CVPR 2019, which allows the authors to accurately identify the part of the paper being addressed. The comment is specific in pointing out that the technique is not novel and provides a direct reference to existing work. This level of detail makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"interested-region-based adversarial attacking\" technique is not novel, referencing Yao et al. as an existing work. This claim is supported by a specific reference to an external source, which provides a clear and verifiable basis for the assertion. The mention of a specific paper and its publication details strengthens the justification, making the claim fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the \"interested-region-based adversarial attacking\" technique, pointing out that it has been proposed earlier by Yao et al. in their work on Trust Region Based Adversarial Attack on Neural Networks at CVPR 2019. This feedback is valuable as it highlights a gap in the originality of the proposed method, which could impact the paper\\'s contribution and significance. However, the comment does not provide specific guidance on how the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the significance of their contribution. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not specify which components are being referred to or how they contribute to the overall contribution of the paper. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs revision or improvement. Additionally, the comment does not provide any guidance on how to address the concern about the significance of the contribution. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, the comment lacks specific examples or references to these components, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or reasoning, the claim remains unverifiable, as it does not provide sufficient support for the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any specific examples or detailed reasoning to support this claim. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the concern about the significance of their contribution. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the dataset, specifically noting that the test set includes multi-turn data and that the publicly available history conversation can provide some assistance in answering the final question. This suggests that there is a risk of data leakage in the dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to mitigate the risk of data leakage. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the test set, mentioning that it includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a potential risk of data leakage in the dataset. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the potential risk of data leakage but lacks grounding because it does not point to a particular section or part of the paper where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question, which suggests a risk of data leakage in the dataset. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset, specifically noting that the test set includes multi-turn data and that the publicly available history conversation can provide assistance in answering the final question. This suggests a risk of data leakage in the dataset. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or mitigate the risk of data leakage. While it highlights an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves the performance of VSD according to the DMD2 paper. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. The claim is based on the DMD2 paper, which claims that TTUR improves the performance of VSD. However, the comment does not provide specific details or examples from the DMD2 paper to support this claim, making it somewhat verifiable. The authors would need to refer to the DMD2 paper themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves the performance of VSD according to the DMD2 paper. This feedback is clear and actionable, as it directs the authors to consider a specific comparison that could strengthen their results. However, the comment could be more helpful if it provided additional context or guidance on how to conduct this comparison or why it would be beneficial. Overall, the comment is mostly helpful as it identifies a potential improvement area and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a question about whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, given that TTUR improves the performance of VSD according to the DMD2 paper. While the comment implies that the authors should include such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the paper applies TTUR proposed by DMD2 (Yin et al. 2024a) in Figure 7 and suggests that a comparison with VSD + TTUR would be more convincing. The claim is based on the DMD2 paper, which claims that TTUR improves the performance of VSD. However, the comment does not provide specific details or examples from the DMD2 paper to support this claim, making it somewhat verifiable. The authors would need to refer to the DMD2 paper themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR proposed by DMD2 (Yin et al."}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. While it highlights a potential inconsistency, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their theoretical result. The comment lacks actionable details, such as recommending specific changes or providing alternative approaches to clarify the theoretical foundation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as line 109, and references Assumption 3.1, allowing the authors to accurately identify the parts being addressed. It is also specific because it questions the theoretical result presented in the paper, particularly regarding the definition of OOD actions and the assumption made in Assumption 3.1. The comment clearly specifies what needs to be addressed, namely the inconsistency between the definition of OOD actions and the assumption made in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. The comment highlights a potential inconsistency between the definition of OOD actions and the assumption made in the paper, questioning the validity of the theoretical result. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to further explore and clarify the theoretical basis to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. It points out a potential inconsistency that questions the validity of the theoretical result, which is a significant concern for the authors. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their theoretical foundation. While it identifies a key area for clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. While it highlights a potential inconsistency, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their theoretical foundation. The comment lacks actionable details, such as recommending specific changes or providing alternative approaches to clarify the theoretical basis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as line 109, and references Assumption 3.1, allowing the authors to accurately identify the parts being addressed. It is also specific because it questions the theoretical result presented in the paper, particularly regarding the definition of OOD actions and the assumption made in Assumption 3.1. The comment clearly specifies what needs to be addressed, namely the potential inconsistency between the definition of OOD actions and the assumption made in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. It highlights a potential inconsistency between the definition of OOD actions and the assumption made in the paper, questioning the validity of the theoretical result. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to further explore and clarify the theoretical basis to address the concern effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. It points out a potential inconsistency that questions the validity of the theoretical result, which is a significant concern for the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take. It suggests that the shallow linguistic dataset analysis should be moved to the appendix if it does not enhance the paper\\'s value or clarity. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is concrete and provides a direct path for the authors to improve their draft by making specific changes to the organization and content of their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"shallow linguistic dataset analysis\" and the \"appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue with the analysis, noting that it lacks clear takeaways or conclusions and suggests that it might be better suited for the appendix. Additionally, it provides a specific recommendation to integrate essential details from the appendix into the main text. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper provides a \"shallow linguistic dataset analysis\" without clear takeaways or conclusions. The reviewer suggests that this analysis might be better suited for the appendix if it does not enhance the paper\\'s value or clarity. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment provides a logical reasoning for its suggestions, it lacks specific examples or references to support the claim about the analysis being shallow or the need for integration. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving the organization and content of their paper. By addressing this feedback, the authors can enhance the clarity and value of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric used in Table 1 and the absence of details regarding the backbone choice, learning rate, and optimization schedules. While the comment highlights these areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the metric and provide the missing experimental details, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by noting the lack of clarity in the metric used in Table 1 and the absence of details regarding the backbone choice, learning rate, and optimization schedules. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are missing. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric used in Table 1 and the absence of details regarding the backbone choice, learning rate, and optimization schedules. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the clarity and completeness of their experimental setup. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to present this information effectively. Overall, the feedback is mostly helpful as it directs the authors to important areas needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper, noting that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised to incorporate this advantage. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption of POMDPs and how it is not leveraged by the paper. It also specifies the issue by pointing out the lack of discussion on how previous decisions change the data observable to the decision-maker, given that only outcomes are observed when the positive decision is given. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which assumes that the decision-maker does not directly observe the target variable Y. The comment suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment identifies a potential issue, it lacks specific examples or references to support the claim or provide a detailed explanation of how the paper could address this issue. This makes the claim somewhat verifiable, as it provides a general direction for improvement but requires more detailed justification or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. This feedback is somewhat helpful as it points out a specific area where the paper could be improved by addressing the limitations of its assumptions. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might address this issue or enhance their analysis. Therefore, the comment is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the paper, noting that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the paper need to be revised to incorporate this advantage. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the assumption of POMDPs and how it is not leveraged by the paper. It also specifies the issue by pointing out the lack of discussion on how previous decisions change the data observable to the decision-maker, given that only outcomes are observed when the positive decision is given. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment identifies a potential issue, it lacks specific examples or references to support the claim or provide a detailed explanation of how the paper could address this issue. This makes the claim somewhat verifiable, as it provides a general direction for improvement but requires more detailed justification or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the number of pretraining tokens_per_sample (256) is extremely small and suggests that it may not be sufficient for a regular-size program. Additionally, it questions the use of batch_size=64 for pretraining. While the comment identifies specific issues, it does not provide concrete guidance on how to address these concerns. The authors are left to infer that they should increase the number of tokens_per_sample and possibly adjust the batch_size, but without detailed instructions on how much to increase or what alternative strategies to consider, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the small number of pretraining tokens_per_sample (256) and questions the use of batch_size=64 for pretraining. However, it does not specify which part of the paper discusses these parameters, making it weakly grounded. The comment is specific in identifying the issue with the small number of tokens and the use of batch_size, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of pretraining tokens_per_sample (256) is extremely small and questions the use of batch_size=64 for pretraining. However, the comment lacks specific reasoning or evidence to support why this is insufficient for a regular-size program. It does not provide references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pretraining process, noting that the tokens_per_sample (256) is extremely small and questioning the use of batch_size=64 for pretraining. This feedback is clear and actionable, as it highlights a potential limitation in the experimental setup that could impact the effectiveness of the pretraining process. By pointing out this issue, the reviewer provides the authors with a concrete area to address, which could lead to improvements in the robustness and generalizability of their model. However, the comment could be more helpful if it offered suggestions on how to increase the tokens_per_sample or adjust the batch_size. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs attention.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the number of pretraining tokens_per_sample (256) is extremely small and questions the use of batch_size=64 for pretraining. However, it does not provide specific guidance on how to address these issues or suggest alternative approaches. The authors are left to infer that they should increase the number of tokens_per_sample and possibly adjust the batch_size, but without detailed instructions on how much to increase or what alternative strategies to consider, the action remains vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the small number of pretraining tokens_per_sample (256) and questions the use of batch_size=64 for pretraining. However, it does not specify which part of the paper discusses these parameters, making it weakly grounded. The comment is specific in identifying the issue with the small number of tokens and the use of batch_size, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of pretraining tokens_per_sample (256) is extremely small and questions the use of batch_size=64 for pretraining. However, the comment lacks specific reasoning or evidence to support why this is insufficient for a regular-size program. It does not provide references or detailed explanations to substantiate the claim, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pretraining process, noting that the number of pretraining tokens_per_sample (256) is extremely small and questioning the use of batch_size=64 for pretraining. This feedback is clear and actionable, as it highlights a potential limitation in the experimental setup that could impact the effectiveness of the pretraining process. By pointing out this issue, the reviewer provides the authors with a concrete area to address, which could lead to"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of ablation experiments in the paper, suggesting that the authors should conduct additional experiments to help readers understand the proposed method. It provides specific examples, such as questioning whether the clustering algorithm can be replaced with other approaches like K-Means, and asking how the model performs when applied to different-sized descendant models. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable. The authors know exactly what additional experiments to conduct to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of ablation experiments, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as questioning whether the clustering algorithm can be replaced with other approaches like K-Means and asking how the model performs when applied to different-sized descendant models. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks enough ablation experiments to help readers understand the proposed method. It provides specific examples, such as questioning whether the clustering algorithm can be replaced with other approaches like K-Means and asking how the model performs when applied to different-sized descendant models. This detailed questioning provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific studies or methodologies that have successfully used ablation experiments in similar contexts, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of ablation experiments, which is crucial for understanding the proposed method. It provides specific examples, such as questioning whether the clustering algorithm can be replaced with other approaches like K-Means and asking how the model performs when applied to different-sized descendant models. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft by conducting additional experiments. However, the comment could be more helpful if it suggested specific ablation experiments to perform or provided examples of similar studies that have effectively used ablation experiments. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the Talking Heads Transformer should be considered the de-facto baseline for all tasks in the paper, and it recommends comparing it with all the tasks presented, rather than just the vanilla transformer. The reviewer also points out that it is difficult to assess the benefit of the proposed interaction modules and many-to-many formulation compared to a simple linear transform. While the comment implies that the authors should include more comparisons, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to expand their comparisons to include the Talking Heads Transformer. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the proposed interaction modules + many to many formulation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as comparing the proposed methods against the Talking Heads Transformer for all tasks and assessing the benefit of the proposed interaction modules. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be considered the de-facto baseline for all tasks in the paper, and it recommends comparing it with all the tasks presented, rather than just the vanilla transformer. The reviewer provides a logical reasoning by stating that it is difficult to gauge the benefit of the proposed interaction modules and many-to-many formulation compared to a simple linear transform. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the importance of the Talking Heads Transformer and its potential impact on the evaluation, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a relevant baseline, the Talking Heads Transformer, and suggests that it should be considered the de-facto baseline for all tasks in the paper. It points out that while there is a comparison to the vanilla transformer, it would be beneficial to compare against the Talking Heads Transformer for all tasks. The comment also highlights the importance of comparing the proposed interaction modules and many-to-many formulation against a simple linear transform, which could help assess the benefit of the proposed methods. This feedback is clear and actionable, providing the authors with specific guidance on how to enhance their paper by including more comprehensive comparisons. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should check and benchmark at least speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. While the comment implies that the authors should verify the performance of their method on this dataset, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it does not provide detailed guidance on how to conduct the check or benchmarking. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests checking and benchmarking speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting a benchmarking task but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should check and benchmark speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. However, the comment does not provide any specific reasoning or evidence to support why this dataset is relevant or why it should be used for benchmarking. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should check and benchmark their method on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their evaluation by including a relevant dataset in their benchmarking. However, the comment could be more helpful if it included additional details on why this dataset is important or how it could enhance the paper\\'s contribution. Overall, the comment is mostly helpful as it offers a concrete suggestion for improvement, but it could be more comprehensive with additional context or guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit suggestion for the authors to reconsider the framing of their paper. It suggests that the paper should focus on the loss function and its applications rather than being centered around breast cancer. The reviewer provides a rationale for this suggestion, explaining that the paper evaluates the loss function over multiple datasets and has a primary contribution that is applicable to any semantic segmentation network. This feedback is concrete, as it directly guides the authors on how to reframe their paper to better align with its core contributions. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" and the \"loss function,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to reconsider the framing of the paper, focusing on the loss function and its applications rather than being centered around breast cancer. The comment specifies what needs to be addressed, such as the evaluation of the loss function over multiple datasets and the primary contribution of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper\\'s framing should shift from breast cancer to the loss function and its applications. The reviewer provides a rationale by explaining that the paper evaluates the loss function over multiple datasets, including breast cancer, and that the primary contribution is a loss function applicable to any semantic segmentation network. This explanation offers logical reasoning to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar works that have successfully applied loss functions in various contexts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to reconsider the framing of their paper. It suggests that the paper should focus on the loss function and its applications rather than being centered around breast cancer. The reviewer explains the rationale behind this suggestion, noting that the paper evaluates the loss function over multiple datasets and has a primary contribution that is applicable to any semantic segmentation network. This feedback is valuable as it offers a perspective that could enhance the paper\\'s focus and impact. However, the comment could be more helpful if it included specific examples or guidance on how to reframe the paper to align with this suggestion. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This is a clear and direct action for the authors to take, providing them with a specific task to perform. The comment is explicit and concrete, as it specifies exactly where the statistics should be included, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 3.1 or 3.2,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of agreement statistics for the corpus. This level of detail provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for agreement statistics to be included in sections 3.1 or 3.2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for more information, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, requesting the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This feedback provides a specific and direct suggestion for improvement, which is valuable for the authors as it guides them on how to enhance their draft. By addressing this request, the authors can provide more detailed information that could strengthen their paper. However, the comment could be more helpful if it explained why these statistics are important or how they might impact the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. While the comment provides some insights into the novelty and inspiration of the work, it does not offer explicit or implicit actions for the authors to take. There is no guidance on how to address these observations or improve the novelty of the work. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the work, specifically mentioning the use of instruction aggregation and LLMs, as well as the novelty of cross-trajectory chaining. It also references existing literature, such as goal-conditioned RL approaches and offline goal chaining. However, the comment does not explicitly mention which part of the paper these points are discussed in, making it weakly grounded. The comment is specific in detailing the novelty and inspiration of the work, providing clear guidance on what aspects are novel and where they fit into the broader context. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. The comment provides some logical reasoning by comparing the work to existing literature, such as offline goal chaining [Chebotar et al., 2021]. However, it lacks specific examples or detailed references to fully substantiate the claim about the novelty of cross-trajectory chaining. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. While the comment provides some insights into the novelty and inspiration of the work, it lacks specific suggestions or actionable feedback for the authors to improve their draft. It does not offer guidance on how to enhance the novelty or differentiate the work from existing literature. Therefore, the comment is somewhat helpful, as it provides some insights but does not fully support the authors in making significant improvements to their draft.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. While the comment provides some insights into the novelty and inspiration of the work, it does not offer explicit or implicit actions for the authors to take. There is no guidance on how to address these observations or improve the novelty of the work. As a result, the comment lacks actionable feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. However, the comment does not specify which part of the paper these points are discussed in, making it weakly grounded. The comment is specific in detailing the novelty and inspiration of the work, providing clear guidance on what aspects are novel and where they fit into the broader context. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but notes that existing LLMs are used. It also points out that the use of consecutive sub-trajectories is straightforward and that cross-trajectory chaining has novelty, but mentions that many of its techniques are inspired by goal-conditioned RL approaches. The comment provides some logical reasoning by comparing the work to existing literature, such as offline goal chaining [Chebotar et al., "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. While the comment implies that the authors should provide a more detailed explanation or discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure where this issue might be discussed. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the authors might have an idea of where the attention module is discussed, the comment lacks full grounding. It is specific in its request for more discussion but does not provide detailed guidance on what aspects should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification and discussion regarding the identity of the attention map and its impact on the expressive power of the attention module. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the attention module could be discussed further. The feedback is somewhat helpful as it points out a potential area for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests an explanation for why the authors are considering decoder-only transformers. This is a clear and direct action for the authors to take, as it prompts them to provide a rationale or justification for their choice. The comment is specific and provides a concrete action for the authors to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is an explanation for considering decoder-only transformers. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the choice of using decoder-only transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area where the authors need to provide more explanation. By asking for an explanation of why the authors are considering decoder-only transformers, the comment prompts the authors to clarify their rationale or methodology. However, the comment lacks depth and does not offer suggestions on how to improve the explanation or what specific aspects of the choice should be elaborated upon. While it provides a clear direction for improvement, it could be more helpful with additional guidance or examples. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the qualitative analysis is lacking important details, specifically the proportion of each error category. It also implies that the paper could be strengthened by including more insights into the underlying causes of the observed issues and potential ways to mitigate them. While the comment identifies areas for improvement, it does not provide explicit guidance on how to incorporate these insights or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"qualitative analysis\" and the \"proportion of each error category,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of detailed analysis and suggests that more insights into the underlying causes of the observed issues and potential mitigation strategies would strengthen the contribution. The comment is specific in detailing what is missing and provides a reference to an external work for context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the qualitative analysis is lacking important details, specifically the proportion of each error category. It suggests that the paper could be strengthened by including more insights into the underlying causes of the observed issues and potential ways to mitigate them. The comment provides a reference to an external work, \"Turpin et al. Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" which could be relevant to the discussion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reference to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the qualitative analysis, which lacks detailed information about the proportion of each error category. It suggests that the paper could be strengthened by including more insights into the underlying causes of the observed issues and potential ways to mitigate them. The comment provides a reference to an external work, \"Turpin et al. Language Models Don\\'t Always Say What They Think,\" which could be relevant to the discussion. While the comment highlights a gap in the analysis and suggests a direction for improvement, it could be more helpful if it offered specific examples or guidance on how to incorporate these insights. Overall, the feedback is mostly helpful as it directs the authors to a potential area for enhancement, but it could be more comprehensive with additional details or suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should empirically validate the inapplicability of Reinforcement Learning, RNNs, and Wasserstein GANs to their proposed approach by applying these methods with data filled by simple methods. This feedback provides a clear and explicit action for the authors to take, as it specifies the methods to be applied and the rationale behind the suggestion. The comment also references a specific study (Klausen et al., 2018b) for context, which adds to the clarity. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"typical MTTP baselines\" and references specific techniques like Reinforcement Learning, RNNs, and Wasserstein GANs. It also specifies the comparison with a Markov chain approach and references a particular study (Klausen et al., 2018b). This provides clear guidance on which part of the paper is being addressed, making it fully grounded. The comment is also specific because it suggests a method for empirically validating the inapplicability of certain techniques to the proposed approach. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should empirically validate the inapplicability of Reinforcement Learning, RNNs, and Wasserstein GANs to their proposed approach by applying these methods with data filled by simple methods. The comment provides a logical reasoning for this suggestion, as it highlights the typical requirement of significant data for training these techniques, which is not applicable to the authors\\' proposed approach. However, the comment lacks specific examples or references to support the claim that these methods are not suitable for incomplete, small data. This makes the claim somewhat verifiable, as it provides a reasonable rationale but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s evaluation by pointing out that the typical baselines for missing data imputation, such as Reinforcement Learning, RNNs, and Wasserstein GANs, require a significant amount of data to train effectively. It suggests that these methods may not be applicable to the authors\\' proposed approach, which is a valid concern. The comment provides a constructive suggestion for empirical validation by proposing to apply these methods with data filled by simple methods to empirically demonstrate their inapplicability. This feedback is clear and actionable, offering a specific way for the authors to strengthen their evaluation and demonstrate the uniqueness of their proposed approach. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of baseline comparison in the paper, specifically mentioning the G-EVAL method and its reliance on GPT-3.5 and GPT-4. It suggests that the authors should demonstrate the performance of these models with the simplest prompt and compare it with the G-EVAL method. This feedback provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"G-EVAL method\" and its reliance on GPT-3.5 and GPT-4, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of baseline comparison using the simplest prompt for these models. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically mentioning the G-EVAL method and its reliance on GPT-3.5 and GPT-4. However, the comment does not provide any supporting evidence or reasoning to justify why this lack of comparison is problematic or how it affects the paper\\'s conclusions. Without additional context or examples, the authors may find it challenging to understand the significance of this claim. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of baseline comparison for the G-EVAL method. It specifically mentions the reliance on GPT-3.5 and GPT-4 without demonstrating their performance with the simplest prompt, which is crucial for evaluating the method\\'s effectiveness. The comment provides a clear and actionable suggestion for the authors to include this comparison, which would enhance the comprehensiveness and validity of their results. By addressing this feedback, the authors can significantly improve the robustness and credibility of their work. Therefore, the comment is highly helpful, as it directs the authors to a specific area for improvement that can lead to a more comprehensive analysis.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a requirement for computing expected rewards or NE gaps to update weights in multiagent environments. It suggests that this process requires full knowledge of the game payoffs, unlike the base policies, which are updated based on observed rewards. Additionally, computing NE gaps necessitates knowledge of the policies of other agents. While the comment identifies a potential issue and provides some context, it does not explicitly instruct the authors on how to address this requirement or suggest specific steps to update the weights. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to incorporate this requirement into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to updating weights in multiagent environments, which involves computing expected rewards or NE gaps for different perturbations. However, it does not explicitly mention a particular section, figure, or table, making it weakly grounded. The comment is specific in detailing the requirements for updating weights, such as needing full knowledge of game payoffs and policies of other agents. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that updating weights in multiagent environments requires full knowledge of game payoffs, unlike the base policies, which are updated based on observed rewards. It also mentions that computing NE gaps necessitates knowledge of the policies of other agents. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that full knowledge of game payoffs is required. This makes the claim somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue related to updating weights in multiagent environments, highlighting the requirement to compute expected rewards or NE gaps for different perturbations. It points out that this process requires full knowledge of the game payoffs, unlike the base policies, which are updated based on observed rewards. Additionally, computing NE gaps necessitates knowledge of the policies of other agents. While the comment provides a clear insight into a potential limitation of the current approach, it lacks actionable suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is somewhat helpful as it points out a critical aspect that needs consideration, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue related to updating weights in multiagent environments, highlighting the requirement to compute expected rewards or NE gaps for different perturbations. It points out that this process requires full knowledge of the game payoffs, unlike the base policies, which are updated based on observed rewards. Additionally, computing NE gaps necessitates knowledge of the policies of other agents. While the comment provides a clear insight into a potential limitation, it does not offer explicit guidance or suggestions on how the authors might address this issue or improve their methodology. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to incorporate this requirement into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper related to updating weights in multiagent environments, which involves computing expected rewards or NE gaps for different perturbations. However, it does not explicitly mention a particular section, figure, or table, making it weakly grounded. The comment is specific in detailing the requirements for updating weights, such as needing full knowledge of game payoffs and policies of other agents. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that updating weights in multiagent environments requires full knowledge of game payoffs, unlike the base policies, which are updated based on observed rewards. It also mentions that computing NE gaps necessitates knowledge of the policies of other agents. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that full knowledge of game payoffs is required. This makes the claim somewhat verifiable, as it provides a basis for the claim but requires further elaboration or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue related to updating weights in multiagent environments, highlighting the requirement to compute expected rewards or NE gaps for different perturbations. It points out"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this comparison is sufficient, whether additional comparisons should be made, or if there are other aspects that should be considered. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a specific comparison made in the paper, which is the comparison with DiffUCO. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the comparison with DiffUCO as the primary focus, but without further details or context, the authors may struggle to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a factual statement about the primary comparison made in the paper, which is the comparison with DiffUCO. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific comparison made in the paper, which is the comparison with DiffUCO. However, it does not provide any additional context, analysis, or suggestions for improvement. Without further elaboration or guidance, the authors are left without actionable feedback on how to enhance their work or address any potential weaknesses. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, the superficiality of the exposition, and the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies specific areas that need improvement, it does not provide explicit instructions or concrete steps for the authors to address these issues. The feedback is somewhat actionable because it points out the need for clarification and elaboration but lacks detailed guidance on how to implement these changes. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the contribution of the paper, specifically the value decomposition and the claim of equivalence between the local policy product and the globally optimal policy. However, it does not specify which sections of the paper are repetitive or superficial, making it weakly grounded. The comment does specify what is missing, such as the lack of explicit definition of local subtasks and their corresponding policies, and the absence of a complete proof of equivalence. This provides some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is repetitive and superficial in its exposition of the value decomposition method, specifically regarding the equivalence of the local policy product to the globally optimal policy. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide explicit evidence or references to substantiate the assertion that the paper is repetitive or superficial. As a result, the claim is difficult for the authors to verify and address without additional context or guidance. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity and depth in the exposition of the value decomposition method. It points out that the paper claims to prove the equivalence of the local policy product to the globally optimal policy but fails to provide a complete proof or detailed explanation. This feedback is valuable as it highlights a critical area for improvement, namely the need for a more thorough and explicit discussion of the decomposition method. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how to improve the exposition. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the performance curve of each algorithm during training is missing. This provides a clear and direct action for the authors to take, which is to include the performance curve in their draft. The comment is specific and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of performance curves for each algorithm during training. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure where these curves should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing element, which is the performance curves, but without clear grounding, it is challenging for the authors to pinpoint where to make the necessary changes. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance curve of each algorithm during training is missing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including these curves or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific omission in the paper, namely the absence of performance curves for each algorithm during training. This is a clear and actionable suggestion that can help the authors improve the comprehensiveness and transparency of their results. By including these curves, the authors can provide a more detailed analysis of their algorithms\\' performance over time, which is crucial for understanding their effectiveness. However, the comment could be more helpful if it provided additional guidance on how to present these curves or what specific aspects of the performance should be highlighted. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed Gaussian kernel-based graph construction method, noting that computing the full adjacency matrix is computationally expensive due to its O(N^2) time complexity. However, it does not provide any explicit or implicit suggestions for addressing this issue or improving the method. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. Since the comment does not offer any actionable steps or suggestions, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the computational complexity of the proposed Gaussian kernel-based graph construction method, specifically mentioning the need to compute the full adjacency matrix. However, it does not specify which part of the paper discusses this method or where the issue is most relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the computational complexity issue but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive due to its O(N^2) time complexity. This claim is somewhat verifiable as it provides a logical reasoning based on the computational complexity of the method. However, the comment lacks specific examples or references to support the assertion about the computational expense, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed Gaussian kernel-based graph construction method, specifically the computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity. This feedback is valuable as it highlights a critical aspect that the authors should consider when evaluating the feasibility and scalability of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or optimizations. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation of the proposed Gaussian kernel-based graph construction method, specifically the computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity. However, it does not provide any explicit or implicit suggestions for addressing this issue or improving the method. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to proceed. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the computational complexity of the proposed Gaussian kernel-based graph construction method, specifically mentioning the need to compute the full adjacency matrix, which is computationally expensive due to its O(N^2) time complexity. However, it does not specify which part of the paper discusses this method or where the issue is most relevant. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the computational complexity issue but lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive due to its O(N^2) time complexity. This claim is somewhat verifiable as it provides a logical reasoning based on the computational complexity of the method. However, the comment lacks specific examples or references to support the assertion about the computational expense, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed Gaussian kernel-based graph construction method, specifically the computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity. This feedback is valuable as it highlights a critical aspect that the authors should consider when evaluating the feasibility and scalability of their method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods or optimizations. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) in Eq. (5) despite case (3) showing the best performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit, as the authors need to infer that they should reconsider their choice of loss reweighting and provide a more compelling explanation. However, the comment lacks concrete details on how to implement this change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the choice of loss reweighting case (1) despite case (3) showing better performance for most widths. The comment further clarifies the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) despite case (3) showing better performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. While the comment highlights a potential inconsistency, it does not provide specific evidence or references to support the claim that case (3) should be used instead of case (1). The reasoning is based on logical questioning rather than concrete evidence, making the claim somewhat verifiable. The authors would need to further investigate and provide a rationale for their choice of loss reweighting case (1).', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the paper regarding the choice of loss reweighting case (1) despite case (3) showing better performance for most widths. It questions the authors\\' explanation regarding the importance of all sub-networks with different widths and the meaning of slimmable networks. This feedback is clear and actionable, as it prompts the authors to reconsider their choice and provide a more compelling explanation. However, the comment could be more helpful if it suggested alternative approaches or provided specific guidance on how to address the issue. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to address fine-tuning multiplicity for tabular LLMs but does not leverage any unique characteristics of tabular data or LLMs. It also notes that the main results are general and irrelevant to the paper\\'s scope. However, the comment does not provide specific guidance on how the authors should address these issues or what unique aspects of tabular data or LLMs should be considered. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that \"the unique challenges of fine-tuning multiplicity in Tabular LLMs remain relatively unexplored\" and critiques the main results for being general and not leveraging unique characteristics of tabular data or LLMs. However, it does not specify which part of the paper this critique is based on, such as specific sections or results, making it weakly grounded. The comment is specific in identifying the issue of general results not leveraging unique characteristics, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage unique characteristics of tabular data or LLMs. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks explicit references or detailed explanations, making it difficult for the authors to understand and address the critique effectively. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s main results, noting that they are general and do not leverage the unique characteristics of tabular data or LLMs. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should focus on demonstrating how their work addresses the specific challenges of fine-tuning multiplicity in Tabular LLMs. However, the comment lacks specific guidance or suggestions on how to achieve this, such as identifying unique aspects of tabular data or LLMs that could be explored. While it points out a relevant issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper claims to address fine-tuning multiplicity for tabular LLMs but does not leverage any unique characteristics of tabular data or LLMs. It also notes that the main results are general and irrelevant to the paper\\'s scope. However, the comment does not provide specific guidance or suggestions on how the authors should address these issues or what unique aspects of tabular data or LLMs should be considered. Without actionable advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that \"the unique challenges of fine-tuning multiplicity in Tabular LLMs remain relatively unexplored\" and critiques the main results for being general and not leveraging unique characteristics of tabular data or LLMs. However, it does not specify which part of the paper this critique is based on, such as specific sections or results, making it weakly grounded. The comment is specific in identifying the issue of general results not leveraging unique characteristics, but without clear grounding, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage unique characteristics of tabular data or LLMs. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks explicit references or detailed explanations, making it difficult for the authors to understand and address the critique effectively. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s main results, noting that they are general and do not leverage the unique characteristics of tabular data or LLMs. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should focus on demonstrating how their work addresses the specific challenges of fine-tuning multiplicity in Tabular LLMs. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and observations about the paper. It suggests that the summation should be a double summation, one over multi-layered garments and the other over vertices of the garment. It also asks for clarification on the function f(\u00b7) mentioned just above eq. 3. Additionally, it mentions existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on a human body and questions the authors about the challenges in simulating multiple layers compared to single-layered clothing. While the comment provides specific points for the authors to consider, it does not explicitly instruct them on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line just above eq. 3\" and \"multi-layered garments,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the summation, the function f(\u00b7), and references existing works like TailorNet and Patel et al. 2021. The comment provides clear guidance on what needs to be clarified or addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the summation and the function f(\u00b7) in the paper. It also references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on a human body. While the comment provides some context by mentioning these references, it lacks specific examples or detailed reasoning to fully substantiate the claim that simulating multiple layers is more challenging than single-layered clothing. The references to existing works are a step towards verification, but the comment could be strengthened with more detailed analysis or comparisons. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several specific questions and points of clarification regarding the paper. It suggests that the summation should be a double summation, one over multi-layered garments and the other over vertices of the garment. It also asks for clarification on the function f(\u00b7) mentioned just above eq. 3. Additionally, the comment references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on a human body and questions the authors about the challenges in simulating multiple layers compared to single-layered clothing. This feedback is clear and actionable, providing the authors with specific areas to clarify and expand upon in their paper. However, it could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft by addressing key points of confusion and suggesting areas for further explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as gamma times the square root of B divided by the minimum estimated distance. It also inquires about proving that the proposed GRADE reduces this supremum. While the comment identifies areas of confusion and suggests that the authors clarify these points, it does not provide explicit instructions or concrete steps for addressing these issues. The authors are left to infer that they need to provide a clearer explanation and proof, but the comment lacks specific guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1\" and \"theoretical analysis,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the theoretical analysis, specifically asking why the supremum is defined as gamma times the square root of B divided by the minimum estimated distance, and how the proposed GRADE reduces this supremum. This provides clear guidance on what needs to be clarified or improved in the theoretical analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as gamma times the square root of B divided by the minimum estimated distance. It also inquires about proving that the proposed GRADE reduces this supremum. While the comment identifies a potential area of confusion, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that there is confusion or to explain why this definition is problematic. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the theoretical analysis, questioning the definition of the supremum and its relevance to the proposed GRADE. It asks for clarification on how the proposed method reduces this supremum, which is a critical aspect of the theoretical analysis. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation and proof of their theoretical claims. However, the comment could be more helpful if it offered suggestions on how to address the confusion or provided examples of similar approaches. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on these samples. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide results and analysis on lengthy dialogues, but it lacks concrete guidance on how to execute this task. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on these samples. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for results and analysis on lengthy dialogues, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on these samples. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would impact the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking whether the performance will drop on these samples. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific aspects should be considered. The comment hints at a need for additional experimentation or analysis but does not offer actionable steps or examples, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more comprehensive and detailed to be fully beneficial. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, to enhance the evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities. While the comment implies that the authors should consider including these modalities, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors need to infer the need for inclusion of additional modalities and how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. However, it does not specify which part of the paper discusses the datasets or where these suggestions should be applied. The authors can infer that it relates to the dataset section, but this inference is not direct. The comment is specific in its suggestion to include additional modalities, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. The comment provides references to existing works that discuss modality bias and learning rates between modalities, which supports the claim. However, the comment could be strengthened by providing specific examples or detailed reasoning on how including these modalities would improve the evaluation. As it stands, the claim is mostly verifiable, as it offers a logical basis but lacks comprehensive evidence or detailed examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities, which can help the authors understand the importance of including these modalities. However, the comment lacks specific guidance on how to incorporate these modalities or what specific changes should be made to the datasets. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities. While the comment implies that the authors should consider including these modalities, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors need to infer the need for inclusion of additional modalities and how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities. However, the comment does not specify which part of the paper discusses the datasets or where these suggestions should be applied, making it weakly grounded. The suggestion is specific in terms of what should be included in the datasets, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities, which supports the claim. However, the comment could be strengthened by providing specific examples or detailed reasoning on how including these modalities would improve the evaluation. While the references are relevant, they do not directly address the current study, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the datasets used in the study should include more natural modalities, such as audio and visual, for better evaluation. It provides references to existing works that discuss modality bias and learning rates between modalities, which can help the authors understand the importance of including these modalities. However, the comment lacks specific guidance on"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. While the comment highlights a potential oversight, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should include a discussion of these related works, but the comment lacks concrete details on how to integrate this information into their paper. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper should discuss these related works, making it weakly grounded. The comment is specific in identifying the similarity and suggesting that these works should be discussed, but it lacks detailed guidance on how to integrate this information into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, the comment does not provide specific examples or detailed comparisons to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the claim is somewhat verifiable, as it lacks sufficient evidence or examples to fully support the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a potential oversight in the paper, noting that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not discuss these related works in the paper. This feedback is somewhat helpful as it identifies a gap in the literature review or discussion section, prompting the authors to consider including these related works to provide a more comprehensive context. However, the comment lacks specific guidance on how to integrate these references or what aspects of the related works are particularly relevant. To be more helpful, the comment could suggest specific aspects of the related works that should be discussed or how they might impact the paper\\'s conclusions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. While the comment identifies a potential oversight, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should include a discussion of these related works, but the comment lacks concrete details on how to integrate this information into their paper. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a similarity between the oracle-context model and some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper should discuss these related works, making it weakly grounded. The comment is specific in identifying the similarity and suggesting that these works should be discussed, but it lacks detailed guidance on how to integrate this information into the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the oracle-context model is similar to some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not provide specific examples or detailed comparisons to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the claim is somewhat verifiable, as it lacks sufficient evidence or examples to fully support the assertion.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper, noting that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not discuss these related works in the paper. This feedback highlights an area where the paper could be improved by providing a more comprehensive literature review or discussion. While the comment points out a gap in the paper, it lacks specific guidance or suggestions on how the authors might address this issue or integrate these related works into their discussion. Therefore, the comment is somewhat helpful, as it provides a general direction"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide more insights into how the observed phenomena can be used to design better resilient systems. It implies that the authors should consider proposing a defense method that resembles a hierarchical system, which would demonstrate the usefulness and significance of the observed results. While the comment implies an action, it does not explicitly instruct the authors to do so. Additionally, it lacks concrete guidance on how to implement this suggestion, such as specific defense methods or design considerations. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"observed phenomenon\" and the need to provide more insights into how to use these observations to design better resilient systems. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a potential approach to address the issue by proposing a defense method that resembles a hierarchical system, which would demonstrate the usefulness and significance of the observed results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks depth in its exploration of the observed phenomena and proposes a specific direction for improvement by suggesting the use of a defense method that resembles a hierarchical system. However, the comment does not provide any supporting evidence, examples, or references to justify why this approach would be beneficial or how it would demonstrate the usefulness and significance of the observed results. Without additional context or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that it only discusses the observed phenomena without providing insights on how to use these observations to design better resilient systems. It suggests a specific direction for improvement by proposing the integration of a defense method that resembles a hierarchical system, which would demonstrate the usefulness and significance of the observed results. This feedback is clear and actionable, offering a concrete suggestion for enhancing the paper\\'s contribution. However, it could be more helpful if it provided additional guidance on how to implement this suggestion or examples of similar approaches. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but it lacks rigorous definitions. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what specific definitions are missing or how they should be developed. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Since the comment is vague and does not offer actionable advice, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but it lacks specific details or examples. It does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is not specific in terms of what definitions are missing or how they should be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but no rigorous definitions are provided. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the authors aim to evaluate a form of reliability or trust by examining what LLMs \"know,\" but no rigorous definitions are provided. This feedback highlights a gap in the paper that could impact the clarity and rigor of the evaluation. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of specific definitions or examples. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide explanations or evidence regarding these aspects. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in terms of what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification or explanation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification and does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment identifies relevant areas for exploration and questions that could lead to improvements in the paper, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should include a theoretical analysis, but it does not specify what aspects of this analysis should be included or how it should be structured. As a result, the authors are left without clear instructions on how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in identifying the theoretical analysis as a missing element, but without clear guidance on where or how to address this issue, it remains under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the theoretical analysis is lacking, namely the justification for why deep layer parameters are more suitable for distillation. This feedback is valuable as it points out a gap in the paper that the authors can address to strengthen their work. However, the comment does not provide detailed guidance or suggestions on how to improve the theoretical analysis or what specific aspects should be considered. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that a significant amount of important paper details are in the appendix, suggesting that the paper is not sufficiently self-contained. However, it does not provide explicit guidance on how the authors should address this issue, such as recommending the inclusion of these details in the main text or suggesting ways to improve the self-containment of the paper. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to address the issue of self-containment, but they are not given clear instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a concern about the distribution of important paper details in the appendix, suggesting that the paper is not sufficiently self-contained. However, it does not specify which sections or details are in the appendix, making it difficult for the authors to pinpoint the exact parts that need attention. The lack of specific guidance or examples makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not sufficiently self-contained. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the details in question, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that a large amount of important details are contained in the appendix, which makes the paper less self-contained. This feedback is valuable as it highlights a potential weakness in the paper\\'s organization and presentation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending ways to integrate these details into the main text or improve the paper\\'s self-contained nature. While it points out a problem, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence regarding the scalability of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment identifies a specific aspect of the argument related to dataset size, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the dataset size, but without clear grounding, it is challenging for the authors to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it questions the sufficiency of the dataset size, suggesting that it may not be considered \"large enough.\" While the comment provides a logical reasoning for questioning the dataset size, it lacks specific examples or references to support the claim that 50K points is not a large enough dataset. This makes the claim somewhat verifiable, as it provides a basis for questioning but requires further elaboration or evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment identifies a potential weakness in the argument, it lacks specific guidance or suggestions on how the authors might address this concern or provide more context regarding the scalability of their method. The feedback is somewhat helpful as it highlights an area for improvement but does not offer detailed advice or actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment identifies a specific aspect of the argument related to dataset size, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the dataset size, but without clear grounding, it is challenging for the authors to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be considered \"large enough.\" While the comment provides a logical reasoning for questioning the dataset size, it lacks specific examples or references to support the claim that 50K points is not a large enough dataset. This makes the claim somewhat verifiable, as it provides a basis for questioning but requires further elaboration or evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' argument about the scalability of gradient descent-based methods for clustering to large datasets. However, it raises a concern about the size of the largest"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically questioning the reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to make the assumptions more practical. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"assumption 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the practicality of the assumptions and asks for clarification on the difficulty of \"overloading the library with ASD subroutines.\" This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically questioning the reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the assumptions are impractical. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions made in the paper, specifically questioning the reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable feedback or detailed reasoning, the authors are left with a general idea of what needs improvement but without clear steps to take. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a sentiment about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the excitement of the methodology. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a sentiment about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on what aspects of the methodology are considered common or lack excitement. Without specific references or detailed feedback, the authors cannot confidently determine which part of the paper needs attention or improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any specific feedback, examples, or suggestions on how the authors might enhance the excitement or improve the methodology. Without actionable guidance or detailed critique, the authors are left without a clear understanding of how to address the issue or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. Without specific guidance or suggestions on how to enhance the excitement of the methodology or improve the draft, the authors are left without a clear understanding of what steps to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on what aspects of the methodology are considered common or lack excitement. Without specific references or detailed feedback, the authors cannot confidently determine which part of the paper needs attention or improvement. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any specific feedback, examples, or suggestions on how the authors might enhance the excitement or improve the methodology. Without actionable guidance or detailed critique, the authors are left without a clear understanding of how to address the issue or improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the excitement of the methodology. Without specific guidance or suggestions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide details on what aspects of the methodology are considered common or lack excitement. Without specific references or detailed feedback, the authors cannot confidently determine which part of the paper needs attention or improvement."}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the paper, specifically mentioning a statement in section 4 that claims \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting,\" while Fig. 4 suggests otherwise. However, the comment does not provide explicit guidance on how the authors should address this inconsistency or what changes are needed to correct it. The action is implicit and vague, as the authors are left to infer that they need to revise the statement or provide a more accurate interpretation of the results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statement in section 4, which claims that \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting,\" while Fig. 4 suggests otherwise. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a statement in section 4 that contradicts the results shown in Fig. 4. The comment provides a specific example of an inconsistency, which is a logical reasoning that supports the claim. However, it lacks detailed evidence or references to substantiate the claim further. While the example is clear, the absence of additional supporting information makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the paper, pointing out a discrepancy between the claim in section 4 that \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting\" and the results presented in Fig. 4, which suggest otherwise. This feedback is clear and actionable, as it directs the authors to revisit and correct the statements in their paper to align with the actual results. However, the comment could be more helpful if it provided additional guidance on how to resolve the inconsistency or suggested ways to present the results more effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a comparison of the proposed method\\'s performance on the VLN Leaderboard with existing methods, specifically mentioning [1, 2, 3] as examples. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue of their method\\'s performance or what steps they might take to improve it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a specific comparison of the proposed method\\'s performance on the VLN Leaderboard with existing methods, referencing specific works such as [1, 2, 3]. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment also specifies what needs to be addressed, namely the comparison with existing methods and the performance ranking. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method\\'s results are not better than existing methods, referencing specific works [1, 2, 3] as examples. However, the comment does not provide detailed reasoning or analysis to support why the proposed method\\'s results are not better or how it compares to the referenced works. The lack of specific comparisons or detailed justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific comparison of the proposed method\\'s performance on the VLN Leaderboard with existing methods, referencing specific works [1, 2, 3]. This comparison highlights the relative ranking of the proposed method and its performance compared to other methods. However, the comment does not offer actionable feedback or suggestions on how the authors might improve their method or address the identified shortcomings. While it provides some insight into the performance of the proposed method, it lacks guidance on how to enhance the draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide specific guidance on how the authors should improve the discussion or what aspects need clarification. The comment lacks explicit instructions or concrete suggestions for addressing the issue, leaving the authors uncertain about how to enhance the clarity and convincingness of their explanation. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of convincingness in the discussion regarding how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the discussion section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 2.2, noting that it is not convincing regarding how semantic similarity is modeled with the proposed approach. While it highlights a potential weakness in the paper, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proposed SEPAI3R3O model, noting that it introduces over 10 parameters that may be difficult to estimate reliably due to limited real-world observations. It also points out that modeling these parameters as time-varying further complicates the estimation process. The reviewer explicitly suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is explicit and provides a clear action for the authors to take, namely to address the uncertainty in parameter estimation and conduct sensitivity analysis. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of having over 10 parameters that may be difficult to estimate reliably, especially when modeled as time-varying. The comment further suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed SEPAI3R3O model introduces over 10 parameters, which may be difficult to estimate reliably due to limited real-world observations. The reviewer further notes that modeling these parameters as time-varying exacerbates the estimation challenge. The comment suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the difficulty of estimating parameters. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, noting that it introduces over 10 parameters that may be difficult to estimate reliably due to limited real-world observations. It further points out that modeling these parameters as time-varying exacerbates the estimation challenge. The reviewer suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and actionable, as it highlights a specific area of concern and offers a constructive suggestion for improvement. By addressing this issue, the authors can enhance the robustness and reliability of their model. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also expresses skepticism about the performance of the proposed method and the relative performances of MC, IB, and HSIC test, suggesting that the results may depend on how the parameters are changing across domains. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also expresses skepticism about the performance of the proposed method and the relative performances of MC, IB, and HSIC test, suggesting that the results may depend on how the parameters are changing across domains. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or analysis. This makes it difficult for the authors to pinpoint where the issue lies. While the comment is specific in its critique of the assumption and the performance of the methods, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the assumption that the causal parameters across domains are random samples, suggesting that this assumption may not be a consequence of not having latent confounders. The reviewer questions the performance of the proposed method and the relative performances of MC, IB, and HSIC test, implying that the results depend on how the parameters are changing across domains. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors may find it challenging to understand and address the critique without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a critical concern about the assumption that the causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also expresses skepticism about the performance of the proposed method and the relative performances of MC, IB, and HSIC test, suggesting that the results may depend on how the parameters are changing across domains. This feedback highlights a potential weakness in the paper and prompts the authors to reconsider their assumptions and the robustness of their methods. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their analysis. While it identifies an important issue, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the assumption that the causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also expresses skepticism about the performance of the proposed method and the relative performances of MC, IB, and HSIC test, suggesting that the results may depend on how the parameters are changing across domains. However, the comment does not provide explicit or implicit actions for the authors to take in response to these concerns. It lacks guidance on how the authors might address these issues or improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the assumption that the causal parameters across domains are random samples and questions whether this assumption is a consequence of not having latent confounders in the system. It also expresses skepticism about the performance of the proposed method and the relative performances of MC, IB, and HSIC test, suggesting that the results may depend on how the parameters are changing across domains. However, the comment does not specify which part of the paper this critique relates to, such as a particular section or analysis. This lack of grounding makes it difficult for the authors to identify the exact area needing improvement. While the comment is specific in its critique of the assumptions and methods, it lacks grounding, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the assumption that the causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the novelty of the structural optimization method, questioning whether it is new or not. It also notes that the title mentions this method, which further weakens the narrative. However, the comment does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to clarify the novelty or improve the narrative, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the novelty of the structural optimization method, questioning whether it is new or not. It also notes that the method is mentioned in the paper title, which further weakens the narrative. However, the comment does not specify which part of the paper should be revised to address this issue, nor does it provide detailed guidance on how to clarify the novelty or improve the narrative. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be new. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the novelty of the structural optimization method, questioning whether it is truly new or not. It also notes that the method is mentioned in the paper title, which further weakens the narrative. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the narrative. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential problem but lacks depth and actionable insights.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, while standard mixup allows for the generation of mixed samples with lambda being 0.5. This implies that the assumption in the proof may not be correct. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the proof. The action is implicit and somewhat vague, as the authors need to infer that they should revise the proof to account for the possibility of lambda being 0.5. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, specifically noting that it requires lambda not to be 0.5, while standard mixup allows for the generation of mixed samples with lambda being 0.5. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof requires lambda not to be 0.5, while standard mixup allows for the generation of mixed samples with lambda being 0.5. This suggests that the assumption in the proof may not be correct. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further investigate the proof to understand the implications of this claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, while standard mixup allows for the generation of mixed samples with lambda being 0.5. This observation highlights a discrepancy that could affect the validity of the proof. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the proof. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. Additionally, it suggests extracting some of the inlined math into environments to facilitate symbol lookup, specifically on page 6. These requests are clear and provide specific guidance on what needs to be done to improve the draft. The actions are direct and concrete, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraph above Theorem 3.1, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely highlighting the set of equations with the same form as the Riccati equation and suggesting the extraction of inlined math into environments for easier symbol lookup. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for clarification and a suggestion for improvement. The first part is a request for clarification, which does not contain a claim or opinion. The second part suggests extracting inlined math into environments to facilitate symbol lookup, which is a suggestion for improvement. Both parts of the comment are factual and do not express opinions or claims, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by asking the authors to highlight which set of equations have the same form as the Riccati equation in a particular paragraph. It also suggests extracting some of the inlined math into environments to facilitate symbol lookup, specifically on page 6. This feedback is clear and directly addresses the need for clarity and organization in the manuscript, offering the authors a concrete way to improve their draft. However, it could be more helpful if it explained why this extraction would be beneficial or provided examples of how it could be done. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and organization of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the need for statistical evidence to clarify subjective terms like \"significant.\" While the comment provides explicit actions\u2014improving clarity through structure and transitions and using statistical evidence for subjective terms\u2014it does not offer detailed guidance on how to achieve these improvements. The authors are given a clear direction but may need to infer specific strategies for implementation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it mentions a specific term, \"significant,\" that could be clarified with statistical evidence. However, it does not specify which sections of the paper are unclear or lack transitions, making it weakly grounded. The comment is specific in its suggestion to use statistical evidence for subjective terms, but without explicit references to sections, the authors may struggle to pinpoint where these improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and it mentions the use of subjective terms like \"significant.\" The reviewer provides a specific example of a term that could be clarified with statistical evidence, such as p-values. This feedback is somewhat verifiable as it identifies a potential issue with clarity and suggests a method for improvement, but it lacks detailed examples or references to support the claim fully. The authors would need to infer the specific sections that need improvement and how to implement the suggested changes, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of writing, particularly in sections that lack clear structure and transitions. It provides a concrete suggestion by recommending the use of statistical evidence, such as p-values, to clarify subjective terms like \"significant.\" This feedback is actionable and provides a clear direction for the authors to enhance the clarity and rigor of their writing. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or provided examples of how to structure the sections more effectively. Overall, the comment is mostly helpful, as it effectively directs the authors toward improving the clarity and rigor of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the detailed information for graph construction is missing, specifically mentioning the lack of explanation on how to define edges and construct a graph for non-euclidean datasets. While the comment identifies a gap in the paper, it does not provide explicit instructions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include this information, and it is somewhat vague because it lacks specific guidance on what details to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of detailed information regarding graph construction, specifically mentioning the lack of explanation on how to define edges and construct a graph for non-euclidean datasets. However, it does not specify which part of the paper this information is missing, making it weakly grounded. The comment is specific in detailing what is missing, which helps the authors understand the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the detailed information for graph construction is missing, specifically mentioning the lack of explanation on how to define edges and construct a graph for non-euclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the detailed information for graph construction, particularly the lack of explanation on how to define edges and construct a graph for non-euclidean datasets. This feedback is valuable as it highlights an area where the authors can provide additional context or guidance to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how other studies have handled similar complexities. Overall, the comment is somewhat helpful as it points out a critical omission but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$, which is a specific request for information. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific information is needed. The comment lacks explicit instructions or concrete details on how to improve the draft, making it vague and unactionable. Authors are left without a clear understanding of what steps to take to address the question, resulting in an unactionable comment.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $\\\\alpha$ and $\\\\beta$, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the determination of the default settings for these hyper-parameters. The comment is specific in its request for information, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for information regarding the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. While it identifies a potential area for improvement, it does not provide any context or suggestions on how the authors might address this issue or why it is important. The comment lacks depth and actionable guidance, leaving the authors with a general question but no clear path for improvement. Therefore, it is barely helpful, as it provides some insight but does not offer comprehensive feedback or suggestions for enhancement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the visual or textual representations used in each method in Table 4. It also points out that the end-to-end performance gain might be attributed to the proposed attention model, suggesting that clarification is needed. While the comment identifies a specific area of confusion, it does not provide explicit instructions on how to address it. The authors can infer that they need to clarify the representations used in the methods, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the visual or textual representations used in each method and questioning whether the end-to-end performance gain is due to the proposed attention model. This provides clear guidance on what needs to be clarified or addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the visual or textual representations used in each method in Table 4, suggesting that this information is crucial for understanding the end-to-end performance gain. However, the comment does not provide any specific reasoning, examples, or references to support the claim that this information is necessary. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of this information or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the visual or textual representations used in each method in Table 4. It questions whether the end-to-end performance gain is due to the proposed attention model, suggesting that this information is crucial for understanding the results. While the comment highlights an important aspect that needs clarification, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and actionable advice, leaving the authors with a general direction to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the convergence analysis, but the lack of detailed instructions on how to do so makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"convergence analysis\" and the \"main part\" of the paper, allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the convergence analysis, including the lack of clarity in the main part, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. The comment also points out the lack of justification for Eq. (15). Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear, as the authors provide a simple proof in the appendix and do not present any related content in the main part of the paper. The reviewer also notes that the proof itself is not clear, mentioning issues with notation and assumptions. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. Therefore, the claim is somewhat verifiable, as it provides some insight but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. It also points out that the convergence assumption is not presented and that Eq. (15) is not well justified. This feedback is clear and actionable, as it provides the authors with specific areas to address and improve in their draft. However, the comment could be more helpful if it offered suggestions on how to clarify these issues or provided examples of how to present the convergence analysis more effectively. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity and rigor of their analysis.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the convergence analysis, but the lack of detailed instructions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"convergence analysis\" and the \"main part\" of the paper, allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the convergence analysis, including the lack of clarity in the main part, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. The comment also points out the lack of justification for Eq. (15). Therefore, this comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the convergence analysis is unclear, as the authors provide a simple proof in the appendix and do not present any related content in the main part of the paper. The reviewer also notes that the proof itself is not clear, mentioning issues with notation and assumptions. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides some insight but requires more information to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. It also points out that the convergence assumption is not presented and that Eq. (15) is not well justified. This feedback is clear and actionable, as it provides the authors with specific areas to address and improve in their draft. However, the comment could be more helpful if"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity and organization in the description of the studied problems, specifically mentioning the insufficient description of uncertainty calibration. It suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment implies that the authors should improve the organization and clarity of their descriptions, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors know they need to improve organization but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the description of uncertainty calibration and suggests that the studied problems are not well-driven and illustrated. It also mentions the need for further organization and summarization of issues such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the organization and clarity of the described problems. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the described problems are not well-driven and illustrated, specifically mentioning the insufficient description of uncertainty calibration as unfriendly for new readers. The reviewer suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to organize and summarize the issues is logical, but without specific examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity and organization of the described problems, particularly noting the insufficient description of uncertainty calibration, which is unfriendly for new readers. It suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and organization of their work. However, the comment could be more helpful if it offered specific suggestions on how to organize and summarize these issues effectively. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and organization of their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific experiments to conduct. The action is implicit, as the authors need to infer that they should include these explorations in their work, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the lack of exploration of PAC-tuning with other techniques, but without clear grounding, it is challenging for the authors to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the absence of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. This feedback is valuable as it highlights an area where the authors could expand their work to provide a more comprehensive analysis. However, the comment lacks specific suggestions or guidance on how to conduct these explorations or what results to expect, which limits its helpfulness. While it provides a clear direction for improvement, the authors are left with a general idea rather than detailed guidance on how to proceed. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to validate the experimental analysis on more models, indicating a clear action that needs to be taken. However, it does not provide specific guidance on which models to include or how to conduct the validation. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the analysis should be validated on more models. The comment is specific in its request for additional validation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any specific reasoning, examples, or references to support why more models are necessary or how the current analysis is insufficient. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental analysis, suggesting that it should be validated on more models. This feedback is clear and actionable, providing the authors with a concrete direction to enhance the robustness and generalizability of their results. However, the comment could be more helpful if it included specific suggestions on which additional models to consider or how to conduct the validation. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a critique of the proposed method, noting that it only shows trainability on a network with 100 layers on CIFAR and that the ImageNet experiments are based on networks with varying normalization layers. It also mentions that the proposed method only has marginal improvement over the baselines. However, the comment does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how to improve the method or what specific changes should be made. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s improvement over the original initialization and critiques the experimental results on CIFAR and ImageNet. It mentions specific references to works by Zagoruyko et al. and Qi et al., which provides some grounding as the authors can infer that these are relevant to the discussion. However, the comment does not specify which part of the paper these critiques pertain to, such as the results section or the discussion section. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the critique of the proposed method\\'s limitations, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method by questioning its improvement over the original initialization and the trainability of a network with 100 layers on CIFAR. It also points out that the ImageNet experiments are based on networks with varying normalization layers and that the proposed method only has marginal improvement over the baselines. The comment references specific works by Zagoruyko et al. and Qi et al., which provides some context and support for the critique. However, the comment lacks detailed analysis or specific examples to fully substantiate the claim about the proposed method\\'s limitations. Therefore, the claim is somewhat verifiable, as it provides some reasoning but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the proposed method by questioning its improvement over the original initialization and the trainability of a network with 100 layers on CIFAR. It also points out that the ImageNet experiments are based on networks with varying normalization layers and that the proposed method only has marginal improvement over the baselines. The comment references specific works by Zagoruyko et al. and Qi et al., which provides some context and support for the critique. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their method. While it identifies weaknesses, it does not offer concrete steps or recommendations for enhancement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the proposed method by questioning its improvement over the original initialization and the trainability of a network with 100 layers on CIFAR. It also points out that the ImageNet experiments are based on networks with varying normalization layers and that the proposed method only has marginal improvement over the baselines. While the comment identifies specific areas for improvement, it does not provide explicit guidance or suggestions on how the authors might address these issues or enhance their method. The feedback lacks actionable steps or detailed advice, leaving the authors without clear direction on how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method by questioning its improvement over the original initialization and the trainability of a network with 100 layers on CIFAR. It also points out that the ImageNet experiments are based on networks with varying normalization layers and that the proposed method only has marginal improvement over the baselines. The comment references specific works by Zagoruyko et al. and Qi et al., which provides some context. However, it does not specify which part of the paper these critiques pertain to, such as the results or discussion sections. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in detailing the critique of the proposed method\\'s limitations, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method by questioning its improvement over the original initialization and the trainability of a network with 100 layers on CIFAR. It also points out that the ImageNet experiments are based on networks with varying normalization layers and that the proposed method only has marginal improvement over the baselines. The comment references specific works by Zagoruyko et al. and"}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. While the comment explicitly states the action needed, it does not provide specific guidance on how to conduct this comparison or what aspects should be emphasized. The authors are left with a clear direction but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to compare robustness and immunizability, providing a clear direction for the authors to enhance their paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with another method from Yu et al. 2021. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with another method from Yu et al. 2021. This feedback is somewhat helpful as it identifies a specific area for improvement by highlighting the need for a comparative analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what aspects should be emphasized. While it offers a direction for the authors to enhance their draft, it could be more helpful with additional context or suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the \"better\" samples produced by the proposed algorithm for adaptive top-k decoding. It suggests that the authors clarify any misunderstandings and requests a plot of the time complexity of the decoding scheme as a function of m. While the comment implies that the authors should provide additional information or a plot, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the request for clarification and the plot. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3)\", which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on whether the work produces \"better\" samples and suggests a plot of the time complexity of the decoding scheme as a function of m. This provides clear guidance on what needs to be addressed or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification and a suggestion for additional information. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the \"better\" samples produced by the proposed algorithm for adaptive top-k decoding. It suggests that the authors clarify any potential misunderstandings and requests a plot of the time complexity of the decoding scheme as a function of m. While the comment identifies a potential area for clarification and improvement, it lacks specific guidance or suggestions on how to address these points. The request for a plot is a useful addition, but the overall feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the postprocessing effort mentioned in footnote 2, indicating that it is not clear. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific information should be added to clarify the postprocessing effort. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarity of the postprocessing effort mentioned in the footnote. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the clarity of the postprocessing effort mentioned in footnote 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the postprocessing effort mentioned in footnote 2, indicating that it is not clear. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this aspect. The comment lacks depth and actionable feedback, leaving the authors with a vague indication of an issue but no clear path to address it. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point is a question asking whether the authors have run their codes for multiple seeds and reported the mean. While it does not explicitly instruct the authors to do so, the question implies that the authors should consider running their codes multiple times and reporting the mean to provide more robust results. The action is implicit but clear, as the authors can infer that they need to conduct additional runs and report the mean to improve the reliability of their findings. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the action of running codes for multiple seeds and reporting the mean, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to run the codes for multiple seeds and report the mean. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking whether the authors have run their codes for multiple seeds and reported the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, so it should be labeled as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question asking whether the authors have run their codes for multiple seeds and reported the mean. While it identifies a potential issue with the reliability of the results, it does not provide any guidance or suggestions on how to address this concern. The comment lacks depth and does not offer actionable feedback or constructive advice for improvement. As a result, it is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup for these datasets. It also points out the absence of results for models like InceptionV3 and ResNet in Table 3, while they are included in Table 2. While the comment highlights specific areas that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The authors can infer that they need to provide more detailed explanations and possibly include the missing models in Table 3, but the comment lacks concrete guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the differences between the BCI and IHC4BC datasets and the absence of certain models in Table 3. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the differences between the BCI and IHC4BC datasets and the experimental setup. It also points out the absence of certain models in Table 3. These are factual inquiries that do not express opinions, judgments, or suggestions that require verification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the differences between the BCI and IHC4BC datasets and the experimental setup for these datasets. It highlights a specific issue with Table 3, noting the absence of results for models like InceptionV3 and ResNet, while Table 2 includes them. This feedback is valuable as it prompts the authors to clarify the experimental setup and ensure consistency across tables. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into why these models were excluded. Overall, the comment is mostly helpful as it identifies a gap in the paper and encourages the authors to provide additional information, but it could be more comprehensive with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Fig 4. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be done, which is to enhance the description of the results in the figure. This level of detail and specificity makes the action explicit and concrete, ensuring that the authors know exactly how to address the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies what needs to be addressed by requesting a more thorough description of the results shown in the figure. This provides clear guidance on what the authors need to do to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide a more thorough description of the results shown in Fig 4. However, it does not provide any specific reasoning or evidence to support why this description is inadequate or how it could be improved. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to enhance the description of the results shown in Fig 4. By specifying that a more thorough description is needed, the reviewer guides the authors on how to improve the clarity and comprehensiveness of their results section. This feedback is specific and directly addresses a potential weakness in the paper, offering a straightforward way for the authors to enhance their draft. However, it could be more helpful if it included examples of what constitutes a thorough description or how to present the results more effectively. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they should incorporate this comparison, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. However, it does not specify which part of the paper this comparison should be made in, leaving the authors to infer that it pertains to the method section. While the comment provides a specific suggestion for improvement, it lacks grounding as it does not explicitly mention a section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. However, the comment does not provide any specific reasoning or evidence to support why [11] is the most relevant literature or why it should be compared in the method part. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. While this feedback identifies a potential area for improvement by highlighting a relevant piece of literature, it lacks specificity and does not provide detailed guidance on how to incorporate this comparison effectively. The comment does not offer suggestions on what aspects of the work should be compared or how the comparison could enhance the paper. As a result, the feedback is somewhat helpful, as it points out a potential area for improvement but does not provide actionable steps for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. However, the comment does not provide explicit guidance on how the authors should address this concern or what steps they should take to justify their process. The action is implicit and vague, as the authors are left to infer that they need to provide a more robust justification for their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the process of removing words with identical English counterparts in the class label translation and cleaning. However, it does not explicitly mention which part of the paper this process is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the justification for this process and references a specific paper for further discussion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. This reference provides a logical basis for the claim, as it highlights a potential issue with the current approach. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks comprehensive support.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. This feedback is somewhat helpful as it points out a potential weakness in the methodology and provides a reference for further exploration. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional context on why this might be a concern. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. However, the comment does not provide explicit guidance on how the authors should address this concern or what steps they should take to justify their process. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the process of removing words with identical English counterparts in the class label translation and cleaning. However, it does not explicitly mention which part of the paper this process is discussed in, making it weakly grounded. The comment is specific in pointing out the potential issue with the justification for this process and references a specific paper for further discussion. This provides a clear basis for the concern, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. This reference provides a logical basis for the claim, as it highlights a potential issue with the current approach. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks comprehensive support.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s process of removing words with identical English counterparts in the class label translation and cleaning. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which suggests that there may be legitimate shared words between English and language-specific vocabularies. This feedback is somewhat helpful as it points out a potential weakness in the methodology and provides a reference for further exploration."}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While the comment implies that the authors should expand their analysis to include additional models, it does not provide specific guidance on which models to include or how to conduct this additional analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or discussion. The authors might infer that it relates to the conclusions or discussion sections, but this inference is not direct. The comment is specific in its suggestion to study more models, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. However, the comment does not provide any specific reasoning, examples, or references to support why additional models are necessary or how they would impact the conclusions. Without such evidence or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While this feedback highlights a potential area for improvement, it lacks specificity and does not provide detailed guidance on which additional models should be considered or how to conduct this analysis. The comment is somewhat helpful as it identifies a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide further explanation or exploration of the reason behind the significant reduction in the norm for OpenCLIP in Figure 7, despite not showing significant improvement for object localization in Table 3. While the comment implies that the authors should investigate this discrepancy, it does not explicitly instruct them to do so or provide specific guidance on how to explore this issue. The action is implicit and somewhat vague, as the authors need to infer the need for further explanation and exploration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the significant reduction in the norm for OpenCLIP in Figure 7 and the lack of significant improvement for object localization in Table 3. The comment further suggests that the authors should provide further explanation or exploration of this discrepancy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the norm shows a significant reduction for OpenCLIP in Figure 7, but it does not show significant improvement for object localization in Table 3. The reviewer suggests that further explanation or exploration of this discrepancy would be helpful for wider adoption. However, the comment lacks specific reasoning or evidence to support why this discrepancy is significant or how it impacts the paper\\'s conclusions. Without detailed justification or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results presented in Figure 7 and Table 3, specifically regarding the significant reduction in the norm for OpenCLIP in Figure 7, yet the lack of significant improvement for object localization in Table 3. It suggests that further explanation or exploration of this discrepancy would be beneficial for the paper\\'s wider adoption. While the comment highlights an important issue, it lacks specific guidance or suggestions on how the authors might address this discrepancy or explore the reasons behind it. Providing more detailed advice or examples could make the feedback more actionable and helpful. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully guide the authors on how to address it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a discrepancy between the results presented in Figure 7 and Table 3, specifically regarding the significant reduction in the norm for OpenCLIP in Figure 7, yet the lack of significant improvement for object localization in Table 3. It suggests that further explanation or exploration of this discrepancy would be helpful for the paper\\'s wider adoption. While the comment implies that the authors should investigate this issue, it does not explicitly instruct them to do so or provide specific guidance on how to explore this discrepancy. The action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the significant reduction in the norm for OpenCLIP in Figure 7 and the lack of significant improvement for object localization in Table 3. The comment further suggests that the authors should provide further explanation or exploration of this discrepancy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the norm shows a significant reduction for OpenCLIP in Figure 7, yet it does not show significant improvement for object localization in Table 3. The reviewer suggests that further explanation or exploration of this discrepancy would be helpful for wider adoption. However, the comment lacks specific reasoning or evidence to support why this discrepancy is significant or how it impacts the paper\\'s conclusions. Without detailed justification or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the results presented in Figure 7 and Table 3, specifically regarding the significant reduction in the norm for OpenCLIP in Figure 7, yet the lack of significant improvement"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of 3D renders in conjunction with G, specifically asking for more details on how the point cloud is utilized in this stage. While the comment implies that the authors should provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more details about the 3D rendering and GAN combination. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of details on how the point cloud is used in conjunction with the 3D rendering and GAN objective. This provides clear guidance on what additional information is needed to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the clarity of the 3D to 2D rendering process, specifically regarding the use of point clouds in conjunction with the GAN objective. The comment highlights a lack of detail in the explanation provided in Section 3.3. However, it does not provide any specific examples, reasoning, or references to support the claim that the explanation is unclear. This makes the comment somewhat verifiable, as the authors would need to infer the exact issues and provide additional details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of 3D renders with the GAN objective, particularly in Section 3.3. It highlights the lack of clarity on how the point cloud is utilized in this stage and suggests that more details about the combination of 3D rendering and GAN would be beneficial. This feedback is clear and actionable, as it points out a specific area where the authors can provide additional information to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how similar concepts have been explained effectively. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also notes that the claim of parameter insensitivity is supported by simple architectures and datasets, which is considered not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their evidence. The feedback lacks actionable steps, such as recommending specific experiments or analyses to strengthen the evidence. As a result, the authors are left without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also critiques the supporting evidence for parameter insensitivity, noting that it relies heavily on simple architectures and datasets. However, the comment does not specify which part of the paper discusses these hyperparameters or the supporting evidence, making it weakly grounded. The comment is specific in identifying the issue of parameter insensitivity and the reliance on simple datasets, but it lacks grounding as it does not point to a specific section or example in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model, and that the claim of parameter insensitivity is supported by simple architectures and datasets. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the evidence is not convincing. Without concrete evidence or references to support the assertion, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It notes that the claim of parameter insensitivity is supported by simple architectures and datasets, which is considered not convincing. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide more convincing evidence. While it highlights a potential weakness, it does not offer actionable steps or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be achieved with other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, particularly regarding computational costs and real-world scenarios. While the comment implies that the authors should discuss these aspects, it does not provide explicit guidance on how to address these concerns or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the specific improvements or discussions required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the marginal improvements over baselines and suggests that further improvements could be achieved with other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, particularly regarding computational costs and real-world scenarios. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results or discussion sections where the improvements are presented. The comment is specific in detailing what aspects could be discussed and improved, such as computational costs and real-world scenarios. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be achieved with other PLMs like RoBERTa and T5. The reviewer provides a logical reasoning by comparing the proposed method with other PLMs and suggesting that improvements could be made. However, the comment lacks specific examples or references to support the claim that RoBERTa or T5 would be more effective, making it somewhat verifiable. The authors would need to further explore and verify this suggestion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines, suggesting that further improvements could be achieved with other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, particularly regarding computational costs and real-world scenarios. The comment provides a constructive suggestion to discuss meaningful aspects of the proposed method and experiments in the context of LLMs, which could help the authors better position their work. However, the comment could be more helpful if it offered specific guidance on how to address these concerns or what aspects to focus on. Overall, the feedback is mostly helpful as it identifies a critical area for improvement and provides a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the use of soft assignment instead of hard assignment in the methodology. It suggests that the authors should report an experiment to prove their conjecture, but it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to provide additional information or evidence to support their claim. However, the comment lacks concrete guidance on how to conduct or report the experiment, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"explanation of using soft assignment instead of hard assignment,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the authors have reported an experiment to prove their conjecture. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment in the methodology. It suggests that the authors have not reported an experiment to prove their conjecture, which is a claim. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the exact issue and provide additional context to fully understand and address the concern. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the use of soft assignment instead of hard assignment in the methodology. It highlights that while the explanation is provided, there is no evidence or experiment reported to support the authors\\' conjecture. This feedback is clear and actionable, as it directs the authors to include an experiment or evidence to clarify their claim. However, the comment could be more helpful if it provided suggestions on how to conduct or report the experiment. Overall, the comment is mostly helpful as it points out a critical gap in the paper and offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their applicability to general federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses the applicability of the methods or how they are limited. The authors cannot confidently determine which sections or parts of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on how the authors might address the limitation or improve the applicability of their methods. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the applicability of the methods. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. This feedback highlights a potential limitation of the methods, which is important for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. Without actionable advice or detailed feedback, the comment provides only a vague insight into a potential issue, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses the applicability of the methods or how they are limited. The authors cannot confidently determine which sections or parts of the paper are being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on how the authors might address the limitation or improve the applicability of their methods. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this limitation is significant or how it affects the applicability of the methods. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented in the paper are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. This feedback highlights a potential limitation of the methods, which is important for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. Without actionable advice or detailed feedback, the comment provides only a vague insight into a potential issue, making it somewhat helpful but"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what constitutes distributional generalization in the context of regression. It provides an example of a smooth regression model that interpolates the training data, suggesting that such a model would exhibit distributional generalization. However, the comment does not offer explicit guidance or suggestions for the authors to address this question or incorporate it into their work. The action is implicit and vague, as the authors are left to infer that they should explore this concept further but without clear direction on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression. It provides an example to illustrate the phenomenon, which could help the authors understand the point being made. However, the comment does not explicitly mention a specific section, table, or figure, making it weakly grounded. The question is specific in its inquiry about the definition and implications of distributional generalization in regression, but without explicit grounding, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and an observation about the phenomenon of distributional generalization in the context of regression. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual and seeks clarification, while the observation is descriptive and does not make a claim that needs justification. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression, providing an example to illustrate the phenomenon. This question prompts the authors to clarify their understanding of distributional generalization in their work, which could be beneficial for improving the clarity and depth of their analysis. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or incorporate it into their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams\" to find additional results. While the comment implies that the authors should update their references and baselines, it does not explicitly instruct them to do so. The suggestion to search for specific items is concrete, but the overall action is inferred. Therefore, the comment is somewhat actionable, as it provides a clear direction but requires the authors to infer the specific actions to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also mentions a specific search term, \"Item Frequencies of Data Streams,\" which could guide the authors in finding additional results. However, the comment does not specify which parts of the paper these references or baselines are located in, making it weakly grounded. The suggestion is specific in terms of what needs to be updated, but without explicit grounding, the authors may struggle to pinpoint the exact sections that require attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the references and baselines in the paper are outdated and recommends including more recent research. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which specific references or baselines are outdated or how to update them. The mention of \"Item Frequencies of Data Streams\" provides a vague suggestion for further exploration but does not substantiate the claim. As a result, the comment is considered borderline verifiable, as it lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the references and baselines are outdated. It suggests that more recent research should be included, which is a valuable piece of feedback for the authors to consider. Additionally, the comment provides a specific suggestion to search for items like \"Item Frequencies of Data Streams,\" which could lead the authors to additional relevant research. However, the comment could be more helpful if it offered more detailed guidance on how to update the references and baselines or provided examples of recent research to include. Overall, the comment is somewhat helpful as it highlights an area for improvement and offers a starting point for the authors, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams\" to find additional results. While the comment implies that the authors should update their references and baselines, it does not explicitly instruct them to do so. The suggestion to search for specific items is concrete, but the overall action is inferred. Therefore, the comment is somewhat actionable, as it provides a clear direction but requires the authors to infer the specific actions to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams\" to find additional results. However, the comment does not specify which parts of the paper these references or baselines are located in, making it weakly grounded. The suggestion is specific in terms of what needs to be updated, but without explicit grounding, the authors may struggle to pinpoint the exact sections that require attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the references and baselines in the paper are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like 'Item Frequencies of Data Streams' to find additional results. However, the comment lacks detailed justification or examples to support the claim that the references and baselines are outdated. The mention of 'Item Frequencies of Data Streams' provides a vague suggestion for further exploration but does not substantiate the claim. As a result, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the references and baselines are outdated. It suggests that more recent research should be included, which is a valuable piece of feedback for the authors to consider. Additionally, the comment provides a specific suggestion to search for"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a discrepancy between the introduction, which emphasizes the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential gap in the experimental analysis, it does not provide explicit instructions on how to address this issue or what specific aspects of the analysis should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more in-depth analysis in high-dimensional action spaces. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a discrepancy between the introduction, which emphasizes the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The comment specifies what needs to be addressed, namely the need for more in-depth analysis of ARAM\\'s performance in high-dimensional action spaces, such as complex robotic manipulators. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the introduction, which emphasizes the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The reviewer suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment identifies a potential gap in the experimental analysis, it lacks specific examples or references to support the claim that more in-depth analysis is necessary. This makes the claim somewhat verifiable, as the authors would need to infer the extent of the gap and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the introduction, which highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by expanding the experimental analysis to better address the challenges mentioned in the introduction. However, the comment could be more helpful if it provided specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of information regarding the computational requirements of the model, suggesting that the good performance might be due to excessive parameters or computation. It implies that the authors should provide this information to better understand the model\\'s efficiency. The reviewer also suggests a potential experiment to test this hypothesis by comparing the model with the same floats as the original transformers. While the action is implicit, it is concrete and provides a clear direction for the authors to follow. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the lack of information regarding the computational requirements of the model, specifically questioning whether the good performance is due to extra parameters or computation. It suggests a potential experiment to test this hypothesis by comparing the model with the same floats as the original transformers. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for the authors to explore. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the computational efficiency of the model, suggesting that the good performance might be due to excessive parameters or computation. The reviewer implies that by making the model have the same floats as the original transformers, the performance would be similar. However, the comment lacks specific evidence or references to support this claim, making it somewhat verifiable. The authors would need to conduct further analysis to substantiate the claim, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically questioning the computational efficiency of the model. It suggests that the good performance might be due to excessive parameters or computation, and it provides a specific suggestion for further investigation by comparing the model with the same floats as the original transformers. This feedback is clear and actionable, offering a concrete direction for the authors to explore and potentially improve the efficiency of their model. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful as it guides the authors toward a meaningful area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing due to inconsistent trends and statistically insignificant improvements. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the presentation of their results. The feedback lacks actionable details, such as recommending ways to enhance the statistical analysis or suggesting alternative methods to demonstrate consistency. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the evaluation and results sections, noting that the results do not show consistent trends and that some improvements are not statistically significant. However, it does not specify which parts of the evaluation or results are problematic, making it difficult for the authors to pinpoint the exact areas needing attention. The lack of specific guidance or examples leaves the authors without clear direction on how to address the issues raised. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and statistically insignificant improvements. However, it does not provide specific examples or detailed reasoning to support these claims. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation and results sections, noting that the results do not show consistent trends and that some improvements are not statistically significant. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the credibility and robustness of their findings. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending statistical tests or methods to ensure significance. While it points out a problem, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should highlight the percentage of subjective questions in the error rate, which could be problematic if it is significantly high. While the comment implies that the authors should conduct an analysis of human agreement to determine this percentage, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this analysis and determine the percentage. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding subjective questions in the paper, suggesting that it would be useful to highlight the percentage of error rate made up of subjective questions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting a method to address the issue by looking at human agreement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should highlight the percentage of subjective questions in the error rate, which could be problematic if it is significantly high. The reviewer agrees with the suggestion and provides a logical reasoning for why this information is important. However, the comment lacks specific examples or references to support the claim about the percentage of subjective questions or the potential impact on the error rate. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that \"several questions require subjective answers,\" and suggests that it would be useful to highlight the percentage of error rate made up of subjective questions. The reviewer provides a logical reasoning for why this information is important, suggesting that if the percentage is significantly high, it could be problematic. However, the comment lacks specific guidance or actionable steps for the authors to take, such as recommending methods to quantify or address the subjective questions. While it points out an area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper would benefit from including additional NLP tasks such as sentiment classification and named-entity recognition, in addition to the current intent recognition task. This feedback provides a clear and direct action for the authors to take, specifying which tasks to consider. The comment is concrete, as it outlines specific tasks that could enhance the evaluation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the evaluation section, noting that it is weak due to the use of only a single dataset and limited NLP tasks (intent recognition). It suggests that the paper would improve by considering additional NLP tasks such as sentiment classification and named-entity recognition. However, the comment does not specify which part of the paper this evaluation is based on, making it weakly grounded. The suggestion to include additional tasks is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where these changes should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak due to the use of only a single dataset and limited NLP tasks (intent recognition). The reviewer suggests that the paper would improve by considering additional NLP tasks such as sentiment classification and named-entity recognition. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion of additional tasks. This makes the claim somewhat verifiable, as the authors would need to infer the potential benefits of including these tasks themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation section of the paper, noting that it is limited to a single dataset and only one type of NLP task (intent recognition). The reviewer suggests that the paper would benefit from considering additional NLP tasks such as sentiment classification and named-entity recognition. This feedback is clear and actionable, providing the authors with specific areas to expand their evaluation, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered suggestions on how to integrate these additional tasks or discussed the potential impact on the results. Overall, the comment is mostly helpful as it directs the authors toward meaningful improvements, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the label \"s\" should be used instead of \"c\" for the \"class semantic feature\" in Figure 3. This is a clear and direct action that the authors can take to correct the labeling error. The comment provides specific guidance on what needs to be changed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the labeling of the \"class semantic feature\" as \"s\" instead of \"c.\" This provides clear guidance on what needs to be corrected in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the labeling of the \"class semantic feature\" in Figure 3, suggesting that it should be labeled as \"s\" instead of \"c.\" This is a factual statement seeking clarification and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it points out a labeling error in Figure 3, suggesting that the label \"s\" should be used instead of \"c\" for the \"class semantic feature.\" This feedback is clear and provides a direct correction that the authors can implement to improve the clarity and accuracy of their figure. However, the comment could be more helpful if it explained why this labeling is important or how it affects the interpretation of the figure. Despite this, the comment is mostly helpful as it offers a straightforward way for the authors to enhance the quality of their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a distinction between de-identification and face swapping, noting that the proposed method appears to be a form of face swapping, similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms. While the comment implies that the authors should conduct a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to conduct the comparison or which face swapping algorithms to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the distinction between de-identification and face swapping, specifically noting that the method proposed in the paper appears to be a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms. However, the comment does not explicitly mention which part of the paper discusses this distinction, making it weakly grounded. The suggestion to compare with state-of-the-art face swapping algorithms is specific, but without explicit grounding, the authors may struggle to pinpoint where to make these comparisons. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the distinction between de-identification and face swapping is not clear, as the proposed method appears to be a form of face swapping similar to deepfake technology. The reviewer suggests that the authors should compare their method with state-of-the-art face swapping algorithms. While the comment provides a logical reasoning for the claim, it lacks specific references or examples of state-of-the-art face swapping algorithms to support the suggestion. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the distinction between de-identification and face swapping. It points out that the proposed method appears to be a form of face swapping, similar to deepfake technology, and suggests that the authors should compare their method with state-of-the-art face swapping algorithms. This feedback is clear and actionable, as it provides a specific direction for the authors to clarify the distinction and improve the paper by comparing their method with relevant benchmarks. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or which specific face swapping algorithms to consider. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as those on Gaussian embeddings, which is the chief baseline from the literature. However, it does not provide specific guidance on how the authors might improve the results or what aspects of the word embeddings need to be addressed. The comment lacks explicit instructions or concrete suggestions for enhancing the experimental results, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results on word embeddings compared to Gaussian embeddings, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as those on Gaussian embeddings, which is the chief baseline from the literature. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the comparison or how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the results on word embeddings in Tables 1 and 2 are not as compelling compared to Gaussian embeddings, which is the chief baseline from the literature. This feedback is somewhat helpful as it highlights a potential weakness in the experimental evaluation, prompting the authors to consider whether their results are adequately justified or if there are gaps in their analysis. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the experimental setup or results. To be more helpful, the comment could include recommendations for enhancing the experimental design or analysis to better differentiate the word embeddings from Gaussian embeddings. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It suggests that the contribution is small if this is the only difference. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the contribution or differentiate their work from existing studies. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and its relation to previous studies, specifically mentioning references to Shi et al., 2018, and Ghosh et al., 2021. It highlights that the method is similar to these previous studies, except for a change in the task and reward function, and questions the contribution of the work. However, the comment does not specify which part of the paper discusses these comparisons or the proposed method, making it weakly grounded. The comment is specific in identifying the issue of similarity to previous work and the potential lack of contribution, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not significantly different from previous studies, except for a change in the task and reward function. The reviewer supports this claim by referencing specific studies (Shi et al., 2018; Ghosh et al., 2021) and mentioning the change in task and reward function. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the lack of contribution. While the references provide some context, the comment could be strengthened with more detailed analysis or comparisons to make the claim more verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It questions the contribution of the work, suggesting that the change in task and reward function is not enough to justify the novelty. The comment also references specific studies (Shi et al., 2018; Ghosh et al., 2021) and mentions a finding that IRL is effective in text summarization. However, the comment lacks specific suggestions or guidance on how the authors might enhance the contribution or differentiate their work from existing studies. While it identifies a potential issue, it does not provide actionable feedback for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It questions the contribution of the work, suggesting that the change in task and reward function is not enough to justify the novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue or enhance the contribution of their work. Without specific guidance or suggestions, the authors are left without actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method and its relation to previous studies, specifically mentioning references to Shi et al., 2018, and Ghosh et al., 2021. It highlights that the method is similar to these previous studies, except for a change in the task and reward function, and questions the contribution of the work. However, the comment does not specify which part of the paper discusses these comparisons or the proposed method, making it weakly grounded. The comment is specific in identifying the issue of similarity to previous work and the potential lack of contribution, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not significantly different from previous studies, except for a change in the task and reward function. The reviewer supports this claim by referencing specific studies (Shi et al., 2018; Ghosh et al., 2021) and mentioning the change in task and reward function. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim about the lack of contribution. While the references provide some context, the comment could be strengthened with more detailed analysis or comparisons to make the claim"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects of the paper could be improved. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not specify which parts of the paper are being evaluated for novelty or how the authors might enhance it. The comment lacks grounding as it does not reference specific sections, figures, or elements of the paper. It also lacks specificity because it does not provide detailed guidance on how the authors could improve the novelty of their work. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. While it identifies a potential issue with the paper\\'s novelty, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might enhance the novelty of their work or address the perceived limitation. As a result, the comment is not helpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. This feedback is clear and direct, giving the authors a specific action to take: conduct an ablation study on query embedding. The comment provides a concrete and actionable suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests the inclusion of an ablation study related to query embedding, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper lacks this study, making it weakly grounded. The comment is specific in its suggestion to include an ablation study on query embedding, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, the comment does not provide any specific examples, reasoning, or references to support why an ablation study is necessary or how it would benefit the paper. Without detailed justification or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks an ablation study related to query embedding. This suggestion is clear and actionable, as it provides a concrete direction for the authors to enhance their work by conducting an ablation study. By addressing this feedback, the authors can gain insights into the significance and impact of query embedding, potentially strengthening their paper. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful improvement area, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying what aspects of the contribution are marginal or how it could be improved. Without explicit or implicit actions, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the work compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or tables where the contribution is discussed. Additionally, the comment does not provide specific details on what aspects of the contribution are considered marginal or how it could be improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any supporting evidence, reasoning, or references to specific works or aspects of the paper that are being evaluated. Without such details, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, referencing specific works [1, 2, 3] as examples. However, it does not provide any constructive feedback or suggestions on how the authors might address this perceived marginality or improve their contribution. Without actionable guidance or specific points for enhancement, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying which aspects of the contribution are considered marginal or how it could be enhanced. Without explicit or implicit actions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the work compared to previous works, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or tables where the contribution is discussed. Additionally, the comment does not provide specific details on what aspects of the contribution are considered marginal or how it could be improved. Without clear guidance or references, the authors are left without a clear understanding of what needs to be addressed. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any supporting evidence, reasoning, or references to specific works or aspects of the paper that are being evaluated. Without such details, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, referencing specific works [1, 2, 3] as examples. However, it does not provide any constructive feedback or suggestions on how the authors might address this perceived marginality or improve their contribution. Without actionable guidance or specific points for enhancement, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment expresses an opinion that the contribution is marginal compared to previous works, but it does not provide any specific guidance or suggestions for improvement. It lacks actionable details, such as identifying which aspects of the contribution are considered marginal or how it could be enhanced. Without explicit or implicit actions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion that the contribution is marginal compared to previous works, but it does not specify which part of the paper this assessment"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any explicit or implicit action for the authors to take. The comment is purely a request for clarification, leaving the authors without any guidance on how to address it. Since the comment lacks actionable content, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in asking for clarification on the performance loss, but without clear grounding, the authors may struggle to identify the exact section or analysis being referred to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. While it identifies a specific area of interest, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks actionable feedback or constructive advice, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as not helpful at all, consistent with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks actionable content, leaving the authors without guidance on how to address the question or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in asking for clarification on the performance loss, but without clear grounding, the authors may struggle to identify the exact section or analysis being referred to. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the loss of performance of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any context, explanation, or suggestions for improvement. The question itself does not offer actionable feedback or guidance on how the authors might address the issue or enhance their analysis. Without additional context or suggestions, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks actionable content, leaving the authors without guidance on how to address the question or improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in asking for clarification on the performance loss, but without clear grounding, the authors may struggle to identify the exact section or analysis being referred to. Therefore,"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper discusses overoptimization as a motivation but does not directly evaluate it. It suggests that the evaluation should focus on calibration and human evaluation instead. The reviewer also mentions that current works often address overoptimization issues with early stopping, such as AlignProp, and recommends that the paper should evaluate without early stopping to explore the tradeoffs of the proposed solutions. Additionally, the reviewer suggests discussing the benefits of not doing early stopping. While the comment provides a clear direction for improvement, it does not specify how to implement these suggestions or what specific aspects to focus on. The actions are explicit but somewhat vague, as the authors know what needs to be done but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s discussion on overoptimization and the evaluation methods used, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, suggesting that the paper should evaluate for overoptimization rather than calibration and human evaluation. The comment provides a clear rationale for why this approach is necessary and offers suggestions for improvement, such as discussing the benefits of not doing early stopping. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of overoptimization in the paper, suggesting that the paper does not directly address this issue. The reviewer provides a reference to a related work, \"AlignProp,\" which addresses overoptimization through early stopping. This reference supports the claim that the paper should evaluate for overoptimization rather than calibration and human evaluation. However, the comment could be strengthened by providing more detailed reasoning or examples on how overoptimization is typically addressed in the field. Despite this, the overall justification is clear and supported by an external reference, making the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation, specifically the lack of direct evaluation for overoptimization. It suggests that the paper should focus on evaluating overoptimization rather than calibration and human evaluation, which is a critical aspect of the work. The reviewer provides a relevant reference, \"AlignProp,\" which addresses overoptimization through early stopping, and recommends that the paper should evaluate without early stopping to explore the tradeoffs of the proposed solutions. Additionally, the comment suggests discussing the benefits of not doing early stopping, which is a constructive and actionable piece of feedback. This feedback is clear and provides a specific direction for improvement, making it mostly helpful. However, it could be further improved by offering more detailed guidance on how to implement these suggestions. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an analysis demonstrating the equivalence between the proposed TW model and TR, and a discussion justifying the use of TW over TR. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to perform these tasks. The action is implicit and somewhat vague, as the authors need to infer that they should include this analysis and discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed TW model and suggests that it is equivalent to TR, providing a specific analysis and a request for a discussion justifying TW over TR. However, it does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the equivalence and justification of the TW model. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed TW model is equivalent to TR, providing a specific analysis to support this claim. The reviewer explains that by representing the core tensor C as a TR and fusing it with the cores G_n, a TR representation equivalent to the TW model can be achieved. This explanation is logical and provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the authors should include an analysis demonstrating this equivalence and a discussion justifying the use of TW over TR. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the relationship between the two models. However, the comment could be more helpful if it included specific suggestions on how to present this analysis or discussion. Overall, the comment is mostly helpful as it guides the authors toward improving their draft by addressing a potential weakness in the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors discuss the transferability of their toolset and proposes an experiment to create a general toolset for all tasks. While the comment implies that the authors should conduct this experiment, it does not explicitly instruct them to do so. The action is concrete, as it specifies the nature of the experiment, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the transferability of the toolset, specifically mentioning that the toolset for the VQA task and the toolset for the reasoning task are not the same. This provides some grounding as it refers to specific tasks, but it does not explicitly mention which part of the paper discusses these toolsets, making it weakly grounded. The comment is specific in suggesting that the authors discuss the transferability of the toolset and experiment with creating a general toolset for all tasks. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the toolset for the VQA task and the toolset for the reasoning task are not the same, implying that the authors should discuss the transferability of their toolset. However, the comment does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how to address the issue. The lack of supporting evidence or detailed explanation makes the claim borderline verifiable, as it provides a general observation but does not offer sufficient justification for the authors to understand the significance of the issue or how to address it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the transferability of the toolset, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. It suggests that the authors should discuss this transferability and possibly experiment with creating a general toolset for all tasks. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, it lacks detailed guidance on how to conduct the experiment or what aspects to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors discuss the transferability of their toolset and proposes an experiment to create a general toolset for all tasks. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them to conduct the experiment or specify how to implement it. The action is concrete, as it outlines a specific area for improvement, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the transferability of the toolset, specifically mentioning that the toolset for the VQA task and the toolset for the reasoning task are not the same. This provides some grounding as it refers to specific tasks, but it does not explicitly mention which part of the paper discusses these toolsets, making it weakly grounded. The comment is specific in suggesting that the authors discuss the transferability of the toolset and experiment with creating a general toolset for all tasks. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the toolset for the VQA task and the toolset for the reasoning task are not the same, implying that the authors should discuss the transferability of their toolset. However, the comment does not provide specific examples or detailed reasoning to support this claim, nor does it offer suggestions on how to address the issue. The lack of supporting evidence or detailed explanation makes the claim borderline verifiable, as it provides a general observation but does not offer sufficient justification for the authors to understand the significance of the issue or how to address it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the transferability of the toolset, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. It suggests that the authors discuss the transferability of their toolset and proposes an experiment to create a general toolset for all tasks. This feedback is somewhat helpful as it points out a specific area for improvement and provides a direction for the authors to explore. However, the comment lacks detailed guidance on how to conduct the experiment or what aspects to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to implement this evaluation or specify how to conduct it. The action is implicit but concrete, as the authors can infer the need for a specific evaluation method. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiple Random Orders,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. The comment specifies what needs to be addressed, namely the evaluation method and its potential benefits. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that multiple random orders would effectively address the issue. This makes the claim somewhat verifiable, as it provides a reasonable rationale but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the model\\'s performance using multiple random feature orders. This approach aims to assess the impact of feature order variability without the need for a complex controller. By suggesting this baseline, the comment helps the authors determine whether the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. This feedback is valuable as it offers a practical method for evaluating the model\\'s performance and understanding its behavior, making it mostly helpful. However, it could be further improved by providing more detailed guidance on how to implement this evaluation or by suggesting additional aspects to consider. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to implement this evaluation or specify how to conduct it. The action is implicit but concrete, as the authors can infer the need for a specific evaluation method. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiple Random Orders,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. The comment specifies what needs to be addressed, namely the evaluation method and its potential benefits. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability. It implies that this baseline would help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment provides a logical rationale for the suggestion, it lacks specific examples or references to support the claim that multiple random orders would effectively address the issue. This makes the claim somewhat verifiable, as it provides a reasonable rationale but requires further elaboration or evidence to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for evaluating the model\\'s performance using multiple random feature orders. This approach aims to assess the impact of feature order variability without the need for a complex controller. By suggesting this baseline, the comment helps the authors determine whether the benefits of"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the related work section, noting that it is severely lacking and specifically mentions the omission of lexically constrained decoding methods. While the comment identifies a specific area that needs improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include these methods in the related work section and possibly as baselines for comparison, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies a problem but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the related work section, namely the omission of lexically constrained decoding methods, both in related work and as baselines for comparison. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is severely lacking, particularly due to the omission of lexically constrained decoding methods. However, the comment does not provide specific references or examples of these methods, nor does it explain why their inclusion would be beneficial. This lack of detailed justification makes it difficult for the authors to understand the significance of the omission and how to address it. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the related work section of the paper, noting that it is severely lacking and specifically mentions the omission of lexically constrained decoding methods. This feedback is valuable as it highlights a critical gap in the literature review, which could impact the comprehensiveness and relevance of the paper. However, the comment could be more helpful if it provided specific examples of lexically constrained decoding methods that should be included or suggested ways to integrate them into the related work section. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed guidance on how to address the issue.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions two specific models, SimVLM and OFA, which are relevant to the field. However, the comment does not provide guidance on how the authors should include these models or datasets in their comparison. While the action is clear (to include these models), the comment lacks concrete instructions on how to implement this change. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that important baseline models and datasets are missing, which makes the comparison incomplete. It explicitly mentions two specific models, SimVLM and OFA, providing clear references for the authors to address. This makes the comment fully grounded, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed by including these models and datasets in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific examples of missing models, SimVLM and OFA, which supports the claim by offering concrete references. However, the comment could be strengthened by explaining why these models are crucial for a comprehensive comparison or how their inclusion would impact the results. While the examples are clear, the lack of detailed reasoning or evidence for the claim's importance makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the comparison is not comprehensive due to the absence of important baseline models and datasets. It specifically mentions two models, SimVLM and OFA, which are relevant to the field, providing the authors with clear examples of what needs to be included for a more comprehensive comparison. This feedback is actionable and provides the authors with specific models to consider, which can significantly enhance the robustness and relevance of their work. However, the comment could be more helpful if it offered additional guidance on how to integrate these models or datasets into the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the paper, noting that important baseline models and datasets are missing, which makes the comparison incomplete. It explicitly mentions two specific models, SimVLM and OFA, providing the authors with clear examples of what needs to be included for a more comprehensive comparison. However, the comment does not provide detailed guidance on how to integrate these models or datasets into the paper, nor does it offer specific suggestions on how to address the issue. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, noting that important baseline models and datasets are missing, which makes the comparison incomplete. It explicitly mentions two specific models, SimVLM and OFA, providing clear references for the authors to address. This makes the comment fully grounded, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed by including these models and datasets in the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific examples of missing models, SimVLM and OFA, which supports the claim by offering concrete references. However, the comment could be strengthened by explaining why these models are crucial for a comprehensive comparison or how their inclusion would impact the results. While the examples are clear, the lack of detailed reasoning or evidence for the claim\\'s importance makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific examples of missing models, SimVLM and OFA, which are relevant to the field, offering the authors clear guidance on what needs to be included for a more robust comparison. This feedback is highly actionable, as it directs the authors to a critical area for improvement"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present new data. It clarifies that the paper presents derivative data, specifically 3D pose estimates from existing datasets. This feedback highlights a discrepancy between the paper\\'s framing and its actual content, which could be disappointing to readers expecting new data. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the paper. The action is implicit, as the authors need to infer that they should clarify the paper\\'s focus or provide additional context, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is that it presents derivative data rather than new data, which was the expectation of the reader. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present new data, which is disappointing to readers. The reviewer supports this claim by explaining that the paper presents derivative data, specifically 3D pose estimates from existing datasets. This explanation provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples of existing datasets used or references to them, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant discrepancy between the manuscript\\'s framing as a dataset paper and the actual content, which does not present new data but rather derivative data from existing datasets. This feedback is clear and actionable, as it highlights a key issue that the authors need to address to align their paper\\'s claims with its actual content. By pointing out this discrepancy, the comment provides valuable guidance for the authors to reconsider their framing or presentation of the data. However, it could be more helpful if it offered suggestions on how to address this issue, such as discussing the implications of using derivative data or suggesting ways to enhance the paper\\'s value. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present new data, which is disappointing to readers. It clarifies that the paper presents derivative data, specifically 3D pose estimates from existing datasets. While the comment identifies a discrepancy between the paper\\'s framing and its actual content, it does not provide explicit guidance on how the authors should address this issue or improve the paper. The action is implicit, as the authors need to infer that they should clarify the paper\\'s focus or provide additional context. However, the comment lacks concrete details on how to do so, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the manuscript, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is that it presents derivative data rather than new data, which was the expectation of the reader. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present new data, which is disappointing to readers. The reviewer supports this claim by explaining that the paper presents derivative data, specifically 3D pose estimates from existing datasets. This explanation provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples of existing datasets used or references to them, which would further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant discrepancy between the manuscript\\'s framing as a dataset paper and the actual content, which does not present new data but rather derivative data from existing datasets. This feedback is clear and actionable, as it highlights a key issue that the authors need to address to align their paper\\'s claims with its actual content. By pointing out this discrepancy, the comment provides valuable guidance for the authors to reconsider their framing"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their analysis. As a result, the comment lacks any actionable steps for the authors to follow, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the critique are problematic or how the authors might address it. Without explicit references to sections or specific issues, the authors cannot confidently determine which part of the paper needs revision. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the authors\\' critique is unwarranted. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary support to be understood or addressed by the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods have specific learning rate schedules for experiments on CIFAR and Face Verification. However, it does not provide any constructive feedback or suggestions on how the authors might address this critique or improve their analysis. The comment lacks actionable guidance or specific recommendations, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the analysis of results and the importance of visualizations in detecting a chair. It asks whether the handle is a consistent and prominent feature across a wide range of chairs, and whether it is the most crucial feature if it is absent. While the comment highlights areas for further exploration, it does not provide explicit instructions or suggestions on how the authors should address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more detailed analysis of the visualizations and their implications for feature detection. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"quantitative and qualitative analysis\" and the \"analysis of the results themselves,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the visualizations and the importance of certain features, such as the handle, in detecting a chair. The comment provides clear guidance on what aspects of the analysis could be further explored or clarified, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the analysis of results and the importance of visualizations in detecting a chair. It does not contain any subjective claims or opinions that require verification. Instead, it is a request for clarification or further explanation, which is a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the analysis of results and the importance of visualizations in detecting a chair. It highlights a potential gap in the paper by questioning whether the handle is a consistent and prominent feature across a wide range of chairs, and whether it is the most crucial feature if it is absent. This feedback prompts the authors to consider a more comprehensive analysis of the visualizations and their implications for feature detection. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the comment is somewhat helpful as it identifies an area for improvement but lacks detailed guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific question about the wording in the beginning of Section 2.2, suggesting that it should be corrected to \"at most\" instead of \"at least.\" It provides a detailed explanation of the issue, including a worst-case scenario and how the correction would affect the competitive ratio. This feedback is explicit and provides concrete guidance on how to address the issue, making it highly actionable. The authors know exactly what needs to be changed and why, ensuring they can effectively improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, suggesting that \"at least\" should be corrected to \"at most,\" and provides a detailed explanation of the reasoning behind this correction. This level of detail helps the authors understand the necessity of the change. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific question about the wording in the beginning of Section 2.2, suggesting that it should be corrected to \"at most\" instead of \"at least.\" The reviewer provides a detailed explanation of the issue, including a worst-case scenario and how the correction would affect the competitive ratio. This detailed reasoning supports the claim, making it fully verifiable. The authors can clearly understand the basis of the claim and the rationale behind the suggested correction, allowing them to effectively address the feedback. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the beginning of Section 2.2, suggesting that \"at least\" should be corrected to \"at most.\" It provides a detailed explanation of the reasoning behind this correction, including a worst-case scenario and how the change would affect the competitive ratio. This feedback is clear and actionable, offering the authors a precise way to improve the clarity and accuracy of their draft. By addressing this minor but important detail, the authors can enhance the precision and correctness of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the notation used in Theorem.1, specifically asking what D^{alpha}_{x} denotes and whether it represents the derivatives of the probabilistic measure \\mu. While the comment identifies a potential issue with notation, it does not provide explicit guidance on how the authors should address this question. The action is implicit, as the authors need to infer that they should clarify the notation in their draft. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks what D^{alpha}_{x} denotes and whether it represents the derivatives of the probabilistic measure \\mu. This provides clear guidance on what needs to be clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the notation used in Theorem.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the notation used in Theorem.1, asking what D^{alpha}_{x} denotes and whether it represents the derivatives of the probabilistic measure \\mu. This feedback is clear and actionable, as it prompts the authors to clarify their notation, which is crucial for the understanding and verification of their theoretical results. By addressing this question, the authors can improve the clarity and rigor of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to present the notation more effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a proper expression for the third face image in Figure 2. This provides a clear and direct action for the authors to take, which is to include the necessary expression for the third face image. The comment is specific and actionable, as it specifies exactly what needs to be added to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the absence of a proper expression for the third face image. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the missing expression for the third face image in Figure 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, namely the absence of a proper expression for the third face image in Figure 2. This is a clear and actionable feedback that directly points out a missing element in the paper, which is crucial for the completeness and clarity of the figures. By addressing this issue, the authors can improve the quality and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to incorporate the missing expression. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which specific aspects of the examples should be compared or how to present the comparison. The authors are given a clear direction but without detailed guidance on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where such an example could be included. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to include an example, but without clear grounding, it is weakly grounded. Therefore, this comment aligns with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any justification or reasoning for why this inclusion would be beneficial or how it would enhance the paper. Without specific examples or detailed explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback is somewhat helpful as it provides a specific suggestion for improving the paper by offering a comparative analysis. However, the comment lacks depth and does not explain why this comparison would be beneficial or how it could enhance the understanding of the proposed model. Without additional context or guidance, the authors may find it challenging to fully implement this suggestion. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that for the code summarization task and the code search task, the dataset size of Vault and CSN should be the same to demonstrate that Vault is better in terms of data quality than CSN. This is an explicit action, as it clearly states what needs to be done to improve the paper. However, it does not provide specific guidance on how to achieve this, such as suggesting a particular dataset size or method for comparison. The action is concrete but could be more detailed, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the dataset size for the code summarization task and the code search task, specifically mentioning \"Vault\" and \"CSN.\" This provides full grounding as it allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, ensuring that the dataset sizes of Vault and CSN are the same to demonstrate the superiority of Vault in terms of data quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the dataset size for the code summarization task and the code search task should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a necessary condition or how it would impact the evaluation of Vault and CSN. Without such justification, the claim is unverifiable, as it lacks the necessary context or explanation to be understood by the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the experimental setup, suggesting that the dataset size for the code summarization task and the code search task should be the same to demonstrate that Vault is better in terms of data quality than CSN. This feedback is clear and actionable, as it provides a concrete suggestion for improving the experimental design. By addressing this point, the authors can enhance the validity and fairness of their comparisons, which is crucial for the credibility of their findings. However, the comment could be more helpful if it included additional guidance on how to achieve this balance in dataset sizes or provided examples of how to implement this change. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement that can significantly enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific concepts that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, implying that the authors should provide clearer definitions or explanations for these concepts. While the comment does not explicitly instruct the authors to do so, the action is clear and concrete, as it specifies the terms that need clarification. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies specific concepts that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" However, it does not specify which sections or parts of the paper these terms appear in, making it difficult for the authors to pinpoint the exact areas that need improvement. While the authors might have an idea of where these terms are used, the comment lacks full grounding. It is specific in identifying the need for clearer explanations of these concepts, but without explicit references, it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some important concepts are not explained well in the paper, specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity, particularly in explaining certain concepts such as \"action-repeat\" and \"dithering phenomenon.\" By pointing out these terms that keep appearing in the paper without proper explanation, the reviewer provides actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples of how they are used in the paper. Overall, the feedback is somewhat helpful as it directs the authors to address important gaps in their explanation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an alternative approach to the current method, where the authors generate a text using the instruction model and then re-encode it using an encoder. The reviewer proposes an alternative method where an instruction embedding is created from the state encoding, passed directly to the executor, and an auxiliary objective is added to bring it closer to the gold instruction encoding. This suggestion provides a clear and concrete action for the authors to consider, specifying the steps and benefits of the proposed method. The comment is explicit and provides detailed guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method, where the authors generate a text using the instruction model and then re-encode it using an encoder. It proposes an alternative method where an instruction embedding is created from the state encoding, passed directly to the executor, and an auxiliary objective is added to bring it closer to the gold instruction encoding. This suggestion provides a clear and specific action for the authors to consider, making the comment fully grounded and specific. The authors can accurately identify the part of the paper being addressed and understand what needs to be addressed. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method, proposing to create an instruction embedding directly from the state encoding and pass it to the executor. The reviewer explains the rationale behind this suggestion, stating that it might work better as it avoids discretization and potential issues with decoding. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that this approach would be more effective. While the suggestion is logical, the absence of concrete evidence or examples makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the current method by proposing an alternative approach. It suggests creating an instruction embedding directly from the state encoding and passing it to the executor, rather than generating text and then re-encoding it. The reviewer also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold instruction encoding. This feedback is clear and actionable, offering a concrete way for the authors to enhance their method. By addressing this suggestion, the authors could potentially improve the robustness and effectiveness of their approach. However, the comment could be more helpful if it included a discussion on how this change might impact the overall performance or theoretical understanding of the model. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the novelty of the proposed model is not significant, but it does not provide any specific guidance or suggestions on how the authors might address this issue. It lacks actionable details, such as recommending ways to enhance the model\\'s novelty or providing examples of how it could be improved. Without explicit or implicit actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the proposed model is not significant, but it does not specify which part of the paper this assessment is based on. It lacks grounding as it does not reference specific sections, figures, or experiments where the novelty is discussed. Additionally, the comment does not provide any specific details or examples of what aspects of the model lack novelty or how it could be improved. As a result, the comment is not grounded and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the novelty of the proposed model is not significant, but it does not provide any specific details or examples to support this claim. Without further elaboration or guidance, the authors are left without actionable feedback on how to address the perceived lack of novelty. The comment lacks depth and specificity, making it difficult for the authors to understand the basis of the critique or how to improve their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class in the pool subset makes the dataset easier rather than harder. It points out that the accuracy might not be a good measure of quality in such a case, as it could be good even if the smaller classes are poorly classified. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the dataset\\'s design. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the dataset, namely the proportion of each class used for the pool subset. It suggests that this distribution makes the dataset easier rather than harder, as it reduces ambiguity between similar numbers. However, the comment does not specify which part of the paper discusses this dataset or the proportion of classes, making it weakly grounded. The comment is specific in detailing the issue with the dataset\\'s class distribution and its impact on accuracy as a measure of quality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that it might be easier rather than harder due to the proportions of certain classes. The reviewer provides a specific example, mentioning the proportions of 9, 6, and 7, which could affect the accuracy as a measure of quality. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim that the dataset is easier due to the class distribution. While the example provides some context, the lack of comprehensive justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportions of certain classes make the dataset easier rather than harder. It points out that the accuracy might not be a good measure of quality in such a case, as it could be good even if the smaller classes are poorly classified. This feedback is somewhat helpful as it identifies a potential issue with the dataset that could affect the evaluation of the model\\'s performance. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the dataset\\'s design. While it highlights an important consideration, it does not provide actionable steps for the authors to take, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportions of certain classes make the dataset easier rather than harder. It points out that the accuracy might not be a good measure of quality in such a case, as it could be good even if the smaller classes are poorly classified. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve the dataset\\'s design or evaluate the model\\'s performance more effectively. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the dataset, namely the proportion of each class used for the pool subset. It suggests that this distribution makes the dataset easier rather than harder, as it reduces ambiguity between similar numbers. However, the comment does not specify which part of the paper discusses this dataset or the proportion of classes, making it weakly grounded. The comment is specific in detailing the issue with the dataset\\'s class distribution and its impact on accuracy as a measure of quality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportions of certain classes make the dataset easier rather than harder. It provides a specific example, mentioning the proportions of 9, 6, and 7, which could affect the accuracy as a measure of quality. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim that the dataset is easier due to the class distribution. While the example provides some context, the absence of comprehensive justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportions of certain classes make the dataset easier"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the reviewer\\'s agreement with the statement about prediction not being done in isolation but questions the main contribution of showing that the task of prediction may have strategic aspects. It also raises a specific question about the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. While the comment identifies areas for clarification and suggests a potential reference, it does not provide explicit instructions or concrete steps for the authors to follow. The actions are implicit and somewhat vague, leaving the authors to infer what needs to be addressed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. The comment provides clear guidance on what needs to be clarified or addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the reviewer\\'s agreement with the statement about prediction not being done in isolation but questions the main contribution of showing that the task of prediction may have strategic aspects. It raises specific questions about the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. While the comment provides some reasoning and references, it lacks detailed justification or examples to fully support the claim about the main contribution. The suggestion to look into Vapnik\\'s work adds some context but does not directly address the reviewer\\'s concern about the main contribution. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed explanation or references to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the reviewer's agreement with the statement about prediction not being done in isolation but questions the main contribution of showing that the task of prediction may have strategic aspects. It raises specific questions about the 'true' payoff in Table 1 and suggests looking into Vapnik's work on teaching a learner with side information. This feedback is somewhat helpful as it identifies areas for clarification and suggests potential references for further exploration. However, it could be more helpful if it provided more detailed guidance or examples on how to address these questions or incorporate Vapnik's work into the paper. Overall, the comment provides some insight but lacks depth and actionable suggestions, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training, given that self-training is a prominent and effective approach. While the comment implies that the authors should consider an alternative method, it does not explicitly instruct them to do so or provide guidance on which specific method to explore. The action is implicit and somewhat vague, as the authors need to infer that they should explore an additional method but are not given concrete steps on how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, given that self-training is a prominent and effective approach. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in its suggestion to explore an additional UDA method, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method focuses solely on domain-alignment methods and recommends exploring another UDA method based on self-training. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the method. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed method, which focuses solely on domain-alignment methods. It suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, which is a prominent and effective approach in the field. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their work. By suggesting an alternative method, the comment offers a concrete way for the authors to enhance the scope and effectiveness of their approach. However, it could be more helpful if it provided additional context or examples of self-training methods that could be explored. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer asks whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. While the comment highlights an issue, it does not provide explicit guidance on how the authors should address it. The authors can infer that they need to investigate and possibly explain these pathologies, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, particularly the \"high-accuracy spikes in low confidence regimes,\" and questions whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies. The reviewer asks whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The question posed provides a direction for further exploration but does not offer a comprehensive explanation or evidence to support the claim. Therefore, the comment is somewhat verifiable, as it requires more detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reliability diagrams, noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer raises a question about whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. This feedback is somewhat helpful as it highlights a potential weakness in the reliability of the proposed methods and prompts the authors to consider whether this is an issue with the dataset or the methods themselves. However, the comment could be more helpful if it provided suggestions on how to address or mitigate these issues. Overall, the comment provides some insight but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer asks whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. While the comment identifies an issue, it does not provide explicit guidance on how the authors should address it. The authors can infer that they need to investigate and possibly explain these pathologies, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, particularly the \"high-accuracy spikes in low confidence regimes,\" and questions whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability diagrams, specifically noting that they do not support the proposed methods and exhibit pathologies such as high-accuracy spikes in low confidence regimes. The reviewer asks whether this is a property of dataset pathologies or a reflection of variance or unpredictability in the proposed methods. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The question posed provides a direction for further exploration but does not offer a comprehensive explanation or evidence to support the claim. Therefore, the comment is somewhat verifiable, as it requires more detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reliability diagrams, noting that they do not support the proposed methods and exhibit pathologies such as"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limitations of the paper, specifically regarding the evaluation of more advanced attacks and the lack of discussion on backdoor removal methods. It highlights that the paper does not consider the possibility of the attacker fine-tuning on a partial subset of the dataset, which could still contain the poisoned data. The reviewer suggests that the paper should evaluate this scenario and discuss the detection of backdoors. However, the comment does not provide explicit guidance on how to address these issues or what specific aspects of the paper should be expanded upon. The action is implicit and somewhat vague, as the authors need to infer the necessary changes and improvements. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second\" point, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the paper\\'s evaluation, specifically the potential for more advanced attacks and the lack of discussion on backdoor removal methods. The comment provides clear guidance on what needs to be addressed, such as evaluating the possibility of the attacker fine-tuning on a partial subset of the dataset and discussing backdoor removal methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the limitations of the paper, specifically regarding the evaluation of more advanced attacks and the lack of discussion on backdoor removal methods. The reviewer points out that the paper does not consider the possibility of the attacker fine-tuning on a partial subset of the dataset, which could still contain the poisoned data, potentially allowing the customer to verify misbehaviors. The comment also highlights that the paper only considers backdoor detection and does not discuss other SOTA methods for backdoor removal. While the comment identifies potential weaknesses, it lacks specific examples or references to support the claim that the paper is incomplete. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper\\'s evaluation, specifically the potential for more advanced attacks that the authors have not considered. It highlights a critical area that could impact the paper\\'s conclusions and suggests that the authors should evaluate the possibility of the attacker fine-tuning on a partial subset of the dataset, which could still contain the poisoned data. The comment also points out that the paper does not discuss backdoor removal methods, which are relevant to the field. By raising these concerns and suggesting areas for improvement, the comment provides actionable feedback that can help the authors enhance the comprehensiveness and robustness of their work. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful, as it effectively directs the authors\\' attention to important aspects that need further exploration and discussion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the use of the original GCN (Kipf and Welling) in the paper and the use of the original adjacency matrix without explanation or ablation study. It raises a question about the reason for not using the conventional graph convolutional operation. While the comment implies that the authors should provide an explanation or an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this discrepancy. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the original GCN (Kipf and Welling) and the difference in using the original adjacency matrix without explanation or ablation study. This allows the authors to identify the relevant part of the paper, making the comment fully grounded. However, the comment lacks specificity as it does not detail why the conventional graph convolutional operation is relevant or what specific issues arise from using the original adjacency matrix without explanation. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the use of the original adjacency matrix without explanation or ablation study, referencing the use of the normalized adjacency matrix with renormalization trick in the original GCN (Kipf and Welling). The reviewer raises a logical question about the reason for not using the conventional graph convolutional operation, which is a valid point. However, the comment lacks specific examples or references to support the claim that the original adjacency matrix is not suitable or that the renormalization trick is necessary. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the methodology used in the paper, specifically the difference between the use of the original adjacency matrix without explanation or ablation study and the normalized adjacency matrix with renormalization trick used in the original GCN (Kipf and Welling). It raises a valid question about the reason for not using the conventional graph convolutional operation, which could be a significant oversight. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or why it is important to consider the conventional operation. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy in the methodology used in the paper, specifically the difference between using the original adjacency matrix without explanation or ablation study and the normalized adjacency matrix with renormalization trick used in the original GCN (Kipf and Welling). It raises a question about the reason for not using the conventional graph convolutional operation. While the comment implies that the authors should provide an explanation or an ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this discrepancy. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the original adjacency matrix without explanation or ablation study, in contrast to the normalized adjacency matrix with renormalization trick used in the original GCN (Kipf and Welling). This allows the authors to identify the relevant part of the paper, making the comment fully grounded. However, the comment lacks specificity as it does not detail why the conventional graph convolutional operation is relevant or what specific issues arise from using the original adjacency matrix without explanation. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the use of the original adjacency matrix without explanation or ablation study, contrasting it with the normalized adjacency matrix with renormalization trick used in the original GCN (Kipf and Welling). The comment raises a logical question about the reason for not using the conventional graph convolutional operation. However, it lacks specific examples or references to support the claim that the original adjacency matrix is not suitable or that the renormalization trick is necessary. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the availability of links for WMT\\'14 training corpora, which is not mentioned in the paper. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should include a link for WMT\\'14 or clarify why it is missing. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a specific question about the availability of links for WMT\\'14 training corpora, which is not mentioned in the paper. However, it does not specify which part of the paper this issue pertains to, such as a section discussing data sources or references. The authors can infer that it relates to the data or references section, but this inference is not direct. The comment is specific in its request for clarification about the availability of links, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the availability of links for WMT\\'14 training corpora. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the availability of links for WMT\\'14 training corpora, which is not mentioned in the paper. This is a relevant point that could help the authors ensure completeness and transparency in their work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or why it is important. While it highlights a potential gap in the paper, it lacks actionable feedback or detailed suggestions for improvement. Therefore, the comment is somewhat helpful, as it identifies an area for clarification but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to select other hyperparameters. This provides a clear and direct action for the authors to take, which is to identify and specify these bounds. The comment is specific and actionable, as it gives the authors a concrete task to address in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"upper and lower bounds for adaptive matrices A_t and B_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to know these bounds to select other hyperparameters. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to select other hyperparameters. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it impacts the selection of hyperparameters. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to know the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. This feedback is clear and actionable, as it provides a direct suggestion for the authors to address in their draft. By specifying this requirement, the comment helps the authors understand what additional information is necessary to improve the clarity and completeness of their work. However, the comment could be more helpful if it provided further guidance on how to determine these bounds or how they might impact the selection of hyperparameters. Overall, the comment is mostly helpful as it directs the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It suggests that the authors should consider including experimental results on the PDBbind dataset to address this concern. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these results into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental results on the PDBbind dataset to enhance the novelty of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests including experimental results on the PDBbind dataset to address this concern. However, the comment does not specify which part of the paper discusses the novelty or where the experimental results are presented, making it weakly grounded. The suggestion to include experimental results on the PDBbind dataset is specific, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand which techniques are considered novel and which are not. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests that the authors should consider including experimental results on the PDBbind dataset to address this concern. While the comment identifies a weakness in the novelty of the work, it lacks specific guidance or suggestions on how to incorporate these results or improve the novelty. The feedback is somewhat helpful as it highlights an area for improvement but does not provide detailed, actionable advice, leaving the authors with a general direction to consider. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It suggests that the authors should consider including experimental results on the PDBbind dataset to address this concern. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these results into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental results on the PDBbind dataset to enhance the novelty of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests including experimental results on the PDBbind dataset to address this concern. However, the comment does not specify which part of the paper discusses the novelty or where the experimental results are presented, making it weakly grounded. The suggestion to include experimental results on the PDBbind dataset is specific, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which techniques are considered novel and which are not. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the novelty of the work, noting that most techniques used have been proposed and demonstrated before. It suggests that the authors should consider including experimental results on the PDBbind dataset to address this concern. While the comment identifies a potential weakness in the novelty of the work, it lacks specific guidance or suggestions on how to incorporate these results or improve the novelty. The feedback provides a general direction for improvement but does not offer detailed, actionable advice, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding error bars to the results comparing pairs of models to demonstrate that the differences are statistically significant and exceed what would be expected from noise when comparing equally performant models. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to improve the draft. The comment is explicit and provides detailed guidance on how to implement the suggested change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding error bars to the results comparing pairs of models to demonstrate statistical significance. However, it does not specify which part of the paper these results are presented in, making it weakly grounded. The comment is specific in its suggestion to add error bars to show the differences exceed noise, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that adding error bars to the results comparing pairs of models would be beneficial. However, it does not provide any specific reasoning or evidence to support why this would be necessary or how it would enhance the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to enhance the presentation of results by adding error bars to demonstrate the statistical significance of the differences between pairs of models. This feedback is specific and offers a concrete way to improve the clarity and robustness of the results section, which is beneficial for the authors. However, it could be more helpful if it explained why error bars are important or how they should be interpreted. Overall, the comment is mostly helpful as it guides the authors on a specific improvement to make their results more informative and convincing.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the definition of \"full state\" on page 2, line 81. It asks what is included in a full state, implying that the authors need to clarify this aspect of their work. This feedback is clear and direct, providing a specific area for the authors to address. The action is explicit and concrete, as it directly instructs the authors to provide a clearer definition of the full state. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of proper definition for \"full state\" and the need to clarify what is included in a full state. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the lack of proper definition for \"full state\" on page 2, line 81. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of \"full state\" on page 2, line 81. It raises a question about what is included in a full state, which is a critical aspect of the paper that needs clarification. This feedback is clear and actionable, as it directs the authors to provide a more precise definition of the full state, which is essential for understanding the scope and implications of their work. However, the comment could be more helpful if it offered suggestions on how to improve the definition or provided examples of what constitutes a full state. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the study is empirical, it lacks new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. However, the comment does not provide specific guidance on what these proposals should be or how to develop them. The action is implicit, as the authors need to infer that they should include new proposals, and it is vague because it lacks concrete details on what these proposals should entail. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment provides a general critique of the paper, stating that it is a good empirical study but lacks new proposals for neural architecture encoding. However, it does not specify which part of the paper this critique pertains to, nor does it provide details on what specific proposals are missing or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is empirical but lacks new proposals for neural architecture encoding. However, it does not provide specific examples or references to support this claim, nor does it explain why new proposals are necessary or how they would enhance the study. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the study is empirical but points out a lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. While the comment identifies a gap in the paper, it does not provide specific guidance or examples of what these proposals might entail. This limits the usefulness of the feedback, as the authors are left with a general suggestion but without detailed direction on how to address the issue. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part is a recommendation to evaluate the paper empirically by comparing it with existing algorithms, which is an explicit action. However, it lacks concrete details on how to conduct this comparison or what specific algorithms should be considered. The second part of the comment provides detailed feedback on theoretical comparisons and practical concerns, such as the potential communication cost between the master and workers. While this part offers specific suggestions for improvement, it does not provide explicit guidance on how to address these issues. Overall, the comment is mostly actionable due to the explicit recommendation and the detailed feedback, but the lack of concrete guidance on empirical comparison limits its actionability.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \"p.5,\" which allows the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on what needs to be addressed, including the lack of empirical comparison with existing algorithms, the need for practical usefulness discussion, and the definition of terms like \\\\Delta_i, \\\\Delta_{med}, and \\\\nabla_i. This level of detail provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two main parts. The first part is a recommendation to evaluate the paper empirically by comparing it with existing algorithms, which is a suggestion rather than a claim. The second part provides detailed feedback on theoretical comparisons and practical concerns, such as the potential communication cost between the master and workers. This part of the comment is mostly verifiable as it offers specific examples and reasoning to support the claim about the potential communication cost. However, it lacks detailed references or specific comparisons to substantiate the claim fully. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a mix of feedback. It initially recommends that the paper be evaluated empirically by comparing it with existing algorithms, which is a clear and actionable suggestion. This part of the comment is highly helpful as it guides the authors on how to enhance the practical relevance of their theoretical work. However, the second part of the comment is less helpful. It provides detailed feedback on theoretical comparisons and practical concerns, such as the potential communication cost between the master and workers. While this feedback is specific, it does not offer actionable steps or suggestions on how to address these concerns. Overall, the comment is mostly helpful due to the initial recommendation and the detailed feedback, but it could be more comprehensive with additional guidance on how to address the practical concerns.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the proposed approach\\'s performance in simulations and its performance in real data, questioning the practical advantage of the method. It suggests including more real data analyses or comparisons to support the method. While the comment implies that additional real data analyses would be beneficial, it does not explicitly instruct the authors to include these analyses or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for additional real data analyses and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in simulations versus real data, questioning the practical advantage of the method. However, it does not specify which part of the paper discusses the simulations or real data analyses, making it weakly grounded. The comment is specific in suggesting that including more real data analyses or comparisons could support the method, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the practical advantage of the proposed method by noting its strong performance in simulations but poor performance in real data. The reviewer suggests including more real data analyses or comparisons to support the method. While the comment highlights a potential issue, it lacks specific examples or references to substantiate the claim about the method\\'s performance in real data. This makes the claim somewhat verifiable, as the authors would need to conduct additional analyses to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it performs well in simulations but poorly in real data. This observation questions the practical advantage of the method. The comment suggests including more real data analyses or comparisons to support the method, providing a clear direction for improvement. However, the feedback could be more helpful if it offered specific guidance on how to conduct these analyses or what aspects to focus on. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a constructive suggestion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a claim made by the authors regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also mentions the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these claims or improve their draft. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding the low discrimination risk of their solution and its impact on utility and fairness. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment does provide some level of specificity by mentioning the importance of the underlying data distribution after imputation and its effect on model effectiveness. However, without explicit references to sections or specific elements of the paper, the authors may struggle to pinpoint where these issues are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' solution has a low discrimination risk while minimally sacrificing utility and improves fairness. It also emphasizes the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or detailed explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the points made.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a claim made by the authors regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also highlights the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment lacks specific suggestions or guidance on how the authors might address these claims or improve their draft. While it points out an area of concern, it does not provide actionable feedback or detailed advice on how to strengthen the paper. Therefore, the comment is somewhat helpful, as it offers some insight but lacks depth and specificity to be fully beneficial for the authors.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a claim made by the authors regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also mentions the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these claims or improve their draft. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim made by the authors regarding the low discrimination risk of their solution and its impact on utility and fairness. It also emphasizes the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment provides some level of specificity by mentioning the importance of the underlying data distribution, but without explicit references to sections or specific elements of the paper, the authors may struggle to pinpoint where these issues are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' solution has a low discrimination risk while minimally sacrificing utility and improves fairness. It also emphasizes the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or detailed explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the points made.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a claim made by the authors regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also highlights the importance of the underlying data distribution after imputation for the effectiveness of the models. However, the comment lacks specific suggestions or guidance on how the authors might address these claims or improve"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use more of the ReferIt data before moving on to other datasets. While the comment implies an action, it does not provide specific guidance on how much more of the ReferIt data should be used or how this should be integrated into the study. The action is somewhat vague, as it lacks concrete details on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could use more of the ReferIt data before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could use more of the ReferIt data before moving on to other datasets. However, it does not provide any reasoning or evidence to support why this would be beneficial or how it could improve the study. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors could use more of the ReferIt data before moving on to other datasets. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion. The comment does not explain why using more of the ReferIt data would be beneficial or how it could enhance the study. Without actionable advice or a clear rationale, the authors may find it challenging to determine how to apply this feedback effectively. Therefore, the comment is barely helpful, as it provides a vague suggestion without sufficient detail to be actionable.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the authors could use more of the ReferIt data before moving on to other datasets. While it implies an action, it does not provide specific guidance on how much more data should be used or how this should be integrated into the study. The action is somewhat vague, as it lacks concrete details on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using more of the ReferIt data before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could use more of the ReferIt data before moving on to other datasets. However, it does not provide any reasoning or evidence to support why this would be beneficial or how it could improve the study. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors could use more of the ReferIt data before moving on to other datasets. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion. The comment does not explain why using more of the ReferIt data would be beneficial or how it could enhance the study. Without actionable advice or a clear rationale, the authors may find it challenging to determine how to apply this feedback effectively. Therefore, the comment is barely helpful, as it provides a vague suggestion without sufficient detail to be actionable.\", 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the authors could use more of the ReferIt data before moving on to other datasets. While it implies an action, it does not provide specific guidance on how much more data should be used or how this should be integrated into the study. The action is somewhat vague, as it lacks concrete details on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests using more of the ReferIt data before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to clarify the explanation in lines 243-245, specifically questioning the choice of 5*3 over 5*2 and the use of k-NN as a classifier. The reviewer asks for elaboration on the reasons behind these choices and the specific values of k and the distance metric used. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve the clarity of their explanation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 243-245, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying the explanation of the choice of 5*3 over 5*2, the use of k-NN as a classifier, and the reasons behind these choices. The comment provides detailed questions that guide the authors on what aspects of the explanation need elaboration, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about specific aspects of the paper, such as the choice of 5*3 over 5*2 and the use of k-NN as a classifier. These questions do not contain subjective opinions, judgments, or suggestions that require verification. They are factual inquiries seeking clarification, making the comment a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that is unclear, namely lines 243-245, and requests clarification on the choice of 5*3 over 5*2 and the use of k-NN as a classifier. It provides detailed questions that guide the authors on what aspects of the explanation need elaboration, such as the reasons behind the choice of 5*3, the use of k-NN, and the specific values of k and the distance metric used. This feedback is clear and actionable, offering the authors a concrete path to improve the clarity and comprehensiveness of their explanation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This provides a clear and direct action for the authors to take, which is to include a detailed description of SAM in their paper. The comment is specific and actionable, as it gives the authors a clear direction on what needs to be added to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or paragraph where this information should be included. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in suggesting that the background of SAM should be detailed, it is not fully grounded because it does not specify where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This feedback is clear and actionable, as it provides a specific area for the authors to expand upon in their paper. By detailing the background of SAM, the authors can enhance the comprehensibility and depth of their work, making it more valuable to readers. However, the comment could be more helpful if it offered additional guidance on how to present this information or what aspects of SAM are particularly relevant to the paper. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides concrete examples of how to enhance the evaluation, such as incorporating image guidance with related reference normal images or color-augmentation for the kNN baseline. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what changes to make to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the inclusion of comprehensive comparisons between language-assisted and vision-assisted approaches. The comment specifies how to enhance the evaluation by suggesting the use of image guidance with related reference normal images or color-augmentation for the kNN baseline. This provides clear guidance on what needs to be addressed in the experimental setup. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. The reviewer suggests specific enhancements, such as incorporating image guidance with related reference normal images or color-augmentation for the kNN baseline, to provide valuable insights. While the comment provides a logical reasoning for the need for these comparisons, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors would need to further explore the suggestions to fully understand their implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental setup, noting the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides a clear and actionable suggestion by recommending the inclusion of image guidance with related reference normal images or color-augmentation for the kNN baseline. This feedback is valuable as it offers a concrete way to enhance the evaluation of LAFT\\'s efficacy, thereby helping the authors improve their draft. The comment is mostly helpful as it provides a detailed direction for enhancing the experimental setup, but it could be more comprehensive by offering additional suggestions or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not mention a closely related line of work, collective entity linking, which considers multiple mentions in the same document. It suggests that the proposed model is a special case of collective entity linking. While the comment identifies a gap in the literature review, it does not explicitly instruct the authors to include this related work or provide guidance on how to integrate it into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include this related work but are not given specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the related work of collective entity linking, which is a closely related line of work. It also specifies that the proposed model is a special case of collective entity linking, providing clear guidance on what aspect of the paper is missing. This allows the authors to accurately identify the part of the paper that needs to be revised. The comment is specific in detailing what is missing, namely the mention of this related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. The reviewer provides a logical reasoning by suggesting that the model considers multiple mentions in the same document, which is a characteristic of collective entity linking. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the literature to fully understand the connection between the proposed model and collective entity linking, which could be a limitation in the current feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the literature review by pointing out that the paper does not mention a closely related line of work, collective entity linking, which considers multiple mentions in the same document. It suggests that the proposed model is a special case of collective entity linking, providing a clear and actionable feedback for the authors to include this related work in their paper. This feedback is valuable as it helps the authors situate their work within the broader context of existing research, potentially enhancing the paper\\'s comprehensiveness and impact. However, the comment could be more helpful if it provided specific examples or references to the collective entity linking literature. Overall, the comment is mostly helpful, as it directs the authors to a relevant area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two separate issues. First, it suggests that truncating the log likelihood function can lower sensitivity and recommends comparing this aspect. This is an explicit suggestion with clear guidance on what the authors should do to address the issue. Second, it points out a minor inconsistency in Algorithm 1, where the query functions for all d data sources are the same, despite the general framework allowing them to be different. The reviewer suggests designing a customized query function for each data source or removing the subscript. This part of the comment is also explicit and provides clear guidance on how to address the issue. Overall, the comment is mostly actionable, as it provides specific suggestions for improvement in both areas.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1\" and \"Truncating the log likelihood function,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on both the truncation of the log likelihood function and the inconsistency in Algorithm 1 regarding the query functions for all d data sources. The comment suggests comparing the truncation effect and offers guidance on customizing query functions for each data source, providing clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two separate issues. First, it suggests that truncating the log likelihood function can lower sensitivity and recommends comparing this aspect. This claim is somewhat verifiable as it provides a logical reasoning for the potential impact of truncation on sensitivity, but it lacks specific examples or references to support the claim fully. Second, the comment points out a minor inconsistency in Algorithm 1 regarding the query functions for all d data sources, suggesting that they could be different. This part of the comment is clear and provides a specific observation that could be addressed. Overall, the review point is somewhat verifiable, as it provides some reasoning and examples but could benefit from more detailed evidence or references to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that truncating the log likelihood function can lower sensitivity and recommends comparing this aspect, which is a clear and actionable suggestion for improvement. This feedback is valuable as it directs the authors to a specific area that could enhance their analysis. Second, the comment points out a minor inconsistency in Algorithm 1 regarding the query functions for all d data sources, suggesting that they could be different. It questions how to design a customized query function for each data source and suggests removing the subscript for clarity. This part of the comment is also helpful as it highlights a potential area for clarification and improvement. Overall, the comment is mostly helpful as it provides clear and actionable feedback on both the truncation of the log likelihood function and the customization of query functions, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of the method should be expanded to include a larger and more diverse dataset, including more complex molecules and materials. While the comment implies that the authors should conduct additional evaluations, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to implement this expansion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to a larger and more diverse dataset, including more complex molecules and materials. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include a larger and more diverse dataset, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to a larger and more diverse dataset. However, the comment does not provide specific examples or references to support the claim that a larger and more diverse dataset would be beneficial. The suggestion is based on a logical assumption that a broader dataset would enhance the method\\'s performance, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the method, specifically noting that it is limited to a small set of molecules from the MD17 dataset. It suggests that expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials, would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their method. By addressing this suggestion, the authors can significantly improve the scope and applicability of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper being reviewed is similar to the StreamingLLM paper and highlights specific similarities, such as the use of sink tokens and local attention. It also mentions that the sink tokens may correspond to certain categories. However, the comment does not provide explicit guidance on how the authors should address this similarity or clarify the differences between their work and the StreamingLLM paper. The suggestion to clarify the differences is implicit and lacks concrete steps, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions the StreamingLLM paper and suggests that the current work is similar to it, particularly in terms of using sink tokens and local attention. It also mentions the possibility of the sink tokens corresponding to specific categories like $C_{special}$ and $C_{punct}$. However, the comment does not specify which part of the paper this comparison or clarification should be addressed in, making it weakly grounded. The comment is specific in detailing the similarities and potential differences with the StreamingLLM paper, providing clear guidance on what needs to be clarified. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is similar to the StreamingLLM paper, particularly in terms of using sink tokens and local attention. It suggests that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The reviewer provides a reference to the StreamingLLM paper, which supports the claim by offering a point of comparison. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reference to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the current work and the StreamingLLM paper, noting that both use sink tokens and perform local attention. It suggests that the sink tokens may correspond to specific categories like $C_{special}$ and $C_{punct}$. The comment also recommends clarifying the differences between the two papers, which is a valuable suggestion for the authors to address. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to clarify the differences. Overall, the feedback is somewhat helpful as it points out a potential overlap and suggests an area for improvement, but it lacks depth and specificity to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results section, specifically mentioning a comparison with ConceptWeaver. This allows the authors to identify the part of the paper being discussed, providing full grounding. The comment also specifies the issue by pointing out the lack of significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide specific suggestions or guidance on how to address this issue, making it under-specific. Therefore, the comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is a lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. The comment supports this claim by referencing a specific paper, \"Concept weaver: Enabling multi-concept fusion in text-to-image models,\" which provides a basis for the comparison. However, the comment lacks detailed analysis or specific examples from the referenced paper to fully substantiate the claim. While the reference provides a starting point, the authors may need to further explore the comparison to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. It references a specific paper, \"Concept weaver,\" providing a basis for the comparison. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights, the authors are left with a general critique that does not effectively guide them in enhancing their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their results or what specific aspects need attention. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results section, specifically mentioning a comparison with ConceptWeaver, which can handle more than two concepts. This allows the authors to identify the part of the paper being discussed, providing full grounding. The comment also specifies the issue by pointing out the lack of significant improvement compared to ConceptWeaver. However, it does not provide specific suggestions or guidance on how to address this issue, making it under-specific. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that there is a lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. The comment supports this claim by referencing a specific paper, \"Concept weaver,\" providing a basis for the comparison. However, the comment lacks detailed analysis or specific examples from the referenced paper to fully substantiate the claim. While the reference provides a starting point, the authors may need to further explore the comparison to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. It references a specific paper, \"Concept weaver,\" providing a basis for the comparison. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights, the authors are left with a general critique that does not effectively guide them in enhancing their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or guidance on how the authors should implement this approach or where in the paper this suggestion should be applied. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to address the problem by alternating between matrix completion and subspace clustering, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an approach to address the problem of subspace clustering with missing data by alternating between matrix completion and subspace clustering. This is a relevant and potentially valuable suggestion for the authors to consider, as it offers a possible solution to a common issue in subspace clustering. However, the comment lacks depth and does not provide specific guidance or examples on how to implement this approach. While it offers a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or recommendations for improving the robustness or mitigating the impact of teacher model limitations. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of CCKT-Det++, specifically mentioning its reliance on teacher models. However, it does not specify which part of the paper discusses the teacher models or how they are integrated into the system. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the issue of potential propagation of limitations or biases from teacher models, it is not fully grounded due to the lack of explicit references. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. The claim is somewhat verifiable as it provides a logical reasoning that teacher models' limitations could impact the system\\'s performance. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance of CCKT-Det++ on teacher models, highlighting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. This feedback is valuable as it points out a critical aspect that the authors should consider when evaluating their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as potential mitigation strategies or alternative approaches. While it provides a clear direction for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete steps or recommendations for improving the robustness or mitigating the impact of teacher model limitations. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on teacher models and highlights a potential issue with the quality and alignment of these models. However, it does not specify which part of the paper discusses the teacher models or how they are integrated into the system, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in identifying the issue of potential propagation of limitations or biases from teacher models, it lacks grounding as it does not provide explicit references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. The claim is somewhat verifiable as it provides a logical reasoning that teacher models' limitations could impact the system\\'s performance. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. This feedback is valuable as it points out a critical aspect that the authors should consider when evaluating their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as potential mitigation strategies or alternative"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should update the comparison objects, consider new ones, or provide additional context to justify the choice of objects. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions the comparison objects used in the experiment and suggests that they are outdated, implying that the performance has not significantly improved. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what specific aspects of the comparison objects are outdated or how they could be improved. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. While it identifies a potential issue with the choice of comparison objects, it lacks specific suggestions or guidance on how the authors might address this concern or improve the experiment. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks about the handling of masks in CNN layers, specifically in the representation block. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the handling of masks need clarification or improvement. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear understanding of what is expected or how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in asking about the handling of masks, but without clear references to the paper, the authors may struggle to pinpoint the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about how masks are handled in CNN layers, specifically in the representation block. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about how masks are handled in CNN layers, specifically in the representation block. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for improvement but does not offer sufficient guidance for the authors to effectively address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Figure 8, specifically asking for an explanation of why \"without dropout\" has a larger training loss. It also mentions that activation clipping may reduce the model capacity. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the training loss and the role of dropout and activation clipping. The comment clearly specifies what needs to be addressed, namely, an explanation for the larger training loss without dropout and the potential impact of activation clipping on model capacity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding Figure 8, specifically asking for an explanation of why \"without dropout\" has a larger training loss. It also mentions that activation clipping may reduce the model capacity. However, the comment does not contain any claims or opinions that require verification. It is a request for additional information and clarification, making it a normal statement. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about Figure 8, asking for an explanation of why \"without dropout\" has a larger training loss. It also mentions that activation clipping may reduce the model capacity, which is a relevant observation. While the comment identifies a potential area for clarification, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their explanation. The feedback is somewhat helpful as it prompts the authors to consider an important aspect of their work, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the paper\\'s significance, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this point or what steps they could take to improve the paper. As a result, the comment lacks actionable content, leaving the authors without a clear understanding of how to respond to the feedback. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the paper\\'s significance, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper should be improved or how the authors might address the issue of establishing a large-scale matting dataset. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the paper\\'s significance, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\\'s opinion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion about the paper\\'s significance, specifically highlighting the importance of establishing a large-scale matting dataset. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this point or enhance the paper\\'s contribution. As a result, the feedback is not helpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the number of adversarial examples is too small to effectively demonstrate the distribution. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue, such as increasing the number of adversarial examples, using a different method to generate them, or exploring alternative ways to demonstrate the distribution. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the number of adversarial examples is too small to effectively demonstrate the distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the distribution are affected or how the authors might address this issue. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is too small to effectively demonstrate the distribution. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the number of adversarial examples used to demonstrate the distribution, suggesting that it may be too small to effectively showcase the distribution. However, it lacks specific guidance or suggestions on how the authors might address this issue, such as increasing the number of adversarial examples or exploring alternative methods to demonstrate the distribution. Without actionable advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It also points out that the analysis experiments or \"Qualitative Studies\" in Section 5.2 are done with a subset of common corruptions, which may not generalize to the full set. The reviewer suggests that it would be better to conduct these experiments with the full set for thoroughness and comparability with other results. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or what specific experiments should be conducted with the full set. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5), which is not appropriate,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the proposed channel-sparse gradients, explaining why they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. The comment further suggests conducting analysis experiments or \"Qualitative Studies\" with the full set of common corruptions for thoroughness and comparability. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the appropriateness of the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. The reviewer provides a logical reasoning by explaining that zeroing out a particular channel may not alter the computation performed. Additionally, the comment critiques the analysis experiments or \"Qualitative Studies\" in Section 5.2, noting that they are done with a subset of common corruptions and may not generalize to the full set. The reviewer suggests conducting these experiments with the full set for thoroughness and comparability. While the reasoning is sound, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of frameworks. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It provides a logical explanation for why this might be the case and highlights the need to conduct analysis experiments or 'Qualitative Studies' with the full set of common corruptions for thoroughness and comparability with other results. This feedback is clear and actionable, offering specific guidance on how to improve the draft by addressing the limitations of the proposed method. However, it could be more helpful if it provided additional suggestions on how to conduct these experiments or what specific results to expect. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proof using concentration-of-measure, which implies a connection to low rank. It questions the claim that the authors do not consider low rank and suggests that the results may be a simple extension of existing results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their claims. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the proof using concentration-of-measure and its connection to low rank. It questions the claim that the authors do not consider low rank and suggests that the results may be a simple extension of existing results. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the proof and its connection to low rank, providing clear guidance on what the authors need to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the authors do not consider sparsity or low rank, suggesting that the proof uses concentration-of-measure, which implies a connection to low rank. The reviewer provides a logical reasoning by pointing out that the high probability considering the tails of the distribution could be related to low rank. However, the comment lacks specific references or detailed examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a reasonable argument but requires additional evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the proof using concentration-of-measure, which implies a connection to low rank, despite the authors\\' claim of not considering low rank. It questions the validity of this claim and suggests that the results may be a simple extension of existing results. While the comment identifies a potential issue with the paper\\'s claims, it lacks specific suggestions or guidance on how the authors might address this concern or clarify their claims. The feedback provides some insight into the paper\\'s weaknesses but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the proof using concentration-of-measure, which implies a connection to low rank, despite the authors\\' claim of not considering low rank. It questions the validity of this claim and suggests that the results may be a simple extension of existing results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their claims. Without actionable steps or detailed advice, the authors are left uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the proof using concentration-of-measure and its connection to low rank. It questions the claim that the authors do not consider low rank and suggests that the results may be a simple extension of existing results. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the proof and its connection to low rank, providing clear guidance on what the authors need to address. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that the authors do not consider sparsity or low rank, suggesting that the proof using concentration-of-measure implies a connection to low rank. The reviewer provides a logical reasoning by pointing out that the high probability considering the tails of the distribution could be related to low rank. However, the comment lacks specific references or detailed examples to fully substantiate the claim. While it raises a valid concern, the absence of concrete evidence or references makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the proof using concentration-of-measure, which implies a connection to low rank, despite the authors\\' claim of not considering low rank. It questions the validity of this claim and suggests that the results may be a simple extension of existing results. While the comment identifies a potential issue with the paper\\'s claims, it lacks specific suggestions or guidance on how the authors might address this concern or clarify"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Limitations section is too concise, contrasting it with the detailed writing style of the main body. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on how to expand the Limitations section or what specific details should be included. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the \"Limitations\" section, noting that it is too concise compared to the detailed writing style of the main body. However, it does not specify which part of the \"Limitations\" section is too concise or what specific details are missing. This lack of detail makes it difficult for the authors to identify the exact areas needing improvement. While the authors might have an idea of where the limitations section is located, the comment is not fully grounded and lacks specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the \"Limitations\" section is too concise, contrasting it with the detailed writing style of the main body. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment points out a discrepancy between the concise nature of the \"Limitations\" section and the detailed writing style of the main body. This feedback highlights a potential inconsistency in the paper\\'s presentation, which could be addressed to improve the overall coherence and clarity. However, the comment lacks specific suggestions or guidance on how to expand or enhance the \"Limitations\" section, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the proposed method is weak, as it appears to be a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might enhance the novelty of their method or differentiate it from existing work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the proposed method is weak, as it appears to be a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not specify which part of the paper discusses the proposed method or how it relates to PatchCore. This lack of explicit reference to a specific section or element makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment provides a general direction for improvement, it does not offer detailed guidance or specific suggestions for addressing the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific references or detailed reasoning to support this claim. Without additional context or examples, it is difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, suggesting that it may be a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment lacks specific details or suggestions on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more details about each challenge, suggesting that this information should be included in an extensive version of Table 1 or in the appendix, similar to the format used in binpwn. Additionally, the reviewer recommends listing all the prompts used in the evaluation, either in the appendix or on GitHub. These suggestions are clear and specific, providing the authors with explicit actions to take to improve their draft. The feedback is concrete, as it outlines exactly what needs to be added or clarified, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely providing more details about each challenge and listing all prompts used in the evaluation. The suggestion to include this information in the appendix is clear and specific, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the repository lacks clear instructions for running the code, which is a factual statement. However, it does not provide specific examples or detailed reasoning to support why the instructions are unclear or how they could be improved. The suggestion to provide more details about each challenge and list all prompts used in the evaluation is a recommendation but lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of clear instructions for running the code due to missing details in the repository. This is a significant concern as it hinders the reproducibility and accessibility of the research. The reviewer provides a clear and actionable suggestion by recommending the inclusion of more detailed instructions, either in an extensive version of Table 1 or in the appendix, similar to the format used in binpwn. Additionally, the comment suggests listing all prompts used in the evaluation, which is another important aspect for reproducibility. This feedback is highly helpful as it not only points out a specific area for improvement but also offers concrete suggestions on how to address the issue, empowering the authors to enhance the clarity and accessibility of their work. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this discrepancy or what changes they should make to align their findings with the major claim. The comment implies that the authors should reconsider their interpretation of the results or provide a more nuanced explanation, but it lacks concrete suggestions or actionable steps. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the model ablation results and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which slightly departs from the major claim of interpretable VQA. The comment provides a logical reasoning by comparing the importance of g_v with other components, but it lacks specific examples or detailed explanations to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA. It highlights that the global representation g_v is more crucial than other components, which slightly departs from the claim that correct answers are anchored on correct visual content. This feedback is somewhat helpful as it points out a potential inconsistency in the paper\\'s findings and suggests that the authors may need to reconsider their interpretation of the results or provide a more nuanced explanation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. Therefore, it is rated as somewhat helpful, as it provides some insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this discrepancy or what changes they should make to align their findings with the major claim. The comment implies that the authors should reconsider their interpretation of the results or provide a more nuanced explanation, but it lacks concrete suggestions or actionable steps. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the model ablation results and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which slightly departs from the major claim of interpretable VQA. The comment provides a logical reasoning by comparing the importance of g_v with other components, but it lacks specific examples or detailed explanations to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This highlights a potential inconsistency in the paper\\'s findings and implies that the authors may need to reconsider their interpretation of the"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the notation in section 3, specifically the use of $f^{-1} = g$ when $d<D$. It suggests that the authors should avoid this notation and prefers using the language of left inverses instead. The comment provides a clear and explicit action for the authors to take, which is to revise the notation to align with the suggested approach. The feedback is concrete, as it specifies the exact change needed and provides a rationale for the suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the notation, specifically the use of $f^{-1} = g$ when $d<D$, and suggests using the language of left inverses instead. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the notation used in the paper, specifically the equation $f^{-1} = g$, which is claimed to be problematic when $d<D$. The reviewer provides a logical reasoning by explaining that $f$ cannot be an invertible function with the given domain definition. However, the comment acknowledges that this is not necessarily a fundamental issue but rather a matter of notation. While the reasoning is sound, the comment could be strengthened by providing additional examples or references to support the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, specifically the equation $f^{-1} = g$, which is problematic when $d<D$. It provides a clear explanation of why this notation is incorrect and suggests using the language of left inverses instead. This feedback is actionable and provides a concrete suggestion for improving the clarity and accuracy of the notation in the paper. By addressing this issue, the authors can enhance the precision and readability of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in their ablation studies on the motion tokenizer. This feedback provides a clear and direct action for the authors to take, specifying which models should be compared and why. The comment is concrete, as it outlines a specific step to enhance the comprehensiveness of the study. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need for comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer. This provides clear guidance on how to improve the analysis presented in Table 4. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], would provide a more comprehensive understanding of the model\\'s relative effectiveness. This claim is somewhat verifiable as it provides a logical reasoning for the inclusion of such comparisons, but it lacks specific examples or detailed references to support the claim fully. The suggestion is based on common knowledge in the field, but without explicit examples or references, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the comprehensiveness of the analysis presented in Table 4. By including these comparisons, the authors can better understand the relative effectiveness of their proposed approach. The comment is mostly helpful as it offers a specific direction for improvement, but it could be more helpful if it included additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the feedback is valuable and provides a clear path for the authors to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies an area that needs clarification, it does not provide explicit guidance on how to address this issue or suggest specific changes. The authors are left to infer that they need to clarify the relationship, but without concrete instructions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"primary-secondary\" relationship and its comparison with nuclearity, which are specific concepts within the paper. However, it does not explicitly mention which part of the paper discusses these concepts, making it weakly grounded. The authors can infer that it relates to sections or discussions where these terms are used, but this inference is not direct. The comment is specific in pointing out the lack of clarity and precise definition of the \"primary-secondary\" relationship compared to nuclearity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or how to address them. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but lacks clarity and precise definition compared to the concept of nuclearity. This feedback highlights a potential area for improvement in terms of clarity and precision in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to clarify the definitions or how to distinguish between the two concepts. While it points out a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies an area that needs improvement, it does not provide explicit guidance on how the authors should clarify these concepts or improve the distinction between them. The comment lacks concrete suggestions or actionable steps for the authors to take, making it barely actionable. The authors are left to infer that they need to clarify the relationship, but without specific instructions, the action remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"primary-secondary\" relationship and its comparison with nuclearity, which are specific concepts within the paper. However, it does not explicitly mention which part of the paper discusses these concepts, making it weakly grounded. The authors can infer that it relates to sections or discussions where these terms are used, but this inference is not direct. The comment is specific in pointing out the lack of clarity and precise definition of the \"primary-secondary\" relationship compared to nuclearity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or how to address them. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the \"primary-secondary\" relationship is mentioned frequently but lacks clarity and precise definition compared to the concept of nuclearity. This feedback highlights a potential area for improvement in terms of clarity and precision in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to clarify the definitions or how to distinguish between the two concepts. While it points out a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the observation that the effect of the mask ratio varies across different datasets, leading to the need for more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. While the comment implies that the authors should include a discussion on the mask ratio and provide guidance, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to address this gap in their paper. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the observation that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to address the issue. The authors can infer that it relates to the limitations or discussions sections, but this inference is not explicit. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which could lead to more tuning. However, it does not provide specific examples or references to support this claim. The suggestion to include an intuitive guide for choosing the mask ratio is also not substantiated with evidence or reasoning. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant observation regarding the varying effects of the mask ratio across different datasets, which could lead to more tuning. It highlights a gap in the discussion section, noting that the impact of the mask ratio is missing. The comment suggests that an intuitive guide for choosing this ratio would be beneficial, providing a clear direction for improvement. However, while it points out the need for additional discussion and guidance, it does not offer specific suggestions or examples on how to address this issue. This limits the comment\\'s helpfulness, as it provides valuable insight but lacks detailed guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the observation that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment implies that the authors should include a discussion on the mask ratio and provide guidance, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to address this gap in their paper. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the observation that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how to address the issue. The authors can infer that it relates to the limitations or discussions sections, but this inference is not explicit. The comment lacks specificity in terms of what needs to be addressed or how to improve the draft. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, which could lead to more tuning. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the observation. Additionally, the suggestion to include an intuitive guide for choosing the mask ratio is not substantiated with evidence or reasoning. Without detailed justification or examples, the claim remains vague and challenging to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights an important observation regarding the varying effects of the mask ratio across different datasets, which could lead to more tuning. It notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. This feedback is valuable as it identifies a gap in the paper and provides a clear direction for improvement. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or provide any guidance on how to improve the clarity of those sections. The action is implicit, as the authors need to infer that they should proof-read the paper again, and it is vague because it lacks specific details on what needs to be improved. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic, making it difficult for the authors to identify the exact parts that need improvement. Additionally, the comment lacks specificity regarding what aspects of the sections are unclear or difficult to follow. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading due to sections that are difficult to follow. However, it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to identify and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. While this feedback highlights an area for improvement, it lacks specificity and does not provide examples or detailed guidance on which sections are problematic. Without actionable suggestions or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and clarity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, and the reviewer guesses it refers to stochastic gates but is uncertain. While the comment identifies a potential issue with terminology, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the term \"STG layer\" and its relation to stochastic gates. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the term \"STG layer\" has never been mentioned in the manuscript and is uncertain about its reference to stochastic gates. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, and the reviewer guesses it refers to stochastic gates. However, the comment lacks specific examples or references to substantiate this claim, making it difficult for the authors to understand the basis of the reviewer\\'s assertion. Without detailed justification or evidence, the claim remains vague and unverifiable. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript, noting that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript. It suggests that the reviewer is guessing the term refers to stochastic gates but is uncertain about it. This feedback is somewhat helpful as it points out a potential inconsistency in terminology that could affect the clarity and coherence of the manuscript. However, the comment lacks actionable guidance on how the authors should address this issue, such as suggesting ways to clarify the term or its relation to stochastic gates. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the improvements resulting from the proposed methodology are limited in some instances and even underperform compared to the baseline in the cases of FiQA and CONALA. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their methodology. There is no guidance on potential changes, additional experiments, or analyses that could be conducted to enhance the methodology. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitations of the proposed methodology in terms of improvements and performance compared to the baseline in specific cases, such as FiQA and CONALA. However, it does not specify which part of the paper discusses these results or where the methodology is described, making it weakly grounded. The comment is specific in identifying the areas where the methodology underperforms, but it lacks grounding as it does not point to a particular section or figure. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements resulting from the proposed methodology are limited and even underperform compared to the baseline in specific cases, such as FiQA and CONALA. However, the comment does not provide any supporting evidence, such as specific data or analysis, to substantiate these claims. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out that the improvements resulting from the proposed methodology are limited in some instances and even underperform compared to the baseline in specific cases, such as FiQA and CONALA. This feedback is somewhat helpful as it identifies areas where the methodology may need improvement or further development. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or enhance their methodology. Without actionable advice or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. While the comment implies that the authors should provide more detailed explanations or comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context or comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. However, it does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The comment is specific in its request for clarification on the contributions beyond [1], but without grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the comparisons are unclear. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of comparisons with a specific work, [1], and asks for clarification on the contributions or advantages beyond that work. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing clearer comparisons and highlighting unique contributions. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue, such as by providing additional context or examples. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It explicitly instructs the authors to provide a well-explained reason for why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and provides a concrete action for the authors to take, ensuring they know exactly what needs to be addressed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"re-balancing step method\" and its role in making multi-modal learning less greedy, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a well-explained reason for why using the average feature of previous samples can stop the training of the uni-modal branch. This level of detail guides the authors on what aspects of the re-balancing step method need further clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method is not well described and analyzed in the full text. It suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim. The suggestion for improvement is clear, but the lack of detailed justification makes the claim somewhat verifiable. The authors would need to infer the exact issues and improvements needed, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It points out that the method is not well described and suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to clarify a critical aspect of their methodology. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of similar methods that could be referenced. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding Section 4.1. The first question asks for clarification on the differences and advantages of the \"Reduce\" part compared to EATA. The second question suggests using entropy instead of energy to identify harmful out-of-distribution (OOD) instances. While the questions imply actions, they are not explicitly stated, and the authors may need to infer that they should provide detailed explanations and comparisons. The suggestions are concrete, as they specify what needs to be addressed, but the action is inferred rather than explicit. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"Reduce part,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the differences and advantages over EATA, and suggests using entropy instead of energy to identify harmful OOD instances. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in Section 4.1, questioning the differences and advantages of the \"Reduce\" part compared to EATA. It also suggests an alternative approach using entropy instead of energy to identify harmful out-of-distribution instances. While the comment highlights a potential area for improvement, it lacks detailed guidance or specific suggestions on how to address these issues or what aspects of the \"Reduce\" part should be compared to EATA. The feedback is somewhat helpful as it points out areas for clarification and improvement, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not explicitly instruct the authors to conduct this comparison or explain why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer that they should consider this comparison but without clear guidance on how to implement it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the comparison of the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact part of the paper that needs attention. While the suggestion is specific in terms of what could be explored, the lack of grounding makes it challenging for the authors to address the comment effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not provide any specific reasoning or evidence to support why this comparison would be beneficial or how it relates to the main claims of the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. While this is a relevant suggestion that could enhance the paper by providing a comparative analysis, the comment lacks specificity and does not provide actionable guidance on how to conduct this comparison or why it would be beneficial. It does not offer detailed feedback or suggestions for improvement, leaving the authors with a general idea but no clear path forward. Therefore, the comment is barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential inconsistency in the naming of the 3r column in Table 4, suggesting that it should be named ATE instead. The reviewer also clarifies that Corr is also Cau-Ant. This feedback is explicit and provides a clear action for the authors to take, which is to correct the naming in the table. The suggestion is concrete, as it specifies exactly what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential inconsistency in naming the 3r column and clarifying that \"Corr is also Cau-Ant.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the naming of a column in Table 4, suggesting that it should be named ATE instead of 3r. The comment also clarifies that \"Corr is also Cau-Ant.\" This is a straightforward correction of a naming inconsistency and does not require any supporting evidence or reasoning. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the labeling of columns in Table 4, suggesting that the 3r column should be named ATE instead. It also clarifies that \"Corr is also Cau-Ant,\" which provides additional context for understanding the table. This feedback is clear and actionable, as it directly points out a naming error that could be easily corrected. However, it could be more helpful if it explained why this naming change is important or how it might impact the interpretation of the results. Despite this, the comment is mostly helpful as it provides a straightforward way for the authors to improve the clarity and accuracy of their table. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides two separate pieces of feedback. The first part suggests that the mechanism is not clearly anchored in prior work, even after the experiments section, and that more explanation of how it builds on existing methods would be beneficial. The second part highlights the difficulty in understanding the figures and suggests annotating or zooming in to provide quantitative grounding. While both pieces of feedback imply actions, they are somewhat vague and lack specific guidance on how to implement these suggestions. The authors know they need to clarify the mechanism and improve figure clarity, but the comments do not provide detailed steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is partially grounded as it mentions specific sections, such as the \"experiments section\" and \"methods section,\" which helps the authors identify the parts of the paper being addressed. However, it lacks specificity in detailing what aspects of the mechanism are unclear or how they could be better anchored in prior work. Additionally, the comment on the figures lacks specific guidance on how to improve their clarity. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the mechanism is not clearly anchored in prior work, even after the experiments section, and suggests that more explanation of how it builds on existing methods would be beneficial. The comment also mentions that the figures are difficult to interpret and suggests annotating or zooming in to provide quantitative grounding. While the comment identifies areas for improvement, it lacks specific examples or references to prior work that could support the claim. The suggestion to clarify the figures is also vague. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement. First, it points out that the mechanism is not clearly anchored in prior work, even after the experiments section, and suggests that more explanation of how it builds on existing methods would be beneficial. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and grounding of their work in the literature. Second, the comment highlights the difficulty in understanding the figures and suggests annotating or zooming in to provide quantitative grounding. This feedback is also actionable, as it offers specific suggestions for improving the clarity of the figures. Overall, the comment is mostly helpful as it provides clear and actionable feedback that can significantly improve the draft. However, it could be more comprehensive by offering additional guidance on how to effectively anchor the mechanism in prior work or by suggesting specific examples of how to clarify the figures. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might enhance the novelty or simplify the approach. As a result, the comment is unactionable because it does not offer any actionable steps for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. However, it does not specify which part of the paper this concern is based on, nor does it provide details on how the novelty could be improved or simplified. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. The reviewer suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment lacks specific examples, references, or detailed reasoning to support the claim of limited novelty or the complexity of the approach. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or simplify the approach. Without actionable feedback or detailed insights, the authors are left with a general critique but no clear path for improvement. Therefore, the comment is barely helpful, as it identifies an issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the paper empirically validates the usefulness of setups and parameters for test-time training, it lacks a theoretical understanding of why these do not collapse. However, it does not provide explicit guidance or suggestions on how the authors should address this gap. The comment implies that the authors should explore theoretical explanations, but it does not specify what kind of theoretical understanding is needed or how to achieve it. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical understanding in the paper regarding why certain setups and parameters do not collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a theoretical understanding, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a theoretical understanding of why certain setups and parameters do not collapse, despite empirically validating their usefulness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper, specifically the lack of theoretical understanding of why certain setups and parameters do not collapse despite empirical validation. This feedback is valuable as it highlights an area where the authors can deepen their analysis and provide a more comprehensive understanding of their results. However, the comment does not offer specific suggestions or guidance on how the authors might address this gap, such as recommending theoretical frameworks or methodologies to explore. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve clarity. The action is implicit, as the authors need to infer that they should clarify the source of the visual analysis, but it lacks concrete details on how to implement this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec.4.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the visual analysis, specifically whether it is based on training or test images. This provides clear guidance on what aspect of the paper needs clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. This is a relevant point that could impact the interpretation of the results. However, the comment lacks specific suggestions or guidance on how the authors might clarify this issue or improve the clarity of their analysis. While it points out a potential area for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the analysis. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to clarify the source of the visual analysis, but the comment does not offer specific steps or examples to follow. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec.4.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the clarity of the visual analysis, questioning whether it is based on training or test images. This provides clear guidance on what aspect of the paper needs clarification. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, the comment lacks supporting evidence, reasoning, or specific examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. This is a relevant point that could impact the interpretation of the results. However, the comment lacks specific suggestions or guidance on how the authors might clarify this issue or improve the clarity of their analysis. While it points out a potential area for improvement, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the analysis. The action is implicit, as the authors need to infer that they should clarify the source of the visual analysis, but it lacks concrete details on how to implement this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It poses questions about the potential performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training and more effective hyperparameter tuning. While the comment implies that the authors should conduct this exploration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the performance of these methods with the DEER method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, questioning whether they would maintain the same performance and whether better performance could be achieved with the DEER method. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or methodology. The authors can infer that it relates to the discussion of methods or results, but this inference is not direct. The comment is specific in its suggestion to explore the performance of other methods with the DEER method, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It poses questions about the potential performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training and more effective hyperparameter tuning. While the comment is based on logical reasoning and a suggestion for further exploration, it lacks specific examples or references to support the claim that these methods would perform better with the DEER method. The suggestion is somewhat verifiable, as it provides a clear direction for potential improvement but requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It poses questions about the potential performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training and more effective hyperparameter tuning. This suggestion could significantly enhance the paper by broadening its impact and providing a deeper understanding of the DEER method\\'s applicability. However, the comment lacks specific guidance or actionable steps for the authors to follow, such as recommending which methods to focus on or how to structure the exploration. While it provides a valuable direction for further research, the feedback could be more helpful with additional details or suggestions. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as reducing the number of notations, clarifying their usage, or providing more context. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to improve the presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. However, it does not specify which sections or parts of the paper contain these notations, making it weakly grounded. The comment is specific in identifying the problem of too many notations, but without explicit references to sections, the authors may struggle to pinpoint where the issue lies. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples or reasoning to support this claim, such as which notations are particularly confusing or how their number affects the clarity of the presentation. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. While it highlights a potential problem, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges that this might be challenging but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. While the action is explicit, it is somewhat vague because it does not provide detailed guidance on how to conduct these experiments or what specific results should be included. The authors know they need to include results from GPT-4V, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results from GPT-4V, even though its API is not yet released. It acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential solution to include results from GPT-4V, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. While the comment provides a logical reasoning for including results from GPT-4V, it lacks specific examples or references to support the claim. The suggestion is based on the assumption that quick experiments through ChatGPT\\'s UI would be sufficient, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. This feedback is clear and actionable, providing the authors with a concrete step to take to enhance the comprehensiveness of their results. However, the comment could be more helpful if it included specific guidance on how to conduct these experiments or what results should be prioritized. Overall, the comment is mostly helpful as it offers a practical suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. While the action is explicit, it is somewhat vague because it does not provide detailed guidance on how to conduct these experiments or what specific results should be included. The authors know they need to include results from GPT-4V, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results from GPT-4V, even though its API is not yet released. It acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a potential solution to include results from GPT-4V, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT's UI. While the comment provides a logical reasoning for including results from GPT-4V, it lacks specific examples or references to support the claim. The suggestion is based on the assumption that quick experiments through ChatGPT's UI would be sufficient, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including results from GPT-4V, even though its API is not yet released. The reviewer acknowledges the challenge but proposes a solution by suggesting quick experiments through ChatGPT\\'s UI. This feedback is clear and actionable, providing the authors with a concrete step to take to enhance the comprehensiveness of their results. However, the comment could"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss more about the theoretical analysis and provide a clearer explanation of why CoPur could perform better than baselines. While the comment implies that the authors should expand their discussion, it does not provide specific guidance on what aspects of the analysis should be elaborated upon or how to structure this discussion. The action is implicit and somewhat vague, as the authors need to infer the details of what needs to be addressed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper provides an extensive theoretical analysis and recommends that the authors discuss more about the analysis and its implications. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to pinpoint the exact section that needs further elaboration. The suggestion to discuss why CoPur could perform better than baselines is specific, but the lack of grounding in the paper's structure makes it challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis and recommends that the authors discuss more about the analysis and its implications. However, it does not provide specific examples or detailed reasoning to support the claim that the analysis is extensive or lacks clarity. The suggestion to discuss why CoPur could perform better than baselines is vague and lacks supporting evidence or references. As a result, the claim is not well-supported, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper provides an extensive theoretical analysis and recommends that the authors discuss more about the analysis and its implications. It also asks why CoPur could perform better than baselines. While the comment identifies areas for improvement, it lacks specific guidance or actionable suggestions on how the authors might enhance their discussion or provide a clearer explanation of their results. The feedback is somewhat helpful as it points out a potential weakness in the paper but does not offer detailed advice on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the reported metrics and evaluation protocol. It notes that the metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions. The reviewer also questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all videos. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer the necessary changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Result/eval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the reported metrics, particularly the lack of metrics related to dynamics and the unclear evaluation protocol regarding camera parameters. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It claims that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions. The reviewer also questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all videos. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim about the evaluation protocol. The lack of explicit examples or detailed explanation makes the claim somewhat verifiable, as the authors would need to infer the full extent of the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol. It points out that the metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions but not their quality. Additionally, the comment questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all videos. This feedback is somewhat helpful as it highlights specific areas where the paper could be improved, such as expanding the metrics to better assess dynamics and clarifying the evaluation protocol. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of alternative metrics or evaluation methods. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several issues with the reported metrics and evaluation protocol. It notes that the metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions. Additionally, the comment questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all videos. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for the authors to take. The actions are implicit and somewhat vague, leaving the authors to infer the necessary changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Result/eval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the reported metrics, particularly the lack of metrics related to dynamics and the unclear evaluation protocol regarding camera parameters. The comment provides clear guidance on what needs to be addressed, such as expanding the metrics to better assess dynamics and clarifying the evaluation protocol. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It claims that the reported metrics are mostly for 3D NVS and that the only metric related to dynamics is keypoint distance, which only assesses the size of motions but not their quality. Additionally, the comment questions the clarity of the evaluation protocol, specifically asking whether camera parameters are consistent across all videos. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The lack of explicit evidence or references makes the claim somewhat verifiable, as the authors would need to infer the full extent of the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several issues with the reported metrics"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the two parts of pretraining and regularization are presented as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. While it identifies a problem with the presentation, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to restructure the presentation to better integrate these components, but the comment lacks concrete suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the presentation of pretraining and regularization, suggesting that they are presented as incremental additions rather than naturally integrated components. However, it does not specify which parts of the paper these additions are discussed in, making it weakly grounded. The comment is specific in identifying the issue with the disjointed presentation and its impact on the coherence of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation of pretraining and regularization is disjointed and detracts from the coherence of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of pretraining and regularization, noting that they are presented as incremental additions rather than naturally integrated components. This observation is relevant and highlights a potential weakness in the paper\\'s coherence. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending ways to integrate these components more effectively. While it points out a problem, it does not provide the authors with a clear path to improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the importance of Renyi divergence is not well explained and questions why it is considered special for readers unfamiliar with differential privacy. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the explanation or what specific aspects should be clarified. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the explanation of Renyi divergence and its importance, specifically questioning why it is considered special for readers unfamiliar with differential privacy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the explanation of Renyi divergence, but without clear grounding, the authors may struggle to identify the exact section needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the explanation of Renyi divergence and its importance, particularly for readers unfamiliar with differential privacy. However, it does not provide any specific examples, references, or detailed reasoning to support why the explanation is unclear or insufficient. The lack of supporting evidence or detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved, namely the explanation of Renyi divergence and its importance. It highlights a potential gap in the understanding for readers unfamiliar with differential privacy, which is a valid concern. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the explanation or make it more accessible. While it points out an area for improvement, it does not offer actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. While the comment implies that the authors should make an effort to improve the clarity of their work, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to simplify and clarify their content without being given concrete steps or examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact sections that need improvement. Additionally, the comment lacks specificity regarding what aspects of simplicity and clarity should be emphasized or how the authors might achieve this. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed justification or references, the comment lacks verifiability, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity in their work, rather than relying solely on mathematical theories. While this is a valid point, the comment lacks specificity and does not provide actionable guidance on how the authors might achieve this. It does not offer examples of where the current work lacks clarity or suggest ways to improve the presentation of mathematical concepts. As a result, the feedback is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not provide specific guidance or examples on how the authors might achieve this, such as simplifying complex mathematical concepts or improving the clarity of their explanations. The action is implicit and lacks concrete details, making it somewhat vague. Authors are left to infer the need for improvement but without clear direction on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact sections that need improvement. Additionally, the comment lacks specificity regarding what aspects of simplicity and clarity should be emphasized or how the authors might achieve this. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not provide any specific examples, references, or reasoning to support this claim. Without detailed justification or evidence, the comment lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity in their work, rather than relying solely on mathematical theories. While this is a valid point, the comment lacks specificity and does not provide actionable guidance on how the authors might achieve this. It does not offer examples of where the current work lacks clarity or suggest ways to improve the presentation of mathematical concepts. As a result, the feedback is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, it does not provide specific guidance or examples on how the authors might achieve this, such as simplifying complex concepts or improving the clarity of their explanations. The action is implicit and lacks concrete details, making it somewhat vague. Authors are left to infer the need for improvement but without clear direction on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specific"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablation study in the work is limited and recommends that the impact of the pre-defined threshold \u03f5 should be further studied. While the comment implies that the authors should conduct additional studies, it does not provide explicit instructions or concrete guidance on how to expand the ablation study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the ablation study in the work is limited and specifically mentions the impact of the pre-defined threshold \u03f5. This provides some level of grounding as it refers to a specific aspect of the study. However, it does not explicitly mention which part of the paper discusses the ablation study, making it weakly grounded. The comment is specific in suggesting that the impact of the pre-defined threshold \u03f5 should be further studied, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablation study in the work is limited, specifically mentioning the impact of the pre-defined threshold \u03f5. However, it does not provide any supporting evidence, reasoning, or examples to justify why the ablation study is limited or how the impact of the threshold \u03f5 should be further studied. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically noting that the impact of the pre-defined threshold \u03f5 should be further explored. This feedback is somewhat helpful as it highlights a specific area for improvement in the study. However, the comment lacks depth and does not provide detailed guidance or suggestions on how the authors might conduct this further study or what specific aspects to focus on. To be more helpful, the comment could include specific recommendations or examples of how to address the limitation. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that only Rouge-L is used for evaluation, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the evaluation. There is no guidance on alternative metrics or methods that could be used, nor is there any indication of how to enhance the reliability of the evaluation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of Rouge-L as the sole evaluation metric, suggesting that it may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not specify which part of the paper discusses the evaluation metrics or where Rouge-L is primarily used. This lack of explicit reference to specific sections or figures makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. While the comment is specific in its critique of the evaluation metric, it is not grounded in the paper, making it weakly grounded. Therefore, this comment aligns with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that using only Rouge-L as an evaluation metric makes the evaluation unreliable, especially for classification tasks where Rouge-L is not sensitive enough. However, the comment lacks specific examples or references to support this claim, such as alternative metrics that could be used or how Rouge-L's limitations impact classification tasks. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the evaluation metric used in the paper, specifically that only Rouge-L is used for evaluation. It suggests that this might not be reliable, especially for classification tasks where Rouge-L may not be sensitive enough. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation process. Without actionable advice or examples of alternative metrics or methods that could be used, the feedback provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that only Rouge-L is used for evaluation, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the evaluation process. There is no guidance on alternative metrics or methods that could be used, nor is there any indication of how to enhance the reliability of the evaluation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a potential issue with the evaluation metric used in the paper, specifically that only Rouge-L is used for evaluation, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not specify which part of the paper discusses the evaluation metrics or where Rouge-L is primarily used, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique of the evaluation metric, it lacks grounding as it does not reference specific sections or figures. Therefore, this comment aligns with category 2, as it is weakly grounded and specific.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that using only Rouge-L as an evaluation metric makes the evaluation unreliable, especially for classification tasks where Rouge-L is not sensitive enough. However, the comment lacks specific examples or references to support this claim, such as alternative metrics that could be used or how Rouge-L's limitations impact classification tasks. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment identifies a potential issue with the evaluation metric used in the paper, specifically that only Rouge-L is used for evaluation, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the evaluation process. Without actionable advice or examples of alternative metrics or methods that could be used, the feedback offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but does not"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the definitions of variables in lines 580-588, stating that they do not properly match the formula (Equation 3) and that the variable n_k is missing. This provides a clear and direct action for the authors to take, which is to correct the definitions to ensure they accurately reflect the formula. The comment is explicit and provides concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula (Equation 3) and the absence of the variable n_k in Equation 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not match the formula (Equation 3) and that the variable n_k is missing. This is a factual observation rather than a subjective claim or suggestion. It does not require verification or evidence beyond the statement itself. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables in lines 580-588, noting that they do not properly match the formula (Equation 3) and that the variable n_k is missing. This feedback is clear and actionable, as it directly points out a discrepancy that needs to be addressed. By highlighting this error, the reviewer provides the authors with a concrete step to take in revising their draft, making the comment highly helpful. However, it could be further improved by suggesting how to correct the definitions or providing additional context. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions that some key experiments are missing. While the comment highlights a potential issue and the need for additional experiments, it does not provide explicit instructions or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of the class-specific token and conduct additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments. However, the comment does not specify which part of the paper discusses the class-specific token or the experiments, making it weakly grounded. The comment is specific in questioning the sufficiency of the strategy and the need for additional experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the conflict with the sample-specific assumption. The suggestion for additional experiments is not fully substantiated with detailed reasoning or examples, making the claim somewhat verifiable. The authors would need to further explore and clarify the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also points out the absence of key experiments, which is a significant omission that could impact the comprehensiveness of the study. While the comment identifies a potential weakness and highlights the need for additional experiments, it lacks specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of the problem but without detailed steps on how to resolve it. Therefore, the comment is somewhat helpful, as it provides insight into a critical area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments. While the comment identifies a potential issue and highlights the need for additional experiments, it does not provide explicit instructions or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of the class-specific token and conduct additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments. However, the comment does not specify which part of the paper discusses the class-specific token or the experiments, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in questioning the strategy and the need for additional experiments, but without clear references or detailed guidance, it remains somewhat vague. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space, suggesting that this strategy might conflict with the sample-specific assumption of the paper. It also mentions the absence of key experiments. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the conflict with the sample-specific assumption. The suggestion for additional experiments is not fully substantiated with detailed reasoning or examples, making the claim somewhat verifiable. The authors would need to further explore and clarify the issue themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, especially in the context of intent discovery evaluation. The reviewer suggests that further clarification is needed to ensure a fair comparison with the baselines. While the comment implies that the authors should clarify the intent discovery experiment setting, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the comparability of the IntenDD experiments to the cited baselines, particularly in the context of intent discovery evaluation. The comment further suggests that further clarification is needed to ensure a fair comparison with the baselines. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the assumption of known number of intent classes during graph construction, questioning the comparability of the IntenDD experiments reported in Table 1 to the cited baselines. The reviewer acknowledges the authors\\' acknowledgment of this limitation but suggests that further clarification is needed to ensure a fair comparison. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left with a general concern about the comparability of results, which could be addressed with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction, which is particularly relevant for the intent discovery evaluation. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, suggesting that further clarification is needed to ensure a fair comparison. The comment acknowledges the authors\\' acknowledgment of this limitation but emphasizes the need for additional clarification. While it points out a critical issue, it could be more helpful by providing specific suggestions on how to address this limitation or offer alternative approaches. Overall, the comment is somewhat helpful as it highlights an important area for improvement but lacks detailed guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the rigorous experimentation in the work but expresses concern about the limited significance of the results. It suggests that the application of d-separation criteria in the intervened graph with known variables and causal relationships is expected to work, and it questions the necessity of the experiments on corrupted CIFAR and ImageNet, which require knowledge of corruption labels. The reviewer provides references to related work that could be considered for comparison. However, the comment does not explicitly instruct the authors on how to address these concerns or improve the significance of their results. The feedback is implicit and lacks concrete guidance on specific actions to take, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges the rigorous experimentation in the work but expresses concern about the limited significance of the results. It suggests that the application of d-separation criteria in the intervened graph with known variables and causal relationships is expected to work, and questions the necessity of the experiments on corrupted CIFAR and ImageNet, which require knowledge of corruption labels. The comment provides references to related work that could be considered for comparison. However, it does not specify which part of the paper these concerns relate to, such as the results section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the concerns about the significance of the results and the necessity of the experiments, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the rigor of the experimentation but questions the significance of the results, particularly regarding the application of d-separation criteria in the intervened graph with known variables and causal relationships. The reviewer suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work, which could support the claim about the limitations of the results. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the limitations of the results. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the rigor of the experimentation but questions the significance of the results, particularly regarding the application of d-separation criteria in the intervened graph with known variables and causal relationships. It suggests that the experiments on corrupted CIFAR and ImageNet require knowledge of corruption labels, which would simplify the problem. The comment provides references to related work that could be considered for comparison, which is a valuable piece of feedback. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the significance of their results. While it highlights an important area for consideration, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the alignment between the reliance on gradient-based saliency methods for evaluating feature map channel importance and the underlying feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their approach. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the alignment between the reliance on gradient-based saliency methods for evaluating feature map channel importance and the underlying feature selection mechanisms in the human brain. However, it does not specify which part of the paper this concern is related to, such as a particular section, figure, or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the alignment between methods and brain mechanisms, but without clear grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the alignment between gradient-based saliency methods and the underlying feature selection mechanisms in the human brain. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the alignment between the reliance on gradient-based saliency methods for evaluating feature map channel importance and the underlying feature selection mechanisms in the human brain. This is a relevant point that could prompt the authors to reconsider their methodology or provide a more nuanced discussion of the limitations of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential weakness, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the use of Pythia as the model choice, noting that it is not state-of-the-art (SOTA) but has the advantage of available checkpoints. However, it does not provide any explicit or implicit suggestions for improvement or alternatives. The comment lacks actionable guidance, leaving the authors uncertain about how to address the issue or whether they should consider a different model choice. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model choice, specifically mentioning the use of Pythia. However, it does not specify which part of the paper discusses the model choice, making it weakly grounded. The comment is specific in pointing out that Pythia is not state-of-the-art but has the advantage of available checkpoints. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper uses Pythia, which is not state-of-the-art (SOTA), but has the advantage of available checkpoints. However, the comment does not provide any supporting evidence or references to substantiate why Pythia is considered not state-of-the-art or why the availability of checkpoints is advantageous. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the model choice, noting that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. While it identifies a weakness in the model selection, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their model choice. Without actionable feedback or detailed advice, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the completeness of offline RL algorithms and the role of image representation learning in the Franka Kitchen image observation version. It suggests that more information or resources should be provided to challenge the community to solve this task. However, the comment does not explicitly instruct the authors on how to address these questions or provide specific guidance on what additional information or resources should be included. The actions are implicit and somewhat vague, leaving the authors to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the completeness of offline RL algorithms and the role of image representation learning in the Franka Kitchen image observation version. It suggests that more information or resources should be provided to challenge the community to solve this task. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its questions about the task\\'s solvability and potential data sources, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and suggestions for further exploration rather than claims. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the completeness of offline RL algorithms and the role of image representation learning in the Franka Kitchen image observation version. It suggests that more information or resources should be provided to challenge the community to solve this task. The comment also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. By prompting the authors to consider these aspects and potentially provide additional information, the comment offers a clear direction for improvement. However, it could be more helpful if it included specific suggestions or examples of what additional information or resources might be beneficial. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for insight into why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should offer a detailed explanation. However, the comment does provide a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is an explanation for the observed weakness of the multilingual model on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification or explanation regarding the performance of the multilingual model on specific evaluations. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the performance of the multilingual model, particularly on the ET\u2192En and LV\u2192EN evaluations. It asks for insight into why the model is \"noticeably weaker\" in these contexts. This feedback is somewhat helpful as it prompts the authors to provide a detailed explanation or analysis of the model\\'s performance, which could lead to a better understanding of the results and potential improvements. However, the comment could be more helpful if it suggested specific areas or methods for addressing the issue or offered guidance on how to present the analysis. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the meaning of the numbers in brackets in tables #1 and #2. This is a clear and direct request for information, providing the authors with a specific action to take. The comment is explicit and concrete, as it directly instructs the authors to clarify the meaning of the numbers in brackets. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of the numbers in brackets, providing a clear direction for the authors to address the issue. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the meaning of numbers in brackets in specific tables. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific issue with the presentation of data in the tables, namely the meaning of the numbers in brackets. This feedback is clear and actionable, prompting the authors to clarify the notation used in their tables. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of the notation. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It asks how these results relate to long-term fairness, as claimed in the paper. While the comment identifies a potential gap in the paper\\'s argument, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the connection between the results and the limitations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"connection of presented RDRO results and the listed limitations,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the results connect to the limitations of previous fairness notions and how they relate to long-term fairness. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It acknowledges the paper\\'s consideration of repeated distributionally robust optimization and its convergence analysis but expresses uncertainty about how these results relate to the limitations of fairness notions. The comment seeks clarification on how the results fit into the context of long-term fairness. While the comment highlights a potential gap in the paper\\'s argument, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to further explore the connection themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It highlights a potential gap in the paper\\'s argument by questioning how the results relate to long-term fairness, as claimed in the paper. This feedback is valuable as it prompts the authors to clarify and strengthen the connection between their results and the limitations discussed, which is crucial for the paper\\'s overall coherence and impact. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns or improve the accuracy. The feedback is somewhat actionable because it highlights areas of concern but lacks detailed instructions on how to resolve them. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. The comment further specifies the need to clarify whether the errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claim about the accuracy or the normalization of errors. The authors are left to infer the significance of these concerns, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. This feedback is somewhat helpful as it identifies specific areas of concern regarding the accuracy and normalization of errors in the paper. However, it lacks detailed guidance or suggestions on how the authors might address these issues or improve the accuracy of their results. While it prompts the authors to consider these aspects, it does not provide actionable steps for improvement, making it somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how the authors should address these concerns or improve the accuracy. The feedback is somewhat actionable because it highlights areas of concern but lacks detailed instructions on how to resolve them. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. The comment further specifies the need to clarify whether the errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and questions the high Euclidean distance error units in Table 1. It asks whether these errors are normalized to per datapoint position errors and points out that an error of 5 cm with HDR-IL seems unreasonably high. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claim about the accuracy or the normalization of errors. The authors are left to infer the significance of these concerns, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide explicit guidance on how the authors should address this issue or what specific conclusions they should reach. The comment lacks concrete details or suggestions on how to improve the paper, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper lacks a conclusion or where the authors should focus their efforts to address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the article does not reach a conclusion and implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It suggests that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specificity and does not provide actionable feedback or guidance on how the authors might address this issue or improve their conclusion. Without detailed suggestions or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is based on a pre-defined labeler strategy. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this issue or improve the contribution of their theoretical results. As a result, the comment lacks actionable guidance, leaving the authors uncertain about how to proceed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, suggesting they are not surprising and have limited contribution to the algorithm design. However, it does not specify which part of the paper these theoretical results are discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the theoretical results are considered limited or how they could be improved. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is based on a pre-defined labeler strategy. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the theoretical results, stating that they are not surprising and have limited contribution to the algorithm design. It suggests that the algorithm design is based on a pre-defined labeler strategy. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their theoretical results. Without clear guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling, planning, and reduces the research contribution. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. It lacks concrete actions or detailed instructions on what specific aspects need to be clarified or expanded upon. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not specify which part of the paper these issues pertain to, making it weakly grounded. The authors might infer that these concerns relate to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed regarding the effectiveness of reverse chain and the focus on comparison, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these concerns and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. Without actionable feedback or detailed advice, the authors are left with a general understanding of what needs improvement but without clear steps to take. Therefore, the comment is somewhat helpful, as it points out areas for enhancement but does not provide sufficient guidance for the authors to effectively improve their draft.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. It lacks concrete actions or detailed instructions on what specific aspects need to be clarified or expanded upon. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not specify which part of the paper these issues pertain to, making it weakly grounded. The authors might infer that these concerns relate to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed regarding the effectiveness of reverse chain and the focus on comparison, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of these concerns and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises two concerns: first, it questions the"}
{"generated_text": "{'actionability_rationale': 'The review point provides an explicit recommendation for rejection based on the weaknesses identified in the paper, specifically the lack of experimental rigor. The reviewer explains that the weaknesses cannot be fixed in time, content space, or degree, and that the required editing is unrealistic in terms of time and space. While the comment clearly states the action of rejection, it lacks specific guidance on how the authors might address these issues if they were to revise the paper. The feedback is somewhat actionable because it provides a clear direction but lacks detailed instructions on how to improve the paper. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides a recommendation for rejection based on the weaknesses identified in the paper, specifically the lack of experimental rigor. However, it does not specify which parts of the paper are lacking in experimental rigor or what specific issues need to be addressed. The authors cannot confidently determine which sections of the paper are being referred to, nor do they have clear guidance on how to improve the experimental rigour. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point provides a recommendation for rejection based on the weaknesses identified in the paper, specifically the lack of experimental rigor. The reviewer explains that the weaknesses cannot be fixed in time, content space, or degree, and that the required editing is unrealistic in terms of time and space. While the comment provides a logical reasoning for the rejection, it lacks specific examples or references to support the claim about the experimental rigour. This makes the claim somewhat verifiable, as it provides a general rationale but lacks detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable recommendation for rejection based on the weaknesses identified in the paper, specifically the lack of experimental rigor. The reviewer explains that the weaknesses cannot be fixed in time, content space, or degree, and that the required editing is unrealistic in terms of time and space. This feedback is helpful as it gives the authors a direct and specific reason for rejection, which can guide them in understanding the shortcomings of their work. However, the comment could be more helpful if it provided additional context or suggestions on how the authors might address these issues if they were to revise the paper. Overall, the comment is mostly helpful, as it effectively highlights a significant issue but could be further improved with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison between Medusa and Medusa+ParallelSpec, specifically regarding the change in draft model architecture. It suggests that a baseline should be provided where only the draft model architecture is altered, or the modified setting should be given a different name to avoid confusion. This feedback implies that the authors should clarify the experimental setup to ensure a fair comparison. While the action is explicit, it lacks concrete guidance on how to implement this change, such as suggesting specific baseline models or how to name the modified setting. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (266-267) in the draft, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between Medusa and Medusa+ParallelSpec, questioning the fairness of the competition due to the change in draft model architecture. The comment provides a clear suggestion for addressing this issue by recommending either a baseline or a different name for the modified setting. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between Medusa and Medusa+ParallelSpec, specifically regarding the change in draft model architecture. The reviewer questions whether the speedup gain is due to the change in draft model architecture or the ability to predict draft tokens in parallel. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the unfair competition. The suggestion to provide a baseline or a different name for the modified setting is logical but not fully substantiated by the comment itself. Therefore, the claim is somewhat verifiable, as it provides a reasonable basis for the concern but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between Medusa and Medusa+ParallelSpec, specifically regarding the change in draft model architecture. It questions whether the speedup gain is due to the change in architecture or the ability to predict draft tokens in parallel. The comment suggests providing a baseline where only the draft model architecture is altered or giving the modified setting a different name to avoid confusion. This feedback is clear and actionable, as it guides the authors on how to improve the clarity and fairness of their experimental setup. However, it could be more helpful if it provided specific suggestions on how to implement these changes or examples of how to present the results. Overall, the comment is mostly helpful, as it effectively directs the authors toward improving the clarity and rigor of their experimental design.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason for focusing on Masked Language Models and whether experiments did not work with an autoregressive LM. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider if they need to justify their choice of Masked Language Models. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the reason for focusing on Masked Language Models and whether experiments did not work with an autoregressive LM. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the rationale behind the choice of Masked Language Models and the experimental results, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the choice of Masked Language Models and whether experiments did not work with an autoregressive LM. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind the focus on Masked Language Models and whether experiments did not work with an autoregressive LM. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with a general inquiry rather than concrete steps to enhance their work. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks how the map is encoded, and second, it suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. While the questions imply actions, they are not explicitly stated. The authors can infer that they need to provide details on how the map is encoded and conduct experiments on the proposed method in YNet. However, the comment lacks concrete guidance on how to address these points, making the actions somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific questions: first, it asks about the encoding of the map, and second, it suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. However, it does not specify which part of the paper these questions pertain to, such as a particular section or figure. The authors might infer that these questions relate to the methodology or results sections, but this inference is not direct. Therefore, the comment is weakly grounded because it does not explicitly mention the part of the paper being addressed, but it is specific in its questions. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for clarification and a suggestion for additional experiments. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions: first, it asks how the map is encoded, and second, it suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. While these questions highlight areas where the paper could be improved, they lack actionable guidance or suggestions on how the authors might address these points. The comment does not provide any constructive feedback or advice on how to enhance the clarity or impact of the paper. As a result, the comment is somewhat helpful, as it identifies areas for improvement but does not offer detailed guidance for the authors to implement those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a claim that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their model. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to a specific comparison between the proposed model and the MSA Transformer in terms of r2. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the proposed model not being significantly better than the MSA Transformer in terms of r2. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a potential issue with the proposed model, suggesting that it is not significantly better than the MSA Transformer in terms of r2. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without additional context or guidance, the authors are left without a clear understanding of how to address this concern or enhance their model. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more mathematical details regarding the concept of an \"ensemble of independent measures on the full feature space\" and its relevance to the scaling of test error in wide DNNs. This feedback provides a clear and direct action for the authors to take, which is to include additional mathematical details to clarify the explanation. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"top of page 6,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the clarity of the explanation regarding the \"ensemble of independent measures on the full feature space\" and its relevance to the scaling of test error. This provides clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a statement regarding the \"ensemble of independent measures on the full feature space\" and its relevance to the scaling of test error in wide DNNs. The reviewer expresses a lack of understanding and requests more mathematical details. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the explanation is unclear. This makes the claim somewhat verifiable, as the authors would need to infer the exact points of confusion and seek additional information to address the feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more mathematical details. It highlights a lack of clarity regarding the concept of an \"ensemble of independent measures on the full feature space\" and its relevance to the scaling of test error in wide DNNs. By pointing out this gap, the comment offers a clear direction for the authors to enhance the clarity and depth of their explanation. However, it could be more helpful if it provided specific suggestions on how to elaborate on this concept or what additional details are needed. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the authors have attempted to use BlenderBot 2.0 with incorporated knowledge and suggests that using domain ontologies from the SGD dataset could improve dialog quality. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of BlenderBot 2.0 with incorporated knowledge and suggests the potential benefits of using domain ontologies from the SGD dataset for improving dialog quality. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to use domain ontologies, but without clear grounding, the authors may struggle to identify the exact section where this suggestion should be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of BlenderBot 2.0 with incorporated knowledge and suggests that using domain ontologies from the SGD dataset could improve dialog quality. While this is a relevant point, the comment lacks specificity and does not provide actionable guidance or suggestions for the authors to follow. It does not offer detailed feedback on how to implement this suggestion or why it would be beneficial, leaving the authors without clear direction on how to address the feedback. Therefore, the comment is barely helpful, as it identifies an area of potential interest but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. While the comment identifies a gap in the clarity of the paper, it does not provide explicit instructions on how to address this issue. The authors can infer that they need to clarify this aspect, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the overlap of samples, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. While the comment provides a logical assumption based on the calculation of Krippendorff $\\\\alpha$, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a reasonable inference but requires further elaboration or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. This feedback is somewhat helpful as it points out a potential area of confusion or lack of detail in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify this aspect. While it highlights an important point, the comment could be more helpful with additional context or actionable advice. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. While the comment highlights a potential area for improvement, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and lacks concrete guidance, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of the paper, particularly the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified regarding the overlap of samples, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. It assumes that the samples should overlap, as the paper calculates Krippendorff $\\\\alpha$. While the comment provides a logical assumption based on the calculation of Krippendorff $\\\\alpha$, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a reasonable inference but requires further elaboration or evidence to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates K"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, the comment does not explicitly instruct the authors to clarify these terms or provide specific guidance on how to address the confusion. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing consistency and accuracy, but this is not explicitly mentioned. The comment is specific in its request for clarification and provides a logical reasoning about the relationship between different types of consistency. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, the comment does not contain any claims or opinions that require verification. It is a request for clarification and an observation, not a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the distinction between arg-wise consistency and accuracy, suggesting that the authors clarify these terms. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement, which could be relevant to the paper\\'s discussion. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not provide detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are being provided, could enhance reproducibility. Additionally, it recommends sharing the code of the implementation, which is considered a significant step towards reproducibility. The comment explicitly states these actions, making them clear and concrete for the authors to follow. The suggestion to provide more details on position embeddings and the request for code are both direct and specific, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing the code of the implementation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these details might be discussed. The suggestion to provide more details and share the code is specific, as it outlines what needs to be addressed to improve reproducibility. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, could enhance reproducibility. It also recommends sharing the code of the implementation, which is considered a significant step towards reproducibility. While the comment provides a logical reasoning for the importance of these details, it lacks specific examples or references to support the claim. The suggestion to share the code is a common practice for reproducibility, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing the code of their implementation, which is a significant step towards ensuring reproducibility. This feedback is clear and specific, offering the authors concrete ways to improve their draft by addressing potential weaknesses in reproducibility. However, the comment could be more helpful if it included examples or detailed guidance on how to present the additional information or share the code. Overall, the comment is mostly helpful as it directs the authors toward specific improvements that can significantly enhance their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing the code of the implementation, which is considered a significant step towards reproducibility. The comment explicitly states these actions, making them clear and concrete for the authors to follow. The suggestion to provide more details on position embeddings and the request for code are both direct and specific, ensuring that the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing the code of the implementation, which is considered a significant step towards reproducibility. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these details might be discussed. The suggestion to provide more details and share the code is specific, as it outlines what needs to be addressed to improve reproducibility. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, could enhance reproducibility. It also recommends sharing the code of the implementation, which is considered a significant step towards reproducibility. While the comment provides a logical reasoning for the importance of these details, it lacks specific examples or references to support the claim. The suggestion to share the code is a common practice for reproducibility, but without detailed justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, to enhance reproducibility. It also recommends sharing"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the draft, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is explicit and provides a clear action for the authors to take, which is to identify and remove the repeated content. The comment is concrete, as it directly points out the problem and gives a specific area for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the presence of a repeated paragraph in the first paragraph of section 3.3. This provides clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. However, it does not provide any supporting evidence or reasoning to substantiate this claim. Without specific examples or references to the repeated content, the authors may find it challenging to identify and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and actionable, as it directly points out a redundancy that needs to be addressed. By highlighting this issue, the authors can take steps to improve the clarity and coherence of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to handle similar situations in the future. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data, which is generated on-the-fly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they could take to improve the sustainability and reusability of their synthetic data. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the sustainability and reusability of synthetic data generated on-the-fly. However, it does not specify which part of the paper this concern is related to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of sustainability and reusability are being questioned or how the authors might address these concerns. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data generated on-the-fly. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. The comment lacks specific examples or detailed explanation, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the sustainability and reusability of synthetic data generated on-the-fly. This is an important consideration for the authors, as it relates to the practicality and efficiency of their approach. However, the comment does not provide any specific suggestions or guidance on how the authors might address this concern or improve their methodology. While it highlights an important aspect for consideration, it lacks actionable feedback, making it somewhat helpful. The authors are given a direction to consider, but without detailed guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights two main issues: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should explore alternative RNA structures and incorporate RNA abundance into their dataset building process, but without specific instructions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to the challenge of RNA folding. It points out that the likelihood of alternative RNA structures is mostly dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses the ProbTransfomer model or the RNA folding challenge, making it weakly grounded. The comment is specific in identifying the need to examine biological circumstances and consider RNA abundance, but without clear grounding, the authors may struggle to pinpoint the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. It also suggests that authors should consider RNA abundance when building datasets. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about biological circumstances. The suggestion to consider RNA abundance is somewhat vague, as it does not provide detailed guidance on how to incorporate this factor into the dataset building process. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. This is a relevant observation that could enhance the paper\\'s analysis. Second, the comment suggests that authors should consider RNA abundance when building datasets, which is another important aspect to address. While the comment highlights these areas, it lacks specific guidance or suggestions on how the authors might incorporate these considerations into their work. The feedback is somewhat helpful as it provides some insight into potential weaknesses but does not offer detailed advice for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two areas for improvement: the lack of examination of alternative RNA structures arising from biological circumstances and the need to consider RNA abundance when building datasets. While the comment highlights these issues, it does not provide explicit guidance or suggestions on how the authors should address them. The authors are left to infer that they should explore alternative RNA structures and incorporate RNA abundance into their dataset building process, but without specific instructions or examples, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to the challenge of RNA folding. It points out that the likelihood of alternative RNA structures arising is mostly dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses the ProbTransfomer model or the RNA folding challenge, making it weakly grounded. The comment is specific in identifying areas for improvement but lacks clear grounding, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. It also suggests that authors should consider RNA abundance when building datasets. While the comment identifies relevant areas for improvement, it lacks specific examples or references to support the claim about biological circumstances. The suggestion to consider RNA abundance is somewhat vague, as it does not provide detailed guidance on how to incorporate this factor into the dataset building process. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. This is a relevant observation that could enhance the paper\\'s analysis. Second, the comment suggests that authors should consider RNA abundance when building datasets, which is another important aspect to address. While the comment highlights these areas, it lacks specific guidance or suggestions"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the numerical results, specifically noting that only a single entropic regularization coefficient (\\eta=1200) is considered. The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the method. The comment suggests that this issue should be acknowledged in the paper and not overlooked. While the action is implicit, it is clear that the authors need to address this concern by either explaining the choice of the regularization coefficient or acknowledging its potential impact on the results. The comment provides a clear direction for improvement, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the choice of a single entropic regularization coefficient (\\eta=1200) and suggests that this may be a weak term leading to sparse couplings. The comment further advises acknowledging this in the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the numerical results, specifically noting the use of a single entropic regularization coefficient (\\eta=1200). The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the method. The comment suggests that this issue should be acknowledged in the paper. While the claim is based on logical reasoning and a potential observation, it lacks specific examples or references to substantiate the claim fully. This makes the comment somewhat verifiable, as it provides a basis for the concern but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the numerical results, specifically noting the use of a single entropic regularization coefficient (\\eta=1200). The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the method. The comment suggests that this issue should be acknowledged in the paper and not overlooked. While the feedback highlights an important consideration, it lacks specific guidance or suggestions on how the authors might address this concern or present their results more robustly. The comment provides a direction for improvement but could be more helpful with additional details or examples. Therefore, it is rated as somewhat helpful, as it offers insight but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the numerical results, specifically noting the use of a single entropic regularization coefficient (\\eta=1200). The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the method. The comment suggests that this issue should be acknowledged in the paper and not overlooked. While the action is implicit, it provides a clear direction for the authors to address this concern by either explaining the choice of the regularization coefficient or acknowledging its potential impact on the results. The feedback is mostly actionable, as it guides the authors to consider and address the issue in their paper.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the choice of a single entropic regularization coefficient (\\eta=1200) and suggests that this coefficient may be weak, leading to sparse couplings that favor the method. The comment further advises acknowledging this in the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the numerical results, specifically noting the use of a single entropic regularization coefficient (\\eta=1200). The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the method. The comment suggests that this issue should be acknowledged in the paper and not overlooked. While the claim is based on logical reasoning and a potential observation, it lacks specific examples or references to substantiate the claim fully. This makes the comment somewhat verifiable, as it provides a basis for the concern but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the numerical results, specifically noting the use of a single entropic regularization coefficient (\\eta=1200). The reviewer suspects that this coefficient is weak and may lead to sparse couplings, which could be favorable to the"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the statement in Table 1 that the Vlachos and Riedel 2014 dataset has no Evidence, and the paper\\'s claim that the dataset includes sources used by the journalists. This comment implies that the authors should clarify or correct the information in Table 1 to accurately reflect the content of the dataset. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy, but they are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the statement in Table 1 that the Vlachos and Riedel 2014 dataset has no Evidence, and the paper\\'s claim that the dataset includes sources used by the journalists. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no Evidence, and the paper\\'s statement that the dataset includes sources used by the journalists. This discrepancy is supported by the paper\\'s claim that it includes sources such as tables with statistics and reports from governments, think tanks, and other organizations. The comment provides a clear and specific example of a contradiction, which is verifiable through the information presented in the paper. However, it could be strengthened by providing additional context or references to the specific sources mentioned in the paper. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the information presented in Table 1 and the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table claims the dataset has no Evidence, while the paper states that it includes sources used by the journalists. This feedback is somewhat helpful as it highlights a potential inconsistency that the authors need to address. However, the comment does not provide specific guidance on how to resolve the discrepancy or suggest ways to clarify the information in the table. To be more helpful, the comment could include suggestions on how to reconcile the information or provide additional context to support the claim. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy between the information presented in Table 1 and the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the table claims the dataset has no Evidence, while the paper states that it includes sources used by the journalists. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or clarify the information in the table. The action is implicit and lacks concrete details, making it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the claim in Table 1 that the Vlachos and Riedel 2014 dataset has no Evidence, and the paper\\'s claim that the dataset includes sources used by the journalists. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between the information presented in Table 1 and the paper regarding the Vlachos and Riedel 2014 dataset. It claims that the dataset has no Evidence, while the paper states that it includes sources used by the journalists. This discrepancy is supported by the paper\\'s claim that the dataset includes sources such as tables with statistics and reports from governments, think tanks, and other organizations, which are available online. The comment provides a clear and specific example of a contradiction, which is verifiable through the information presented in the paper. However, it could be strengthened by providing additional context or references to the specific sources mentioned in the paper. Therefore, the comment is mostly verifiable, aligning with a score"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include details about the parameters used in each simulator, such as whether they used the GPU pipeline in IsaacGym, the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This feedback provides a clear and direct action for the authors to take, specifying exactly what information needs to be added to improve the transparency and reproducibility of their work. The comment is explicit and concrete, offering a straightforward path for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to include details about the parameters for each simulator, such as the GPU pipeline in IsaacGym or the CPU pipeline, the substeps for physics simulation, and the number of total vertices in the simulation. This provides clear guidance on where the authors should focus their attention to improve their draft. The comment is also specific, as it clearly specifies what information is missing and how it can be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that different simulators have varying parameters that can significantly impact performance. It requests the inclusion of specific details about the parameters used in each simulator, such as the GPU pipeline, CPU pipeline, substeps for physics simulation, and the number of total vertices. While the comment highlights the importance of providing these details, it does not provide specific examples or references to support the claim that these details are crucial. The suggestion is logical and reasonable, but without additional justification or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more detailed information about the parameters used in different simulators. It suggests including details such as the GPU pipeline, CPU pipeline, substeps for physics simulation, and the number of total vertices in the simulation. This feedback is clear and actionable, as it directly guides the authors on what additional information is needed to enhance the transparency and reproducibility of their work. By addressing this suggestion, the authors can significantly improve the clarity and utility of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the hyperparameters $s$ and $k$ in the proposed method and criticizes the empirical selection of these values in the supplementary material. It suggests that the authors should provide a more detailed explanation or justification for their choice of $s$ and $k$. While the comment implies that the authors should offer a more thorough discussion or analysis of these hyperparameters, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know they need to provide additional information about the hyperparameters. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the empirical selection of hyperparameters $s$ and $k$, explaining how this affects the generalizability of the proposed loss function. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the empirical selection of hyperparameters $s$ and $k$ reduces the generalizability of the proposed loss function. The reviewer provides a logical reasoning by explaining that the choice of these hyperparameters is crucial for the effectiveness of the method and that the empirical selection based on cross-validation may limit the generalizability. However, the comment lacks specific examples or references to support the claim about the impact of the hyperparameters on generalizability. This makes the claim somewhat verifiable, as it provides a reasonable basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, specifically the empirical selection of hyperparameters $s$ and $k$ in the sparse-CL and k-NL masks. It highlights that the choice of these parameters is crucial for the effectiveness of the method and that the empirical selection may limit the generalizability of the proposed loss function. The comment provides a clear and actionable suggestion for improvement by recommending that the authors provide a more detailed explanation or justification for their choice of $s$ and $k$. This feedback is valuable as it guides the authors to enhance the transparency and robustness of their method, making the comment mostly helpful. However, it could be further improved by offering specific suggestions on how to address the issue or by providing examples of alternative approaches. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. While the action is explicit, it lacks concrete guidance on how to conduct this comparison or what specific aspects to focus on. The authors are given a clear direction but are left to determine the exact steps and metrics to use for the comparison. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner\" and the specific technique used by the authors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with OpenTuner to evaluate the optimization times and the adaptability of different search techniques. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. The claim is somewhat verifiable as it provides a logical reasoning for the comparison, suggesting that such a comparison could reveal the effectiveness of the authors\\' method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore and justify the comparison themselves, which limits the thoroughness of the justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the authors only use simulated annealing in OpenTuner, which uses a list of search techniques and an AUC meta technique to select the best search technique. The reviewer suggests that the authors should compare the optimization times of their method with OpenTuner, which can adaptively use different search techniques. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by conducting a comparative analysis. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work lacks novelty, as diffusion models have been introduced into the anomaly detection area by other works. It also mentions that the paper only makes minor adjustments to NCSN and combines popular techniques like time step embedding and anomaly score correspondence. However, the comment does not provide specific guidance or suggestions on how the authors could enhance the novelty or originality of their work. It lacks actionable details, such as recommending alternative approaches or specific improvements to consider. As a result, the authors are left without a clear understanding of how to address the feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, mentioning that there are existing works that have introduced diffusion models into the anomaly detection area. It also notes that the paper only makes minor adjustments to NCSN and combines popular techniques like time step embedding and anomaly score correspondence. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction or methodology sections. This lack of explicit reference makes it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while the comment provides some context on existing works and the adjustments made, it does not offer specific guidance on how to enhance the novelty or originality of the work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work lacks novelty due to the introduction of diffusion models into the anomaly detection area, referencing specific works. It also notes that the paper only makes minor adjustments to NCSN and combines popular techniques. While the comment provides some references to existing works, it lacks detailed justification or specific examples of how the adjustments are minor or how they relate to existing literature. This makes the claim somewhat verifiable, as it provides a general direction but lacks comprehensive evidence or detailed reasoning to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of novelty in the work, noting that diffusion models have been introduced into the anomaly detection area by other works. It also points out that the paper only makes minor adjustments to NCSN and combines popular techniques like time step embedding and anomaly score correspondence. However, the comment lacks specific suggestions or guidance on how the authors could enhance the novelty or originality of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: grammar errors and the lack of labeled axes in Figure 2. While the comment identifies these issues, it does not provide explicit guidance on how to correct them. The authors can infer that they need to address the grammar errors and label the axes in Figure 2, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: grammar errors and the lack of labeled axes in Figure 2. However, it does not specify which sections of the paper contain the grammar errors, making it weakly grounded. The comment is specific about the issues it identifies, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of factual observations about grammar errors and the lack of labeled axes in Figure 2. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: grammar errors and the lack of labeled axes in Figure 2. By pointing out these issues, the reviewer provides clear and actionable feedback that can help the authors improve the clarity and professionalism of their manuscript. However, the comment could be more helpful if it offered suggestions on how to correct the grammar errors or provided guidance on labeling the axes in Figure 2. Overall, the feedback is somewhat helpful as it highlights areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis in Section 5.2 is inadequate and suggests that more quantitative error analysis would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to conduct more quantitative error analysis. The comment is specific in its suggestion, making it highly actionable. The authors know exactly what needs to be done to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the error analysis, suggesting that more quantitative error analysis would be beneficial. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in Section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the current analysis is inadequate. Without these details, the authors may find it challenging to understand the basis of the critique and how to improve their analysis. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks the necessary evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in Section 5.2, noting that it is inadequate and suggesting that more quantitative error analysis would be beneficial. This feedback is clear and actionable, providing the authors with a concrete direction for improvement. By highlighting the need for more quantitative analysis, the comment helps the authors understand where their draft can be strengthened. However, it could be more helpful if it offered specific suggestions on how to conduct this quantitative analysis or what aspects should be focused on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that they should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between distributions. Additionally, it points out a potential issue with Fig. 6c and 6d, suggesting that the authors should cross-check if the Proxy-A distance is close. These actions are clear and provide concrete guidance on how the authors can improve their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance. Additionally, it points out a potential issue with the figures, asking the authors to cross-check if the Proxy-A distance is close. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that relying solely on t-SNE for evaluating distribution alignment is not sufficient and recommends measuring the Proxy-A distance as well. This claim is somewhat verifiable as it provides a logical reasoning for considering additional metrics, but it lacks specific references or examples to fully substantiate the claim. The suggestion to cross-check Fig. 6c and 6d is a specific point, but it does not provide detailed reasoning or evidence for why these figures might be problematic. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance as well. This is a clear and constructive suggestion that can help the authors improve their analysis. Additionally, the comment points out a potential issue with Fig. 6c and 6d, suggesting that they might be identical and recommending cross-checking to ensure accuracy. This feedback is valuable as it guides the authors toward a more comprehensive evaluation of their results and highlights a potential error in their figures. Overall, the comment is mostly helpful, as it provides clear guidance on how to enhance the analysis and improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While the comment implies that the authors should provide an explanation or discuss these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the rationale behind using cross entropy for the first (P \u00e2\u0080\u0093 floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While it identifies areas where the authors might need to provide more explanation or justification, it does not offer specific suggestions or guidance on how to address these questions. The comment highlights potential weaknesses in the paper but lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are given some insight into areas that need clarification but are not provided with a clear path to improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper did not discuss these works in the related work section. However, it does not provide explicit guidance on how the authors should address this omission. The comment implies that the authors should include these references in their related work section, but it does not specify how to integrate them or what additional context should be provided. The action is implicit and somewhat vague, as the authors need to infer that they should add these references but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the validation of the proposed cross-modality adaptation in BEVDepth and 2DPASS, but it does not specify which part of the paper this observation pertains to. The authors might infer that it relates to the related work section, but this inference is not explicit. The comment is specific in identifying the validation in BEVDepth and 2DPASS, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper did not discuss these works in the related work section. However, the comment does not provide specific references or examples of how these works are relevant or how they should be integrated into the related work section. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential oversight in the paper, specifically the validation of the proposed cross-modality adaptation in BEVDepth and 2DPASS, which were not discussed in the related work section. This feedback is somewhat helpful as it identifies a gap in the paper\\'s literature review that could be addressed to strengthen the context and relevance of the proposed method. However, the comment lacks specific guidance on how the authors should integrate these references or what additional context should be provided. To be more helpful, the comment could suggest how the authors might incorporate these references into their related work section or provide more detailed feedback on how to enhance the literature review. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but these works are not discussed in the related work section. While the comment identifies a potential oversight, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include these references in their related work section, but the comment lacks specific instructions on how to integrate them or what additional context should be provided. Therefore, the comment is somewhat actionable, as it suggests an action but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the validation of the proposed cross-modality adaptation in BEVDepth and 2DPASS, but it does not specify which part of the paper this observation pertains to. The authors might infer that it relates to the related work section, but this inference is not explicit. The comment is specific in identifying the validation in BEVDepth and 2DPASS, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper did not discuss these works in the related work section. However, the comment does not provide specific references or examples of how these works are relevant or how they should be integrated into the related work section. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper, specifically the validation of the proposed cross-modality adaptation in BEVDepth and 2DPASS, which were not discussed in the related work section. This feedback is somewhat helpful as it points out a gap in the literature review that could be addressed to strengthen the context and relevance of the proposed method. However"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Table 1 only presents test loss as a metric for performance degradation and lacks generation results like BLEU scores to assess the quality of output. This feedback implies that the authors should include generation results in their table to provide a more comprehensive evaluation of their model\\'s performance. While the action is explicit, it is somewhat vague because it does not specify which generation results should be included or how they should be presented. The authors know they need to add generation results, but the comment could be more detailed in guiding them on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of generation results like BLEU scores to assess the quality of output. This provides clear guidance on what the authors need to add to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including generation results like BLEU scores to assess the quality of output. This is a factual observation rather than a claim or suggestion that requires verification. It is a descriptive statement about the content of the table, not an opinion or judgment. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only includes test loss as a metric for performance degradation without providing generation results like BLEU scores to assess the quality of output. This feedback is clear and actionable, as it directs the authors to include additional metrics that would enhance the comprehensiveness and accuracy of their evaluation. By highlighting this omission, the comment provides a concrete step for the authors to take to improve their draft, making it mostly helpful. However, it could be more helpful if it suggested how to integrate these additional metrics or provided examples of how they might be presented. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments to validate their analysis, particularly for discussions on different regimes. While the action is implied, it is clear that the authors need to conduct additional experiments to support their theoretical findings. The comment provides a specific area for improvement, but it does not offer detailed guidance on how to design or execute these experiments. Therefore, the action is explicit but somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate the analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to support the analysis, but without explicit references to sections or parts of the paper, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments would validate the analysis, particularly for discussions on different regimes. However, it does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the importance of the experiments themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including experiments would validate the analysis, particularly for discussions on different regimes. While this feedback highlights an area where the paper could be strengthened, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific aspects should be focused on. The comment is somewhat helpful as it identifies a potential improvement but does not offer actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that including experiments would validate the analysis, particularly for discussions on different regimes. While the action is implied, it is clear that the authors need to conduct additional experiments to support their theoretical findings. However, the comment does not provide specific guidance on how to design or execute these experiments, leaving the authors with a general idea of what needs to be done but without detailed instructions. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate the analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for experiments to support the analysis, but without explicit references to sections or parts of the paper, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including experiments would validate the analysis, particularly for discussions on different regimes. However, it does not provide specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the importance of the experiments themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including experiments would validate the analysis, particularly for discussions on different regimes. While this feedback highlights an area where the paper could be strengthened, it lacks specificity and does not provide detailed guidance on how to conduct these experiments or what specific aspects should be focused on. The comment identifies a potential improvement but does not offer actionable steps for the authors to take, making it somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that including experiments would validate the analysis, particularly for discussions on different regimes. While the action is implied, it is clear that the authors need to conduct additional experiments to support their theoretical findings. However, the comment does not provide specific guidance on how to design or execute these experiments, leaving the authors with a general idea of what needs to be done but without detailed instructions. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks concrete details on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including experiments to validate"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks detailed guidance on how to implement the suggestion or what specific insights these baselines might offer. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in its suggestion to include two naive baselines, but without clear grounding, it is challenging for the authors to pinpoint where to make these additions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not provide any justification or reasoning for why these specific baselines would be beneficial or how they would contribute to the understanding of the benchmark. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. This feedback is somewhat helpful as it offers a specific suggestion for improving the experimental setup by adding additional baselines. However, the comment lacks depth and does not explain why these specific baselines would be beneficial or how they would enhance the understanding of the benchmark. To be more helpful, the comment could provide more context or reasoning about why these baselines are important or how they might contribute to the analysis. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the preliminaries, noting that the description of advantage-weighted regression lacks a key piece: the Q function is w.r.t. \\\\mu, which is crucial for understanding the constrained optimization in Eq. 4. While the comment highlights a specific area that needs clarification, it does not provide explicit instructions on how to address this issue. The authors can infer that they need to clarify the description of advantage-weighted regression, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"preliminaries\" and the specific equation (Eq. 4), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the description of advantage-weighted regression, particularly the clarification that the Q function is w.r.t. \\\\mu, which is crucial for understanding the constrained optimization in Eq. 4. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of advantage-weighted regression is unclear, specifically noting that it lacks a key piece: the Q function is w.r.t. \\\\mu, which is essential for understanding the constrained optimization in Eq. 4. While the comment identifies a specific area of confusion, it does not provide detailed reasoning or examples to support why this omission is critical. The lack of explicit justification or references makes the claim somewhat verifiable, as the authors would need to infer the importance of the missing piece themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper regarding the description of advantage-weighted regression. It points out that the Q function is missing a crucial piece, namely its dependence on \\\\mu, which is essential for understanding the constrained optimization in Eq. 4. This feedback is clear and actionable, as it directs the authors to clarify this aspect of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to improve the clarity of this explanation. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method has multiple stages, which makes it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the algorithm. There is no guidance on potential modifications, alternative approaches, or specific steps to simplify the algorithm. As a result, the authors are left without any actionable information on how to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm and its complexity compared to existing pruning methods. However, it does not specify which part of the paper discusses the algorithm or where the issue of multiple stages is elaborated. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in pointing out the issue of complexity, it is not grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to having multiple stages, while many existing pruning methods do not require fine-tuning. However, the comment lacks specific examples or references to existing pruning methods that do not require fine-tuning, making it difficult for the authors to understand the basis of the claim. Without detailed comparisons or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the proposed method, noting that while each part is effective, the overall algorithm is cumbersome due to having multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment does not provide specific suggestions or guidance on how the authors might simplify the algorithm or address the issue of multiple stages. While it identifies a potential weakness, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are given some insight into the problem but are left without clear steps to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method has multiple stages, which makes it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or simplify the algorithm. There is no guidance on potential modifications, alternative approaches, or specific steps to improve the draft. As a result, the authors are left without any actionable information on how to enhance their work. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method, noting that it has multiple stages compared to existing pruning methods that do not require fine-tuning. However, it does not specify which part of the paper discusses the algorithm or where the issue of multiple stages is elaborated. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in pointing out the issue of complexity, it is not grounded because it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the proposed method is cumbersome due to having multiple stages, while many existing pruning methods do not require fine-tuning. However, the comment lacks specific examples or references to existing pruning methods that do not require fine-tuning, making it difficult for the authors to understand the basis of the claim. Without detailed comparisons or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that while each part is effective, the overall algorithm is cumbersome due to having multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or simplify the algorithm. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given some insight into the problem but are left without clear steps to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the justification for the advantage of the new quantile function (3) over the existing function (2). It points out that the changes made to the multiplicative factors affect the sensitivity to tail parameters and questions the desirability of reduced sensitivity. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or present supporting data. The action is implicit and vague, as the authors are left to infer that they need to provide supporting data or clarify the advantages of the new function. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the quantile function (3) and compares it to the existing function (2), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the new quantile function, namely that the changes made to the multiplicative factors affect the sensitivity to tail parameters and questions the desirability of reduced sensitivity. The comment provides a clear rationale for the concern, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is not justified. It provides a specific observation that the new function changes the multiplicative factors into an additive term, which affects the sensitivity to tail parameters. However, the comment lacks supporting data or evidence to substantiate why this change is desirable or how it improves the function. The claim is somewhat verifiable as it highlights a potential issue but requires additional explanation or data to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the new quantile function (3) compared to the existing function (2), specifically noting that the changes made to the multiplicative factors affect the sensitivity to tail parameters. However, it lacks depth and does not provide any supporting data or reasoning to justify why the reduced sensitivity is desirable or how it impacts the overall function. The comment highlights a concern but does not offer actionable feedback or suggestions for improvement, such as how the authors might address this issue or present supporting data. As a result, the comment is barely helpful, as it points out a potential weakness but does not provide the authors with a clear path to improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out a potential issue with the new quantile function (3) compared to the existing function (2), specifically noting that the changes made to the multiplicative factors affect the sensitivity to tail parameters. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or present supporting data. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to provide supporting data or clarify the advantages of the new function, but without specific instructions, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the quantile function (3) and compares it to the existing function (2), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the new quantile function, namely that the changes made to the multiplicative factors affect the sensitivity to tail parameters and questions the desirability of reduced sensitivity. The comment provides a clear rationale for the concern, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is not justified. It highlights that the changes made to the multiplicative factors affect the sensitivity to tail parameters and questions the desirability of reduced sensitivity. However, the comment lacks supporting data or evidence to substantiate why this change is desirable or how it improves the function. The claim is somewhat verifiable as it points out a potential issue but requires additional explanation or data to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the new quantile function (3) compared to the existing function (2), specifically noting that the changes made to the multiplicative factors affect the sensitivity to tail parameters. However, it lacks depth and does not provide any supporting data or reasoning to justify why the reduced sensitivity is desirable or how it impacts the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 3 is confusing and suggests improving it. It also critiques the contribution over SWE-Bench, stating that the contribution is low due to the authors\\' claim of new additions in testing fault localization and LLM\\'s capability of discovering issues. The reviewer provides specific reasoning, explaining that if a model can fix a bug, it inherently tests fault localization capabilities, and that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. This feedback is explicit and provides concrete reasoning for the authors to consider revising their claims and potentially improving the clarity of their contribution. However, it does not specify how to improve Figure 3 or provide detailed guidance on how to address the contribution issue. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks specific instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the confusion in Figure 3 and critiques the contribution over SWE-Bench, explaining the reasoning behind the claim that the contribution is low. The comment further elaborates on the issues with the authors\\' claims regarding fault localization and LLM capabilities, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the contribution of the paper, specifically regarding Figure 3 and the contribution over SWE-Bench. The reviewer provides logical reasoning to support their claim, explaining that if a model can fix a bug, it inherently tests fault localization capabilities, and that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. This reasoning is clear and well-supported, providing a strong foundation for the claim. However, the comment could be strengthened by referencing specific examples or studies that support the argument, which would make it fully verifiable. Therefore, the comment is categorized as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, suggesting that it is confusing and recommending improvement. It also critiques the contribution over SWE-Bench, pointing out that the contribution is low due to the authors\\' claim of new additions in testing fault localization and LLM\\'s capability of discovering issues itself. The reviewer provides a logical explanation, highlighting that if a model can fix a bug, it inherently tests fault localization capabilities, and that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. This feedback is clear and actionable, offering the authors a concrete direction for revising their claims and improving the clarity of their contribution. However, it could be more helpful if it included specific suggestions on how to improve Figure 3 or provide additional context for the critique. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some key descriptions are missing, specifically regarding the selection of topics for complementary attributes in topic control experiments. It provides a clear and explicit action for the authors to take by asking them to provide more details on how to select these topics. The comment is specific in its request, leaving no ambiguity about what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the missing descriptions in the topic control experiments. It explicitly mentions the need to clarify how topics are selected to constitute complementary attributes, providing a clear direction for the authors to address. This makes the comment fully grounded, as it directly references a specific part of the paper that needs attention. The comment is also specific, as it clearly identifies the missing information and the need for clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about missing descriptions in the topic control experiments, specifically questioning how topics are selected to constitute complementary attributes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that these descriptions are missing. Without additional context or justification, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the missing descriptions regarding the selection of topics for complementary attributes in topic control experiments. By pointing out this omission, the reviewer provides a clear and actionable suggestion for improvement. The comment is specific and offers a direct question that the authors can address to enhance the clarity and comprehensiveness of their work. This feedback is valuable as it guides the authors toward a specific area needing clarification, making it mostly helpful. However, it could be more helpful if it included additional guidance or examples on how to provide these descriptions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of convincing evidence for the general applicability of the system identification method to improve sim-to-real policy deployment, given that the real-world manipulation only contains a single case. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. There is no guidance on what additional experiments, analyses, or comparisons could be conducted to strengthen the argument. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the real-world manipulation containing only a single case, which raises concerns about the general applicability of the system identification method for sim-to-real policy deployment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the limited real-world cases and the need for convincing evidence of the method\\'s general applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited number of real-world cases used to test the system identification method, questioning its general applicability for sim-to-real policy deployment. However, the comment does not provide specific examples or references to support this claim, nor does it offer detailed reasoning or evidence to substantiate the concern. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the limited number of real-world cases used to test the system identification method, questioning its general applicability for sim-to-real policy deployment. This feedback highlights a potential weakness in the paper, which is important for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might strengthen their argument or provide more convincing evidence. While it identifies an area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the ShortcutQA and questions whether the edits might introduce ambiguity, leading to performance degradation. It suggests providing details on how \"answerable\" the distracted texts are and requests examples and qualitative results. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so. The action is concrete, as it specifies what information is needed, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the quality of the ShortcutQA and questions whether the edits might introduce ambiguity, leading to performance degradation. The comment further requests details on how \"answerable\" the distracted texts are and asks for examples and qualitative results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the quality of the ShortcutQA, questioning whether the edits might introduce ambiguity, leading to performance degradation. The reviewer provides a logical reasoning by pointing out the manual verification of semantics but acknowledges the potential for ambiguity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide more detailed information to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the quality of the ShortcutQA, questioning whether the edits might introduce ambiguity, despite the manual verification of semantics. It suggests providing details on how \"answerable\" the distracted texts are and requests examples and qualitative results to support the claim. This feedback is clear and actionable, as it prompts the authors to address a potential weakness in their methodology and provides specific guidance on how to improve the transparency and robustness of their findings. However, the comment could be more helpful if it offered suggestions on how to quantify or measure the ambiguity introduced by the edits. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" This is an explicit suggestion that the authors can follow to improve the clarity of their draft. However, it does not provide specific guidance on where or how to include this pointer, leaving some ambiguity in how to implement the action. The action is concrete but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 41,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a forward pointer to the definition of \"deep.\" This provides clear guidance on what the authors need to do to improve the clarity of their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The comment suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning or evidence to support why this would improve clarity or what specific issues the current text has. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" This is a specific and actionable suggestion that can help the authors improve the clarity of their draft by providing a reference to the definition of a key term. However, the comment does not provide additional context or explanation about why this would improve the clarity or what specific issues the current text has. While it offers a clear direction for improvement, it lacks depth and could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a practical concern about the number of archetypes (k) and suggests that the authors should explore whether their framework allows for model selection to identify an appropriate k. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to perform the model selection. The action is implicit and somewhat vague, as the authors need to infer that they should explore model selection and identify an appropriate k. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific question about the number of archetypes (k) and suggests exploring whether the presented framework allows for model selection to identify an appropriate k. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this issue might be discussed. While the authors might infer that it relates to the methodology or results sections, the comment lacks explicit grounding. It is specific in its inquiry about model selection and the identification of k, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for clarification or an inquiry about the methodology used in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual question seeking information, so it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a practical concern about the number of archetypes (k) and suggests that the authors should explore whether their framework allows for model selection to identify an appropriate k. This feedback is somewhat helpful as it identifies a potential area for improvement in the methodology section, prompting the authors to consider model selection as a means to determine the optimal number of archetypes. However, the comment lacks specific guidance or suggestions on how to implement model selection or what aspects of the framework might need to be adjusted to accommodate this approach. To be more helpful, the comment could provide examples of model selection techniques or suggest specific steps to consider. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for the location of Theorem 1 and notes that it is missing at the beginning of page 6, where Theorem 2 is present. It also suggests keeping the counting between Assumptions, Lemmas, and Theorems separate. This feedback provides clear and explicit actions for the authors to take, such as locating and inserting Theorem 1 and ensuring proper separation of the counting. The instructions are concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Theorem 1 and suggesting that the counting between Assumptions, Lemmas, and Theorems should be kept separate. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the presence or absence of specific elements in the paper, such as Theorem 1 and the separation of counting between Assumptions, Lemmas, and Theorems. These are objective observations that do not require verification or evidence. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the absence of Theorem 1, which is mentioned at the beginning of page 6. It also suggests that the counting between Assumptions, Lemmas, and Theorems should be kept separate. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. However, the comment could be more helpful if it explained why the separation of counting is important or provided additional guidance on how to implement this suggestion. Despite this, the comment is mostly helpful as it directs the authors to a critical oversight and offers a straightforward way to improve their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or whether they should consider revising their assumptions. Without specific suggestions or actions, the authors are left without direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors might infer that it relates to the methodology or experimental setup, but this is not explicitly stated. The comment is specific in detailing the concern about the assumption\\'s generalizability, providing a clear direction for the authors to consider. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. The reviewer questions whether this assumption generalizes to long document summarization. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors might find it challenging to address the concern without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires further elaboration to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this concern or explore the generalizability of their assumption. Without actionable feedback or detailed advice, the authors are left with a general idea of what to consider but without clear steps to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or explore the generalizability of their assumption. Without specific actions or detailed feedback, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors might infer that it relates to the methodology or experimental setup, but this is not explicitly stated. The comment is specific in detailing the concern about the assumption\\'s generalizability, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors might find it challenging to address the concern without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires further elaboration to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is straightforward and lacks significant novelty, and it raises a question about the clarity of certain parts, specifically mentioning line 180. However, it does not provide explicit guidance on how the authors should address these issues or improve the clarity of the method. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Since the feedback is vague and does not offer a clear path for improvement, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 180,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the method, particularly regarding how multiple different graphs can be obtained and the potential impact of learning different weights for edges. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is straightforward and lacks significant novelty, and it questions the clarity of certain parts, such as how multiple different graphs can be obtained. However, the comment does not provide specific examples or detailed reasoning to support these claims. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a perceived lack of novelty in the proposed method and questions the clarity of certain parts, specifically mentioning line 180. However, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their method. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are limited in scope and suggests that the authors should include an example of learning the geometry of a more complicated manifold. While the comment implies that the authors should expand their experiments to include a more complex scenario, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experiments to include a more challenging manifold. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the scope of the experiments, specifically mentioning the limited number of simulations and the lack of examples of learning geometry on more complex manifolds. It provides specific details about the current experiments, such as the unit sphere and spiral curves, and suggests an additional example involving a more complicated manifold. However, it does not explicitly mention which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in detailing what is missing or could be improved, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited in scope, specifically mentioning the use of a unit sphere and spiral curves as examples. The reviewer suggests that including an example of learning geometry on a more complicated manifold would be beneficial. While the comment provides a logical reasoning for expanding the experiments, it lacks specific examples or references to support the claim that a more complex manifold would be more instructive. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that the current experiments are limited to a unit sphere and spiral curves. It suggests that including an example of learning geometry on a more complicated manifold would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and enhance the comprehensiveness of their study. However, the comment could be more helpful if it offered additional guidance on how to approach the inclusion of a more complex manifold or provided examples of such experiments. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a weakness in the paper, stating that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the naturalness of the template or suggestions for utilizing the LLM's abilities more effectively. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the current knowledge relying on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this issue might be addressed, the comment lacks full grounding. It is specific in identifying the weakness but not grounded in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific weakness in the paper, noting that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). This feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable suggestions. The authors are informed of a potential issue but are not provided with guidance on how to address it or improve the naturalness of the template. Therefore, the comment is rated as somewhat helpful, as it points out a problem but does not offer detailed advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of baselines is small, which affects the universality and generality of the work. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as recommending the inclusion of additional baselines or explaining how the current number of baselines impacts the study. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of a small number of baselines, which affects the universality and generality of the work. However, it does not specify which part of the paper discusses the baselines or where the authors should add more baselines. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in identifying the issue of universality and generality, it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines is small, which affects the universality and generality of the work. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, it is difficult for the authors to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the number of baselines used in the study, suggesting that it may limit the universality and generality of the findings. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue, such as recommending additional baselines or explaining how the current number of baselines affects the study. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of information regarding the tokenizer training, specifically mentioning the absence of details about the mixture of corpus size used and the software stack. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include this information, but it does not specify how to do so or what specific details should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of information regarding the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what is missing, namely the mixture of corpus size and software stack, which provides clear guidance for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks specific examples or detailed reasoning to justify why this information is crucial or how its absence impacts the paper. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification for the authors to understand the significance of the missing information. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the lack of information about the tokenizer training, specifically mentioning the absence of details about the mixture of corpus size used and the software stack. This is a relevant point that could impact the reproducibility and understanding of the experimental setup. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific information should be included. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical omission but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out the absence of information regarding the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include this information, but it lacks specific instructions or suggestions on what details should be included or how to present them. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of information about the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what is missing, namely the mixture of corpus size and software stack, which provides clear guidance for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training, specifically mentioning the lack of details about the mixture of corpus size used and the software stack. However, it does not provide any supporting evidence or references to substantiate this claim. The comment lacks specific examples or detailed reasoning to justify why this information is crucial or how its absence impacts the paper. As a result, the claim is unverifiable, as it does not provide sufficient evidence or justification for the authors to understand the significance of the missing information. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper regarding the lack of information about the tokenizer training, specifically mentioning the absence of details about the mixture of corpus size used and the software stack. This is an important point that could impact the reproducibility and understanding of the experimental setup. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific information should be included. While it highlights a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant area for improvement but does not offer detailed"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the additional complexity is warranted and suggests that the authors should address this question. While the comment implies that the authors should provide a justification for the complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the necessity of the additional steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"positive mining framework\" and references \"[A] - Audio-Visual Instance Discrimination with Cross-Modal Agreement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the additional complexity of the proposed method is warranted and highlights the need for a clearer explanation of the contributions over prior work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It references \"[A] - Audio-Visual Instance Discrimination with Cross-Modal Agreement\" as a potential comparison, which provides some context for the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim that the additional complexity is not warranted. While the reference to \"[A]\" is a step towards verification, the lack of detailed justification or comparison makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, questioning whether the additional complexity of the positive mining framework is warranted compared to a simpler multi-view contrastive objective. It highlights the need for a clearer explanation of the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. By pointing out this lack of clarity, the comment provides actionable feedback that can help the authors refine their paper to better justify and explain their methodological choices. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how to clarify the necessity of these steps. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the additional complexity is warranted and suggests that the authors should address this question. While the comment implies that the authors should provide a justification for the complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the necessity of the additional steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"positive mining framework\" and references \"[A] - Audio-Visual Instance Discrimination with Cross-Modal Agreement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the additional complexity of the proposed method is warranted and highlights the need for a clearer explanation of the contributions over prior work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It references \"[A] - Audio-Visual Instance Discrimination with Cross-Modal Agreement\" as a potential comparison, which provides some context for the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim that the additional complexity is not warranted. While the reference to \"[A]\" is a step towards verification, the lack of detailed justification or comparison makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the proposed method, questioning whether the additional complexity of the positive mining framework is warranted compared to a simpler multi-view contrastive objective. It highlights the need for a clearer explanation of the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. By pointing out this lack of clarity, the comment provides actionable"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the computational cost of the multi-marginal OT and spline calculations, which may limit the scalability of the approach for large datasets. It suggests that a more comprehensive discussion is needed to address this issue. While the comment implies that the authors should provide a detailed discussion on computational complexity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to address the issue or what aspects of the discussion should be expanded. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational cost of multi-marginal OT and spline calculations, suggesting that this may limit the scalability of the approach for large datasets. However, it does not specify which part of the paper discusses these computational aspects, making it weakly grounded. The comment is specific in identifying the issue of scalability and the need for a more comprehensive discussion, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the computational complexity of multi-marginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for real-world applications. The comment suggests that a more comprehensive discussion is needed to address this issue. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the computational complexity or the potential limitations. This makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the approach regarding computational cost, specifically the scalability of the multi-marginal OT and spline calculations for large datasets. It suggests that a more comprehensive discussion is needed to address this issue, which is a valuable insight for the authors. However, the comment lacks specific guidance or suggestions on how to improve the discussion or address the scalability concerns. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point challenges the authors\\' claim that non-uniform label noise is not too common in practice by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. It provides a concrete example of real-world noise datasets where non-uniform label noise exists, which supports the claim. However, the comment does not explicitly instruct the authors to address this issue or suggest how they might incorporate this information into their work. The action is implicit and concrete, as it provides a clear example of where the authors' claim is challenged, but it does not directly instruct them on how to respond. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment challenges the authors\\' claim about non-uniform label noise by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a clear and specific reference to support the claim that non-uniform label noise is common in real-world datasets. The comment is fully grounded as it explicitly mentions the dataset and paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed example of where the authors\\' claim is challenged. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim about non-uniform label noise by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a concrete example of real-world noise datasets where non-uniform label noise exists, supporting the claim with external evidence. The reference to the paper by Kun Yi and Jianxin Wu adds credibility to the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed information about the specific findings in the referenced paper that support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment challenges the authors\\' claim that non-uniform label noise is not too common in practice by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a concrete example of real-world noise datasets where non-uniform label noise exists, supporting the claim with external evidence. The reference to the paper by Kun Yi and Jianxin Wu adds credibility to the critique, making it a valuable contribution to the authors. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or incorporate this information into their work. Overall, the comment is mostly helpful as it provides a clear and actionable critique, but it could be further enhanced with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they might need to increase the sample size or provide a more robust analysis to mitigate the bias. However, the comment lacks concrete suggestions or detailed instructions on how to implement these changes, making the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation, noting that the limited sample size of 10 samples may lead to biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. This claim is somewhat verifiable as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the assertion. The comment highlights a potential issue but does not provide detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in Section 6.2, noting that it was based on only 10 samples. This is a relevant observation as a small sample size can lead to biased findings. The comment highlights the potential impact of this limitation, which is valuable information for the authors to consider. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue, such as recommending a larger sample size or alternative methods to mitigate bias. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they might need to increase the sample size or provide a more robust analysis to mitigate the bias. However, the comment lacks concrete suggestions or detailed instructions on how to implement these changes, making the action implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the evaluation, noting that the limited sample size of 10 samples may lead to biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 was based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. This claim is somewhat verifiable as it provides a logical reasoning for the potential bias, but it lacks specific examples or references to support the assertion. The comment highlights a potential issue but does not provide detailed evidence or examples to substantiate the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation in Section 6.2, noting that it was based on only 10 samples. This is a relevant observation as a small sample size can lead to biased findings. The comment highlights the potential impact of this limitation, which is valuable information for the authors to consider. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue, such as recommending a larger sample size or alternative methods to mitigate bias. While it points out a critical area for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalizability of the method to significantly different combinatorial optimization problems, noting that the paper acknowledges this limitation but does not address it experimentally. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation in their experiments or analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct additional experiments or analyses to explore the generalizability of their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the generalizability of the method to significantly different combinatorial optimization problems, which the paper acknowledges but does not address experimentally. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of generalizability and the need for experimental exploration, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The reviewer acknowledges this limitation but notes that the paper does not address it experimentally. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the method\\'s generalizability. The absence of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. The comment acknowledges this limitation but points out that the paper does not address it experimentally. This feedback is somewhat helpful as it highlights an important area for improvement, namely the need to explore the generalizability of the method. However, the comment could be more helpful if it provided suggestions on how to address this limitation, such as proposing specific experiments or analyses to test the method\\'s generalizability. Overall, the comment offers a clear direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. The comment acknowledges this limitation but points out that the paper does not address it experimentally. While the comment highlights an important area for improvement, it does not provide explicit guidance or suggestions on how the authors might address this limitation in their experiments or analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct additional experiments or analyses to explore the generalizability of their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the generalizability of the method to significantly different combinatorial optimization problems, noting that the paper acknowledges this limitation but does not address it experimentally. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of generalizability and the need for experimental exploration, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The reviewer acknowledges this limitation but notes that the paper does not address it experimentally. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the method\\'s generalizability. The absence of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the method, noting that it is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. The comment"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a difficulty in understanding the baselines described in the Results section, specifically mentioning the lines 256-261. It questions the authors\\' attempt to explain these baselines and their relation to InterFair, as well as their competitiveness. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the baselines and their relation to InterFair, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Results section, specifically lines 256-261, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding how the baselines work and their relation to InterFair, as well as whether they are sufficiently competitive. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have difficulty grasping the baselines described in the Results section, specifically mentioning lines 256-261. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or explanation of why the baselines are unclear or how they relate to InterFair. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the baselines in the Results section, particularly in lines 256-261. It points out that the authors\\' attempt to explain these baselines is unclear, and questions their relation to InterFair and their competitiveness. This feedback is somewhat helpful as it highlights a specific area where the authors need to improve the clarity and comprehensiveness of their explanation. However, it lacks detailed guidance or suggestions on how to address this issue, such as providing additional context or examples. Therefore, the comment is rated as somewhat helpful, as it provides some insight but not enough actionable advice for the authors to fully improve their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit guidance or suggestions on how the authors should improve this comparison. The comment lacks specific details or concrete steps for the authors to take, such as recommending additional baselines to include or suggesting ways to enhance the comparison. As a result, the authors are left without a clear understanding of what actions to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights an issue with the comparison to other baselines on cycle counting and ZINC, indicating that it is insufficient. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the authors might have an idea of where these comparisons are presented, the comment lacks full grounding. It is specific in identifying the issue with the comparison but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the comparison to other baselines on cycle counting and ZINC. However, it lacks depth and does not provide any suggestions or guidance on how the authors might enhance this comparison. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights an issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is effective, while others are not. However, it does not provide explicit guidance on how to achieve this explanation or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is effective, while others are not. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for a clear explanation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this explanation should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while others are not. However, it does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while others are not. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically the need for a more detailed explanation of the effectiveness of certain combinations. However, the comment lacks specific guidance or suggestions on how to provide this explanation, such as which aspects should be highlighted or how to structure the discussion. While it points out a relevant issue, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of SLQ, as quantified by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It specifically mentions that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these issues. The feedback lacks actionable steps or detailed advice, leaving the authors without a clear path to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of SLQ appears to be less competitive compared to previous CRD methods, as evidenced by the F1 score and conductance values. The comment further highlights specific comparisons in Figures 3 and 4, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. The comment provides specific examples from Figures 3 and 4, which support the claim by showing that SLQ performs worse than CRD in one instance and has a very small improvement over ACL in another. This detailed evidence makes the claim mostly verifiable, as it provides clear reasoning and examples to substantiate the assertion. However, the comment could be strengthened by referencing specific CRD methods or providing more detailed comparisons to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of SLQ, as quantified by F1 score and conductance values, compared to previous CRD methods. It points out that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. This feedback is somewhat helpful as it highlights areas where the authors' work may need improvement or clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or improve their results. Without actionable advice or detailed feedback, the authors may find it challenging to effectively use this comment to enhance their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the performance of SLQ, as measured by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It specifically mentions that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. However, the comment does not provide any explicit or implicit suggestions for improvement or guidance on how the authors might address these issues. Without actionable steps or detailed advice, the authors are left without a clear path to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance of SLQ appears to be less competitive compared to previous CRD methods, as evidenced by the F1 score and conductance values. The comment further highlights specific comparisons in Figures 3 and 4, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as quantified by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It provides specific examples from Figures 3 and 4, which support the claim by showing that SLQ performs worse than CRD in one instance and has a very small improvement over ACL in another. This detailed evidence makes the claim mostly verifiable, as it provides clear reasoning and examples to substantiate the assertion. However, the comment could be strengthened by referencing specific CRD methods or providing more detailed comparisons to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more baselines to their study to perform robust performance comparisons. This feedback provides a clear and direct action for the authors to take, specifying what needs to be added to improve the draft. The comment is concrete in its suggestion, leaving no ambiguity about the necessary steps to enhance the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines in the paper, suggesting that the current choice is limited to naive or old models. It encourages the authors to add more baselines for robust performance comparisons. However, the comment does not specify which part of the paper discusses the baselines, making it weakly grounded. The suggestion to add more baselines is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive or old models, suggesting that more baselines should be added for robust performance comparisons. However, the comment does not provide specific examples of the current baselines or references to alternative models that could be considered. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the selection of baselines, noting that the current choices are limited to naive or old models. It encourages the authors to add more baselines to perform robust performance comparisons, which is a clear and actionable suggestion. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and validity of their study by expanding the scope of their baseline comparisons. However, the comment could be more helpful if it provided specific examples of additional baselines that could be considered or detailed reasons why these additions would be beneficial. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of target structure in Table 2 and questions the generalizability of the proposed method to other target structures with different dimensions. It explicitly suggests that the authors either justify their choice or provide additional experiments demonstrating the method\\'s adaptability to various target structures. This feedback is clear and provides a concrete action for the authors to take, which is to either justify their choice or conduct additional experiments. The comment is explicit and provides detailed guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structure and suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of target structure in Table 2, questioning the generalizability of the proposed method to other target structures with different dimensions. The reviewer suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability. This claim is somewhat verifiable as it points out a potential limitation in the study and suggests a direction for improvement. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of target structure in Table 2, questioning the generalizability of the proposed method to other target structures with different dimensions. It suggests that the authors either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is clear and actionable, as it guides the authors to address a potential limitation in their work and provides a concrete direction for improvement. By doing so, the comment offers valuable insights that can help the authors enhance the robustness and applicability of their approach. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s application scope should be expanded to include more realistic scenarios, such as medical diagnosis, to enhance its impact and relevance. While the comment implies that the authors should consider exploring these applications, it does not provide specific guidance on how to achieve this or what aspects of the knapsack problem could be adapted to these scenarios. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to expand the application scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the research\\'s application scope is limited to the knapsack problem and lacks exploration of more realistic scenarios, such as medical diagnosis. It implies that expanding the application scope to include healthcare would increase the paper\\'s impact and relevance. However, the comment does not specify which part of the paper discusses the knapsack problem or where the application scope could be expanded. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a direction for improvement, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s application scope is limited to the knapsack problem and suggests that exploring applications in more realistic scenarios, such as medical diagnosis, would increase the paper\\'s impact and relevance. While the comment provides a logical reasoning for expanding the application scope, it lacks specific examples or references to support the claim. The suggestion is somewhat verifiable, as it highlights a potential area for improvement but requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s application scope, specifically noting that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare would significantly increase the paper\\'s impact and relevance. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their work and enhance its applicability. However, the comment could be more helpful if it offered suggestions on how to adapt the knapsack problem to medical diagnosis or provided examples of potential applications. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the claimed benefits of the method and the results presented in Figure 3. It suggests that the method does not improve robustness and sensitivity as claimed, and it highlights specific domains where the new method is noisier compared to the competitors. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the robustness and sensitivity of their method. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the robustness and sensitivity of their method but without specific instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the new method is noisier in two domains and equally noisy as the competitors in the rest, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation, referencing Figure 3 to support this claim. However, the comment lacks specific details or examples from the figure to substantiate the claim, such as exact measurements or comparisons. This makes it somewhat verifiable, as the authors would need to review Figure 3 to understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the claimed benefits of the method and the results presented in Figure 3. It points out that the new method is noisier in two domains and equally noisy as the competitors in the rest, suggesting that the method does not improve robustness and sensitivity as claimed. This feedback is somewhat helpful as it highlights a specific area where the authors need to address a discrepancy between their claims and the actual results. However, the comment could be more helpful if it provided suggestions on how to resolve this issue or improve the robustness and sensitivity of the method. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. While it implies that the authors should consider the impact of such methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the robustness of their conclusion under different removal methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the robustness of the conclusion, but without clear grounding, it is challenging for the authors to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the robustness of the conclusion against more sophisticated or aggressive removal methods. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a valuable point that encourages the authors to consider the limitations of their findings and explore the robustness of their conclusions under different conditions. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as recommending particular methods or approaches to test the robustness of their conclusions. While it prompts an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper regarding the distinction between explainable AI and interpretable methods, as well as the lack of explanation for the definition of interpretability. It also notes that the paper does not provide references to work in this area. While the comment identifies specific areas that need clarification and references, it does not explicitly instruct the authors on how to address these issues. The action is implicit, as the authors can infer that they need to clarify the definitions and provide references, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issues with the paper, including the lack of explanation for the definition of interpretability, the failure to differentiate between explainable AI and interpretable methods, and the absence of references to work in this area. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, without providing a clear explanation of the difference between the two concepts. The reviewer also notes that the paper does not provide references to work in this area. This claim is somewhat verifiable as it highlights a gap in the paper\\'s explanation and references, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to further explore and clarify the distinction between explainable AI and interpretable methods to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the distinction between explainable AI and interpretable methods, as well as the lack of explanation for the definition of interpretability. It also points out that the paper does not provide references to work in this area. This feedback is clear and actionable, as it highlights specific areas where the authors need to clarify and expand their discussion. By addressing these points, the authors can improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided suggestions on how to differentiate between the two concepts or offered examples of relevant work. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification about the training data used for the probes in the compositionality and transitivity experiments. While it explicitly requests information, it does not provide specific guidance on how the authors should address this question or what kind of information is expected. The action is clear but lacks concrete details on how to implement the response, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"compositionality and transitivity experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification about the training data used for the probes in these experiments. This provides clear guidance on what information is needed to address the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the training data used in the compositionality and transitivity experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for clarification regarding the training data used in the compositionality and transitivity experiments. While it identifies a specific area that needs further explanation, it does not provide any additional context or suggestions on how the authors might address this issue. The comment is somewhat helpful as it prompts the authors to provide more detailed information, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, referencing [C] as a potential source. However, the comment does not provide explicit instructions or concrete guidance on how the authors should address these issues or improve the clarity of their explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their argument and consider alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. The comment further provides a suggestion by referencing a potential method, bi-directional beam search, which could be explored to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, referencing [C] as a potential source. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanation is unclear or unconvincing. While the suggestion to explore bi-directional beam search is relevant, the comment does not provide enough context or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, referencing [C] as a potential source. However, the comment does not provide specific guidance or suggestions on how the authors might clarify their explanation or improve the argument. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more comprehensive and detailed to be fully beneficial.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of clarity in the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, referencing [C] as a potential source. However, the comment does not provide explicit instructions or concrete guidance on how the authors should address these issues or improve the clarity of their explanation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their argument and consider alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L133-134,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. The comment further provides a suggestion by referencing a potential method, bi-directional beam search, which could be explored to address the issue. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-directional beam search for such applications, referencing [C] as a potential source. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanation is unclear or unconvincing. While the suggestion to explore bi-directional beam search is relevant, the comment does not provide enough context or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to perform bi-direction"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is crucial for applications in rare event sampling and mentions recent work to overcome it. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their approach. The feedback is implicit and lacks concrete steps for the authors to take, making it somewhat actionable. The authors can infer that they need to address the limitations of reverse KL, but the comment does not offer specific advice on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is crucial for applications in rare event sampling and mentions recent work to overcome it. However, the comment does not explicitly mention which part of the paper discusses the use of reverse KL, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issues with reverse KL and the need to address them, particularly in the context of rare event sampling. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It suggests that this limitation is crucial for applications in rare event sampling and mentions recent work to overcome it. The comment provides a logical reasoning for the concern, referencing the mode-seeking nature of reverse KL and the need to cover all modes of a density. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the references or conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the use of reverse KL in training flows, specifically questioning the assumption of differentiability of the function $g$ and the mode-seeking nature of reverse KL. It highlights the potential limitations of this approach, particularly in applications involving rare event sampling, where covering all modes of a density is crucial. The comment also references recent work in the field of normalizing flows to overcome these limitations, providing a direction for potential improvements. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues or incorporate the referenced work into their methodology. Overall, the feedback is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance for implementation.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is needed to address this issue. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct a specific analysis or provide guidance on how to perform it. The action is implicit but concrete, as the authors can infer that they need to analyze the dataset in detail. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. The comment further suggests that a detailed analysis of the curated dataset would be needed to address this issue. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset would be needed to address this concern. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to conduct the analysis or what aspects to focus on. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed instructions for addressing it, leaving the authors with a general direction but no concrete steps to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset would be needed to address this issue. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to conduct the analysis or what specific aspects to focus on. The action is implicit but concrete, as the authors can infer that they need to analyze the dataset in detail. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. The comment further suggests that a detailed analysis of the curated dataset would be needed to address this issue. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the ViStruct Suite, specifically noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset would be needed to address this issue. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to conduct the analysis or what aspects to focus on. The feedback is somewhat helpful as it points out a potential weakness"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural or behavioral parallels. It also points out the need to discuss sensitivity with regard to n. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to justify the model implementation or address the concerns about the stopping rule. The authors can infer that they need to provide more context or justification for their choices, but the lack of detailed instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the stopping rule with n consecutive identical samples, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the arbitrariness of the stopping rule and the lack of discussion on sensitivity with regard to n. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the stopping rule with n consecutive identical samples is arbitrary and lacks neural or behavioral parallels. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model implementation, suggesting that the stopping rule with n consecutive identical samples is arbitrary and lacks neural or behavioral parallels. It also points out the need to discuss sensitivity with regard to n. This feedback is clear and actionable, as it provides the authors with concrete areas to address and improve upon in their draft. However, the comment could be more helpful if it offered suggestions on how to justify the stopping rule or provided examples of alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that requires further explanation and justification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of time complexity analysis for the proposed algorithms and the discrepancy between the proposed method being described as a \"learn-to-search\" algorithm and its adoption of a heuristics node pair selection policy. The reviewer explicitly instructs the authors to provide the time complexity analysis and to report the running time of the proposed method. Additionally, it suggests that the authors should investigate whether their proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. These actions are clear and concrete, giving the authors specific tasks to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed algorithms,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the lack of time complexity analysis and the discrepancy in the description of the proposed method. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide the time complexity analysis for their proposed algorithms, as the maximum common subgraph detection problem is NP-hard. The reviewer also points out a discrepancy in the description of the proposed method, suggesting that it is a \"learn-to-search\" algorithm but adopts a heuristics node pair selection policy. The comment further suggests that it would be interesting to see if the proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. While the comment provides a logical reasoning for the need for time complexity analysis and the potential interest in comparing search times, it lacks specific references or detailed examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies two critical areas for improvement in the paper. First, it points out the lack of time complexity analysis for the proposed algorithms, which is important given the NP-hard nature of the maximum common subgraph detection problem. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. Second, the comment highlights a discrepancy in the description of the proposed method, suggesting that it is a \"learn-to-search\" algorithm but adopts a heuristics node pair selection policy. The reviewer suggests that it would be interesting to see if the proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. This feedback is specific and provides a clear rationale for further investigation, making the comment mostly helpful. However, it could be more helpful if it offered suggestions on how to conduct the time complexity analysis or how to compare search times. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quality control, specifically mentioning the absence of filtering or manual evaluation of data quality collected through an automatic model-based approach. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific methods for implementing quality control. The action is implicit, as the authors can infer that they need to implement quality control measures, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of quality control in the data collection process, specifically mentioning the absence of filtering or manual evaluation. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the need for quality control measures, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control, specifically mentioning the absence of filtering or manual evaluation of data quality collected through an automatic model-based approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the data collection process, specifically the lack of quality control measures such as filtering or manual evaluation. This is an important point that could impact the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending particular methods or tools for quality control. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that for most tasks, a small set of labeled data is available, and it mentions that snorkel also relies on a small development set to tune hyperparameters. The reviewer implies that using these labels could provide a bound on the performance of a classifier and suggests comparing a confidence interval from a small development set with the Frechet bound. While the comment provides a clear direction for comparison, it does not explicitly instruct the authors to perform this comparison or specify how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"snorkel,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting that using a small set of labeled data could provide a bound on the performance of a classifier and compares this with the Frechet bound. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using a small set of labeled data could provide a bound on the performance of a classifier, comparing it with the Frechet bound. The comment provides a logical reasoning by mentioning that snorkel relies on a small development set for tuning hyperparameters, which could be used for this purpose. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the suggestion to fully understand and apply it, which is why it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that using a small set of labeled data could provide a bound on the performance of a classifier, comparing it with the Frechet bound. This is a constructive suggestion that could enhance the analysis and provide additional insights into the performance of the classifier. However, the comment lacks specific guidance or examples on how to implement this suggestion, which limits its helpfulness. While it points out a relevant aspect for exploration, it does not offer detailed steps or examples for the authors to follow, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides specific reasoning by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. However, the comment does not offer any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. There is no guidance on potential modifications or alternative approaches that could be explored. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and provides specific details about the limitation, such as the applicability to low-dimensional input spaces and the largest dimensionality in the experiments being 3. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it explains the issue with the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. The comment provides a logical reasoning by explaining the limitation based on the largest dimensionality in the experiments being 3. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. This is a critical observation that could impact the scope and applicability of the method. The comment provides a specific reasoning behind this limitation, explaining that the largest dimensionality in the experiments is 3 due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. However, the comment does not offer any suggestions or guidance on how the authors might address this limitation or expand the applicability of their method. While it highlights an important issue, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides specific reasoning by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. However, the comment does not offer any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. Without actionable guidance or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and provides specific details about the limitation, such as the applicability to low-dimensional input spaces and the largest dimensionality in the experiments being 3. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it explains the issue with the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling of the shape constraint. The comment provides a logical reasoning by explaining the limitation based on the largest dimensionality in the experiments being 3. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results presented in Tables 1 and 2 are usually within their standard deviations, which leads the reviewer to question the claim that the presented method is significantly better than others. However, the comment does not provide specific examples or detailed reasoning to support this critique. The lack of detailed evidence or references makes it difficult for the authors to understand the basis of the reviewer\\'s concern, thus rendering the claim borderline verifiable. The authors would need to make a significant effort to address the critique without additional context or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This feedback is somewhat helpful as it identifies a potential weakness in the authors\\' argument and prompts them to reconsider their claim. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable advice or detailed feedback, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a challenge in generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggestions for potential solutions. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the challenge of generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity, which introduces additional relationships in the table. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem of multiple entries associated with the same entity, but it lacks detailed guidance on how to address this issue or where in the paper this problem is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a challenge in generating synthetic tabular data due to the presence of multiple entries associated with the same entity, which introduces additional relationships in the table. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific challenge in generating synthetic tabular data, noting that multiple entries associated with the same entity can introduce additional relationships in the table. This is a relevant observation that could help the authors understand the complexities involved in their data generation process. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their approach. Without additional context or specific recommendations, the feedback is limited in its usefulness. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. However, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should provide a broader context or validation on other datasets, but it does not specify which datasets to consider or how to conduct this validation. The action is implicit and somewhat vague, leaving the authors with a general direction but without concrete steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and raises a concern about its applicability and relevance to other scenarios. However, it does not specify which part of the paper discusses the benchmark, making it weakly grounded. The comment is specific in identifying the issue of overemphasis on the benchmark without broader context or validation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. However, the comment lacks specific examples or references to support the claim that the benchmark is overemphasized or to explain why this could lead to questions about its applicability. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. This feedback is valuable as it prompts the authors to broaden the context and validation of their work, which could enhance the paper\\'s significance and generalizability. However, the comment lacks specific suggestions or guidance on how to address this issue, such as which other datasets should be considered or how to validate the benchmark\\'s applicability. While it points out a critical area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. However, it does not provide explicit guidance on how the authors should address this concern or suggest specific steps to broaden the context or validation of their work. The comment implies that the authors should provide a broader context or validation on other datasets, but it lacks concrete suggestions or examples. As a result, the action is implicit and somewhat vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and raises a concern about its applicability and relevance to other scenarios. However, it does not specify which part of the paper discusses the benchmark, making it weakly grounded. The comment is specific in identifying the issue of overemphasis on the benchmark without broader context or validation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. However, the comment lacks specific examples or references to support the claim that the benchmark is overemphasized or to explain why this could lead to questions about its applicability. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability and relevance to other scenarios. This feedback is valuable as it prompts the authors to broaden the context and validation of their work, which could enhance the paper\\'s significance and generalizability. However, the comment lacks specific suggestions or guidance on how to address this issue, such as which other datasets should be considered or how to validate the benchmark\\'s applicability. While it points out a critical area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the overemphasis on the AmbiQT benchmark without considering its applic"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of annotation training details and guidelines, noting that this is important for professional translators who may encounter similar non-standard tasks. It also mentions the lack of information about the tool used. While the comment identifies areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to include this information, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in identifying the need for annotation training details and guidelines, as well as the lack of information about the tool used. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks annotation training details and guidelines, which is important for professional translators. However, the comment does not provide specific examples or references to support this claim. It also mentions the lack of information about the tool used, but again, without detailed examples or references. The lack of specific evidence or reasoning makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the absence of annotation training details and guidelines, which is important for professional translators. It highlights the need for this information, noting that it is often a concern for such tasks. Additionally, the comment mentions the lack of information about the tool used, which is another important aspect that should be included. While the comment effectively identifies areas that need improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are given a clear direction to include this information, but the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides valuable insights but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about Table 1: whether \"EX/NORB\" should be bold-faced and whether the difference between 0.59+/-0.12 and 0.58+/-0.11 is statistically significant. While the questions imply that the authors should clarify these aspects, they do not provide explicit instructions or concrete guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify these points. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether \"EX/NORB\" should be bold-faced and whether the difference between the values is statistically significant. This provides clear guidance on what needs to be clarified or addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions about the presentation and statistical significance of data in Table 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about Table 1, questioning whether \"EX/NORB\" should be bold-faced and whether the difference between the values is statistically significant. While these questions highlight areas that need clarification, they do not provide actionable feedback or suggestions for improvement. The authors are left with a list of questions rather than guidance on how to address these issues, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics and that the paper lacks details on this aspect. This direct request for information provides a clear and concrete action for the authors to take, ensuring they know exactly what information is needed to address the comment. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"video level supervision experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the metric used for this experiment, noting that it does not use tracklet-based metrics and asking for details on the metric employed. This provides clear guidance on what needs to be clarified or added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of a specific metric for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. However, the comment lacks any supporting evidence, reasoning, or references to substantiate the claim that the paper should include tracklet-based metrics. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. This feedback is clear and actionable, as it prompts the authors to clarify or provide details on the metric used, which is important for understanding and evaluating the results. By addressing this question, the authors can enhance the transparency and comprehensibility of their work. However, the comment could be more helpful if it suggested how the authors might justify or explain the choice of metric or provided additional context. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might learn person-related features, which could be undesirable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate or resolve it. The action is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of \"person blocking\" on the models and suggests a potential reason for this effect, which is that models learn person-related features. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of \"person blocking\" on models, suggesting that models might learn person-related features, which could be undesirable. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of \"person blocking\" on models, as shown in Figure 4. It suggests that models might learn person-related features, which could be undesirable. This feedback identifies a potential issue that the authors should consider, prompting them to explore and address this aspect in their analysis. However, the comment lacks specific guidance or suggestions on how to investigate or resolve this concern, such as proposing methods to mitigate the issue or further experiments to validate the hypothesis. While it points out an area for improvement, the feedback could be more actionable and comprehensive. Therefore, it is somewhat helpful, as it provides some insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have tried the combination of TF-IDF and dense retrieval for evidence sentence extraction. While the comment implies that the authors should consider this combination, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this combination. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of TF-IDF and dense retrieval, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks whether the authors have tried this particular combination for evidence sentence extraction, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. While it identifies a potential area for exploration, it does not provide any context, reasoning, or suggestions on why this combination might be beneficial or how it could improve the paper. The comment lacks depth and actionable guidance, making it difficult for the authors to understand the significance of the question or how to address it. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer sufficient value for the authors to improve their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were incorrectly identified as highly correlated despite not being neighboring countries. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides specific examples and questions that could guide the authors in improving their draft, it does not explicitly instruct them to include these examples or questions. The action is implicit but concrete, as the authors can infer what needs to be added or clarified. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were incorrectly identified as highly correlated despite not being neighboring countries. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, it provides enough context for the authors to infer that it relates to the discussion or results sections where time-series prediction is mentioned. The comment is specific in detailing what needs to be addressed regarding the examples and the relationship between trajectories and eigenvectors. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were incorrectly identified as highly correlated despite not being neighboring countries. The comment also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides specific examples and questions, it lacks detailed reasoning or evidence to fully substantiate the claim that these examples are indicative of poor performance. The authors may need to infer the relevance of these examples to the overall critique, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where UK and Russia were incorrectly identified as highly correlated despite not being neighboring countries. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is clear and actionable, providing specific areas for the authors to consider and improve upon in their draft. By addressing these points, the authors can enhance the comprehensiveness and robustness of their analysis. However, the comment could be more helpful if it offered additional guidance or examples on how to identify and present these examples effectively. Overall, the comment is mostly helpful, as it directs the authors to important areas for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not provide any explicit or implicit actions for the authors to take in response to this critique. There is no guidance on how the authors might address this issue, such as clarifying their claims, revising their framework description, or providing additional context. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what aspects of the framework are overblown or how the claims could be better substantiated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s claims of proposing a \"learning framework\" are overblown, suggesting that it is not a new framework but rather a modified loss and architecture. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. While it identifies a potential issue with the paper\\'s claims, it lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique or enhance their work. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2. It suggests that this customization may limit cross-model generalization and proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to achieve this. The action is implicit but concrete, as the authors can infer that they need to explore alternative approaches to prompt design. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, and suggests that this customization may limit cross-model generalization. It proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these prompts are discussed. The comment is specific in detailing the issue of cross-model generalization and suggests potential improvements. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the customization of learned prompts for specific transformer-based architectures may limit cross-model generalization. The reviewer supports this claim by noting that separate training of prompts is required for each new architecture, which could be a limitation for broader applicability. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, which may limit cross-model generalization. It suggests that separate training of prompts for each new architecture could be a limitation. The comment proposes an alternative approach by exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. This feedback is clear and actionable, as it provides a direction for the authors to consider in improving the generalizability of their approach. However, the comment could be more helpful if it included specific suggestions or examples of how to achieve this universality. Overall, the comment is mostly helpful, as it offers valuable insights and a clear direction for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, which may limit cross-model generalization. It suggests exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to achieve this. The action is implicit but concrete, as the authors can infer that they need to explore alternative approaches to prompt design. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, and suggests that this customization may limit cross-model generalization. It proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these prompts are discussed. The comment is specific in detailing the issue of cross-model generalization and suggests potential improvements. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, may limit cross-model generalization. The reviewer supports this claim by noting that separate training of prompts is required for each new architecture, which could be a limitation for broader applicability. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, which may limit cross-model generalization. It suggests that separate training of prompts for each new architecture could be a limitation for broader applic"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of baselines in the paper, which raises a concern about the antiquated nature of the model architecture. It suggests that the current methodology may not be more effective or novel compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to evaluate the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. This feedback is explicit and provides concrete guidance on how the authors can address the issue by including additional baselines. The authors know exactly what needs to be done to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the absence of baselines and the antiquated nature of the model architecture, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of comparisons to other models and suggests evaluating the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of baselines raises concerns about the antiquated nature of the model architecture and suggests that the current methodology may not be more effective or novel compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to evaluate the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. This reasoning is clear and supported by a specific example, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or examples of the advanced models mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the absence of baselines, which raises concerns about the antiquated nature of the model architecture. It highlights that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting compared to contemporary time-series forecasting architectures. The comment provides a clear and actionable suggestion by recommending the evaluation of the model against advanced time-series forecasting models, such as those available in the \"Time-Series Library\" repository. This feedback is highly helpful as it not only points out a critical weakness but also offers a concrete solution for improvement, empowering the authors to enhance the validity and novelty of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. While the comment implies that the authors should add a strong baseline, it does not explicitly instruct them to do so or specify which tasks or baselines to consider. The action is implicit and somewhat vague, as the authors need to infer that they should enhance their baselines but lack detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks strong baselines, specifically mentioning that the only baselines presented are standard MLPs. However, it does not specify which tasks or baselines are being discussed, making it weakly grounded. The comment is specific in its critique of the lack of strong baselines, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks strong baselines, specifically mentioning that the only baselines presented are standard MLPs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the inclusion of additional strong baselines would be beneficial or necessary. Without such support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the only baselines presented are standard MLPs. While it acknowledges that the paper is primarily theoretical, it suggests that including at least one strong baseline in one of the tasks would enhance the paper. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks detailed guidance on which baselines to consider or how to implement them. The authors are given a direction to improve their work, but the comment could be more comprehensive by offering more specific suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to two prior works cited in the paper. It also suggests including these prior works for comparison in the experimental results tables. This feedback provides a direct and concrete action for the authors to take, specifying exactly what needs to be done to improve the draft. The authors know exactly how to apply the feedback, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the prior works cited by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: a more thorough comparison of the proposed method to the prior works and their inclusion in the experimental results tables. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. While the comment identifies a potential issue with the lack of differentiation between the proposed method and the prior works, it does not provide specific examples or detailed reasoning to support the claim. The suggestion to include the prior works in the experimental results tables is a logical step, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the proposed method is very similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. This feedback is clear and actionable, providing the authors with a specific direction to enhance the clarity and differentiation of their work. By addressing this suggestion, the authors can improve the novelty and contribution of their paper, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the broader goals identified in the paper, which makes it difficult to evaluate the claim about the non-existence of visualization systems for interpretable reinforcement learning. While the comment identifies a gap in the paper, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the broader goals, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about the non-existence of visualization systems for interpretable reinforcement learning that effectively address broader goals. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the broader goals, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that there are no visualization systems for interpretable reinforcement learning that address broader goals. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. However, the comment does not provide specific examples or references to support the claim or refute it. This lack of detailed evidence or reasoning makes the claim borderline verifiable, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the broader goals mentioned in the paper, specifically questioning the claim that there are no visualization systems for interpretable reinforcement learning that address these goals. This feedback highlights an important area for clarification, prompting the authors to provide more detailed information about the broader goals and how they relate to the proposed work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending ways to clarify the goals or providing examples of existing systems. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the broader goals identified in the paper, questioning the claim that there are no visualization systems for interpretable reinforcement learning that address these goals. However, it does not provide explicit guidance or suggestions on how the authors should clarify these goals or address the claim. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they need to clarify the broader goals, but the comment does not specify how to do so. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a claim about the non-existence of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the broader goals, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the claim that there are no visualization systems for interpretable reinforcement learning that address broader goals. It highlights the lack of clarity regarding these broader goals, making it difficult to evaluate the claim. However, the comment does not provide specific examples or references to support the claim or refute it. This lack of detailed evidence or reasoning makes the claim borderline verifiable, as it requires more information to be fully substantiated. Therefore, the comment aligns with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the broader goals mentioned in the paper, specifically questioning the claim that there are no visualization systems for interpretable reinforcement learning that address these goals. This feedback highlights an important area for clarification, prompting the authors to provide more detailed information about the broader goals and how they relate to the proposed work. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending ways to clarify the goals or providing examples of existing systems. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the introduced AAL and SLS seem to be independent and that the improvements are slight, suggesting that applying AAL or SLS separately may not provide a stable improvement. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the stability of the improvements. The action is implicit and vague, as the authors are left to infer that they need to explore the interdependence of AAL and SLS or find ways to enhance their stability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table (1-4),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the independence of AAL and SLS and the slight improvements observed in the tables. The comment provides clear guidance on what needs to be addressed, namely the stability of improvements when applying AAL or SLS separately. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduced AAL and SLS seem to be independent and that the improvements are slight, suggesting that applying AAL or SLS separately may not provide a stable improvement. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. The authors are left to infer the basis of the claim, making it difficult to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the independence of the introduced AAL and SLS methods, noting that the improvements observed in Table (1-4) are slight. It raises a concern about the stability of improvements when applying these methods separately. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the stability of their results. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left to infer potential areas for improvement but without clear direction, which limits the utility of the comment.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should explore the effects of their method on different tasks or utilize multiple datasets for the same task to gain deeper insights. This feedback provides a clear and direct action for the authors to take, specifying what additional experiments or datasets should be considered. The comment is concrete, as it outlines a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the limitations of the experiments, specifically mentioning the limited task (sentiment classification) and dataset (SST2). This provides some grounding as it allows the authors to identify the parts of the paper being discussed. However, the comment does not specify which sections or experiments are being referred to, making it weakly grounded. It is specific in suggesting that the authors should explore different tasks or datasets to gain deeper insights, but without explicit references, the authors may still struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task and one dataset, suggesting that exploring different tasks or datasets would provide deeper insights. This claim is somewhat verifiable as it highlights a limitation in the scope of the experiments. However, it lacks specific examples or references to other tasks or datasets that could be explored, which would strengthen the justification. The authors would need to infer which tasks or datasets might be suitable for further exploration, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that the experiments are limited to only one task (sentiment classification) and one dataset (SST2). It suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task would provide deeper insights. This feedback is clear and actionable, as it directs the authors to expand their experimental setup to gain a more comprehensive understanding of their method\\'s performance. However, the comment could be more helpful if it provided specific examples of other tasks or datasets that could be explored. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it is easier to fit. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what steps they should consider to improve the validity of their experiments. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it is easier to fit. However, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide details on what aspects of the simulated data are problematic or how the authors might address this issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the validity of the experimental designs, specifically regarding the use of simulated data instead of real-world data. However, the comment lacks supporting evidence or reasoning to justify why simulated data would be easier to fit or why it is not representative of real-world scenarios. Without specific examples or references, the claim remains unverifiable, making it difficult for the authors to understand and address the concern. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the experimental designs, specifically questioning whether the simulated data used in the experiments is realistic or if it is easier to fit. While it identifies a potential issue with the validity of the experimental setup, it lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. While the comment implies that the authors should consider adding these metrics, it does not explicitly instruct them to do so. The action is concrete, as it specifies the type of metric to include, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improving the evaluation and comparison of models. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. The comment provides a logical reasoning by suggesting specific metrics that could be used to improve the evaluation process. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the suggested metrics to fully understand the impact of this feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a concrete suggestion for improving their study. By addressing this limitation, the authors can strengthen their evaluation framework and potentially enhance the impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point is a question asking whether the mechanism can be used in vision transformers. While it raises an interesting point, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider if they decide to explore this possibility. As a result, the authors are left without any actionable steps to take after reading this comment. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the mechanism in vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or details about the mechanism or its current limitations. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking whether the mechanism can be used in vision transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the mechanism in vision transformers. While it highlights an interesting area for exploration, it does not provide any specific guidance or suggestions for the authors to consider. The comment lacks depth and actionable feedback, leaving the authors without clear direction on how to address this question or what steps to take if they decide to investigate this possibility. As a result, the comment is not very helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, why the precision of IMLE is better than the proposed Adaptive IMLE, and second, whether the proposed method can be applied to different domains. While the questions imply that the authors should provide explanations or evidence for these points, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions regarding the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its questions, as it seeks clarification on the precision and applicability of the methods. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking for clarification on the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. These questions do not contain any subjective opinions, judgments, or suggestions that require verification. They are purely factual inquiries seeking additional information. Therefore, the classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that seek clarification on the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. While these questions are relevant and could prompt the authors to provide additional insights or evidence, they do not offer specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it identifies areas for improvement but lacks depth and actionable advice, leaving the authors with a general direction to explore rather than concrete steps to take. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental results are lacking and questions whether all the modules are necessary. However, it does not provide specific guidance on how to address this issue or what aspects of the experimental results should be improved. The action is implicit, as the authors can infer that they need to provide more detailed experimental results or justify the necessity of each module, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper these results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where the experimental results are presented, the comment lacks full grounding. It is specific in its critique of the experimental results but does not provide detailed guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, the comment does not provide specific examples or reasoning to support this claim, such as which modules are unnecessary or how their removal would impact the results. Without detailed justification or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, specifically questioning whether all the modules are necessary. This feedback is somewhat helpful as it prompts the authors to reconsider the necessity of each module and potentially streamline their experimental setup. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address the issue, such as which modules could be removed or how to improve the experimental design. To be more helpful, the comment could include specific examples or reasoning to support the claim that some modules are unnecessary. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the number of layers considered in the study, noting that many GNNs tend to oversmooth as more layers are added. It suggests exploring the network\\'s behavior with more layers, such as 32 and 64. While the comment implies that the authors should investigate this further, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this exploration. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include more layers. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the number of layers considered in the study, specifically mentioning that the authors have considered up to 8 layers. It suggests exploring the network\\'s behavior with more layers, such as 32 and 64. However, the comment does not explicitly mention which part of the paper discusses the number of layers, making it weakly grounded. The suggestion to explore more layers is specific, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the number of layers considered in the study, noting that many GNNs tend to oversmooth as more layers are added. It suggests exploring the network\\'s behavior with more layers, such as 32 and 64. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about oversmoothing. The suggestion to explore more layers is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the study, noting that many GNNs tend to oversmooth as more layers are added. It suggests exploring the network\\'s behavior with more layers, such as 32 and 64, which could provide valuable insights. While the comment highlights an important area for further investigation, it lacks specific guidance or suggestions on how to conduct this exploration or what aspects to focus on. The feedback is somewhat helpful as it points out a potential limitation but does not offer detailed advice on how to address it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of their experimental results. This is a clear and direct action that the authors can take to address the concern about the limited improvement of MT over ST. The comment provides a concrete step for the authors to follow, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST, suggesting that the authors perform significance tests to ensure the reliability of their experimental results. However, it does not specify which part of the paper this improvement is discussed in, making it weakly grounded. The comment is specific in suggesting a method to address the issue of limited improvement, but without clear grounding, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is \"very limited\" and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific examples or detailed reasoning to support the claim that the improvement is indeed limited. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the improvement of MT over ST is \"very limited.\" It provides a clear and actionable suggestion for the authors to perform significance tests to ensure the reliability of their experimental results. This feedback is valuable as it guides the authors on how to strengthen their analysis and provide more robust evidence for their claims. However, the comment could be more helpful if it offered additional guidance on which significance tests to perform or how to interpret the results. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement that can enhance the rigor of their study.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer suggests that the authors should evaluate the framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to better understand its performance. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the types of GNN blocks to consider, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5\" and \"the node and graph classification models employ similar GCN blocks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model-agnostic claim, suggesting that the evaluation should include different GNN blocks like GAT, GraphSAGE, GIN, and Geniepath. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer suggests that the framework should be evaluated on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to better understand its performance. This claim is somewhat verifiable as it provides a logical reasoning for expanding the evaluation to different GNN blocks, but it lacks specific examples or references to support the suggestion. The authors would need to further explore and justify why these specific GNN blocks are relevant, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the evaluation of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer suggests expanding the evaluation to include other GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, to better understand the framework\\'s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness of their evaluation. By addressing this suggestion, the authors can strengthen the robustness and generalizability of their framework. However, the comment could be more helpful if it included specific reasons why these GNN blocks are relevant or how they might affect the results. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an error analysis to understand how the approach behaves when one of its components makes a mistake. It provides a specific example, mentioning \"GPT-4O,\" which implies that the authors should consider the impact of potential errors in this component. While the comment implies that an error analysis is necessary, it does not explicitly instruct the authors to conduct this analysis or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components makes a mistake. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an error analysis and provides a clear example of what could be included, such as the impact of GPT-4O missing details. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components makes a mistake. However, the comment does not provide specific examples or detailed reasoning to support the claim that an error analysis is necessary. The suggestion is based on a general observation about the complexity of the method, but without further elaboration, it lacks the necessary support to be fully verifiable. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the method has many components, which could lead to complexity. It suggests that an error analysis should be conducted to understand how the approach behaves when one of its components makes a mistake. The comment provides a specific example, mentioning \"GPT-4O,\" which helps the authors understand the context of the error analysis. However, the comment could be more helpful if it offered suggestions on how to conduct the error analysis or provided additional guidance on what aspects to focus on. Overall, the feedback is somewhat helpful as it highlights an area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should include an error analysis to understand how the approach behaves when one of its components makes a mistake. It provides a specific example, mentioning \"GPT-4O,\" which implies that the authors should consider the impact of potential errors in this component. While the comment implies that an error analysis is necessary, it does not explicitly instruct the authors to conduct this analysis or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components makes a mistake. It provides a specific example, mentioning \"GPT-4O,\" which implies that the authors should consider the impact of potential errors in this component. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in its request for an error analysis, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components makes a mistake. It provides a specific example, mentioning \"GPT-4O,\" which implies that the authors should consider the impact of potential errors in this component. However, the comment lacks detailed reasoning or evidence to support the claim that an error analysis is necessary. Without further elaboration or examples, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but requires more detailed justification to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the method has many components, which could lead to complexity. It suggests that an error analysis should be conducted to understand how the approach behaves when one of its"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the reversible version has a higher computational cost during training and questions the practicality of the approach given the current cost. It also suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment implies that the authors should include these scores, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to present these scores or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the computational cost of the reversible version and the necessity of the gating mechanism. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific about the computational cost and the necessity of the gating mechanism, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the reversible version has a higher computational cost during training and questions the practicality of the approach given the current cost. It also suggests including perplexity/BLEU scores to verify the necessity of the gating mechanism. While the comment raises a valid concern about the practicality of the approach, it lacks specific examples or references to support the claim about the computational cost. The suggestion to include perplexity/BLEU scores is a logical extension but does not provide detailed reasoning or evidence for its necessity. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the paper\\'s recognition of the higher computational cost of the reversible version during training, questioning the practicality of the approach given the current cost. It suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment identifies a relevant issue and provides a specific suggestion for improvement, it lacks depth and does not offer detailed guidance on how to present these scores or what aspects of the gating mechanism should be emphasized. The feedback is somewhat helpful as it highlights an area for improvement but could be more comprehensive and actionable with additional details or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. While the comment implies that an error analysis should be included, it does not explicitly instruct the authors to add one or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors know they need to address the lack of error analysis but may not be entirely sure of the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not specify which part of the paper should include this analysis or where it should be placed. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in identifying the need for an error analysis but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no mention of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide any specific examples or references to support this claim. It lacks detailed reasoning or evidence to substantiate why an error analysis is necessary or how it would improve the understanding of SetCSE. As a result, the claim is not verifiable due to the absence of supporting evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by pointing out the absence of an error analysis. This feedback is valuable as it highlights a potential weakness in the paper that could affect the understanding of the limitations of SetCSE in certain scenarios. However, the comment does not provide specific guidance on how to conduct an error analysis or what aspects should be included. While it directs the authors to an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to consider these possibilities and possibly explore alternative methods. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential limitations of the current approach, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. The authors are left to infer the potential issues, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it highlights an area for consideration, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The action is implicit and lacks concrete details, making it barely actionable. Authors may infer that they need to consider these possibilities, but the lack of specific guidance makes it difficult to determine the exact steps to take.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential limitations of the current approach, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim. The authors are left to infer the potential issues, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. While the comment identifies a potential limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback highlights an"}
{"generated_text": "{'actionability_rationale': 'The review point provides an implicit suggestion for the authors to find other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. While the comment implies that the authors should explore different environments to showcase the benefits of HA3C, it does not explicitly instruct them to do so. The action is somewhat vague, as it lacks specific guidance on how to identify suitable tasks or how to structure the demonstration. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results, specifically mentioning the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. It provides a rationale for this observation, suggesting that the benefit of HA3C may lie in the structure of the problem, where the causal relationship based on history is simple. However, the comment does not specify which part of the paper this analysis is based on, making it weakly grounded. The suggestion to find other tasks or artificial tasks to demonstrate HA3C\\'s effectiveness is specific but not explicitly mentioned in the comment. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a claim that the improvement of HA3C is marginal over baseline algorithms on MuJoCo control tasks, suggesting that this does not necessarily indicate HA3C\\'s ineffectiveness. The reviewer offers a rationale for this claim, explaining that the benefit of HA3C may lie in the structure of the problem, where the causal relationship based on history is simple. This explanation provides some logical reasoning and a perspective on the problem, making the claim somewhat verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a nuanced perspective on the experimental results, suggesting that the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks does not necessarily indicate ineffectiveness. It offers a rationale for this observation, explaining that the benefit of HA3C may lie in the structure of the problem, where the causal relationship based on history is simple. The reviewer further suggests that the authors explore other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. This feedback is mostly helpful as it offers a constructive critique and actionable advice for the authors to consider, potentially leading to improvements in the paper. However, it could be more helpful if it provided specific examples or guidance on how to identify suitable tasks. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should focus on the insights derived from the data rather than just reporting aggregate numbers. It implies that the authors should provide key takeaways or insights that are generalizable and hold broader significance for the community. While the comment provides a clear direction for improvement, it does not specify exactly what insights or takeaways should be included or how to present them. The action is implicit but concrete, as the authors know they need to provide more detailed insights, but the comment lacks specific guidance on how to achieve this. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the novelty of the dataset and the key contributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of focus on insights derived from the data to deepen understanding of LLM capabilities. The comment suggests that the authors should provide key takeaways or insights that are generalizable and hold broader significance for the community. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not fully address the key contributions beyond reporting aggregate numbers, as it lacks clear insights or takeaways that are generalizable and hold broader significance for the community. The reviewer provides a logical reasoning by suggesting that the paper should focus on insights derived from the data to deepen understanding of LLM capabilities. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific insights or takeaways that are missing, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key issue with the paper, which is the lack of focus on insights derived from the data rather than just reporting aggregate numbers. It suggests that the paper should provide more detailed insights or takeaways that are generalizable and hold broader significance for the community. This feedback is clear and actionable, as it directs the authors to focus on providing more meaningful insights from their experiments. However, the comment could be more helpful if it offered specific examples or guidance on how to derive these insights. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a false claim in the paper, specifically that GAN is the de facto choice for vocoders. It suggests that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate these alternative vocoders into their paper. The action is implicit and lacks concrete details, making it somewhat actionable. The authors know they need to address the claim, but the comment does not specify how to do so, leaving them with a vague understanding of the necessary steps.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"GAN has been the de facto choice for vocoders,\" pointing out that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, stating that \"GAN has been the de facto choice for vocoders,\" and provides a counter-argument by mentioning other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This provides a logical basis for the claim, as it highlights the existence of alternative choices that are not mentioned in the paper. However, the comment could be strengthened by providing specific references or examples of these alternative vocoders to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a reasonable basis for the claim but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a false claim in the paper, specifically that GAN is the de facto choice for vocoders. It provides a counter-argument by mentioning other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This feedback is valuable as it challenges the authors to reconsider their assumptions and potentially revise their claims or provide a more comprehensive overview of vocoders. However, the comment could be more helpful if it offered suggestions on how to incorporate these alternative vocoders into the paper or discussed the implications of this revision. Overall, the comment is mostly helpful as it prompts the authors to address a significant oversight in their paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a false claim in the paper, specifically that GAN is the de facto choice for vocoders. It suggests that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate these alternative vocoders into their paper. The action is implicit and lacks concrete details, making it somewhat actionable. The authors know they need to address the claim, but the comment does not specify how to do so, leaving them with a vague understanding of the necessary steps.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"GAN has been the de facto choice for vocoders,\" pointing out that there are other popular vocoders choices like WaveNet, WaveRnn, and diffusion-based approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges a claim made in the paper, stating that GAN is the de facto choice for vocoders, and provides a counter-argument by mentioning other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This provides a logical basis for the claim, as it highlights the existence of alternative choices that are not mentioned in the paper. However, the comment could be strengthened by providing specific references or examples of these alternative vocoders to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a reasonable basis for the claim but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a false claim in the paper, specifically that GAN is the de facto choice for vocoders. It provides a counter-argument by mentioning other popular vocoders like WaveNet, WaveRnn, and diffusion-based approaches. This feedback is"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need further explanation or justification. The action is implicit, as the authors can infer that they need to provide more detailed explanations and empirical justifications for their design choices, but the comment lacks concrete steps on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions the approach and its design choices, but it does not specify which part of the paper these choices are discussed in, making it weakly grounded. However, it does specify that the design choices are not fully explained or empirically justified, particularly mentioning the choice of token similarity metric. This provides some level of specificity regarding what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or references leaves the claim somewhat unverifiable, as it requires the authors to infer the basis of the critique. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that while the approach is straightforward and sensible, it contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. However, the comment lacks actionable guidance or suggestions on how the authors might address these issues, such as providing additional explanations or empirical justifications for their design choices. While it points out a potential weakness, it does not offer detailed advice on how to improve the draft, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side (LHS) contains T and W, while the right-hand side (RHS) does not. Additionally, it notes that the formulas for the mean and variance have j on the LHS but not on the RHS. This feedback is explicit and provides concrete guidance on what needs to be corrected, namely, ensuring consistency in the notation across the equations. The authors know exactly what needs to be done to address the issue, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Equation 4 and Equation 6) and highlights the inconsistencies in the notation. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the inconsistencies in the notation, such as the presence of T and W on the LHS but not on the RHS, and the presence of j on the LHS but not on the RHS of the formulas for the mean and variance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific inconsistencies in the notation of Equations (4) and (6), noting that the left-hand side contains T and W, while the right-hand side does not, and that the formulas for the mean and variance have j on the LHS but not on the RHS. This is a factual observation and does not contain any subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side contains T and W, while the right-hand side does not, and that the formulas for the mean and variance have j on the LHS but not on the RHS. This feedback is clear and actionable, as it directly points out areas where the authors need to correct the notation to ensure consistency. By addressing these inconsistencies, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided suggestions on how to maintain consistency in notation throughout the paper. Overall, the comment is mostly helpful as it provides specific guidance for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the evaluation is insufficient, including the number of models constructed, the evaluation of image distortion after warping, and the discussion on potential countermeasures against the proposed approach. While the comment highlights specific aspects that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their evaluation and include discussions on potential countermeasures, but the comment lacks concrete steps or examples on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation section, specifically mentioning the number of models constructed and the lack of evaluation regarding image distortion after warping. It also points out the absence of a discussion on potential countermeasures against the proposed approach. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation and discussion sections. The comment is specific in detailing what is missing in the evaluation and the need for a discussion on countermeasures. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is insufficient due to the limited number of models constructed and the lack of evaluation regarding image distortion after warping. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the evaluation is insufficient, specifically mentioning the limited number of models constructed during evaluations and the lack of evaluation regarding image distortion after warping. It also points out the absence of a discussion on potential countermeasures against the proposed approach. This feedback is clear and actionable, as it provides specific areas for improvement that the authors can address to enhance the robustness and comprehensiveness of their evaluation. However, the comment could be more helpful if it offered suggestions on how to expand the evaluation or discuss potential countermeasures. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the classification of discourse particles in Table A3, suggesting that they might be a mix of discourse particles and imported vocabulary. It implies that if they are indeed a mix, the table should be separated, and glosses would be helpful. While the comment provides a clear action to consider separating the table and adding glosses, it does not explicitly instruct the authors to do so. The action is implicit but concrete, as the authors can infer the need for separation and the addition of glosses. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether all the items in the table are discourse particles or a mix of discourse and imported vocabulary. The comment suggests separating the table if they are a mix and mentions the potential use of glosses. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question and a suggestion for improvement regarding the classification and presentation of discourse particles in Table A3. It does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table A3, questioning whether all the items are discourse particles or a mix of discourse and imported vocabulary. It suggests separating the table if they are a mix and recommends the inclusion of glosses for clarity. This feedback is clear and actionable, providing the authors with a concrete step to improve the organization and presentation of their data. By addressing this issue, the authors can enhance the clarity and usability of their table, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind formula (4), specifically why it involves a maximum over all possible pieces for unoccupied squares. While the comment highlights a lack of understanding, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the rationale behind the formula, but it is vague because it does not specify how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by questioning the rationale behind the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what aspect of the formula needs clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the rationale behind formula (4), specifically why it involves a maximum over all possible pieces for unoccupied squares. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the rationale behind formula (4), particularly why it involves a maximum over all possible pieces for unoccupied squares. This feedback is somewhat helpful as it prompts the authors to clarify a potentially confusing aspect of their work. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve the clarity of their explanation. To be more helpful, the comment could include suggestions for alternative explanations or examples that might help clarify the concept. Therefore, the comment is rated as somewhat helpful, as it identifies a potential area for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments lack a comparison to state-of-the-art subset selection methods. While it explicitly identifies an area that needs improvement, it does not provide specific guidance on which subset selection methods should be included or how to conduct the comparison. The action is clear but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, namely the lack of comparison to state-of-the-art subset selection methods. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for a comparison to existing methods, but without explicit references to sections or figures, the authors may struggle to pinpoint where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any specific examples or references to these methods, nor does it explain why such a comparison is necessary or how it would benefit the paper. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the paper, namely the lack of comparison to state-of-the-art subset selection methods in the experiments. This feedback is clear and actionable, as it directs the authors to include such comparisons to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided examples of relevant subset selection methods or suggested how to incorporate them into the experiments. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is somewhat vague and needs to be more concise. It also mentions that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific guidance on how to enhance the novelty or how to make the paper more concise. The feedback lacks actionable details, such as suggesting ways to differentiate the paper from existing works or how to present the novelty more effectively. As a result, the authors are left without clear direction on how to address the feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is somewhat vague and needs to be more concise. It mentions that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which parts of the paper are being referred to, nor does it provide detailed guidance on how to enhance the novelty or make the paper more concise. Without explicit references to sections or specific elements, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity in detailing what aspects of the novelty are unclear or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the paper is somewhat vague and needs to be more concise. However, it does not provide specific examples or detailed reasoning to support this claim. The comment mentions that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN, but it does not explain how these elements contribute to the novelty or why they are not novel. Without additional context or evidence, the claim remains unverifiable, as it lacks the necessary details to help the authors understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the novelty of the paper, suggesting that it is somewhat vague and needs to be more concise. It points out that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment lacks specific guidance or suggestions on how to enhance the novelty or make the paper more concise. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an issue but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback provides a clear and explicit action for the authors to take, which is to include such benchmarks to enhance the usability and availability of the work to the community. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use benchmarks to enhance the usability and availability of the work, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where this suggestion fits. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using evaluation benchmarks of the user simulator would demonstrate how smaller models perform as user simulators, making the benchmark more usable and available to the community. However, the comment does not provide specific examples or references to support this claim, nor does it explain why this would be important or how it would enhance the work. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance and relevance of the suggestion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an important enhancement to the paper by recommending the use of evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the usability and availability of their work to the community. By incorporating these benchmarks, the authors can enhance the impact and applicability of their research. However, the comment could be more helpful if it included specific examples or references to similar benchmarks or evaluations. Overall, the feedback is mostly helpful as it offers a clear suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should conduct experiments, provide a discussion, or make any specific changes to address this issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in asking about the impact of open-set detectors, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the impact of open-set detectors on the performance of the proposed method. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the impact of open-set detectors on the performance of the proposed method. This is a valid concern that could influence the evaluation and interpretation of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the impact they should consider. While it highlights an important area for exploration, it lacks actionable feedback or detailed suggestions, making it somewhat helpful. The authors are given a direction to consider but are not provided with a clear path to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate observations. The first observation notes the presence of a star in Table 1 without an explanation, suggesting that the authors should clarify or fix this. The second observation questions the meaning of \"from-scratch\" in Table 5, asking for clarification or correction. Both observations imply actions for the authors to take, but they are not explicitly stated. The actions are concrete, as the authors know they need to provide explanations or corrections for the symbols and clarify the meaning of \"from-scratch.\" Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the symbols and the clarification needed for \"from-scratch\" in Table 5. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate observations. The first observation questions the absence of an explanation for the star symbol in Table 1, which is a factual statement that does not require verification. The second observation questions the meaning of \"from-scratch\" in Table 5, which is also a factual statement. Therefore, the overall comment is composed of factual statements, making it \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of explanation for the star symbol in Table 1 and the ambiguity regarding the meaning of \"from-scratch\" in Table 5. By pointing out these inconsistencies, the comment provides clear and actionable feedback that can help the authors improve the clarity and accuracy of their tables. However, the comment could be more helpful if it offered suggestions on how to clarify these points or provided examples of how to address them. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. However, the comment does not provide explicit guidance or suggestions for the authors to address this observation. It lacks concrete actions or detailed advice on how the authors might explore or explain this phenomenon further. The feedback is vague and does not offer a clear path for the authors to take in response to the comment, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. This provides clear guidance on what aspect of the results is being questioned and how it could be further explored. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. This observation challenges the authors to reconsider their findings and provides a potential explanation for the results. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or further explore the phenomenon. While it prompts the authors to consider an alternative explanation, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. However, the comment does not provide explicit guidance or suggestions for the authors to address this observation. It lacks concrete actions or detailed advice on how the authors might explore or explain this phenomenon further. The feedback is vague and does not offer a clear path for the authors to take in response to the comment, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. This provides clear guidance on what aspect of the results is being questioned and how it could be further explored. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the expected relationship between transferability and noise intensity, suggesting that as inputs become increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. This observation challenges the authors to reconsider their findings and provides a potential explanation for the results. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or further explore the phenomenon. While it prompts the authors to consider an alternative explanation, it lacks actionable advice, making it somewhat helpful. Therefore, the"}
{"generated_text": "{'actionability_rationale': 'The review point provides several explicit actions for the authors to take. First, it suggests conducting ablation studies with only importance weighting or the rejection to better understand their effects, which is a clear and concrete action. Additionally, it points out the issue with the font size in figures and requests an explanation for the ChopperCommand results in Fig. 6(a). These suggestions are direct and provide specific guidance on what the authors need to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"ablation studies,\" \"the fonts in the figures,\" and \"Fig. 6(a). This allows the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as conducting ablation studies to understand the effects of importance weighting or rejection, and requesting an explanation for the ChopperCommand results in Fig. 6(a). Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes several claims. First, it suggests that conducting ablation studies with only importance weighting or the rejection would help understand their effects better. This is a logical suggestion based on common practices in research, making it somewhat verifiable. However, the comment lacks specific examples or references to support the claim about the effects of these components. Additionally, the comment mentions the issue with the font size in figures and requests an explanation for the ChopperCommand results in Fig. 6(a), which are specific observations but do not require justification. Overall, the comment provides some support for its claims but lacks detailed evidence or references, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It suggests conducting ablation studies to better understand the effects of importance weighting or rejection, which is a clear and concrete recommendation. Additionally, it points out the issue with the font size in figures and requests an explanation for the ChopperCommand results in Fig. 6(a). This feedback is specific and provides the authors with clear directions on how to enhance their draft. However, the comment could be more helpful if it offered additional insights or suggestions for explaining the ChopperCommand results. Overall, the comment is mostly helpful as it provides valuable guidance for improving the manuscript.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of technical clarity regarding the main learning framework, specifically mentioning the need to explain the implementation of the balancing term and the penalty term. While the comment highlights a specific area that requires clarification, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to provide more detailed explanations or examples of these terms, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but does not offer detailed instructions on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main learning framework Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanation for the implementation of the balancing term and the penalty term. This provides clear guidance on what the authors need to clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning the lack of explanation for the main learning framework Equation (18) and the implementation of the balancing term and penalty term. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of weakness in the paper, namely the lack of technical clarity regarding the main learning framework, Equation (18), and the implementation of the balancing term and penalty term. By pointing out these areas that need clarification, the comment provides the authors with a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to enhance the technical clarity or provided examples of how to explain these concepts more effectively. Overall, the feedback is somewhat helpful as it highlights a critical area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation and the use of 2D projections to represent high-dimensional decision boundaries. It suggests that the authors clarify how well the fixed tessellations with updated predictions capture the model\\'s behavior and acknowledges the potential variability in results based on the projection method and parameters. While the comment identifies specific areas of concern, it does not provide explicit instructions or concrete steps for addressing these issues. The authors are left to infer that they need to clarify and possibly revise their approach, but the lack of detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"figures\" and \"Voronoi tesselation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns about the fixed tessellations and the use of 2D projections to represent high-dimensional decision boundaries. The comment clearly specifies what needs to be addressed, such as clarifying how well the fixed tessellations capture the model\\'s behavior and acknowledging the variability in results based on projection methods. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation, specifically noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. The reviewer suggests that the authors clarify how well these fixed tessellations capture the model\\'s behavior with updated predictions. Additionally, the comment questions the use of 2D projections to represent high-dimensional decision boundaries, noting the potential variability based on projection methods and parameters. While the comment identifies specific areas of concern, it lacks detailed examples or references to support the claim about the fixed tessellations and the variability of results. This makes the claim somewhat verifiable, as the authors would need to further explore and address these concerns themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the decision boundary generation, noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. It suggests that the authors clarify how well these fixed tessellations capture the model\\'s behavior with updated predictions. Additionally, it raises concerns about the use of 2D projections to represent high-dimensional decision boundaries, acknowledging the potential variability based on projection methods and parameters. This feedback is clear and actionable, as it directs the authors to address the limitations in their approach and provides a rationale for improvement. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these concerns. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of an ablation study and the lack of comparison to methods from the past decade. While it identifies specific areas that need attention, it does not provide explicit instructions on how to conduct these studies or what specific comparisons should be made. The actions are implicit and somewhat vague, as the authors can infer that they need to include an ablation study and compare their methods to those from the past decade, but they are not given detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out the absence of an ablation study and the lack of comparison to methods from the past decade. However, it does not specify which part of the paper should include these elements, making it weakly grounded. The comment is specific in identifying the need for an ablation study and a comparison to past methods, but without explicit references to sections or figures, the authors may struggle to pinpoint where these additions should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study and does not compare its methods to those from the past decade. However, it does not provide any specific examples or reasoning to support why these additions are necessary or how they would improve the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas where the paper could be improved: the absence of an ablation study and the lack of comparison to methods from the past decade. This feedback is clear and actionable, as it provides the authors with concrete steps to enhance their work by including these elements. However, the comment could be more helpful if it offered suggestions on how to conduct the ablation study or which past methods to compare with. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While the comment implies that the authors should expand their theoretical analysis to cover more complex models, it does not provide specific guidance on which models to focus on or how to conduct this expansion. The action is implicit and somewhat vague, as the authors need to infer the specific models to consider and the level of detail required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, it does not specify which sections or parts of the paper should include these additional results, making it weakly grounded. The comment is specific in its suggestion to include more theoretical results on more complicated models, but without clear grounding, the authors may struggle to identify the exact sections that need expansion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these additional results are necessary or how they would enhance the paper. Without such evidence or justification, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide guidance on which specific models or aspects should be considered. Without detailed suggestions or examples, the authors may find it challenging to determine how to address this feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for expansion but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifies that the existing results in Fig. 11 are insufficient for this purpose, leaving the authors with a clear action to take: conduct additional ablation studies. The comment is explicit and provides concrete guidance on what needs to be added to strengthen the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, specifically mentioning Fig. 11. This provides full grounding as it explicitly references a specific figure in the paper. The comment is also specific because it clearly specifies what needs to be addressed: additional ablation studies to demonstrate the necessity of the proposed DA Inversion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing Fig. 11 as insufficient. However, the comment lacks specific examples or detailed reasoning to support why additional studies are necessary or how they would enhance the demonstration. The claim is somewhat verifiable as it points out a potential gap in the current evidence, but it lacks the depth and specificity needed for a fully verifiable claim. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It highlights that the existing results in Fig. 11 are insufficient for this purpose, providing a clear and actionable suggestion for the authors to enhance their paper. By recommending additional studies, the comment offers a concrete way for the authors to strengthen their argument and provide more evidence for the necessity of their proposed method. However, the comment could be more helpful if it provided specific guidance on how to design these additional studies or what aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of clustering in the 2nd phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this issue. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to conduct one or provide specific guidance on how to structure the ablation. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of clustering in the 2nd phase of training and suggests that a clear ablation study should be presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of clustering in the 2nd phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. The reviewer suggests that a clear ablation study should be presented to address this issue. While the comment raises a valid concern, it lacks specific examples or references to support the claim that clustering is unnecessary. The suggestion for an ablation study provides some direction, but the initial claim is not fully substantiated with evidence or reasoning. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the necessity of clustering in the 2nd phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this issue. This feedback is valuable as it prompts the authors to reconsider the utility of clustering and provides a specific direction for improvement by recommending an ablation study. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies a potential area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment mentions that the forgetting in Fig2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or what changes, if any, are needed in their figures or analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by noting that the forgetting in Fig2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the forgetting in Fig2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the forgetting behavior in Fig2a, noting that it is not as drastic as in class incremental and even shows a slight increase near epoch 150. This feedback is somewhat helpful as it highlights a potential area of concern or discrepancy in the results. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable advice or detailed feedback, the authors may find it challenging to effectively use this comment to enhance their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While the comment implies that this is a necessary addition, it does not explicitly instruct the authors to make this change or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should make this addition and determine the best way to present it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not provide any specific reasoning or evidence to support why this is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While this is a relevant point, the comment lacks specificity and does not provide detailed guidance on how to present this information or why it is important. It does not offer actionable advice or examples of how to effectively communicate this aspect of the work. As a result, the feedback is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While the comment implies that this is a necessary addition, it does not explicitly instruct the authors to make this change or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should make this addition and determine the best way to present it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in suggesting a potential improvement but lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not provide any specific reasoning or evidence to support why this is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While this is a relevant point, the comment lacks specificity and does not provide detailed guidance on how to present this information or why it is important. It does not offer actionable advice or examples of how to effectively communicate this aspect of the work. As a result, the feedback is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While the comment implies that this is a necessary addition, it does not explicitly instruct the authors to make this change or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should make this addition and determine the best way to present it. Therefore, this comment"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the meaning of RMSD in Figure 3. It provides a specific question, \"is it the RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus?,\" which gives the authors a clear and direct action to take. The comment is specific and actionable, as it directly guides the authors on what needs to be clarified in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the meaning of RMSD, distinguishing between RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific area of confusion in the paper regarding the interpretation of RMSD in Figure 3. It provides a clear and direct question, asking whether RMSD refers to the RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus. This feedback is actionable, as it prompts the authors to clarify this point in their draft, ensuring that readers understand the meaning of RMSD in the context of their work. By addressing this clarification, the authors can improve the clarity and accuracy of their presentation. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It implies that the authors should address the question of whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to the sections discussing regret scaling or phase transitions, but this is not explicitly stated. The comment is specific in its suggestion to address the necessity of phase transitions and the question of smooth regret scaling. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the current treatment is insufficient, it does not provide specific examples or references to support this claim. The suggestion is logical and raises an important consideration, but without detailed justification or evidence, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. This feedback is clear and actionable, as it directs the authors to consider a specific aspect of their work that may be overlooked. By addressing this point, the authors could enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided additional context or suggestions on how to explore this question further. Overall, the comment is mostly helpful, as it identifies a meaningful area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies an action, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors might infer that it relates to sections discussing regret scaling or phase transitions, but this is not explicitly stated. The comment is specific in its suggestion to address the necessity of phase transitions and the question of smooth regret scaling. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It raises a specific question about whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the current treatment is insufficient, it does not provide specific examples or references to support this claim. The suggestion is logical and raises an important consideration, but without detailed justification or evidence, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label':"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper, noting that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. While the comment implies that the authors should clarify the inclusion of these prior works, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to address the issue of missing comparisons and clarify the inclusion of prior works. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper regarding the lack of comparison to previous robust RL methods, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. However, the comment does not specify which part of the paper should include these comparisons or where the authors should clarify the inclusion of prior works. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the authors should be explicit about the inclusion of prior works, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparisons to previous robust RL methods are missing, despite these methods being cited. The reviewer suggests that if GAD or EG already include these prior works, the authors should be explicit about this. However, the comment lacks specific examples or references to the cited methods, making it difficult for the authors to understand which methods are missing or how to address the issue. This lack of detailed justification or examples results in the comment being unverifiable, as it does not provide sufficient evidence or reasoning to support the claim. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. This feedback is somewhat helpful as it points out a gap in the paper that could be addressed to strengthen the comparison and context. However, the comment lacks specific guidance on how to make these comparisons more explicit or what aspects of the prior works should be highlighted. To be more helpful, the comment could provide examples or suggestions on how to incorporate these comparisons effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the paper, noting that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. While the comment implies that the authors should clarify the inclusion of prior works, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors can infer that they need to address the issue of missing comparisons and clarify the inclusion of prior works. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a potential issue with the paper, noting that comparisons to previous robust reinforcement learning (RL) methods are missing, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. However, the comment does not specify which part of the paper should include these comparisons or where the authors should clarify the inclusion of prior works. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the authors should be explicit about the inclusion of prior works, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparisons to previous robust RL methods are missing, despite these methods being cited. It suggests that if GAD or EG already include these prior works, the authors should be explicit about this. However, the comment lacks specific examples or references to the cited methods, making it difficult for the authors to understand which methods are missing or how to address the issue. Without detailed justification or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper,"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is clear and direct, providing the authors with a specific action to take: to include more details about these aspects in their draft. The comment is concrete, as it specifies exactly what information is missing and what needs to be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for more details about the choice of parameters and learning objectives, but without explicit references to sections or figures, the authors may struggle to pinpoint where these details should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the choice of parameters ($k_1, k_2, k_3$), networks, and learning objectives. However, it does not provide any specific reasoning or evidence to support why these details are necessary or how they would improve the paper. The comment lacks context or examples, making it difficult for the authors to understand the significance of the suggestion. As a result, the claim is unverifiable due to the absence of supporting evidence or justification.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more details should be provided about the choice of parameters ($k_1, k_2, k_3$), the networks, and the learning objectives. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided examples or guidance on how to present this additional information effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify this relationship, provide an explanation, or make any changes to their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to a section discussing the methodology or results, but this inference is not direct. The comment is specific in questioning the relationship between the two variables, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback or specific advice, leaving the authors without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests including FTA as a baseline in the experiments. Second, it points out the inconsistency in comparing the method in a supervised learning setting but omitting it in a reinforcement learning (RL) setting, questioning the validity of the performance comparison. The reviewer provides a clear and explicit action for the authors to take, which is to include FTA as a baseline and justify the choice of methods in both settings. This feedback is concrete and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the choice of sparse representation learning method and the inclusion of FTA as a baseline in the experiments. It provides clear guidance on what needs to be addressed, such as justifying the choice of method and including FTA as a baseline. However, it does not explicitly mention which part of the paper these issues pertain to, such as the methodology or results sections. The authors can infer that these issues relate to the methodology and results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests including FTA as a baseline in the experiments. The reviewer provides a logical argument by questioning the omission of FTA in the reinforcement learning setting, which could affect the validity of the performance comparison. This reasoning is clear and supports the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the need for a rigorous comparison. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises two important points. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests including FTA as a baseline in the experiments. This feedback is actionable and provides a clear direction for the authors to improve their methodology by justifying their choice of method and ensuring a comprehensive comparison. Second, the comment points out an inconsistency in the experimental setup, questioning why the method is compared in a supervised learning setting but omitted in a reinforcement learning setting. This observation highlights a potential gap in the paper that needs to be addressed. The comment is mostly helpful as it identifies specific areas for improvement and provides clear guidance on how to enhance the rigor and comprehensiveness of the paper. However, it could be more helpful if it offered additional suggestions or examples for addressing these issues. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation for the choice of shift and scaling described on page 4, line 154, where the authors claim it is the more appropriate choice. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply points out the missing explanation without suggesting how the authors should address this issue. As a result, the authors are left without guidance on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation for the choice of shift and scaling described in that section, clearly specifying what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors neglect to explain why a particular choice of shift and scaling is more appropriate. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of explanation for the choice of shift and scaling described on page 4, line 154. It points out that the authors claim this choice is more appropriate but fail to provide justification or reasoning. This feedback is clear and actionable, as it directs the authors to include an explanation for their choice, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present this explanation or what aspects of the choice are crucial to justify. Overall, the comment is mostly helpful as it highlights a gap in the paper and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors revise the use of \"partial inference of GFlowNets\" in the title and elsewhere, indicating a clear and direct action for the authors to take. However, it does not provide specific guidance on how to revise this, such as suggesting alternative phrasing or terminology. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology and suggests a revision. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"partial inference of GFlowNets\" in the title and elsewhere is an issue and suggests revision. However, the comment does not provide any reasoning, examples, or references to support why this terminology is problematic or how it could be improved. Without additional context or justification, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the title and elsewhere in the paper, suggesting that \"partial inference of GFlowNets\" should be revised. While it highlights a potential inconsistency or confusion in the terminology, it does not provide further explanation or suggestions on how to address this issue. The comment lacks depth and actionable guidance, leaving the authors with a general suggestion but no clear direction on how to implement the revision. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making the necessary changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only uses bertscore to measure the similarity of the newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not provide specific guidance on which matrices to consider or how to incorporate them into the analysis. The action is implicit, as the authors need to infer that they should explore additional metrics, and it is vague because it lacks concrete suggestions on how to implement this change. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"bertscore\" and the need to discuss other matrices for measuring the stealthiness of the generated content. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is under-specific because it does not specify which other matrices should be considered or how they could be incorporated into the analysis. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper only measures similarity using bertscore and suggests that there are other matrices that could measure the stealthiness of the generated content. However, the comment does not provide specific examples or references to these alternative matrices, making it difficult for the authors to understand or address the suggestion. The lack of detailed justification or examples renders the claim borderline verifiable, as it provides some direction but insufficient support. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that it only uses bertscore to measure the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which is a valuable observation. However, the comment lacks specific guidance or suggestions on which alternative matrices to consider or how to incorporate them into the analysis. While it highlights an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues that need to be addressed, including the need to clearly highlight the issues with existing estimators and the lack of defined basic notation. It also points out specific elements of the notation that are unclear, such as the dimensionality p, the unit ball S_p, the outer product (v) \u2297 2, the constraint set \u0398, and the constant d^2. While the comment identifies these areas that require clarification, it does not provide explicit guidance on how to address them. The authors can infer that they need to clarify these elements, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the issues with existing estimators, the lack of defined basic notation, and the unclear elements of the notation, such as the dimensionality p, the unit ball S_p, and the constant d^2. This allows the authors to accurately identify the parts of the paper being addressed. However, the comment lacks specificity in terms of what needs to be clarified or improved regarding the heuristic nature of Algorithm 1. While it points out several areas that need clarification, it does not provide detailed guidance on how to address these issues. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises concerns about the clarity of the paper, specifically regarding the notation and the heuristic nature of Algorithm 1. It highlights specific elements of the notation that are unclear, such as the dimensionality p, the unit ball S_p, and the constant d^2. However, the comment does not provide detailed reasoning or examples to support why these elements are unclear or how they impact the clarity of the paper. The lack of specific examples or detailed explanation makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific areas where the paper could be improved, including the need to highlight the issues with existing estimators and the lack of defined basic notation. It provides examples of unclear elements, such as the dimensionality p, the unit ball S_p, and the constant d^2, which helps the authors pinpoint areas that require clarification. However, the comment lacks detailed guidance on how to address these issues or suggestions for improvement. While it points out important areas for clarification, it does not offer actionable steps or specific examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several specific areas for improvement, including the need to highlight issues with existing estimators and the lack of defined basic notation. It provides examples of unclear elements, such as the dimensionality p, the unit ball S_p, and the constant d^2, which helps the authors identify areas that require clarification. However, the comment does not provide explicit guidance on how to address these issues or suggest specific changes to make the notation clearer. While the authors can infer that they need to clarify these elements, the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific elements of the paper, such as the issues with existing estimators and the lack of defined basic notation. It also points out specific elements of the notation that are unclear, such as the dimensionality p, the unit ball S_p, and the constant d^2. This allows the authors to accurately identify the parts of the paper being addressed. However, the comment lacks specificity in terms of what needs to be clarified or improved regarding the heuristic nature of Algorithm 1. While it points out several areas that need clarification, it does not provide detailed guidance on how to address these issues. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': \"The review point raises concerns about the clarity of the paper, specifically regarding the notation and the heuristic nature of Algorithm 1. It highlights specific elements of the notation that are unclear, such as the dimensionality p, the unit ball S_p, and the constant d^2. However, the comment lacks detailed reasoning or examples to support why these elements are unclear or how they impact the clarity of the paper. The lack of specific examples or detailed explanation makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is somewhat verifiable,"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions using three perceptual loss functions for PSR, two of which are new, but does not specify which parts of the loss functions are novel. The reviewer suggests that the authors should elaborate on which parts of the loss functions are new. This feedback provides a clear and explicit action for the authors to take, which is to provide more details about the novel aspects of the loss functions. The suggestion is concrete, as it directly guides the authors on what additional information to include in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s claim about using three perceptual loss functions for PSR, two of which are new. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, elaborating on which parts of the loss functions are new. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the novelty of the loss functions mentioned in the paper, stating that the neural network and loss functions used (reconstruction error, TV, perceptual loss, and dice) are not new in the field of medical imaging. The reviewer suggests that the authors elaborate on which parts of the loss functions are novel. While the comment raises a valid concern about the novelty of the loss functions, it lacks specific examples or references to support the claim that these functions are not new. This makes the claim somewhat verifiable, as the authors would need to further investigate to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s claim that three perceptual loss functions for PSR are new, noting that the neural network and loss functions used (reconstruction error, TV, perceptual loss, and dice) are not novel in the field of medical imaging. The reviewer suggests that the authors should elaborate on which parts of the loss functions are new. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the novelty of their approach. By addressing this point, the authors can clarify their contribution and differentiate their work from existing methods. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on the novelty of the loss functions. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and originality of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results do not exhibit significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset, specifically mentioning Table 5 in [1]. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to enhance the experimental results to demonstrate significant improvements and possibly provide additional comparisons or analyses. However, the lack of detailed instructions or examples makes the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5 in [1],\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by pointing out that the experimental results do not exhibit significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not exhibit significant improvement in real-life datasets and criticizes the comparison on the ZINC dataset. However, the comment lacks specific examples or detailed reasoning to support these claims. The mention of \"Table 5 in [1]\" provides some context, but without further elaboration, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the experimental results, noting that they do not exhibit any significant improvement in real-life datasets. It also critiques the comparison on the ZINC dataset, specifically mentioning Table 5 in [1]. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their experimental results. Providing more detailed feedback or actionable steps would make the comment more helpful. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that the SLM performs better than larger models due to limited data availability. It provides examples from various experiments, such as Figure 3(b) showing LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to refute or clarify the claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or explanation to support their claim. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3(b)\" and provides specific examples of experiments, such as LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the claim that the SLM performs better than larger models due to limited data availability, providing concrete examples from the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b), which show that larger models perform better than smaller ones. This evidence is clear and detailed, making the claim mostly verifiable. However, the comment could be strengthened by providing more context or references to the experiments mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b), which show that larger models perform better than smaller ones. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and provide a more robust explanation or evidence to support their argument. However, the comment could be more helpful if it offered suggestions on how to address the issue or provide additional context. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification or revision, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b), which show that larger models perform better than smaller ones. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to refute or clarify the claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional evidence or explanation to support their claim. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3(b)\" and provides specific examples of experiments, such as LucaOne performing better than BSM models and BSM-270M model performing better than BSM-110M model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with the claim that the SLM performs better than larger models due to limited data availability, providing concrete examples from the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b), which show that larger models perform better than smaller ones. This evidence is clear and detailed, making the claim mostly verifiable. However, the comment could be strengthened by providing more context or references to the experiments mentioned, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b), which show that larger models perform better than smaller ones. This feedback is clear and actionable, as it directs the authors to reconsider their claim and provide a more robust explanation or evidence to support their argument. However, the comment could be more helpful if"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an inconsistency in the notation, specifically mentioning the issue with the notation for nu in Figures 2 & 3 and again in Figures 4. It also notes a change in notation on Page 4. While the comment identifies specific areas of inconsistency, it does not provide explicit guidance on how to resolve these issues. The authors can infer that they need to ensure consistency in notation throughout the paper, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figures 2, 3, and 4, as well as Page 4, allowing the authors to accurately identify the areas being addressed. It is also specific because it details the issue of notation inconsistency, particularly with the notation for nu. The comment provides clear guidance on what needs to be addressed, namely the need for consistent notation throughout the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, specifically mentioning the issue with the notation for nu in Figures 2 & 3 and again in Figures 4, and on Page 4. However, the comment does not provide specific examples or detailed reasoning to support the claim of inconsistency. Without explicit references to the exact notations that are inconsistent, the authors may find it challenging to identify and correct the issues. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in the paper, noting inconsistencies in the use of notation for nu across different sections and figures. This feedback is valuable as it highlights a potential source of confusion for readers, which could impact the clarity and understanding of the paper. By pointing out these inconsistencies, the comment provides actionable guidance for the authors to ensure consistency in notation throughout the paper. However, the comment could be more helpful if it suggested specific ways to address the inconsistency or provided examples of how to maintain consistency. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors conduct more experiments in challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This is a clear and direct action for the authors to take, providing them with a specific direction for improvement. The comment also includes a reference to a relevant paper, which can guide the authors in setting up the experiments. Therefore, the action is explicit and concrete, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically dexterous manipulations in Adroit. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the methodology. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. The comment is specific in suggesting a particular type of experiment to conduct, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments in challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. However, the comment does not provide any specific reasoning or evidence to support why these tasks are more challenging or why they would better validate the method. The suggestion is vague and lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This feedback is clear and actionable, providing a specific direction for the authors to enhance the robustness and applicability of their work. By suggesting a particular type of experiment, the comment offers a concrete way for the authors to improve their draft. However, it could be more helpful if it included additional guidance on how to design or interpret these experiments. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction, specifically regarding the assumptions made by Williams et al. (2019), Lyu et al. (2021), Boursier et al. (2022), and Wang & Ma (2023). It suggests that some of these papers assume linear separability, which is a stronger assumption than the feature direction of each arbitrary training sample acting as a perfect linear classifier. The reviewer also asks if this refers to orthogonally separable data. While the comment implies that the authors should clarify or address these assumptions, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the fairness of the summary. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the summary of the referenced papers, highlighting the assumption of linear separability and questioning the strength of the assumption. The comment further provides a link to a specific type of data, orthogonally separable data, which could be relevant to the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary in the introduction regarding the assumptions made by various papers. It highlights that some papers assume linear separability, which is a stronger assumption than the feature direction of each arbitrary training sample acting as a perfect linear classifier. The comment also asks if this refers to orthogonally separable data. While the comment raises a valid concern about the assumptions made, it lacks specific examples or references to support the claim that these assumptions are unfair. The mention of orthogonally separable data provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the summary in the introduction, particularly regarding the assumptions made by various papers. It highlights that some papers assume linear separability, which is a stronger assumption than the feature direction of each arbitrary training sample acting as a perfect linear classifier. The comment also raises a question about whether this refers to orthogonally separable data. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s presentation and encourages the authors to clarify or address these assumptions. However, the comment could be more helpful if it provided specific suggestions on how to improve the fairness of the summary or offered examples of how to better present these assumptions. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the fairness of the summary in the introduction, particularly regarding the assumptions made by various papers. It highlights that some papers assume linear separability, which is a stronger assumption than the feature direction of each arbitrary training sample acting as a perfect linear classifier. The comment also raises a question about whether this refers to orthogonally separable data. While the comment implies that the authors should clarify or address these assumptions, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the fairness of the summary. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the fairness of the summary, highlighting the assumptions made by various papers and questioning the strength of the assumptions. The comment further provides a link to a specific type of data, orthogonally separable data, which could be relevant to the discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the fairness of the summary in the introduction regarding the assumptions made by various papers. It highlights that some papers assume linear separability, which is a stronger assumption than the feature direction of each arbitrary training sample acting as a perfect linear classifier. The comment also raises a question about whether this refers to orthogonally separable data. While the comment raises a valid concern about the assumptions made, it lacks specific examples or references to support the"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from zero during training iterations. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the method. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that it holds only when the upweight is very close to 0 and may not accurately reflect each sample\\'s influence when weights are far from 0 during training iterations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability of the per-sample weight tuning method, specifically the influence function. It claims that the theoretical approximation of each sample\\'s contribution from Taylor\\'s first-order expansion is not valid when the weights are far from zero. This claim is somewhat verifiable as it provides a logical reasoning based on the limitations of Taylor\\'s first-order expansion. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to further investigate and possibly provide additional evidence to fully address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from zero during training iterations. This is a critical observation that could impact the reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from zero during training iterations. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific improvements. The feedback lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that it may not accurately reflect each sample\\'s influence when weights are far from zero during training iterations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability of the per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from zero during training iterations. The comment provides a logical reasoning based on the limitations of Taylor\\'s first-order expansion, which supports the claim. However, it lacks specific examples or references to fully substantiate the claim, making it somewhat verifiable. The authors would need to further investigate and possibly provide additional evidence to fully address the concern. Therefore, the comment is rated as somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s per-sample weight tuning method, specifically noting that the influence function may not accurately reflect each sample\\'s influence when the weights are far from zero during training iterations. This is a critical observation that could impact the reliability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with centering in partial shapes and scenes, suggesting that centering may not be well-defined for such cases. It explicitly advises the authors to address this issue. Additionally, it provides a relevant observation about the experiment with up to 50% missing points, noting that the ground-truth center is provided in this case but may not be in general. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be addressed and how to implement the suggested improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Centering in Partial Shapes and Scenes,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that centering may not be well-defined for partial shapes or scenes and suggests that the authors address this issue. The comment is specific in detailing what needs to be addressed, providing clear guidance on the potential problem and its implications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the applicability of centering for partial shapes and scenes, suggesting that it may not be well-defined in such cases. The reviewer provides a logical reasoning by pointing out that centering is effective for complete shapes but may not be suitable for partial ones. This reasoning is supported by the observation that the experiment with up to 50% missing points assumes a known ground-truth center, which may not be the case in general when training with partial shapes. While the comment lacks specific references or examples, the logical reasoning and the comparison to complete shapes provide a reasonable basis for the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with centering in partial shapes and scenes, noting that centering may not be well-defined for such cases. It provides a clear and actionable suggestion for the authors to address this issue, which is important for the robustness and applicability of their method. Additionally, the comment points out a limitation in the experimental setup, where the ground-truth center is provided for up to 50% missing points, which may not be the case in general. This feedback is valuable as it guides the authors to consider broader scenarios and improve the relevance of their experiments. However, the comment could be more helpful if it offered specific suggestions on how to address the issue of centering for partial shapes or scenes. Overall, the comment is mostly helpful, as it provides clear guidance on a critical aspect of the work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an action for the authors to take, which is to ensemble models trained with the proposed negative augmentations and without them to see if it improves performance. This is an explicit suggestion with concrete details on how to implement the action, providing clear guidance on what the authors should do to enhance their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, suggesting an action related to the texture semantics and the use of negative samples. It references a similar approach from [1] and proposes an ensemble of models trained with and without the proposed negative augmentations. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The suggestion is specific, as it provides a clear direction for the authors to explore an ensemble approach to improve performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an action for the authors to take, which is to ensemble models trained with and without the proposed negative augmentations. While the comment provides a logical reasoning for this suggestion, it lacks specific references or examples from the literature to fully substantiate the claim. The suggestion is based on a comparison with a similar approach in [1], but without detailed examples or references, the authors may find it challenging to fully understand and implement the suggestion. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for the authors to explore an ensemble of models trained with and without the proposed negative augmentations. This is a constructive suggestion that could potentially enhance the performance of the models discussed in the paper. By suggesting a method to test the effectiveness of the proposed augmentation, the comment offers a clear and actionable direction for improvement. However, the comment could be more helpful if it included additional details on how to implement the ensemble approach or discussed potential benefits. Overall, the feedback is mostly helpful as it provides a clear direction for enhancing the study, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities and mentions a discrepancy between the partitioning method used in the main text and Appendix B. It also references a claim about the sample efficiency of Eq. 7 over Eq. 7 in the main text and Appendix B. While the comment highlights specific areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify or justify the claims about sample efficiency and the partitioning method, but the comment lacks concrete steps or detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide clear guidance on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"page 6,\" \"page 5,\" and \"Appendix B,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the guarantee of D_i going through all possible transition probabilities and mentioning a discrepancy between the partitioning method used in the main text and Appendix B. The comment is specific in detailing what needs to be addressed, providing clear guidance on the areas of concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities and mentions a discrepancy between the partitioning method used in the main text and Appendix B. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims or questions. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the guarantee of D_i going through all possible transition probabilities, which is a critical aspect of the paper. It also points out a discrepancy between the partitioning method used in the main text and Appendix B, suggesting that the former uses one buffer with a different sampling method. This feedback is somewhat helpful as it highlights a potential weakness in the paper\\'s methodology and encourages the authors to clarify or justify their claims about sample efficiency. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered guidance on how to ensure that D_i adequately covers all transition probabilities. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the guarantee of D_i going through all possible transition probabilities and mentions a discrepancy between the partitioning method used in the main text and Appendix B. It also references a claim about the sample efficiency of Eq. 7 over Eq. 7 in the main text and Appendix B. While the comment identifies specific areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to clarify or justify the claims about sample efficiency and the partitioning method, but the comment lacks concrete steps or detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide clear guidance on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper, including \"page 6,\" \"page 5,\" and \"Appendix B,\" allowing the authors to accurately identify the parts being addressed. It also specifies the issue by questioning the guarantee of D_i going through all possible transition probabilities and mentioning a discrepancy between the partitioning method used in the main text and Appendix B. The comment is specific in detailing what needs to be addressed, providing clear guidance on the areas of concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the guarantee of D_i going through all possible transition probabilities and mentions a discrepancy between the partitioning method used in the main text and Appendix B. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims or questions. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific concern about the guarantee of D"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors form clusters for tokens in Figure 1 and notes that it is unclear in Section 3. While the comment highlights a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking about the method used to form clusters for tokens in Figure 1 and noting that it is unclear in Section 3. This provides clear guidance on what needs to be clarified or improved. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the methodology used to form clusters for tokens in Figure 1, as mentioned in Section 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology used to form clusters for tokens in Figure 1, noting that it is unclear in Section 3. This feedback is somewhat helpful as it identifies a potential area of confusion for the readers. However, it lacks depth and does not provide suggestions or guidance on how the authors might clarify this aspect in their draft. To be more helpful, the comment could include suggestions on how to present the methodology or provide additional details to enhance clarity. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s potential application for large language models in real-world settings. While the comment identifies a problem, it does not provide specific guidance or suggestions on how the authors might address this issue, such as proposing alternative methods or strategies to reduce the complexity or time cost. The action is implicit and vague, as the authors are left to infer potential solutions on their own. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the introduction of additional hyperparameters in SimNPO, which increases the complexity and time cost of experiments. However, it does not specify which part of the paper discusses these hyperparameters or where they are introduced, making it weakly grounded. The comment is specific in detailing the issue with the additional hyperparameters and their impact on the method\\'s application, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that require manual adjustment for optimal performance, significantly increasing the complexity and time cost of experiments. This claim is somewhat verifiable as it provides a logical reasoning for the increased complexity and time cost, but it lacks specific examples or references to support the assertion about the impact on large language models in real-world settings. The comment could be strengthened by providing more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s potential application for large language models in real-world settings. The comment provides a clear and actionable insight into a critical weakness of the method, which can guide the authors in addressing the complexity and time cost issues. However, the comment could be more helpful if it offered suggestions on how to mitigate these issues or alternative approaches to consider. Overall, the feedback is mostly helpful as it highlights a key area for improvement and provides some direction for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the emphasis on affordance prompting, noting that it is overengineered and lacks sufficient demonstration of its advantages. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the presentation of affordance prompting. The feedback lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the emphasis on affordance prompting, noting that it is overengineered and lacks sufficient demonstration of its advantages. However, it does not specify which part of the paper this critique pertains to, such as a particular section or example, making it weakly grounded. The comment does specify what needs to be addressed\u2014namely, the overemphasis on affordance prompting and the lack of demonstration of its advantages. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the emphasis on affordance prompting, stating that it is overengineered and lacks sufficient demonstration of its advantages. However, the comment does not provide specific examples or detailed reasoning to support this claim, such as how the Pick&place example fails to illustrate the benefits of affordance prompting. Without concrete evidence or detailed explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the emphasis on affordance prompting, noting that it is overengineered and lacks sufficient demonstration of its advantages. However, it does not provide specific examples or detailed feedback on how the authors might address this issue or improve the presentation of affordance prompting. Without actionable suggestions or guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. While the action is explicit, it lacks concrete guidance on how to conduct these studies or which specific parts should be tested. The authors are given a clear direction to include ablation studies, but the comment could be more helpful by providing examples or detailed instructions on how to implement these studies. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the paper these studies should address, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where ablation studies could be relevant, the comment lacks full grounding. It is specific in suggesting the need for ablation studies but does not provide detailed guidance on how to conduct them. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not provide specific examples or detailed reasoning to support why these studies are necessary or how they would be beneficial. The claim lacks concrete evidence or references to substantiate the need for ablation studies, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This is a valuable suggestion as it highlights the importance of thoroughly evaluating the contributions of each component. However, the comment lacks specificity regarding which parts of the pipeline should be tested or how the ablation studies should be conducted. While it provides a clear direction for improvement, the feedback could be more actionable by offering detailed guidance or examples. Therefore, the comment is somewhat helpful, as it identifies an area for enhancement but does not fully support the authors in implementing the suggested changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra training cost. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance on how to address this concern or what specific analyses or experiments could be conducted to better demonstrate the necessity of the instruction-tuning stage. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage, which is a specific aspect of the paper. It raises a concern about the potential impact of additional training and tuning costs introduced by this stage, questioning whether the performance improvement could be attributed to these costs. However, the comment does not explicitly mention which part of the paper discusses the instruction-tuning stage, making it weakly grounded. The authors can infer that it relates to the conclusion section, but this inference is not direct. The comment is specific in detailing the concern about the necessity of the instruction-tuning stage and the potential impact of additional costs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. The reviewer questions whether the performance improvement could also be attributed to these costs. While the comment provides a logical reasoning by pointing out the potential impact of additional costs, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to further explore the implications of the instruction-tuning stage to address the concern fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the conclusion regarding the necessity of the instruction-tuning stage in MoE models. It raises a valid concern about the additional training and tuning costs introduced by this stage and questions whether the performance improvement could be attributed to these costs. This feedback is somewhat helpful as it prompts the authors to consider alternative explanations for the observed performance gains and encourages them to explore the impact of additional costs. However, the comment could be more helpful if it provided specific suggestions on how to address this concern or further analyses that could be conducted to strengthen the conclusion. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to these costs. While the comment implies that the authors should consider this possibility, it does not provide explicit guidance on how to address this concern or what specific analyses or experiments could be conducted to better demonstrate the necessity of the instruction-tuning stage. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It raises a question about whether the performance improvement could also be attributed to these costs. However, the comment does not explicitly mention which part of the paper discusses the instruction-tuning stage, making it weakly grounded. The authors can infer that it relates to the conclusion section, but this inference is not direct. The comment is specific in detailing the concern about the necessity of the instruction-tuning stage and the potential impact of additional costs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to these costs. While the comment provides a logical reasoning by pointing out the potential impact of additional costs, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to further explore the implications of the instruction-tuning stage to address the concern fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the evaluation setup is outdated and suggests that the authors update it to reflect more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. It also recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback provides clear and concrete actions for the authors to take, specifying both the need for updating the evaluation setup and the type of setup that would be more challenging and representative. The authors know exactly what changes to make and why, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"evaluation setup\" and references specific models like Llama-1 and Mistral-v0.1, as well as more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it suggests updating the evaluation setup to reflect more recent models and recommends testing the approach on a challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated and suggests that the authors update it to reflect more recent models and advancements in quality. The reviewer provides specific examples of models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2, which have been released more recently and are more advanced than those used in the current evaluation. Additionally, the reviewer suggests testing the approach on a more challenging setup, such as instruction tuning on Alpaca/OASST. This provides a clear and detailed rationale for the claim, making it fully verifiable. The use of specific examples and a suggestion for a more challenging setup strengthens the justification, allowing the authors to understand the basis of the critique and make informed improvements.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated and does not reflect recent advancements in model quality. It provides specific examples of models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2, which have been released more recently and are more advanced. The reviewer also suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback is highly actionable, as it not only points out the need for updating the evaluation setup but also provides concrete suggestions for improvement. By addressing these points, the authors can significantly enhance the relevance and impact of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of logical coherence in the second section, resulting in a somewhat disorganized content. However, it does not provide specific guidance on how the authors should address this issue or suggest ways to improve the logical structure. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to enhance the coherence of their content. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of logical coherence and the resulting disorganized content. However, the comment does not provide specific suggestions or examples of how to improve the logical structure, which would make it more actionable. Therefore, this comment is fully grounded and under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence, resulting in a disorganized content. However, it does not provide specific examples or detailed reasoning to support this claim. Without explicit references to sections or specific issues, the authors may find it challenging to understand and address the problem. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the second section of the paper, noting a lack of logical coherence that results in a somewhat disorganized content. While it highlights a potential problem, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable feedback or examples, the authors may find it challenging to improve the coherence of their content. Therefore, the comment is barely helpful, as it points out a problem but does not offer a clear path for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to mention the language they focus on when retrieving Reddit posts. This is a clear and direct action that the authors can take to address the comment. The feedback is specific and provides a concrete step for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to mention the language used for retrieving Reddit posts, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the language used for retrieval. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking the authors to mention the language they focus on when retrieving Reddit posts. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, instructing the authors to include a mention of the language they focus on when retrieving Reddit posts. This is a specific and straightforward piece of feedback that can help the authors improve the clarity and completeness of their work. By addressing this comment, the authors can enhance the transparency and reproducibility of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it provided additional context or suggestions on why mentioning the language is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of comparisons with recent works, specifically mentioning \"[1].\" However, it does not provide explicit guidance on which specific recent works should be included or how the comparisons should be made. The action is implicit, as the authors can infer that they need to add comparisons with recent works, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of comparisons with recent works, specifically mentioning \"[1].\" However, it does not specify which part of the paper should include these comparisons or where the comparisons are missing. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the mention of \"[1]\" provides some grounding, the comment lacks specificity regarding what specific comparisons are missing or how they should be integrated. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning \"[1].\" However, it does not provide any additional context, reasoning, or examples to support why these comparisons are necessary or how they would enhance the paper. Without further elaboration or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of comparisons with recent works, specifically mentioning \"[1].\" This feedback is clear and actionable, as it directs the authors to include comparisons with relevant recent works to strengthen their paper. However, the comment could be more helpful if it provided additional guidance on which specific recent works should be considered or how the comparisons should be structured. Overall, the comment is mostly helpful as it highlights a critical area for enhancement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this is a concern that needs addressing or how the authors might investigate this issue. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the applicability of TSG in a particular context, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. While this question highlights a potential area of interest or concern, it does not provide any actionable feedback or suggestions for the authors to address this issue. The comment lacks depth and does not offer guidance on how the authors might explore or address this question in their work. As a result, the comment is not helpful at all, as it does not provide the authors with any actionable steps or insights to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints to enhance reproducibility. It provides a clear and concrete action for the authors to take, specifying that they should attach these materials via anonymous repositories in the paper submission. This direct and specific guidance gives the authors a clear path to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of limited reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. This provides full grounding as it clearly identifies the parts of the paper that need to be addressed. The comment is also specific, as it outlines what needs to be released to enhance reproducibility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks reproducibility due to the absence of training code, dialogue dataset, and model checkpoints. The reviewer suggests attaching these materials via anonymous repositories to facilitate verification and reproducibility. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to attach materials is a logical step, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s reproducibility, emphasizing the need for the authors to release their training code, dialogue dataset, and model checkpoints. This feedback is clear and actionable, providing a direct suggestion for enhancing the paper\\'s verifiability and allowing reviewers and readers to replicate the results. By recommending the attachment of these materials via anonymous repositories, the comment offers a concrete step for the authors to take to improve the transparency and reproducibility of their work. This level of detail and specificity makes the comment highly helpful, as it empowers the authors to make significant improvements to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main result is somewhat obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main result is somewhat obvious because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the result are considered obvious or how the authors might address this concern. Without clear grounding or detailed feedback, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is obvious because gradient boosting minimizes objectives in functional space. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, it is difficult for the authors to understand the basis of the claim or how it relates to their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the main result is somewhat obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their results. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contribution of the work is insufficient and that the paper does not adequately explain the specifics of the proposed model. It also mentions the lack of related work and appropriate analysis. However, the comment does not provide explicit guidance or concrete suggestions on how the authors can address these issues. The feedback lacks actionable details, such as recommending specific areas for improvement or providing examples of what additional information or analysis could be included. As a result, the authors are left without a clear understanding of how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution of the work, stating that it is insufficient and not explicitly expressed in the paper. It also mentions that the work appears incomplete due to the lack of related work and appropriate analysis. However, the comment does not specify which parts of the paper are lacking in detail or analysis, making it difficult for the authors to pinpoint the exact areas needing improvement. While the authors might have an idea of where these issues might lie, the comment lacks full grounding and specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficient and not explicitly expressed in the paper. It also states that the work appears incomplete due to the lack of related work and appropriate analysis. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide enough information for the authors to address the issues effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the contribution is insufficient and not explicitly expressed. It also points out that the work appears incomplete due to the lack of related work and appropriate analysis. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the clarity and depth of their contribution. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a problem but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the interpretation of the results presented in Figure 2a and Figure 2b. It points out that the x-axis label \"item\" in Figure 2b is unclear and suggests that the training steps might refer to outer-loop iterations or raw experience. Additionally, it recommends that Figure 2a should also be given with iterations or training steps as the x-axis. While the comment explicitly states the need for clarification and suggests specific actions to improve the figures, it does not provide detailed guidance on how to implement these changes. The authors are given a clear direction but may need to infer the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the clarity of the training steps and suggesting that the x-axis label \"item\" in Figure 2b is unclear. Additionally, it recommends that Figure 2a should also be given with iterations or training steps as the x-axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the results presented in Figure 2a and Figure 2b. It questions the interpretation of the x-axis label \"item\" in Figure 2b and suggests that the training steps might refer to outer-loop iterations or raw experience. The comment also recommends that Figure 2a should be given with iterations or training steps as the x-axis. While the comment identifies potential issues with the clarity of the figures, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left with a general suggestion for improvement without a clear understanding of the exact problem or how to address it. Therefore, the comment is somewhat verifiable, as it provides some guidance but requires more detailed justification or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the results presented in Figure 2a and Figure 2b. It points out that the x-axis label \"item\" in Figure 2b is unclear and suggests that the training steps might refer to outer-loop iterations or raw experience. Additionally, it recommends that Figure 2a should also be given with iterations or training steps as the x-axis. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and interpretability of the figures. By addressing these points, the authors can enhance the comprehensibility of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the rationale behind using different metrics (flops, latency, and 1/FPS) for different hardware devices instead of a uniform cost. While the comment implies that the authors should consider using a consistent metric, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of using a uniform metric. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metrics used to evaluate different hardware devices, specifically questioning why different metrics like flops, latency, and 1/FPS are used instead of a uniform cost. However, it does not specify which part of the paper this question pertains to, such as a specific section or analysis. The authors can infer that it relates to the methodology or results sections where these metrics are discussed, but this inference is not direct. The comment is specific in its inquiry about the rationale behind the chosen metrics, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the rationale behind using different metrics (flops, latency, and 1/FPS) for different hardware devices instead of a uniform cost. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of metrics used to evaluate different hardware devices, specifically questioning why different metrics like flops, latency, and 1/FPS are used instead of a uniform cost. This feedback prompts the authors to reconsider their methodology and potentially improve the consistency and comprehensiveness of their analysis. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing a uniform metric or explaining the rationale behind the current choice of metrics. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the maximum iterations set in the experiments and whether these iterations might significantly slow down the training speed. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the two-dimensional Wasserstein distance and the application of the Sinkhorn algorithm. It raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. This provides a clear and specific issue for the authors to address, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the Sinkhorn algorithm to approximate the two-dimensional Wasserstein distance, noting that iterations are needed before each gradient descent. It asks about the maximum iterations set in the experiments and whether these iterations might significantly slow down the training speed. While the comment raises a valid concern about the computational efficiency of the method, it lacks specific examples or references to support the claim about the potential impact on training speed. The reasoning is logical but incomplete, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of the Sinkhorn algorithm to approximate the two-dimensional Wasserstein distance, noting that iterations are needed before each gradient descent. It specifically asks about the maximum iterations set in the experiments and whether these iterations might significantly slow down the training speed. This feedback is valuable as it prompts the authors to consider the computational efficiency of their approach and to provide more detailed information about their experimental setup. However, the comment could be more helpful if it suggested ways to address the potential issue of slow training speed or provided guidance on how to optimize the algorithm. Overall, the comment is mostly helpful as it identifies a relevant area for improvement and encourages the authors to provide additional information, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major weakness in the paper, specifically the lack of theoretical results to support the soundness of the method. It suggests that the current approach appears more like a heuristic rather than a theoretically sound method. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific theoretical results are needed. The action is implicit and vague, as the authors are left to infer that they need to provide theoretical results but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a major weakness in the paper, specifically the soundness of the method. It points out that the teacher policy is trained to maximize the distribution matching between the student policy\\'s state-action visiting distribution and the expert\\'s distribution, and questions whether the student policy can still perform correct distribution matching. The comment suggests that theoretical results are needed to support the soundness of the approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the soundness of the method and the need for theoretical results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical support for its soundness, specifically regarding the teacher policy\\'s ability to maximize distribution matching and its impact on the student policy. The reviewer suggests that the current approach appears more like a heuristic rather than a theoretically sound method. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim about the lack of theoretical results. This makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, specifically the lack of theoretical support for the soundness of the method. It points out that the teacher policy is trained to maximize distribution matching, but questions whether the student policy can still perform this matching correctly. The reviewer suggests that theoretical results are needed to validate the method, implying that it currently appears more like a heuristic rather than a theoretically sound approach. This feedback is clear and actionable, as it directs the authors to provide theoretical results to strengthen the paper\\'s foundation. However, the comment could be more helpful if it offered specific suggestions on how to derive these theoretical results or what aspects of the method need further theoretical exploration. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze and discuss the reasons for the proposed method\\'s poor performance in some classes in Table 3. While the action is implicit, it is clear that the authors need to provide an explanation and discussion of the observed performance issues. The comment does not provide specific guidance on how to conduct this analysis or what aspects to focus on, but it does give a clear direction for improvement. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the reasons for the proposed method\\'s poor performance in some classes. This provides clear guidance on what the authors need to analyze and discuss. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method does not perform well in some classes and recommends analyzing and discussing the reasons for this. However, the comment lacks specific examples or detailed reasoning to support the claim that the method performs poorly in certain classes. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method\\'s performance in certain classes, as evidenced by Table 3. It suggests that the authors should analyze and discuss the reasons for this poor performance. While the comment highlights an area for improvement, it lacks detailed guidance or suggestions on how to conduct the analysis or what specific aspects to focus on. Providing more context or examples would make the feedback more actionable. Therefore, the comment is somewhat helpful, as it directs the authors to an important area for improvement but does not fully support them in achieving it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that some settings are not rigorously designed. It provides an explicit action by suggesting that the MTT should be tested on unseen tasks to ensure robustness. Additionally, it implies that the experimental results should be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment does not explicitly instruct the authors to make these changes, the actions are clear and concrete, providing a direct path for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the variation of model behavior under different datasets or settings. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the experimental design and results, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. However, the comment lacks detailed reasoning or examples to support why this is a concern or how it impacts the results. The suggestion to discuss or explain the variation of model behavior under different datasets or settings is also vague and does not provide specific examples or references. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that some are not rigorously designed. It provides a clear example by suggesting that the MTT should be tested on unseen tasks to ensure robustness. Additionally, it implies that the experimental results should be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. This feedback is actionable and provides the authors with a clear direction for improving the rigor and comprehensiveness of their experimental design and results. However, the comment could be more helpful if it offered specific suggestions on how to implement these changes or examples of how to discuss the variation of model behavior. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the quality of their experimental analysis.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that some are not rigorously designed. It provides an explicit suggestion to test the MTT on unseen tasks to ensure robustness. Additionally, it implies that the experimental results should be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment does not explicitly instruct the authors to make these changes, the actions are clear and concrete, providing a direct path for improvement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies specific issues with the experimental settings, such as the need to test MTT on unseen tasks and the variation of model behavior under different datasets or settings. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the experimental design and results, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should be tested on unseen tasks. However, the comment lacks detailed reasoning or examples to support why this is a concern or how it impacts the results. The suggestion to discuss or explain the variation of model behavior under different datasets or settings is also vague and does not provide specific guidance on how to address these issues. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental settings, noting that some are not rigorously designed. It provides a clear and actionable suggestion by recommending that the MTT should be tested on unseen tasks to ensure robustness. Additionally, it implies that the experimental results should be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. This feedback is valuable as it guides the"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the data collection process, specifically whether it was randomized for the 5 layouts. It suggests that the data was collected in the same order, which could introduce learning effects across different layouts. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should investigate and possibly randomize the data collection process to mitigate learning effects. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the data collection process for the 5 layouts, specifically whether it was randomized. It suggests that the data was collected in the same order, which could introduce learning effects across different layouts. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the data collection process and suggesting a potential issue with learning effects. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the data collection process, specifically whether it was randomized for the 5 layouts. The reviewer suggests that the data was collected in the same order, which could introduce learning effects across different layouts. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the data collection process, specifically whether it was randomized for the 5 layouts. It suggests that the data was collected in the same order, which could introduce learning effects across different layouts. This feedback is valuable as it points out a potential issue that could affect the validity of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern, such as recommending a randomized data collection process or suggesting ways to mitigate learning effects. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether this is a misunderstanding, an oversight, or a point that needs clarification. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. This provides clear guidance on what aspect of the paper needs clarification or further explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or examples to justify why node ordering should not play a role. The comment lacks specific references or detailed explanations, making it difficult for the authors to understand and address the issue. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. While it identifies a potential area of confusion or misunderstanding, it does not provide any constructive feedback or suggestions for improvement. The comment lacks depth and does not offer guidance on how the authors might address this issue or clarify their approach. As a result, the comment is not helpful at all, as it does not provide actionable insights or suggestions for enhancing the draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they should consider to enhance the novelty of their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, it does not specify which part of the paper this comment pertains to, such as a specific section or discussion. The authors cannot confidently determine the exact part of the paper being addressed, making the comment weakly grounded. The comment is specific in identifying the potential issue with the novelty of the work, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, the comment does not provide specific details or examples from the referenced work to support this claim. It lacks detailed reasoning or evidence to substantiate why the previous work is considered a potential obstacle to the novelty of the current work. As a result, the claim is not fully verifiable, as it requires additional information or references to be substantiated. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment points out a potential issue with the novelty of the work, noting that a previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands. This feedback is somewhat helpful as it highlights a potential weakness in the novelty of the current work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed feedback, the authors may find it challenging to effectively respond to this critique. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights a potential issue with the novelty of the work due to the presence of a similar dexterous manipulation benchmark with musculoskeletal hands in previous work [5]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might differentiate their work or enhance its novelty. As a result, the comment lacks actionable content, making it unactionable. Therefore, the authors are left without a clear path forward for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, it does not specify which part of the paper this comment pertains to, such as a specific section or discussion. Without clear references or explicit mentions of sections, the authors cannot confidently determine the exact part of the paper being addressed. The comment lacks specificity in identifying what aspects of the current work are being compared to the previous work, making it difficult for the authors to understand the critique fully. Therefore, the comment is not grounded and lacks specificity, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, the comment does not provide specific details or examples from the referenced work to support this claim. It lacks detailed reasoning or evidence to substantiate why the previous work is considered a potential obstacle to the novelty of the current work. As a result, the claim is not fully verifiable, as it requires additional information or references to be substantiated. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a potential issue with the novelty of the work, noting that a previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which may detract from the novelty of the current work. However, the comment does not provide specific guidance or suggestions on how the"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the selection of datasets should be made clearer, including specifying the pool of datasets and the selection process. It provides examples of similar works, such as OpenML100 and OpenML CC-18, and mentions the need for detailed information on the selection of the splitting procedure and split ratios. While the comment does not explicitly instruct the authors to make these changes, the suggestions are clear and concrete, providing a direct path for improvement. The authors know exactly what needs to be done to enhance the clarity of their work, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of datasets as a main contribution and provides specific guidance on how to improve clarity. It suggests that the authors should specify the pool of datasets and the selection process, and provides examples of similar works, such as OpenML100 and OpenML CC-18, and references to Bischl et al. and Gijsbers et al. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of datasets is a main contribution and suggests that the selection process should be made clearer. It provides examples of similar works, such as OpenML100 and OpenML CC-18, which can serve as references for the authors. Additionally, it mentions the need for detailed information on the selection of the splitting procedure and split ratios. This provides a logical basis for the claim, as it references existing works and suggests specific areas for improvement. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current selection process is unclear. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the clarity of the dataset selection process. It suggests that the authors should provide more detailed information on the pool of datasets and the selection criteria, referencing examples from similar works like OpenML100 and OpenML CC-18. Additionally, it points out the need for detailed information on the selection of the splitting procedure and split ratios, noting that this aspect appears ad-hoc. The comment is highly helpful as it provides specific and actionable feedback, guiding the authors on how to enhance the clarity and rigor of their work. By addressing these points, the authors can significantly improve the quality and comprehensiveness of their draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the ablation study lacks a critical comparison, specifically mentioning the need for a baseline where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. The reviewer provides a clear and concrete action for the authors to take, which is to include this comparison to determine if the proposed method outperforms conventional baselines under the same computational constraints. The comment also specifies that comparing to a model initiated with random parameters does not provide a relevant benchmark, further guiding the authors on what needs to be added to their study. This level of detail and specificity makes the comment highly actionable, as it provides a clear path for the authors to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the ablation study, namely the inclusion of a baseline where an unconditional diffusion model is refined using the suggested architectural changes, followed by either consistency or progressive distillation. The comment further explains why this comparison is valuable and contrasts it with a comparison to a model initiated with random parameters, which is not relevant. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison, specifically mentioning the need for a baseline where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. The reviewer argues that this comparison would determine if the proposed method outperforms conventional baselines under the same computational constraints. The comment provides a logical reasoning for the claim, suggesting that the current comparison to a model initiated with random parameters is not relevant. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is mostly verifiable, as it provides a clear rationale but could be strengthened with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the ablation study, specifically the lack of a baseline comparison where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. This feedback is valuable as it highlights the importance of including a relevant comparison to determine the effectiveness of the proposed method under the same computational constraints. The comment also points out that comparing to a model initiated with random parameters does not provide a meaningful benchmark. This feedback is clear and actionable, guiding the authors on how to strengthen their study by providing a more comprehensive comparison. Therefore, the comment is highly helpful, as it offers specific and constructive advice for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects to design more diverse tasks. However, it does not provide specific guidance on which tasks to refer to or how to incorporate these tasks into the paper. The action is implicit, as the authors need to infer that they should explore additional tasks, and it is vague because it lacks concrete details on how to implement this suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects to design more diverse tasks. However, it does not specify which part of the paper discusses the tasks or how the tasks are currently structured. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a solution to the issue of homogeneity in task difficulty, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects to design more diverse tasks. However, the comment does not provide specific examples or references to these projects, making it difficult for the authors to understand the basis of the claim or how to implement the suggested changes. The lack of detailed justification or references renders the claim borderline verifiable, as it provides some direction but insufficient support for the authors to fully understand and address the issue. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the homogeneity of the tasks in the paper, suggesting that the difficulties of these tasks are too similar. It provides a specific suggestion to refer to other projects, such as [1] and [2], to design more diverse tasks. This feedback is actionable and offers a concrete direction for the authors to enhance the diversity and complexity of their tasks. However, the comment could be more helpful if it provided additional context or examples of how these tasks could be diversified. Overall, the comment is mostly helpful as it guides the authors toward improving the variety of tasks in their study, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison in Table 2 is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. It suggests that the settings should be aligned with lines 349-360, referencing a specific work, LUMOS, as a potential source for further information. While the comment implies that the authors should adjust their comparison to be more fair, it does not provide explicit instructions on how to make these changes or what specific adjustments need to be made. The action is implicit and somewhat vague, as the authors can infer the need for adjustment but lack detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and references specific lines (349-360), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to differences in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. The comment further provides a reference to a specific work, LUMOS, which could be relevant for further discussion or comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to differences in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. The reviewer provides a logical reasoning by suggesting that the settings should be aligned with lines 349-360, referencing a specific work, LUMOS, as a potential source for further information. This reasoning is supported by the reference to LUMOS, which could provide a basis for understanding the context of the comparison. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the fairness of the comparison in Table 2, noting that the training data size for LEPA may be larger than the \"Without Plan/Without Self-Reflection\" settings. It provides a logical reasoning for this observation and suggests that the settings should be aligned with lines 349-360, referencing a specific work, LUMOS, as a potential source for further information. This feedback is clear and actionable, as it directs the authors to consider and potentially adjust their comparison to ensure fairness. However, the comment could be more helpful if it offered additional guidance on how to align the settings or what specific adjustments might be necessary. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of experiments with real datasets and suggests that the authors should consider using datasets from the GLUE benchmark, such as QQP, to compute similarity between sentence pairs. It also recommends showing results on real-world diversity datasets. While the comment implies that the authors should include these datasets in their experiments, it does not explicitly instruct them to do so. The action is concrete, as it specifies the types of datasets to consider, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of synthetic datasets and suggests using datasets from the GLUE benchmark, such as QQP, and real-world diversity datasets. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the lack of experiments with real datasets and suggests particular datasets to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' decision to use only synthetic datasets and suggests that they should consider using real datasets from the GLUE benchmark and diversity datasets. The comment provides a logical reasoning by suggesting that using real datasets would be more relevant and practical. However, it lacks specific examples or references to support the claim that real datasets would be more beneficial, making the claim somewhat verifiable. The authors would need to further explore and justify why real datasets would be more appropriate, which is not fully addressed in the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the experiments are conducted only on synthetic datasets, without any results shown for real datasets. It suggests using datasets from the GLUE benchmark, such as QQP, to compute similarity between sentence pairs, and recommends showing results on real-world diversity datasets. This feedback is clear and actionable, as it provides specific examples of datasets that could be used to enhance the paper\\'s relevance and applicability. By addressing this suggestion, the authors can significantly improve the robustness and generalizability of their findings. However, the comment could be more helpful if it offered additional guidance on how to integrate these datasets or what specific aspects to focus on when using them. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be included, making it highly actionable. The authors know exactly what information to add and how to integrate it into their paper, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, indicating that this is an important piece of information currently lacking. However, it does not specify which part of the paper should include these details, making it weakly grounded. The comment is specific in its request for additional information on the optimization process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks details on how to solve the optimization, which is an important piece of information. However, the comment does not provide any specific reasoning, examples, or references to support why this information is crucial or how its absence impacts the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the optimization process. It suggests that the authors should provide more information on how to solve the optimization, which is an important piece of information currently missing. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs improvement. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and direct, giving the authors a specific action to take: include these models in their evaluation. The comment provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, the comment does not specify which part of the paper discusses the evaluation or where these models are mentioned, making it weakly grounded. The comment is specific in its suggestion to include these models for a more comprehensive comparison, but without explicit grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. While the comment highlights a potential gap in the evaluation, it does not provide specific reasoning or evidence to support why these models are particularly relevant or how their inclusion would enhance the comparison. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the importance of these models themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the evaluation by questioning the exclusion of LLaVA-series and Qwen-VL from the comparison. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it directs the authors to consider expanding their evaluation to include these models, which could significantly enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these models into the evaluation. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include captions or descriptions along with OCR heavy datasets. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including captions or descriptions along with OCR heavy datasets, which implies that it is addressing a specific aspect of the paper related to the presentation or discussion of these datasets. However, it does not explicitly mention which part of the paper this feedback pertains to, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of captions or descriptions for OCR datasets, providing clear guidance on what needs to be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include captions or descriptions along with OCR heavy datasets. However, it does not provide any reasoning or evidence to support why this is necessary or how it would improve the paper. The comment lacks specific examples or references to justify the need for these additions, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include captions or descriptions along with OCR heavy datasets. While this feedback is somewhat helpful, it lacks specificity and does not provide detailed guidance on why these additions are necessary or how they would enhance the paper. The comment identifies a potential area for improvement but does not offer actionable steps or examples, leaving the authors with limited direction on how to implement the suggestion. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and clarity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1, which states that the loss of TKD is assumed less than IYOR, and Equation 7, which contradicts this assumption. However, the comment does not provide explicit guidance on how the authors should address this discrepancy or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should reconcile the contradiction between the assumption and the equation, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by pointing out the discrepancy between the assumption and the equation, which is a clear indication of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, stating that the loss of TKD is assumed to be less than IYOR, while Equation 7 suggests otherwise. This claim is somewhat verifiable as it points out a specific inconsistency between two parts of the paper. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the issue and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7, which suggests that the loss of TKD is assumed to be less than IYOR, while Equation 7 contradicts this assumption. This feedback is somewhat helpful as it points out a potential inconsistency that the authors need to address. However, the comment lacks depth and does not provide specific guidance on how to resolve the discrepancy or what implications this might have for the paper. To be more helpful, the comment could include suggestions on how to reconcile the assumptions with the equation or what steps the authors should take to address this issue. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between Assumption 3.1 and Equation 7, stating that the loss of TKD is assumed to be less than IYOR, while Equation 7 suggests otherwise. However, it does not provide explicit guidance on how the authors should address this discrepancy or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should reconcile the contradiction between the assumption and the equation, but it lacks concrete details on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by pointing out the discrepancy between the assumption and the equation, which is a clear indication of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, stating that the loss of TKD is assumed to be less than IYOR, while Equation 7 suggests otherwise. This claim is somewhat verifiable as it points out a specific inconsistency between two parts of the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it difficult for the authors to understand the exact nature of the issue and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7, stating that the loss of TKD is assumed to be less than IYOR, while Equation 7 suggests otherwise. This feedback highlights a potential inconsistency that the authors need to address, which is valuable information for improving the draft. However, the comment lacks depth and does not provide specific guidance on how to resolve the discrepancy or what implications this might have for the paper. To be more helpful, the comment could include suggestions on how to reconcile the assumptions with the equation or what steps the authors should take to address this issue. Therefore, the comment is somewhat helpful, consistent with a score of 3.', 'help"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether question 3 (weakness 2 and 4) mentioned above indicates other limitations. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on how the authors should address this issue or what steps they should consider to clarify the point. As a result, the comment lacks actionable content, leaving the authors without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"question 3\" and \"weakness 2 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about whether question 3 indicates other limitations, providing a specific area for the authors to clarify. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding whether question 3 (weakness 2 and 4) indicates other limitations. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether question 3 (weakness 2 and 4) mentioned above indicates other limitations. While it identifies a potential area of confusion or lack of clarity, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the clarity of their paper. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to make a change or provide guidance on how to implement such a shift. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of middle layers and justify their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the choice of using last-layer hidden states, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the choice of using the last-layer hidden states for the classifier, given that many works have identified middle layers as more effective for probing. This feedback prompts the authors to reconsider their methodology and potentially explore the use of middle layers, which could enhance the robustness and generalizability of their findings. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as recommending alternative approaches or experiments to validate the choice. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation for using certain use cases is unclear and suggests that the use of GUE to determine modeling decisions is arbitrary and potentially incongruous. It also notes that the representations learned may have limited generalizability. While the comment identifies issues, it does not provide explicit guidance on how to address these concerns or improve the motivation. The authors can infer that they need to clarify the motivation and consider the implications of using GUE, but the lack of specific suggestions makes the comment somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation for using certain use cases and the potential incongruity of using GUE to determine modeling decisions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the motivation and the generalizability of the representations learned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using certain use cases is unclear and that the use of GUE to determine modeling decisions is arbitrary and potentially incongruous. The comment provides a logical reasoning by explaining that the representations learned using these modeling decisions may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of motivation for the use cases discussed in the paper, specifically questioning the arbitrary nature of using GUE to determine modeling decisions. It highlights a potential issue with the generalizability of the representations learned from these modeling decisions, which are optimized for a relatively narrow set of tasks. While the comment points out a significant weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation. The feedback is somewhat helpful as it directs the authors to consider the broader implications of their modeling decisions, but it lacks depth and actionable advice, leaving the authors with a general direction to explore without detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a lack of motivation for the use cases discussed in the paper and questions the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the motivation. The feedback lacks specific actions or concrete steps for the authors to take, making it somewhat vague and actionable. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation for using certain use cases and the potential incongruity of using GUE to determine modeling decisions. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the motivation and the generalizability of the representations learned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using certain use cases is unclear and that the use of GUE to determine modeling decisions is arbitrary and potentially incongruous. It provides a logical reasoning by explaining that the representations learned using these modeling decisions may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of motivation for the use cases discussed in the paper and questions the arbitrary nature of using GUE to determine modeling decisions. It highlights a potential issue with the generalizability of the representations learned from these modeling decisions, which are optimized for a relatively narrow set of tasks presented in GUE. While the comment points out a significant weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation. The feedback is somewhat helpful as it directs the authors to consider the broader implications of their modeling"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper reads clunkily due to significant grammar and spelling errors and requires a major editing pass. This provides a clear and direct action for the authors to take, which is to address the grammar and spelling issues and perform a thorough editing process. The feedback is specific and actionable, giving the authors a clear path forward to improve the readability and quality of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies issues with the grammar and spelling of the paper, suggesting that it reads clunkily due to these errors. However, it does not specify which sections or parts of the paper contain these errors, making it difficult for the authors to pinpoint the exact areas needing attention. The comment is specific in its critique of the writing quality but lacks grounding as it does not reference specific sections or lines. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper reads clunkily due to significant grammar and spelling errors, requiring a major editing pass. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issues effectively. Without explicit examples or references to specific errors, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the presence of grammar and spelling errors that make the text difficult to read. It suggests that the paper requires a major editing pass to address these issues. While the comment highlights a critical area for improvement, it lacks specific examples or guidance on which errors to prioritize or how to correct them. This limits the usefulness of the feedback, as the authors are left with a general understanding of the problem but without actionable steps to address it. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment highlights areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The questions are implicit and lack concrete steps for the authors to take, making it difficult for them to know exactly what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in terms of what needs to be addressed, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment highlights potential areas of concern, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claims but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises several important questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. These questions are relevant and could help the authors clarify their methodology and assumptions. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending additional analyses or references to support the claims. While it identifies areas for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises several questions about the consistency of SITE as an estimator of the true average ITE, the assumptions required for it to be a valid estimator of the causal effect, and the implicit nature of the objective function for the regression. While the questions highlight areas of concern, they do not provide explicit guidance or suggestions on how the authors should address these issues. The questions are implicit and lack concrete steps for the authors to take, making it difficult for them to know exactly what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises several questions about the consistency of SITE as an estimator of the true average ITE, the assumptions required for it to be a valid estimator of the causal effect, and the implicit nature of the objective function for the regression. It also questions whether the loss function being defined over minibatches causes issues. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in terms of what needs to be addressed, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the consistency of SITE as an estimator of the true average ITE and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment highlights potential areas of concern, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they might need to explore alternative approaches or provide additional explanations to mitigate this limitation. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously, specifically addressing the issue of shifting focus to a new target object if it changes between clicks. This is a specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses OIS or interactive segmentation, making it weakly grounded. The authors can infer that it relates to sections discussing the method or experimental results, but this inference is not direct. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It provides a logical reasoning by explaining that Object-level Understanding relies on Mask Guidance from previous interactions, which could lead to difficulties in shifting focus to a new target object if it changes between clicks. This reasoning is supported by a reference to a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which provides a basis for the claim. However, the comment could be strengthened by including more detailed examples or specific scenarios to illustrate the potential limitations. Overall, the claim is mostly verifiable due to the logical reasoning and the reference to relevant literature, but it could benefit from more detailed examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. This is a critical point that could impact the practical utility of the method. The comment provides a clear and actionable suggestion for the authors to address this issue, which could significantly enhance the method\\'s applicability. However, the comment could be more helpful if it offered specific suggestions on how to mitigate this limitation or explored potential solutions. Overall, the feedback is mostly helpful as it identifies a key area for improvement and provides a direction for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It suggests that the authors consider the practicality of this assumption, particularly in light of the user\\'s knowledge of the domain. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific aspects of the assumption need to be revised. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It references specific scenarios, such as intrusion and fraud detection systems, to provide context. However, it does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in questioning the realism of the assumption and its implications, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It references common scenarios, such as intrusion and fraud detection systems, to provide context. However, the comment does not provide specific examples or detailed reasoning to support the claim that this assumption is unrealistic. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It references common scenarios, such as intrusion and fraud detection systems, to provide context. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve their assumptions. While it identifies an area for consideration, it does not provide actionable feedback or detailed insights that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it prompts the authors to reflect on their assumptions but does not fully support them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the limitations and challenges of HLOP and the experimental design, which makes it difficult to assess the tradeoffs between using HLOP and other approaches. The reviewer explicitly suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be added to their draft. The comment is explicit and concrete, offering a straightforward path for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a lack of discussion on the limitations and challenges of HLOP and the experimental design, making it difficult to assess the tradeoffs between using HLOP versus other approaches. It suggests including a discussion on the potential downsides of HLOP and the limitations of the evaluation process. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or results sections where these topics might be addressed. The comment is specific in detailing what needs to be addressed, providing clear guidance on the potential downsides and limitations to be discussed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the limitations and challenges of HLOP and the experimental design, making it difficult to assess the tradeoffs between using HLOP and other approaches. The reviewer suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues that need to be addressed, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the limitations and challenges of HLOP and the experimental design. This feedback highlights an important area that the authors need to address to provide a more comprehensive understanding of their work. The comment suggests including a discussion on the potential downsides of HLOP and the limitations of the evaluation process, which would help readers assess the tradeoffs between using HLOP and other approaches. This feedback is clear and actionable, offering specific guidance on what the authors should include to improve their draft. However, it could be more helpful if it provided examples or detailed suggestions on how to address these issues. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the effectiveness of the proposed gating scheme on additional language models, such as FlanT5 and Llama, which have been released after GPT-2. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional evaluations. The suggestion is concrete, as it specifies the models to consider and the potential impact on the contribution. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the effectiveness of the proposed gating scheme on additional language models, such as FlanT5 and Llama, which have been released after GPT-2. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors can infer that it relates to the evaluation or discussion sections, but this inference is not direct. The comment is specific in suggesting additional models to evaluate, but it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating the effectiveness of the proposed gating scheme on additional language models, such as FlanT5 and Llama, would enhance the contribution. However, the comment does not provide specific reasoning or evidence to support why these models are relevant or how they would improve the contribution. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general idea but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that many language models have been released since GPT-2, such as FlanT5 and Llama, which have not been studied. It suggests that evaluating the effectiveness of the proposed gating scheme on these models would enhance the contribution. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by expanding the evaluation to include these recent models. However, the comment could be more helpful if it offered additional guidance on how to conduct these evaluations or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" While the comment implies that the authors should include this work in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this work in their comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" However, it does not specify which part of the paper this suggestion pertains to, such as the related work section or the discussion section. The authors can infer that it relates to the comparison of their method with existing literature, but this inference is not direct. The comment is specific in suggesting a particular work to consider, but it lacks full grounding as it does not explicitly mention the section of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should cite and compare their work with some recent works that might be highly correlated, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" While the comment provides a specific example of a relevant work, it does not offer detailed reasoning or evidence to support why this particular work is relevant or how it might impact the authors\\' work. The suggestion is somewhat verifiable as it points to a specific work, but it lacks comprehensive justification or explanation, making it difficult for the authors to fully understand the basis of the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, specifically mentioning \"Differential Treatment for Stuff and Things: A Simple Unsupervised Domain Adaptation Method for Semantic Segmentation - Wang et al. cvpr2020.\" This feedback is somewhat helpful as it provides a specific example of a relevant work that could be included in the authors\\' discussion or comparison section. However, the comment could be more helpful if it explained why this particular work is relevant or how it could impact the authors\\' research. Additionally, the comment lacks detailed guidance on how to integrate this work into the paper or what aspects should be emphasized in the comparison. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for the authors but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding more detail about how UNKs (unknown tokens) are handled by the neural decoder, or at least providing a citation to the dictionary-based replacement strategy being used. This feedback implies that the authors should include additional information or references to clarify this aspect of their work. While the action is explicit, it is somewhat vague because it does not specify exactly what additional details or information should be included. The authors know they need to provide more information or a citation, but the comment does not offer specific guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation to the dictionary-based replacement strategy being used. This feedback is specific as it clearly identifies the issue of UNK handling and the need for additional information or a citation. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation to the dictionary-based replacement strategy being used. This is a request for additional information or clarification, which does not constitute a claim or opinion. It is a factual statement seeking further explanation, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests adding more detail about how UNKs (unknown tokens) are handled by the neural decoder, or at least providing a citation to the dictionary-based replacement strategy being used. This feedback is clear and actionable, as it directs the authors to include additional information that could enhance the clarity and comprehensiveness of their work. By addressing this suggestion, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this information. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and offers a clear direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. While the action is explicit, it lacks concrete guidance on how to implement this comparison or what specific aspects to focus on when comparing with pre-trained models. The authors are given a clear direction to include additional experiments, but the comment could be more actionable if it provided more detailed instructions on how to conduct these comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the authors\\' code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting a comparison with SOTA methods, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. However, the comment does not provide any specific examples or references to support why this comparison is necessary or how it would benefit the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental evaluation by including comparisons with relevant SOTA methods. By doing so, the authors can better position their work in the context of existing research and potentially identify areas for improvement or innovation. However, the comment could be more helpful if it provided additional guidance on how to effectively incorporate these comparisons into the experiments or what specific aspects to focus on when comparing with pre-trained models. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistical significance of the results in Table 3, specifically regarding the comparison between Scheduled Bernoulli and AttendOut. It asks for an explanation of why AttendOut has lower variance and seeks clarification on the statistical significance value of the comparison. While the comment implies that the authors should provide additional information or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or statistical analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the statistical significance of the results, specifically why AttendOut has lower variance and seeks clarification on the statistical significance value when comparing Scheduled Bernoulli and AttendOut. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the results presented in Table 3, specifically regarding the statistical significance of the comparison between Scheduled Bernoulli and AttendOut. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the statistical significance of the results presented in Table 3, particularly regarding the comparison between Scheduled Bernoulli and AttendOut. It asks for an explanation of why AttendOut has lower variance and seeks clarification on the statistical significance value of the comparison. This feedback is somewhat helpful as it prompts the authors to provide additional context or analysis that could enhance the clarity and robustness of their results. However, it could be more helpful if it suggested specific methods or approaches for addressing these questions. Overall, the comment provides some guidance but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the prediction lengths used in the experimental results do not align with the definition of \"long-term.\" It recommends following the same settings as the original dataset, specifically mentioning {96, 192, 336, 720}. This feedback provides a clear and concrete action for the authors to take, as it specifies the exact changes needed to align with the intended long-term forecasting setting. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the specific issue with the prediction lengths, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the prediction lengths not aligning with the definition of \"long-term\" and suggests following the same settings as the original dataset. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results show long-term forecasting but questions the alignment of the prediction lengths with the definition of \"long-term.\" It suggests following the same settings as the original dataset, specifically mentioning {96, 192, 336, 720}. This claim is somewhat verifiable as it provides a logical reasoning based on the definition of \"long-term\" and suggests a specific setting that aligns with it. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the prediction lengths used do not align with the definition of \"long-term.\" It suggests following the same settings as the original dataset, which is a clear and actionable recommendation. This feedback provides the authors with a concrete way to improve the consistency and accuracy of their experimental setup, making the comment highly helpful. By addressing this issue, the authors can enhance the validity and reliability of their results, which is crucial for the overall quality of the paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the difference between confidence and accuracy for one sample being unreasonable when used in Eq. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting a method to resolve the discrepancy or providing additional context. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the difference between confidence and accuracy for one sample being unreasonable when used in Eq. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the confidence and accuracy values, but without clear references to the paper, the authors may struggle to pinpoint the exact location where this issue arises. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for one sample is unreasonable when used in Eq. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the difference between confidence and accuracy for one sample being unreasonable when used in Eq. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern or improve their analysis. Without actionable feedback or detailed explanations, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a potential issue but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions whether the method can be adapted to account for shifts in the data distribution. While the comment implies that the authors should consider this issue, it does not provide explicit guidance or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to adapt the method for shifts in the data distribution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the calculation of divergence between a sample and the data, using the residual approach. It raises a concern about the method's applicability when the sample is shifted from the data distribution. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the method\\'s limitations and suggesting a potential adaptation for shifts in the data distribution. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions the method\\'s applicability when the sample is shifted from the data distribution. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the method may fail in such settings. The reasoning is based on logical reasoning about the method\\'s limitations, but without detailed evidence or examples, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the approach used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It raises a concern about the method\\'s applicability when the sample is shifted from the data distribution, suggesting that the authors consider adapting the method to account for such shifts. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed advice on how to overcome it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the method used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions the method\\'s applicability when the sample is shifted from the data distribution and suggests considering ways to adapt the method for such shifts. While the comment implies that the authors should explore this issue, it does not provide explicit guidance or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate adapting the method for shifts in the data distribution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the calculation of divergence between a sample and the data using the residual approach. It raises a concern about the method\\'s applicability when the sample is shifted from the data distribution, suggesting that the authors consider adapting the method to account for such shifts. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the method\\'s limitations and suggesting a potential adaptation, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the method used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions the method\\'s applicability when the sample is shifted from the data distribution, suggesting that the authors consider adapting the method to account for such shifts. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the method may fail in such settings. The reasoning is based on logical reasoning about the method\\'s limitations, but without detailed evidence or examples, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the approach used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It raises a concern about the method\\'s applicability when the sample is shifted from the data distribution, suggesting that the authors consider adapting the method to account for such shifts. While"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the context-independent replacement of words, specifically asking if replacing a word like w_i affects the context of w_{i-1} and w_{i+1}. The reviewer suggests that it might be better to replace entire phrases rather than individual words to maintain coherence. While the comment implies that the authors should consider this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of context-independent word replacement and consider replacing phrases instead. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 076-079, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the context-independent replacement of words and suggests that replacing entire phrases might be preferable to maintain coherence. The comment provides clear guidance on what aspect of the paper needs attention, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the context-independent replacement of words, specifically asking if replacing a word like w_i affects the context of w_{i-1} and w_{i+1}. The reviewer suggests that it might be better to replace entire phrases rather than individual words to maintain coherence. While the comment is based on a logical reasoning about the potential impact of word replacement on text coherence, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a reasonable concern but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the context-independent replacement of words, particularly regarding the potential impact on the coherence of the text. It suggests that replacing entire phrases might be preferable to individual words to maintain coherence. This feedback is clear and actionable, as it prompts the authors to consider the implications of their word replacement strategy and potentially revise their approach to ensure coherence. However, the comment could be more helpful if it provided examples or detailed guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on which methods to compare or how to conduct the comparison. While the action is direct, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods, which is a specific suggestion for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or section where runtime comparisons are typically discussed. Without explicit references to sections or specific elements of the paper, the authors may find it challenging to pinpoint where this suggestion should be implemented. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods. However, it does not provide any reasoning, evidence, or examples to support why this comparison is necessary or how it would benefit the paper. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the importance or necessity of the suggested change. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a clear and actionable suggestion for improvement. This feedback provides a specific direction for the authors to enhance their work by comparing the performance of different methods in terms of runtime. However, the comment could be more helpful if it included examples of methods to compare or guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The reviewer implies that the authors should compare and explore these architectures as they did for the other two parts of the framework. While the comment provides a clear direction for improvement, it does not specify which ECG-specific architectures should be considered or how to implement the comparison. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the current limitations of the ECG encoder, suggesting that it could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The comment further suggests that these architectures should be compared and explored, similar to how different methods were explored for the other two parts of the framework. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder, which uses only 1-D CNN layers and average pooling, could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The comment implies that these architectures could significantly enhance the current ECG encoder. However, it does not provide specific examples or references to support the claim that these architectures would improve the ECG encoder. The suggestion is somewhat verifiable as it highlights a potential area for improvement but lacks detailed justification or evidence, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the MEIT framework, focusing on the ECG encoder. It points out that the current ECG encoder uses only 1-D CNN layers and average pooling, suggesting that more advanced ECG-specific architectures using SSL or transformer-based approaches could significantly enhance the encoder\\'s performance. The comment implies that the authors should compare and explore these architectures, similar to how different methods were explored for the other parts of the framework. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. However, it could be more helpful if it suggested specific architectures or methodologies to consider. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The reviewer implies that the authors should compare and explore these architectures as they did for the other two parts of the framework. While the comment provides a clear direction for improvement, it lacks specific guidance on which ECG-specific architectures to consider or how to implement the comparison. The action is implicit but concrete, as it outlines a specific area for enhancement. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the current limitations of the ECG encoder, suggesting that it could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The comment further suggests that these architectures should be compared and explored, similar to how different methods were explored for the other two parts of the framework. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by incorporating ECG-specific architectures using SSL or transformer-based approaches. The comment implies that these architectures could significantly enhance the current ECG encoder. However, it does not provide specific examples or references to support the claim that these architectures would improve the ECG encoder. The suggestion is somewhat verifiable as it highlights a potential area for improvement but lacks detailed justification or evidence, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rephrase the abstract to accurately reflect the focus on explainability rather than defense methodology. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and why. The comment is highly actionable because it gives the authors a specific and concrete task to perform, ensuring they know exactly how to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which inaccurately suggests a defense methodology is proposed, and provides a clear suggestion to rephrase the abstract to accurately reflect the focus on explainability. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract inaccurately suggests a defense methodology is proposed, while the paper actually presents a model-agnostic explainability technique for deep neural networks. The reviewer suggests rephrasing the abstract to accurately reflect the focus on explainability. This claim is mostly verifiable as it provides a logical reasoning for the misalignment between the abstract and the paper\\'s content. However, it lacks specific examples or references to support the claim fully. The authors would need to make a significant effort to understand and address the issue, making the comment mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it inaccurately suggests a defense methodology is proposed, while the paper actually presents a model-agnostic explainability technique for deep neural networks. The comment provides a clear and actionable suggestion to rephrase the abstract to accurately reflect the focus on explainability. This feedback is highly helpful as it guides the authors on how to improve the clarity and accuracy of their abstract, ensuring that readers understand the true focus of the paper. By addressing this issue, the authors can enhance the precision and effectiveness of their communication, making the comment highly beneficial for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). While it identifies specific examples of such methods (FINER, Incode, and SL2A-INR), it does not provide explicit guidance on how the authors should incorporate these comparisons into their work. The action is implicit, as the authors need to infer that they should include these comparisons, and it is somewhat vague because it does not specify how to integrate these comparisons into the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It mentions specific examples such as FINER, Incode, and SL2A-INR, which provides some grounding as the authors can infer that these are the methods being referred to. However, the comment does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in detailing what is missing, namely comparisons to recent methods that propose new activation functions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). The comment provides specific examples of such methods, which helps to substantiate the claim. However, it does not include detailed reasoning or references to explain why these comparisons are necessary or how they would enhance the paper. While the examples are clear, the lack of additional justification or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It mentions specific examples, such as FINER, Incode, and SL2A-INR, which gives the authors a clear direction for enhancing their work. However, the comment could be more helpful if it provided additional context or guidance on how to integrate these comparisons into the paper. Overall, the feedback is somewhat helpful as it points out a relevant area for improvement but lacks detailed suggestions for implementation. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides specific examples of such methods, which helps the authors understand what is missing. However, the comment does not explicitly instruct the authors to include these comparisons or provide guidance on how to integrate them into the paper. While the action is implicit, it is concrete because the authors know what specific comparisons to consider. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a specific area where the paper could be improved by lacking comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides examples of such methods, such as FINER, Incode, and SL2A-INR, which helps ground the comment. However, it does not explicitly mention which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in detailing what is missing, namely comparisons to recent methods, which provides clear guidance for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides specific examples of such methods, which helps to substantiate the claim. However, the comment does not include detailed reasoning or references to explain why these comparisons are necessary or how they would enhance the paper. While the examples are clear, the lack of additional justification or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by lacking comparisons to recent methods that propose new or adaptive activation functions for implicit neural representations (INRs). It provides specific examples of such methods, such as FINER, Incode, and SL2A-INR, which gives the authors a clear direction for enhancing their work. However, the comment could be more helpful if it provided additional context or guidance on how to integrate these comparisons into the paper. Overall, the feedback is somewhat helpful as it points out"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a straightforward method, such as the one described in the reference https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are finetuned. It implies that the evaluation setting could be improved. However, the comment does not provide specific guidance on how to improve the evaluation setting or what aspects of the evaluation should be adjusted. The action is implicit and somewhat vague, as the authors need to infer that they should consider the suggested method and its implications for their evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a straightforward method, such as the one described in the reference https://arxiv.org/abs/2309.16039, works well in practice and challenges the value of research on length extrapolation, especially when models are finetuned. However, it does not specify which part of the paper this evaluation setting is being discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment provides a specific suggestion for improvement, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, especially when models are finetuned. However, the comment does not provide specific examples or detailed reasoning to support this claim. The mention of a reference (https://arxiv.org/abs/2309.16039) does not offer enough context or explanation to substantiate the claim. Without additional details or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, especially when models are finetuned. It implies that the evaluation setting could be improved. However, the comment lacks specificity and does not provide detailed guidance on how to improve the evaluation setting or what specific aspects of the evaluation should be addressed. While it identifies a potential issue, it does not offer actionable steps or suggestions for improvement, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more comprehensive and actionable to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training and testing environments used in the autoencoder experiment. It explicitly asks the authors to clarify which environment is used for training and which for testing, and suggests that a cross-validation approach would be preferable to demonstrate the robustness of the results. While the comment does not explicitly instruct the authors to perform a cross-validation, the suggestion is clear and concrete, providing a direct action for the authors to take. The authors know exactly what needs to be done to address the feedback, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the training and testing environments used in the autoencoder experiment and suggests a preferable approach, such as cross-validation, to demonstrate the robustness of the results. This provides clear guidance on what needs to be clarified or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the training and testing environments used in the autoencoder experiment. It suggests that a cross-validation approach would be preferable to demonstrate the robustness of the results. While the comment does not contain an opinion or claim, it is a request for clarification and does not require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methodology described in Section 2.4, where the autoencoder is trained on one environment and tested on all others. It questions the choice of training and testing environments and suggests that a cross-validation approach would be preferable to demonstrate the robustness of the results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a cross-validation approach. However, the comment could be more helpful if it explained why cross-validation is preferable or provided examples of how it could be implemented. Overall, the comment is mostly helpful as it guides the authors toward a specific improvement that could enhance the robustness of their results.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the number of refinements is mentioned, it does not provide evidence of an actual improvement. The comment implies that the authors should include a comparison to show the improvement in generation quality. However, it does not explicitly instruct the authors to perform this comparison or provide specific guidance on how to conduct it. The action is implicit but concrete, as the authors can infer that they need to include a comparison to substantiate the improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It mentions the statistic of the number of refinements, which provides some grounding as it relates to a specific aspect of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a comparison to show improvement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to demonstrate the improvement in generation quality due to refinement during inference. The comment suggests that while the number of refinements is mentioned, it does not provide evidence of an actual improvement. This claim is somewhat verifiable as it highlights a specific area where the paper could be strengthened by including a comparison. However, the comment lacks detailed examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing a comparison to demonstrate the improvement in generation quality due to refinement during inference. It acknowledges the mention of the number of refinements but points out that this does not constitute evidence of an actual improvement. This feedback is clear and actionable, as it directs the authors to include a comparison that would substantiate the claim of improvement. However, the comment could be more helpful if it suggested specific methods or metrics for conducting this comparison. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the paper, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions. The first question asks about the missing threshold in the PMI calculation, implying that the authors should clarify or provide this information. The second question asks if the partitions were done randomly, suggesting that the authors should clarify this aspect as well. While the questions imply actions, they are not explicitly stated, and the authors may need to infer the need for clarification. Additionally, the questions are somewhat vague, as they do not provide specific guidance on how to address the issues. Therefore, the comment is somewhat actionable, as it identifies areas for clarification but lacks detailed instructions on how to implement the changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers, \"336\" and \"371,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises questions about the missing threshold in the PMI calculation and the randomness of the partitions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions: one asking about the missing threshold in the PMI calculation and the other questioning the randomness of the partitions. These questions are requests for clarification and do not contain subjective opinions, judgments, or suggestions that require verification. Therefore, they are factual statements and should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions: one asking about the missing threshold in the PMI calculation and the other questioning the randomness of the partitions. While these questions identify areas that need clarification, they do not provide specific guidance or suggestions on how the authors might address these issues. The lack of actionable feedback or detailed advice limits the usefulness of the comment, making it somewhat helpful. The authors are given some insight into potential areas for improvement but are not fully empowered to make significant changes to their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-tuning. While the comment implies that the authors should include this comparison, it does not explicitly instruct them to do so. The action is clear but somewhat vague, as it lacks specific guidance on how to present the comparison or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-turning. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a comparison, but without clear grounding, the authors may struggle to identify the exact section that needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the training time of the MDP and a suggestion to provide a comparison with ImageNet pretraining and individual dataset fine-turning. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training time of the MDP and suggests providing a comparison with ImageNet pretraining and individual dataset fine-turning. This feedback is somewhat helpful as it prompts the authors to consider and address the training time aspect of their work, which could be an important factor for readers to understand. However, the comment lacks depth and does not provide specific guidance on how to conduct or present the comparison, nor does it suggest why this information is crucial for the paper. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific aspects to focus on. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the author\\'s claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, and the actual structure of G-PDE, which is an incremental improvement over GraphCON[1]. However, the comment does not provide explicit guidance or suggestions on how the authors should address this discrepancy or clarify their claims. The feedback lacks actionable details, such as recommending specific changes to the text or providing examples of how to better align the claim with the actual structure. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE, which is intended to leverage the advantages of both spike ODE and graph ODE. It points out that the fundamental structure of G-PDE is an incremental improvement over GraphCON[1], where the static encoder is substituted by SNN. This provides full grounding as it clearly identifies the part of the paper being addressed, specifically the claim about the design of G-PDE. The comment is also specific, as it details the discrepancy between the authors\\' claim and the actual structure of G-PDE. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the author\\'s assertion about G-PDE being intentionally designed to leverage the advantages of both spike ODE and graph ODE is not accurate, as it is an incremental improvement over GraphCON[1]. The comment provides a specific reference to GraphCON[1] to support its claim, which is a clear and logical reasoning. This makes the claim mostly verifiable, as it offers a specific reference to substantiate the critique. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment addresses a specific claim made by the authors regarding the design of G-PDE, noting that it is an incremental improvement over GraphCON[1] rather than an intentional design to leverage the advantages of both spike ODE and graph ODE. This feedback is somewhat helpful as it identifies a potential discrepancy between the authors\\' claim and the actual structure of G-PDE. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this discrepancy or clarify their claims. While it highlights an area for improvement, it does not offer actionable steps or detailed feedback, leaving the authors with limited guidance on how to enhance their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a discrepancy between the authors\\' claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, and the actual structure of G-PDE, which is an incremental improvement over GraphCON[1]. However, the comment does not provide explicit guidance or suggestions on how the authors should address this discrepancy or clarify their claims. Without actionable advice or specific recommendations, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the design of G-PDE, which is intended to leverage the advantages of both spike ODE and graph ODE. It points out that the fundamental structure of G-PDE is an incremental improvement over GraphCON[1], where the static encoder is substituted by SNN. This provides full grounding as it clearly identifies the part of the paper being addressed, specifically the claim about the design of G-PDE. The comment is also specific, as it details the discrepancy between the authors\\' claim and the actual structure of G-PDE. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the author\\'s assertion about G-PDE being intentionally designed to leverage the advantages of both spike ODE and graph ODE is not accurate, as it is an incremental improvement over GraphCON[1], where the static encoder is substituted by SNN. The comment provides a specific reference to GraphCON[1] to support its claim, which is a clear and logical reasoning. This makes the claim mostly verifiable, as it offers a specific reference to substantiate the critique. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the proposed method, noting that it does not outperform Jiang et al. significantly in certain metrics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes might be necessary. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed method compared to Jiang et al. in specific metrics, such as Penetration(Dep) and Sim-Disp(Mean). However, it does not specify which part of the paper discusses these results or where the comparison is made, making it weakly grounded. The comment is specific in detailing the performance differences between the proposed method and Jiang et al., but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform Jiang et al. significantly, providing specific examples from the metrics Penetration(Dep) and Sim-Disp(Mean). However, the comment lacks detailed reasoning or references to support the claim that the performance difference is negligible. While the examples are clear, the absence of a broader context or detailed analysis makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it does not outperform Jiang et al. significantly in certain metrics. It provides specific examples, such as the performance difference in Penetration(Dep) and Sim-Disp(Mean), which helps the authors understand the magnitude of the problem. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the performance of the proposed method. While it highlights a critical area for improvement, the feedback could be more helpful if it included specific recommendations or insights on how to enhance the method. Therefore, the comment is somewhat helpful, as it provides valuable information but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method does not outperform Jiang et al. significantly, providing specific examples from metrics like Penetration(Dep) and Sim-Disp(Mean). However, it does not offer any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed method compared to Jiang et al. in specific metrics, such as Penetration(Dep) and Sim-Disp(Mean). However, it does not specify which part of the paper discusses these results or where the comparison is made, making it weakly grounded. The comment is specific in detailing the performance differences between the proposed method and Jiang et al., but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform Jiang et al. significantly, providing specific examples from the metrics Penetration(Dep) and Sim-Disp(Mean). However, the comment lacks detailed reasoning or references to support the claim that the performance difference is negligible. While the examples are clear, the absence of a broader context or detailed analysis makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it does not outperform Jiang et al. significantly in certain metrics. It provides specific examples, such as the performance difference in Penetration(Dep) and Sim-Disp(Mean), which helps the authors understand the magnitude of the problem. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the performance of the proposed method. While it highlights a critical area for improvement, the feedback could be more helpful if it included specific recommendations or insights on how to enhance the method. Therefore, the comment is somewhat helpful, as it provides valuable information but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'action"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: the lack of comparison with existing work on OOD detection in time-series data and the unclear nature of the related work subtitles. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The suggestion to compare with existing work is implicit and lacks concrete details on which specific works to include or how to structure the comparison. Similarly, the comment on the related work subtitles is vague, as it does not specify how to make them more descriptive or relevant to the content. Therefore, the comment is barely actionable, as it provides some insight but lacks actionable steps for the authors to follow.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"vFSAD\" and references a specific work by Kaur et al. This allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the related work subtitles, noting that they are not descriptive and seemingly unrelated to the actual content. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes two claims. First, it claims that \"vFSAD\" refers to OOD detection in time-series data and that this area includes a large quantity of work that has not been compared with or even mentioned. This claim is somewhat verifiable as it provides a general reference to the field of OOD detection in time-series data but lacks specific examples or references to substantiate the claim fully. Second, the comment critiques the related work subtitles of \"Policy\" and \"Evaluation tasks,\" stating they are not descriptive and seemingly unrelated to the actual content. This claim is somewhat verifiable as it identifies a potential issue with the organization of the related work section but does not provide specific examples or references to support the claim. Overall, the review point provides some support for its claims but lacks detailed evidence or examples, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it points out that the term \"vFSAD\" is unclear and suggests that it refers to OOD detection in time-series data, which is a large and relevant area that has not been adequately compared or mentioned in the paper. This feedback is valuable as it directs the authors to a critical aspect of their work that may be overlooked. Second, the comment critiques the related work subtitles, noting that they are not descriptive and seem unrelated to the actual content. This observation highlights a potential issue with the organization and clarity of the paper, prompting the authors to reconsider the structure of their related work section. While the comment provides some actionable insights, it could be more helpful if it offered suggestions on how to improve the related work section or provided examples of how to make it more descriptive. Overall, the comment is mostly helpful as it identifies key areas for improvement but lacks detailed guidance on implementation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study should be added to justify the selection of memory size. This is a clear and direct action for the authors to take, providing them with a specific task to improve their draft. The comment also specifies what needs to be included in the ablation study, making the action concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an ablation study to justify the selection of memory size, indicating that the effect of memory size is ambiguous. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an ablation study to address the ambiguity, but without clear grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of memory size is ambiguous and suggests adding an ablation study to justify the memory size selection. However, the comment does not provide any specific reasoning or evidence to support why the effect of memory size is ambiguous or how an ablation study would address this issue. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the ambiguity regarding the effect of memory size. It suggests that an ablation study should be added to justify the selection of memory size. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting an additional analysis. However, the comment could be more helpful if it offered suggestions on how to structure the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the use of the abbreviation \"GNN\" in the paper. It notes that the abbreviation appears on page 1 but is not fully defined until Section 2, on page 2. This observation implies that the authors should ensure consistency in the use of abbreviations throughout the paper. However, the comment does not explicitly instruct the authors to make this change or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should correct the inconsistency in abbreviation usage. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abbreviation \"GNN\" and its inconsistent use in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the inconsistency in the definition of \"GNN,\" noting that it appears on page 1 but is not fully defined until Section 2, on page 2. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a specific inconsistency in the use of the abbreviation \"GNN\" in the paper. It notes that the abbreviation appears on page 1 but is not fully defined until Section 2, on page 2. This observation is factual and does not require any supporting evidence or reasoning. The comment is descriptive and does not contain subjective opinions or claims that need verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the use of the abbreviation \"GNN\" in the paper. It points out that the abbreviation appears on page 1 but is not fully defined until Section 2, on page 2. This feedback is clear and actionable, as it highlights a potential confusion for readers and suggests that the authors should ensure consistency in the use of abbreviations throughout the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending the placement of the full definition closer to the first appearance of the abbreviation. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or improve their results. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of baseline methods on the DAVIS dataset, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the performance issue and the need for further investigation, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. The comment references a specific paper, \"UnOVOST: Unsupervised Offline Video Object Segmentation and Tracking,\" which provides a benchmark for comparison. This reference supports the claim by offering a concrete example of state-of-the-art performance. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced paper. Overall, the claim is mostly verifiable due to the reference provided, but it could be further strengthened with additional details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of baseline methods on the DAVIS dataset, comparing it to state-of-the-art results. It highlights that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. By referencing a specific paper, \"UnOVOST: Unsupervised Offline Video Object Segmentation and Tracking,\" the comment provides a concrete example of state-of-the-art performance. This feedback is somewhat helpful as it points out a potential weakness in the paper and suggests a direction for improvement by comparing the proposed method with top-performing ones. However, the comment could be more helpful if it offered suggestions on how to address this issue or further explored the implications of this finding. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or improve their results. Without actionable steps or concrete advice, the authors are left uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of baseline methods on the DAVIS dataset, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the performance issue and the need for further investigation, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is rather low, comparing it to state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. The comment references a specific paper, \"UnOVOST: Unsupervised Offline Video Object Segmentation and Tracking,\" which provides a benchmark for comparison. This reference supports the claim by offering a concrete example of state-of-the-art performance. However, the comment could be strengthened by providing more detailed comparisons or specific examples from the referenced paper. Overall, the claim is mostly verifiable due to the reference provided, but it could be further strengthened with additional details.', 'verifiability_label': '4', \"helpfulness_rationale\": \"The review comment identifies"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reporting of results for the proposed two-step decoding method, specifically asking if the results are reported in the paper and whether they are obtained with or without the two-step method. The reviewer also inquires about the performance of the two-step method if it is not included. While the comment implies that the authors should clarify this aspect of their results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the reporting of results for the proposed two-step decoding method, specifically asking if the results are reported in the paper and whether they are obtained with or without the two-step method. It also inquires about the performance of the two-step method if it is not included. However, the comment does not specify where in the paper these results should be found or how they are discussed, making it weakly grounded. The comment is specific in its request for clarification about the results and their performance, but it lacks grounding as it does not point to a specific section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification regarding the reporting of results for the proposed two-step decoding method. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the reporting of results for the proposed two-step decoding method, asking if the results are reported in the paper and whether they are obtained with or without the two-step method. It also inquires about the performance of the two-step method if it is not included. This feedback is somewhat helpful as it prompts the authors to clarify a potential gap in their reporting, which could be important for readers to understand the effectiveness of the proposed method. However, the comment could be more helpful if it provided suggestions on how to present this information or why it is crucial for the paper. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to address the issue. The comment provides specific guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the figures,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by stating that the font size is too small and suggests a solution by recommending an increase to improve readability. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a specific action to improve the readability of the figures by increasing the font size. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement that provides a clear instruction, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures in the paper, noting that the font size is too small and recommending that it be increased to improve readability. This feedback is clear and actionable, providing the authors with a straightforward way to enhance the clarity and accessibility of their figures. By addressing this issue, the authors can significantly improve the overall quality and usability of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively increase the font size without compromising the figure\\'s content. Despite this, the feedback is mostly helpful as it directs the authors toward a specific and beneficial improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point notes that only synthetic problems are considered in the experiments, implying that the authors should consider including real-world problems as well. However, the comment does not explicitly instruct the authors to do so or provide guidance on how to incorporate real-world problems into their experiments. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental scope but lack specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a concern about the experiments, specifically noting that only synthetic problems are considered. However, it does not specify which part of the paper discusses the experiments or where this limitation is most apparent. Without explicit references to sections, figures, or tables, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity regarding what specific synthetic problems are being considered or how the inclusion of real-world problems could improve the experiments. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that only synthetic problems are considered in the experiments, which is a factual observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the experimental setup, specifically noting that only synthetic problems are considered. This feedback is somewhat helpful as it highlights an area where the authors could expand their work to include real-world problems, which could enhance the applicability and generalizability of their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how to incorporate real-world problems into the experiments. To be more helpful, the comment could include examples of real-world problems or suggest ways to adapt the current framework to include them. Therefore, the comment is rated as somewhat helpful, as it identifies a potential improvement but does not fully guide the authors in implementing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This feedback provides a clear and direct action for the authors to take, specifying what additional comparisons are needed to enhance the evaluation of their work. The comment is concrete, as it clearly outlines the action required and the type of comparison that should be made. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NLE baselines\" and \"NLE interpretability tools,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to compare the explainer, which generates natural language explanations, with other NLE interpretability tools. This provides clear guidance on what additional comparisons are necessary to enhance the evaluation of the work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This claim is somewhat verifiable as it suggests a logical extension of the evaluation by comparing the explainer with other tools in the same domain. However, the comment does not provide specific examples or references to these other NLE interpretability tools, which would strengthen the justification. The authors would need to make an effort to identify and compare with these tools themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a missing element in the evaluation of the paper, specifically the lack of comparison with NLE (Natural Language Explanations) baselines. It points out that the authors have only compared their explainer, which generates natural language explanations, with feature attribution type of explanations. The comment suggests that the authors should also compare their explainer with other NLE interpretability tools, which is a clear and actionable suggestion. This feedback is valuable as it guides the authors to expand their evaluation and potentially strengthen the validity of their claims. However, the comment could be more helpful if it provided specific examples of NLE interpretability tools or explained why such comparisons are important. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with Eq. (5), noting that it only uses one pertinent positive data point and does not account for the diversity of data points that satisfy Eq. (1) and Eq. (2). The reviewer suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. This feedback provides a clear and explicit action for the authors to take, which is to expand the test to include the diversity of data points. The suggestion is concrete, as it specifies what needs to be added or changed to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with Eq. (5), noting that it only uses one pertinent positive data point and does not account for the diversity of data points that satisfy Eq. (1) and Eq. (2). The comment further suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Eq. (5) only uses one pertinent positive data point and does not account for the diversity of data points that satisfy Eq. (1) and Eq. (2). The reviewer suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. While the comment identifies a potential issue with the current approach, it lacks specific examples or references to support the claim that the current approach is insufficient. The suggestion to include an exhaustive test is logical, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of Eq. (5), noting that it only uses one pertinent positive data point and does not account for the diversity of data points that satisfy Eq. (1) and Eq. (2). The reviewer suggests that Eq. (5) should include an exhaustive test over the diversity of all these data points. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. By highlighting the need for a more comprehensive test, the comment offers valuable guidance for enhancing the robustness and validity of the paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their results with existing supervised retrievers to demonstrate how document augmentation can enhance performance. It implies that the authors should include comparisons with InPars-V2 and Promptagator, which were not included due to supervision data limitations. The comment provides a clear and concrete action for the authors to take, which is to show the additional performance boost from augmented queries or documents. This guidance is explicit and provides a specific direction for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"results\" and the \"document augmentation,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the comparison of results with existing supervised retrievers and the demonstration of how document augmentation can enhance performance. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results are compared fully without using supervision data, which is why InPars-V2 and Promptagator are not included in the comparison. The reviewer proposes that it would be beneficial to show how document augmentation can help on top of existing supervised retrievers. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that document augmentation would add additional performance boost. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It points out that the results are compared fully without using supervision data, which is why certain models like InPars-V2 and Promptagator are not included in the comparison. The reviewer suggests that it would be beneficial to demonstrate how document augmentation can enhance performance on top of existing supervised retrievers. This feedback is specific and constructive, offering a clear direction for the authors to expand their analysis and provide a more comprehensive evaluation of their approach. By addressing this suggestion, the authors can significantly improve the depth and relevance of their work, making the comment highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the discussion regarding the cache hierarchy, specifically the order in which the three dimensions are applied and whether they share data. It notes that while the individual levels are discussed in their construction, the way they are applied together is not addressed. The comment implies that the authors should clarify the application of the cache hierarchy, but it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the application of the cache hierarchy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"cache hierarchy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue, which is the lack of discussion on the order in which the three dimensions are applied and whether they share data. The comment further specifies the contradiction with the initial hierarchy claim, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically mentioning the lack of information on the order in which the three dimensions are applied and whether they share data. The comment also notes a contradiction with the initial hierarchy claim, as the individual levels are discussed in their construction but not in their application together. While the comment identifies a gap in the discussion, it lacks specific examples or references to support the claim of contradiction. This makes the claim somewhat verifiable, as the authors would need to further explore the paper to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the discussion of the cache hierarchy. It points out that while the individual levels are discussed in their construction, there is no explanation of how they are applied together. This is crucial information that could impact the understanding of the methodology and its implications. The comment highlights a contradiction with the initial hierarchy claim, which is important for the authors to address. However, while it identifies a critical area for improvement, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it directs the authors to a specific area needing clarification but lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the management of GPU memory during pretraining, specifically regarding the number of forward and backward propagations. While it implies that the authors should explain their approach to managing GPU memory, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of their memory management strategy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the management of GPU memory during pretraining, particularly regarding the number of forward and backward propagations. This provides clear guidance on what aspect of the paper needs clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the management of GPU memory during pretraining, specifically regarding the number of forward and backward propagations. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the management of GPU memory during pretraining, particularly regarding the number of forward and backward propagations shown in Figure 2. This feedback is somewhat helpful as it prompts the authors to clarify their approach to managing GPU memory, which is an important aspect of their work. However, the comment could be more helpful if it provided suggestions or examples on how to address the issue of GPU memory management. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to rewrite the Abstract to better present their contributions. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The reviewer specifies the issue with the current Abstract and suggests a solution, which gives the authors a concrete path forward in improving their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Abstract, which is its lack of clarity and difficulty in understanding the contributions. The comment provides a clear direction for improvement by recommending a rewrite to better present the contributions. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Abstract is not well-written and difficult to understand, suggesting a need for rewriting. However, the comment lacks specific examples or detailed reasoning to support why the current Abstract is unclear or how it could be improved. Without such evidence or guidance, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Abstract, noting that it is not well-written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite the Abstract to better present the contributions. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete step to enhance the clarity and effectiveness of their communication. However, the comment could be more helpful if it provided examples of how to improve the writing or suggested specific changes to consider. Overall, the comment is mostly helpful as it highlights a critical issue and offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point continues a previous discussion about ADE being a dataset for Image parsing and potentially biased among different scenes, which may favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this potential bias or improve the dataset to mitigate it. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous point about ADE being a dataset for Image parsing and potentially biased among different scenes. However, it does not explicitly mention which part of the paper this continuation addresses, making it weakly grounded. The comment is specific in its observation about the potential bias in the dataset, but it lacks detailed guidance on how the authors might address this issue or improve the dataset. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that ADE is a dataset for Image parsing and suggests that it may be biased among different scenes, favoring the performance of the proposed method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment continues a previous point about the potential bias in the ADE dataset for Image parsing, suggesting that it may favor the performance of the proposed method. However, it does not provide specific details or suggestions on how the authors might address this bias or improve the dataset. Without actionable guidance or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies an area of concern but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices for each relation (edge type) and suggests that the two matrices might be the same. It also notes that many matrices are not used in the following text. While the comment implies that the authors should clarify why two matrices are used and why some matrices are not used, it does not provide explicit instructions or concrete guidance on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of two matrices for each relation and noting that many matrices are not used in the following text. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions and observations about the use of matrices in the paper. It does not contain any subjective opinions, claims, or suggestions that require verification. The questions are factual and seek clarification, making the comment a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the use of two matrices for each relation (edge type) in section 2.1.2. It points out a potential inconsistency and asks for clarification on why two matrices are used when they might be the same. Additionally, it notes that many matrices are not used in the following text, suggesting a need for further explanation or justification. While the comment identifies a potential issue and prompts the authors to clarify their approach, it lacks detailed guidance or suggestions on how to address these concerns. The feedback is somewhat helpful as it highlights areas for improvement but could be more comprehensive with additional advice or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the semantics of the upsampled feature map being stronger than the original one, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might clarify or address this issue in their paper. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of understanding regarding the semantics of the upsampled feature map being stronger than the original one. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the semantics of the upsampled feature map being stronger than the original one. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the semantics of the upsampled feature map being stronger than the original one. By pointing out this lack of understanding, the reviewer highlights an important aspect that needs clarification. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it points out a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so or provide specific guidance on how to present this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with the referenced work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. However, it does not explicitly mention which part of the paper this clarification should be addressed in, making it weakly grounded. The comment is specific in its request for clarification on the differences between methods, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. However, the comment does not provide any specific reasoning or evidence to support why this clarification is necessary or how it would benefit the paper. The mention of [1] as a reference is not sufficient to substantiate the claim, as it lacks detailed comparison or analysis. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. This feedback is somewhat helpful as it identifies a specific area for improvement by pointing out the need for a clearer differentiation between methods. However, the comment lacks depth and does not provide detailed guidance on how to achieve this clarification or what specific aspects should be highlighted. To be more helpful, the comment could include suggestions on how to present the comparison or what key differences should be emphasized. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. While the comment implies that the authors should provide a detailed comparison, it does not explicitly instruct them to do so or provide specific guidance on how to present this comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with the referenced work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. However, it does not explicitly indicate which part of the paper this clarification should be addressed in, making it weakly grounded. The comment is specific in its request for clarification on the differences between methods, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. However, the comment does not provide any specific reasoning or evidence to support why this clarification is necessary or how it would benefit the paper. The mention of [1] as a reference is not sufficient to substantiate the claim, as it lacks detailed comparison or analysis. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. This feedback is somewhat helpful as it identifies a specific area for improvement by pointing out the need for a clearer differentiation between methods. However, the comment lacks depth and does not provide detailed guidance on how to achieve this clarification or what specific aspects should be highlighted. To be more helpful, the comment could include suggestions on how to present the comparison or what key differences should be emphasized. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically mentioning [1] as a reference. While the comment implies"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the theoretical basis for the empirical results in LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comments are vague and lack concrete actions or detailed advice, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the theoretical basis for empirically verified results in LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not specify which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the theoretical concerns and the perceived lack of clarity regarding the empirical results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims. The first claim questions the theoretical basis for empirically verified results in LoRA tuning, suggesting that the imposed structure of B and A might not be the most effective. The second claim questions the necessity of step size tuning despite theoretical claims. While the comments express doubts and provide logical reasoning, they lack specific examples, references, or detailed explanations to fully substantiate the claims. This makes the claims somewhat verifiable, as the authors would need to further explore and clarify the points raised.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas of concern: the theoretical basis for empirically verified results in LoRA tuning and the necessity of step size tuning despite theoretical claims. It raises questions about the theoretical justification for the empirical results and the potential limitations of the theoretical framework. However, the comment lacks actionable suggestions or guidance on how the authors might address these concerns or improve their draft. While it points out important areas for clarification, it does not provide detailed feedback or constructive advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors conduct more ablation studies or analysis on problems other than the shortest path problem. While the comment implies that additional experiments are needed to strengthen the paper\\'s claims, it does not provide explicit instructions on which specific problems to explore or how to design these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental environments and the design of the architecture (PathGNN), specifically mentioning the bias towards the shortest path problem. It suggests conducting more ablation studies or analysis on problems other than the shortest path problem. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or experiments. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting additional analyses, but it lacks full grounding because it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem and that the architecture (PathGNN) has a bias towards this problem. The reviewer recommends conducting more ablation studies or analysis on problems other than the shortest path problem to make the findings more convincing. However, the comment lacks specific examples or references to support the claim about the bias or the need for additional studies. This makes the claim somewhat verifiable, as the authors would need to infer the basis of the suggestion and determine how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the experimental setup, noting that most environments are closely related to the shortest path problem. It suggests that the authors conduct more ablation studies or analysis on problems other than the shortest path problem to strengthen the validity of their findings. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their work. By addressing this suggestion, the authors can improve the comprehensiveness and applicability of their study. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. While the action is implied, it is clear that the authors need to expand their baseline comparisons to include more recent models. The comment provides a specific direction for improvement, making it mostly actionable. However, it could be more actionable if it listed specific models or provided examples of how to incorporate them into the comparisons. Therefore, the comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion of baselines. The authors can infer that it relates to the comparison section, but this inference is not direct. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, the comment does not provide specific examples or references to these models, making it difficult for the authors to understand which models should be included or why they are relevant. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to make an effort to identify and incorporate the suggested models themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of more recent models. However, the comment lacks specificity and does not provide examples or detailed guidance on which models should be considered or how they might enhance the paper. To be more helpful, the comment could specify which recent models are relevant or provide a rationale for why these models are important. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also mentions that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific guidance on how to address these issues or suggest ways to improve the visualization or analysis. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also mentions that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not specify which part of the paper should include this visualization or where the analysis for insight is absent. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding. It is specific about the lack of visualization and insight but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim unverifiable, as it does not provide sufficient justification for the authors to address the issues effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending particular visualization techniques or analytical methods to enhance the paper\\'s novelty and insight. While it highlights important areas for improvement, the feedback lacks actionable details, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the analysis. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also mentions that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not specify which part of the paper should include this visualization or where the analysis for insight is absent. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these elements are discussed, the comment lacks full grounding. It is specific about the lack of visualization and insight but does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or references renders the claim unverifiable, as it does not provide sufficient justification for the authors to address the issues effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern with the experimental section, specifically noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and demonstrating its improvement over multiple baseline models. While the comment implies that the authors should report results for additional models, it does not explicitly instruct them to do so. The action is concrete, as it specifies the models to consider, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results showing only small benefits over the baseline model and suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and convincingly demonstrating improvement over multiple baseline models. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current results show only small benefits over the baseline model and suggests that reporting results for other models would strengthen the paper. The reviewer provides a logical reasoning by stating that reporting results for additional models would emphasize the generality of the method and convincingly demonstrate its improvement over multiple baseline models. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that have demonstrated the benefits of reporting results for multiple models. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific concern with the experimental section of the paper, noting that the current results show only small benefits over the baseline model. It provides a clear and actionable suggestion by recommending that the authors report results for other models, such as MetaOptNet, to emphasize the generality of the method and convincingly demonstrate its improvement over multiple baseline models. This feedback is valuable as it guides the authors on how to strengthen their experimental evaluation and improve the overall impact of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively present these results or what specific models to consider. Overall, the comment is mostly helpful, as it provides clear direction for enhancing the paper\\'s quality and impact.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a concern with the experimental section, noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and convincingly demonstrating its improvement over multiple baseline models. While the comment implies that the authors should report results for additional models, it does not explicitly instruct them to do so. The action is concrete, as it specifies the models to consider, but it is inferred rather than explicitly stated. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results showing only small benefits over the baseline model and suggests reporting results for other models, such as MetaOptNet, to strengthen the paper. This feedback provides clear guidance on how to improve the experimental section, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current results show only small benefits over the baseline model and suggests that reporting results for other models would strengthen the paper. The reviewer provides a logical reasoning by stating that reporting results for additional models would emphasize the generality of the method and convincingly demonstrate its improvement over multiple baseline models. This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to similar studies that have demonstrated the benefits of reporting results for multiple models. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific concern with the experimental section of the paper, noting that the current results show only small benefits over the baseline model. It provides a clear and actionable suggestion by recommending that the authors report results for other models, such as MetaOptNet, to emphasize the generality of the method and convincingly demonstrate its improvement over multiple baseline models."}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. While the comment explicitly states the action needed\u2014adding these comparisons\u2014the suggestion is somewhat vague because it does not provide specific guidance on how to integrate these methods into the paper or what aspects of the proposed method should be evaluated against them. The authors are aware of the need for a broader comparison but may need to infer the exact steps to take to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in suggesting which methods should be added to provide a broader evaluation of the proposed method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. While the comment provides a logical reasoning for the need for additional comparisons, it lacks specific references or examples of how these methods would enhance the evaluation. This makes the claim somewhat verifiable, as the authors would need to infer the potential benefits of including these methods themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s comparison, suggesting that the authors should include well-established methods like FTML and LFW to provide a more comprehensive evaluation of the proposed method. This feedback is clear and actionable, as it directs the authors to expand their comparison, which could enhance the paper\\'s rigor and credibility. However, the comment could be more helpful if it provided specific guidance on how to integrate these methods or what aspects of the proposed method should be evaluated against them. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed CRF variants underperform hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded. Additionally, it points out that location embeddings provide additional information on the main dataset but not on the extra dataset, implying that they may be useful for specific types of datasets. However, the comment does not provide explicit guidance on how the authors should adjust their focus or what specific changes they should make to their paper. The suggestions are implicit and lack concrete details, leaving the authors to infer the necessary actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, including the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It also mentions the use of location embeddings and their impact on the main dataset. However, the comment does not explicitly mention which sections of the paper discuss these topics, making it weakly grounded. The comment is specific in detailing the issues with the focus on CRF and the potential usefulness of location embeddings, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This claim is supported by the observation that location embeddings provide additional information on the main dataset but not in the extra dataset. However, the comment lacks specific examples or detailed comparisons to substantiate the claim fully. While the reasoning is logical, the absence of concrete evidence or references makes the claim somewhat verifiable. The authors would need to further explore and provide more detailed analysis to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the proposed CRF variants underperform hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded. Additionally, it points out that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they may be useful for specific types of datasets. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their approach. While it highlights important areas for consideration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the impact of the training-testing inconsistency. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific aspects need to be clarified. The comment lacks actionable guidance, leaving the authors uncertain about how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the impact of the training-testing inconsistency, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine the exact section being addressed, making the comment weakly grounded. However, it does specify the issue of training-testing inconsistency, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of the training-testing inconsistency, but it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity regarding the impact of the training-testing inconsistency, which is a relevant issue that could affect the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their discussion. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to resolve it. Therefore, the comment is barely helpful, as it highlights a potential weakness but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the condition for y membership being unclear due to the disjoint nature of sets S, and claims that are not backed up, specifically mentioning the second line after Eq. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the condition for y membership and provide evidence for their claims, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out areas needing clarification but does not offer detailed guidance on how to implement the changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"condition for y membership\" and references the \"sets S\" as being disjoint, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the clarity of the condition and mentions that some claims are not backed up, particularly the second line after Eq. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of sets S, as defined above. It also states that some claims are not backed up, specifically mentioning the second line after Eq. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The mention of disjoint sets provides some context, but additional explanation or references would be needed to fully verify the claims. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues: the condition for y membership being unclear due to the disjoint nature of sets S, and claims that are not backed up, particularly mentioning the second line after Eq. While the comment points out these weaknesses, it lacks detailed guidance or suggestions on how the authors might clarify the condition or provide evidence for their claims. This limits the usefulness of the feedback, as the authors are left to infer the necessary improvements without clear direction. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that certain key references that are highly related are not compared or explained in the paper. However, it does not provide specific guidance on which references are missing or how the authors should address this issue. The action is implicit, as the authors need to infer that they should include these references and explain their relevance, but it lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of certain key references that are highly related to the work being presented. However, it does not specify which references are missing or how they relate to the paper, making it difficult for the authors to identify the exact parts of the paper that need attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that certain key references are not compared or explained in the paper. However, it does not provide specific examples of these references or explain why their inclusion would be beneficial. Without detailed justification or references, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that certain key references that are highly related are not compared or explained. This feedback is valuable as it highlights a gap in the paper that the authors can address to strengthen their work. However, the comment lacks depth and does not provide specific guidance on which references are missing or how they should be integrated into the paper. While it points out an area for improvement, it does not offer actionable steps or suggestions for the authors to follow. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, suggesting that the results in Figure 7(c) and (d) do not meet expectations. It points out that COCO-LM achieves significant improvements with fewer labels but that these improvements gradually diminish with more labels. The reviewer also suggests that the authors check if COCO-LM benefits sentence retrieval tasks with learned anisotropy text representations. While the comment identifies specific areas of concern and provides a direction for further investigation, it does not explicitly instruct the authors on how to address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL regarding few-shot ability, noting that the results do not meet expectations and suggesting that COCO-LM may not bring benefits to sentence retrieval tasks with learned anisotropy text representations. This provides clear guidance on what needs to be addressed in the analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, suggesting that the results in Figure 7(c) and (d) do not meet expectations. The reviewer points out that COCO-LM achieves significant improvements with fewer labels but that these improvements gradually diminish with more labels. Additionally, the comment suggests that the authors check if COCO-LM benefits sentence retrieval tasks with learned anisotropy text representations. While the comment provides specific examples and a suggestion for further analysis, it lacks detailed reasoning or references to support the claim that the analysis is not convincing. The authors would need to infer the basis of the concern, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern with the analysis of SCL in section 5.2 regarding few-shot ability. It points out that the results in Figure 7(c) and (d) do not meet the authors\\' expectations, as COCO-LM achieves significant improvements with fewer labels but the improvements gradually diminish with more labels. The comment also suggests that the authors check if COCO-LM benefits sentence retrieval tasks with learned anisotropy text representations. This feedback is clear and actionable, providing the authors with specific areas to investigate and improve upon. However, it could be more helpful if it offered additional guidance or examples on how to address these issues. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for further analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete guidance on which specific LLMs to focus on or how to design these additional experiments. The authors are left with a general idea of what needs to be done but without detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental results or discussion sections, but this inference is not direct. The comment is specific in its suggestion to conduct additional experiments, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. However, the comment does not provide any reasoning, evidence, or references to support why this is necessary or how it would improve the paper. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on other Large Language Models (LLMs) to demonstrate the generalization of the proposed framework. This feedback is somewhat helpful as it provides a clear direction for expanding the experimental validation of the framework. However, it lacks specificity regarding which specific LLMs should be tested or how these experiments should be designed to effectively demonstrate generalization. Without detailed guidance or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to clarify the distinction between short and long videos to determine the downsample layers. It also recommends conducting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. While the comment provides explicit actions\u2014clarifying the distinction and conducting a comparison\u2014it does not offer detailed guidance on how to implement these actions. The authors are given a clear direction but may need to infer the specific steps to take, such as which videos to compare or how to structure the comparison. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarity on the distinction between short and long videos and suggesting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need clarity on the distinction between short and long videos to determine the downsample layers. It also recommends conducting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the need for this clarification or comparison. The claim is somewhat verifiable as it highlights a potential area for improvement but requires more detailed justification or evidence to fully substantiate the need for these changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for clarity regarding the distinction between short and long videos, which is crucial for determining the downsample layers. It provides a specific suggestion for improvement by recommending an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft by providing additional context and evidence. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in terms of efficiency when generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider improving the efficiency of their method, but it lacks concrete steps or recommendations on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the efficiency of generating multiple objects, which is mentioned in the paper. This allows the authors to identify the relevant part of the paper being discussed, providing full grounding. The comment also specifies the issue by pointing out the potential limitation in terms of efficiency, particularly for scenes with a high number of objects or complex interactions. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, indicating a potential limitation in terms of efficiency. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in terms of efficiency when generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This is a relevant observation that could impact the usability and practicality of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. While it highlights an important area for consideration, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit and concrete actions for the authors to take. It suggests that the technical contribution is thin and that the algorithm proposed may be considered incremental due to the use of an interpolative decomposition that is not proposed by the paper. The reviewer recommends that the authors focus on finding additional applications and deeply evaluating the approach. This feedback is actionable because it clearly outlines what the authors need to do to improve their draft, including identifying new applications and conducting a thorough evaluation. The comment provides specific guidance on how to enhance the manuscript, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the algorithm proposed and the use of an interpolative decomposition. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in suggesting that the authors focus on finding additional applications and deeply evaluating the approach to enhance the manuscript. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is thin and that the algorithm proposed may be considered incremental because the interpolative decomposition used is not proposed by the paper. The reviewer suggests that the authors focus on finding additional applications and deeply evaluating the approach to enhance the manuscript. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the algorithm is incremental. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the technical contribution of the paper, suggesting that the proposed algorithm may be considered incremental due to the use of an interpolative decomposition that is not proposed by the paper. The reviewer provides a constructive suggestion for improvement by recommending that the authors focus on finding additional applications and deeply evaluating the approach. This feedback is actionable and provides a clear direction for enhancing the manuscript, such as exploring new applications or evaluating the approach more thoroughly. However, the comment could be more helpful if it offered specific examples or guidance on how to find additional applications or evaluate the approach. Overall, the comment is mostly helpful as it provides valuable insights and suggestions for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the neural network library used for implementing the system and notes that there are no details on the implementation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should provide details on the implementation or if there are specific aspects that need clarification. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the neural network library used for implementing the system and notes that there are no details on the implementation. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its request for details on the implementation, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the neural network library used for implementation. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the neural network library used for implementing the system, noting that there are no details provided. This is a valuable piece of feedback as it highlights a gap in the paper that could impact the reproducibility and understanding of the work. However, the comment does not offer suggestions or guidance on how the authors might address this issue, such as recommending specific libraries or providing more detailed information. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant omission but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the clarity of descriptions, noting that some math notations are undefined and that details in Figure illustrations are missing. However, it does not provide explicit instructions or suggestions on how to address these issues. The comment ends with a request for more information, which implies that the authors should provide additional details, but it does not specify what those details should be. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the undefined notations and missing details. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the clarity of descriptions, mentioning undefined math notations and missing details in Figure illustrations. However, it does not specify which parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as undefined notations and missing details in figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in Figure illustrations. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of specific examples or references to the unclear parts of the paper limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas where the descriptions are unclear, mentioning undefined math notations and missing details in Figure illustrations. By pointing out these issues, the reviewer provides the authors with actionable feedback that can help improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included specific suggestions or examples of how to clarify these issues. Overall, the feedback is somewhat helpful as it directs the authors to areas needing improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\\\nu in the text, in addition to the explanation provided in Algorithm 1. This feedback is clear and direct, providing a specific action for the authors to take. The suggestion is concrete, as it specifies exactly what needs to be added to the text. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to mention the meaning of the notation \\\\nu in the text, in addition to the explanation provided in Algorithm 1. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention the meaning of the notation \\\\nu in the text, in addition to the explanation provided in Algorithm 1. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. It is a factual statement seeking additional information, so it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of explanation for the notation \\\\nu in the text, in addition to the explanation provided in Algorithm 1. This feedback is clear and actionable, as it directs the authors to include a textual explanation for the notation, which is crucial for reader comprehension. By addressing this point, the authors can enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively integrate the explanation into the text. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a finding from the appendix, which suggests that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises an interesting question about whether the model is underfit due to pseudo-labels being very accurate, leading to better feedback from positive learning than a noise robust loss. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should explore the implications of this finding and possibly adjust their approach. The lack of concrete steps or suggestions makes the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the finding that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9, and it raises an interesting question about whether the model is underfit due to pseudo-labels being very accurate. The comment provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that the use of noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It also raises an interesting question about whether the model is underfit due to pseudo-labels being very accurate. However, the comment lacks specific evidence, detailed reasoning, or references to support the claim or the question. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a pertinent question about whether the model is underfit due to pseudo-labels being very accurate, leading to better feedback from positive learning than a noise robust loss. This feedback is somewhat helpful as it prompts the authors to consider the implications of their findings and potentially explore alternative approaches to address any underfitting issues. However, the comment could be more helpful if it provided specific suggestions or guidance on how to investigate or address the issue. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises a question about whether the model is underfit due to pseudo-labels being very accurate, leading to better feedback from positive learning than a noise robust loss. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors need to infer that they should explore the implications of this finding and possibly adjust their approach. The lack of concrete steps or suggestions makes the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the finding that using noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9, and it raises an interesting question about whether the model is underfit due to pseudo-labels being very accurate. The comment provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that the use of noise robust loss on pseudo-labels performs lower than using positive learning from Eq 9. It raises an interesting question about whether the model is underfit due to pseudo-labels being very accurate, leading to better feedback from positive learning than a noise robust loss. However, the comment lacks specific evidence, detailed reasoning, or references to support the claim or the question. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights an interesting finding from the appendix, noting that using noise robust loss on pseudo-labels performs lower than"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim made in line 248, specifically questioning why an additional exponentiation would significantly increase the runtime to the point of being a consideration for the attacker. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should clarify, provide additional explanation, or address this concern in their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim about the runtime increase due to an additional exponentiation, providing a clear indication of what needs to be clarified or addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the claim made in the paper regarding the runtime increase due to an additional exponentiation. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about a claim made in the paper regarding the runtime increase due to an additional exponentiation. It highlights a potential misunderstanding or lack of clarity in the explanation provided. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or clarify the claim. While it identifies a point of confusion, it lacks actionable feedback or constructive advice, making it somewhat helpful. The authors are left with a question to ponder but without clear direction on how to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the improvements of the proposed methods compared to existing related works and suggests that the experiments are lacking in comparison with state-of-the-art (SOTA) methods. While the comment implies that the authors should compare their methods with these related works, it does not provide explicit instructions or concrete guidance on how to conduct these comparisons or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for comparison and determine which aspects to compare. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract sections, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements of the proposed methods compared to existing related works and suggesting that the experiments are lacking in comparison with state-of-the-art (SOTA) methods. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of comparison with state-of-the-art (SOTA) methods, referencing specific related works. However, it does not provide detailed reasoning or examples of how these methods should be compared or what specific aspects of the proposed methods are lacking. The claim is somewhat verifiable as it highlights a potential gap in the paper\\'s evaluation, but it lacks the depth and specificity needed for a fully verifiable comment. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of comparison with state-of-the-art (SOTA) methods in the paper. It highlights the need to address this gap by comparing the proposed methods with existing related works, such as \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" This feedback is clear and actionable, as it directs the authors to include a comparison with relevant SOTA methods to strengthen their experimental evaluation. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the experiments demonstrate the proposed method\\'s enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and the enhancement of the proposed method, suggesting that the effectiveness of introducing more learnable parameters, such as the temperature, has been previously proven. However, it does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how the authors might address this concern or improve their work. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments\\' demonstration of the proposed method\\'s enhancement is not surprising because it introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. However, the comment lacks specific references or examples to support the claim that the effectiveness of these parameters has been previously proven. Without detailed evidence or citations, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the experiments demonstrate the proposed method\\'s enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, whose effectiveness has been previously proven. While the comment identifies a potential limitation in the novelty of the results, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their work. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges that the experiments demonstrate the proposed method\\'s enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, whose effectiveness has been previously proven. However, the comment does not provide any explicit or implicit actions for the authors to take in response to this observation. It lacks guidance on how the authors might address this concern or improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and the enhancement of the proposed method, suggesting that the effectiveness of introducing more learnable parameters, such as the temperature, has been previously proven. However, it does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how the authors might address this concern or improve their work. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point acknowledges that the experiments demonstrate the proposed method's enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, whose effectiveness has been previously proven. However, the comment lacks specific references or examples to support the claim that the effectiveness of these parameters has been previously proven. Without detailed evidence or citations, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the experiments demonstrate the proposed method\\'s enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, whose effectiveness has been previously proven. While the comment identifies a potential limitation in the novelty of the results, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their work. Without actionable"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting ways to integrate the neuroscience inspiration more effectively or remove it altogether. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not specify which part of the paper this issue is related to, nor does it provide details on what aspects of the neuroscience inspiration are considered unnecessary or distracting. Without specific references or detailed feedback, the authors cannot confidently determine which parts of the paper need revision or improvement. Therefore, this comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide specific details or examples of what aspects of the neuroscience inspiration are considered unnecessary or distracting. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the issue. The comment lacks depth and specificity, making it difficult for the authors to effectively improve their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to update Table 3 by adding information about the source dataset in the caption. This is a clear and direct action that the authors can take to improve the clarity of their presentation. The comment also suggests that the image and table captions should contain all necessary information about the experiment, which is another specific and actionable piece of advice. The feedback is concrete and provides clear guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, which does not provide information about the source dataset used in the experiment. The comment suggests adding this information to the caption to improve clarity and consistency. The feedback is clear and provides a specific action for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the caption in Table 3 is unclear regarding the source dataset used. The reviewer suggests adding information about the source dataset to the caption to improve clarity. This claim is somewhat verifiable as it identifies a specific issue with the caption and provides a suggestion for improvement. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The addition of \"Apart from that, great job!\" at the end of the comment does not contribute to the verifiability of the initial claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the caption in Table 3, noting that it does not specify the source dataset used. It provides a clear and actionable suggestion to add this information to the caption, which would enhance the transparency and accessibility of the experimental setup for readers. Additionally, the comment highlights the importance of including all necessary information in the captions to avoid the need for readers to search for details in the main text. While the feedback is mostly helpful, it could be more comprehensive by offering additional guidance on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of explicit descriptions of the specific architectures used for value networks, policy networks, and uncertainty-aware networks. It highlights that this omission makes it difficult for readers to replicate and evaluate the approach. The comment provides a clear and direct action for the authors to take, which is to include explicit descriptions of these architectures. This feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the lack of explicit descriptions of the architectures used for value networks, policy networks, and uncertainty-aware networks. This makes it difficult for readers to replicate and evaluate the approach. However, the comment does not specify which part of the paper should include these descriptions, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is missing, which is the explicit description of the architectures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used for value networks, policy networks, and uncertainty-aware networks, making it difficult for readers to replicate and evaluate the approach. This claim is somewhat verifiable as it highlights a specific issue that could impact the reproducibility and evaluation of the work. However, the comment does not provide detailed examples or references to support the claim, leaving the authors to infer the potential impact of this omission. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of explicit descriptions of the architectures used for value networks, policy networks, and uncertainty-aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. By pointing out this gap, the comment provides clear and actionable feedback that can help the authors improve the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to provide these descriptions or examples of what information should be included. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as assuming the transition model P is true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and assuming learned models are consistent. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific changes to make the assumptions more reasonable. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions related to the applicability of EMCTS to real complex problems, such as the assumption of a true transition model P, the requirement of $Q^{\\pi}$ being linear, and the assumption of consistent learned models. However, it does not explicitly mention which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that might make EMCTS inapplicable, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions might make EMCTS inapplicable to real complex problems, citing specific assumptions such as the assumption of a true transition model P, the requirement of $Q^{\"}{\\\\pi}$ being linear, and the assumption of consistent learned models. However, the comment lacks detailed reasoning or evidence to support why these assumptions are unreasonable or how they might affect the applicability of EMCTS. The claim is somewhat verifiable as it provides some context, but it requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of a true transition model P, the requirement of $Q^{\\\\pi}$ being linear, and the assumption of consistent learned models. This feedback is somewhat helpful as it points out specific areas where the assumptions might be problematic, providing the authors with a starting point for revising their assumptions. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the applicability of EMCTS. To be more helpful, the comment could include specific recommendations or examples of how to modify these assumptions. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of a true transition model P, the requirement of $Q^{\\\\pi}$ being linear, and the assumption of consistent learned models. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific changes to make the assumptions more reasonable. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific assumptions related to the applicability of EMCTS to real complex problems, such as the assumption of a true transition model P, the requirement of $Q^{\\\\pi}$ being linear, and the assumption of consistent learned models. However, it does not explicitly mention which part of the paper these assumptions are discussed in, making it weakly grounded. The comment is specific in detailing the assumptions that might make EMCTS inapplicable, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions might make EMCTS inapplicable to real complex problems, citing specific assumptions such as the assumption of a true transition model P, the requirement of $Q^{\\\\pi}$ being linear, and the assumption of consistent learned models. However, the comment lacks detailed reasoning or evidence to support why these assumptions are unreasonable or how they might affect the applicability of EMCTS. The claim is somewhat verifiable as it provides some context, but it requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of a true transition model P, the requirement of $Q^{\\\\pi}$ being linear, and the assumption of consistent learned models. This feedback is somewhat helpful as it points out specific areas where"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the relationship between explicitness (E) and size (S) may be related to the given dataset, and that the different capacity requirements in the 3rd paragraph might be due to input modality differences. It also implies that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. However, the comment does not explicitly instruct the authors on how to address these issues or provide concrete steps for improvement. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the relationship between explicitness (E) and size (S) and suggests that the different capacity requirements in the 3rd paragraph might be due to input modality differences. The comment further provides guidance on how to evaluate disentanglement and the capacity of probing, including factors like training time, cost, and learning rate. This level of detail and clarity makes the comment fully grounded and specific, corresponding to label 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the relationship between explicitness (E) and size (S) may be related to the given dataset, and that the different capacity requirements in the 3rd paragraph might be due to input modality differences. The comment provides a logical reasoning for this claim, suggesting that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. However, it lacks specific examples or references to support the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the relationship between explicitness (E) and size (S) and their potential impact on the given dataset. It suggests that the different capacity requirements in the 3rd paragraph might be due to input modality differences. The comment also offers guidance on evaluating disentanglement, emphasizing the importance of providing enough capacity and training time. Additionally, it highlights the need to consider factors like training time, cost, and learning rate when evaluating the capacity of probing. This feedback is clear and actionable, offering the authors a structured approach to improve their draft by addressing specific aspects of their methodology. However, it could be more helpful if it provided examples or specific suggestions for implementation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper title should not include abbreviations. This is an explicit and concrete action, as it directly instructs the authors to make a specific change to their title. The comment provides clear guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper title should not include abbreviations. However, it does not specify which part of the paper this suggestion pertains to, such as the title itself or a specific section where the title is mentioned. Without explicit references to the title or the relevant section, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding why abbreviations should be avoided or what impact this change might have on the paper. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper title should not include abbreviations. However, it does not provide any reasoning or evidence to support why abbreviations are unnecessary or problematic. Without additional context or justification, the claim lacks verifiability. The authors may find it challenging to understand the basis of this suggestion, making it difficult for them to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper title should not include abbreviations. While this is a specific and actionable piece of feedback, it lacks context or explanation as to why abbreviations are unnecessary or how this change might impact the paper\\'s readability or clarity. Without additional guidance or reasoning, the authors may find it challenging to fully understand the rationale behind this suggestion. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and context.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the transferability of the discriminator to other tasks and domains without further training, as well as its effectiveness with limited data. It also mentions that the discriminator can be small, which is an important insight. However, the comment does not provide explicit guidance or suggestions on how the authors should address these points or incorporate the insight into their work. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to apply this information to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as the transferability of the discriminator to other tasks and domains without further training, and its effectiveness with limited data. It also mentions that the discriminator can be small, which is an important insight. However, the comment does not explicitly mention which part of the paper these observations are based on, making it weakly grounded. The authors can infer that it relates to sections discussing the discriminator or experimental results, but this inference is not direct. The comment is specific in detailing what needs to be addressed regarding the transferability and effectiveness of the discriminator. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and observations about the transferability and effectiveness of the discriminator, as well as its size. It does not contain any subjective claims or opinions that require verification. The questions are factual and seek clarification, making the comment a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several points of interest regarding the discriminator\\'s transferability to other tasks and domains without further training, as well as its effectiveness with limited data. It also notes that the discriminator can be small, which is an important insight. However, the comment does not provide specific guidance or suggestions on how the authors might address these points or incorporate the insight into their work. While it identifies areas of interest, it lacks actionable feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the current SOTA GNN-QE should be included as a baseline and compared with the proposed approach. This provides a clear and direct action for the authors to take, ensuring that they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"current SOTA GNN-QE,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by suggesting that the current SOTA GNN-QE should be included as a baseline and compared with the proposed approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE is omitted from the baselines, despite being the closest work in terms of components to the proposed approach. The reviewer suggests that this baseline should be added and compared. However, the comment does not provide specific references or detailed reasoning to support why this baseline is crucial or how it would impact the evaluation. Without additional context or evidence, the claim is somewhat verifiable, as it lacks the depth needed for a fully substantiated argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper by pointing out that the current state-of-the-art (SOTA) GNN-QE is not included as a baseline, despite being the closest work in terms of components to the proposed approach. The comment explicitly suggests that this baseline should be added and compared, which provides a clear and actionable recommendation for the authors to enhance the comprehensiveness and validity of their evaluation. By highlighting this gap, the reviewer offers a specific and constructive suggestion that can significantly improve the paper\\'s rigor and relevance. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. The reviewer acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to prove the correctness of the findings. While the comment implies that the authors should address these concerns, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the pretraining data and its potential impact on GPT-2 understanding, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. However, the comment does not provide specific evidence or references to support these claims, making it difficult for the authors to address the concerns effectively. The lack of detailed reasoning or examples makes the claim borderline verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the pretraining data and its impact on GPT-2 understanding language, suggesting that the setting may not be reasonable. It also points out that facts may have been learned before training, which could affect the validity of the findings. The comment acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to prove the correctness of the findings. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address these concerns. This limits its helpfulness, as it provides insight but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. The reviewer acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to prove the correctness of the findings. While the comment implies that the authors should address these concerns, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. The comment acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to prove the correctness of the findings. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about the pretraining data and its potential impact on GPT-2 understanding, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the pretraining data and its impact on GPT-2 understanding language. It suggests that the setting may not be reasonable and that facts may have been learned before training. However, the comment lacks specific evidence, examples, or references to support these claims, making it difficult for the authors to address the concerns effectively. The reasoning is based on logical reasoning but lacks detailed justification, making the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the pretraining data and its impact on GPT-2 understanding"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific areas where the proposed method is not thoroughly explained, such as the computation of terms in equation (4) and the optimization algorithm. It explicitly instructs the authors to provide a clear explanation of these aspects, which is a direct and concrete action. The comment also clarifies that every term in the math formulas should be explained unless it is extremely obvious, giving the authors a clear direction on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\" and \"optimization algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out missing computations and the need for a clear explanation of the optimization algorithm, including how to calculate $p(x_k|d)$. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of terms in equation (4) and the optimization algorithm. The reviewer provides a logical reasoning by suggesting that every term in the math formulas should be explained unless it is extremely obvious, which is not the case for (4). This reasoning is clear and provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the proposed method is not thoroughly explained, particularly regarding the computation of terms in equation (4) and the optimization algorithm. It provides a clear and actionable suggestion for improvement by recommending that every term in the math formulas should be explained unless it is extremely obvious. This feedback is valuable as it guides the authors on what aspects of their method need clarification, helping them to enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional guidance on how to improve the explanation or provided examples of how to clarify the terms. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area needing improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors need to provide implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also highlights the importance of these details for reproducibility and fairness of comparison. The comment further suggests that the lack of implementation details makes it difficult to evaluate the significance of the experimental results, weakening the overall contribution. The authors are given a clear and concrete action to take, which is to provide detailed implementation information. This feedback is explicit and provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, such as providing detailed implementation information to ensure reproducibility and fairness of comparison. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details for the RAMP algorithm, the algorithms compared with, and other aspects of the experiments makes the experimental results non-reproducible and difficult to assess the fairness of comparison. The reviewer supports this claim by noting that the lack of implementation details hinders the evaluation of the significance of the experimental results. However, the comment does not provide specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of implementation details for the RAMP algorithm and other aspects of the experiments. This omission makes the experimental results non-reproducible and hinders the assessment of fairness in comparison with existing methods. The comment highlights the importance of providing detailed implementation information to ensure the validity and impact of the experimental results. By suggesting that a thorough description of the implementation details is needed, the comment offers clear and actionable feedback that can significantly improve the paper. This feedback is highly helpful as it guides the authors on what specific information is missing and how to address it, thereby enhancing the quality and reproducibility of the work.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. However, it notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. This comment provides some context and perspective on the novelty of the approach but does not offer any actionable feedback or suggestions for improvement. The authors are left without guidance on how to address or enhance their work based on this observation. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the concept of employing a mixture of experts (MoE) for a task, noting that it is not unusual due to its extensive application in various tasks such as general LLM, summarization, and machine translation. However, it also mentions that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. This comment provides some context and perspective on the novelty of the approach but does not specify which part of the paper this observation pertains to. The authors might infer that it relates to the introduction or related work sections, but this is not explicitly stated. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is specific in its critique of the concept\\'s novelty. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. This comment provides a logical reasoning based on the widespread use of MoE in other domains, which supports the claim that the application in text detection is not groundbreaking. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. While this comment provides some context and perspective on the novelty of the approach, it does not offer actionable feedback or suggestions for improvement. The authors are left without guidance on how to enhance their work or address the perceived lack of novelty. Therefore, the comment is rated as barely helpful, as it provides limited value for improving the draft.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not provide any actionable feedback or suggestions for improvement. It lacks specificity and does not offer guidance on how the authors might address or enhance their work based on this observation. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. However, the comment does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how the authors might address or enhance their work based on this insight. Without explicit references or actionable suggestions, the comment lacks both grounding and specificity, making it unactionable. Therefore, it aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It also notes that the application of MoE in text detection is relatively new but not groundbreaking in terms of its fundamental idea. This comment provides a logical reasoning based on the widespread use of MoE in other domains, which supports the claim that the application in text detection is not groundbreaking"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to conduct the statistical analysis or which specific tests should be performed. The action is implicit, as the authors need to infer that they should include statistical analysis, and it is somewhat vague because it does not specify the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of \"SpaceTGN achieving significant performance improvement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of statistical analysis to support the claim of significance. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' assertion of significant performance improvement for SpaceTGN is not supported by statistical analysis. This claim is somewhat verifiable as it highlights a gap in the paper\\'s methodology. However, it lacks specific examples or references to statistical tests that should be conducted to substantiate the claim. The comment suggests that the authors should include statistical analysis, but without detailed guidance or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. This is a significant issue that could impact the credibility and robustness of the paper\\'s findings. By pointing out this omission, the comment provides clear and actionable feedback, encouraging the authors to include statistical analysis to strengthen their claims. However, the comment could be more helpful if it offered suggestions on which specific statistical tests should be conducted or how to present the results. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential source of confusion regarding the presentation of scores, noting that it is unclear why certain scores are excerpted versus reproduced. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to clarify the presentation. The action is implicit, as the authors can infer that they need to clarify the presentation of scores, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the clarity of the presentation of scores, specifically noting that it is unclear why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue is related to, such as a particular section or table where these scores are presented. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in terms of the issue it identifies, it lacks grounding as it does not provide explicit references to the paper\\'s sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential source of confusion regarding the presentation of scores, noting that it is unclear why certain scores are excerpted versus reproduced. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that this confusion exists. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential source of confusion in the paper regarding the presentation of scores, noting that it is unclear why certain scores are excerpted versus reproduced. While it highlights an area that could benefit from clarification, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential weakness in the paper, but it lacks depth and actionable advice, leaving the authors with a general direction to improve clarity without detailed steps. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the method, noting that it primarily involves the application of consistency models in place of other generative models. The reviewer suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the novelty of the method, which involves the application of consistency models. However, it does not explicitly mention a particular section, figure, or table, making it weakly grounded. The comment is specific in that it questions the novelty of the method and suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot. This provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is somewhat simply applying consistency models in place of other generative models for learning target distributions, suggesting limited novelty. The reviewer provides a logical reasoning by questioning the novelty of the approach, which is supported by the comparison to other generative models. However, the comment lacks specific examples or references to previous generative models that could be compared to the consistency models, making it somewhat verifiable. The authors would need to further explore the literature to fully understand the novelty claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the method, noting that it primarily involves the application of consistency models in place of other generative models for learning target distributions. The reviewer suggests that the authors should provide more commentary on how consistency models achieve something that previous generative models cannot, which is a constructive suggestion for improvement. However, the comment lacks specific guidance or examples on how the authors might address this issue, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more detailed to be fully actionable. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric used in Table 2 is limited to MSE, which does not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should consider additional metrics, modify the existing ones, or provide more detailed explanations. Without specific actions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that the use of MSE alone cannot reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric used in Table 2 is limited to MSE, which does not adequately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only uses MSE, which may not adequately reflect the accuracy of nowcasting. This feedback is somewhat helpful as it points out a potential limitation in the evaluation process. However, it lacks depth and does not provide suggestions on how the authors might address this issue or improve the evaluation metric. Without actionable guidance or additional context, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the evaluation metric used in Table 2, specifically that it only uses MSE, which may not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that the use of MSE alone cannot reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric used in Table 2 is limited to MSE, which may not adequately reflect the accuracy of nowcasting. However, the comment lacks supporting evidence, reasoning, or specific examples to substantiate this claim. Without additional context or detailed explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only uses MSE, which may not adequately reflect the accuracy of nowcasting. This feedback is somewhat helpful as it highlights a potential limitation in the evaluation process. However, it lacks depth and does not provide suggestions on how the authors might address this issue or improve the evaluation metric. Without actionable guidance or additional context, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation in the evaluation metric used in Table 2, specifically noting that it only uses MSE, which may not adequately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue or improve the evaluation metric. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP) and notes that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The feedback lacks actionable steps, such as recommending specific experiments or analyses to better demonstrate the benefit of FFA-LoRA. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP), specifically mentioning the performance gap between the vanilla LoRA and the proposed FFA-LoRA across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. This provides some level of grounding as it refers to specific aspects of the evaluation. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the empirical result that suggests the impact of DP noise is the same on both LoRA and FFA-LoRA, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well supported by empirical evaluation, as the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. The comment provides a logical reasoning by suggesting that the empirical result implies a lack of impact of DP noise on both LoRA and FFA-LoRA. However, it lacks specific examples or references to substantiate the claim further. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires additional details to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP). It points out that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets $\\\\epsilon$, including $\\\\epsilon = 0$. This observation suggests that the impact of DP noise is the same on both LoRA and FFA-LoRA, which is a critical finding that needs further exploration. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their empirical evaluation. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add specific ablation studies to the existing ablation study of ENGINE. It suggests including \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA\" and recommends providing more detailed analysis of the ablation results. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable. The authors know exactly what additional studies to include and how to analyze the results more thoroughly, ensuring a direct path to improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be added by suggesting \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA\" and recommending more detailed analysis of the ablation results. This provides clear guidance on what additional content is needed and how to improve the analysis, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation study of ENGINE is incomplete and provides specific suggestions for additional ablation studies. It also recommends giving more detailed analysis to the ablation results. While the comment provides a clear suggestion for improvement, it lacks specific references or detailed reasoning to fully substantiate the claim that the ablation study is incomplete. The authors would need to infer the importance of these suggestions, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the ablation study of the ENGINE model. It suggests adding additional ablation studies, specifically \"Cap-CapNE-ClipNE-EA\" and \"Cap-CapNE-ClipNE-NE-EA,\" which provides clear and actionable feedback. Additionally, the comment recommends giving more detailed analysis to the ablation results, which is another constructive suggestion for enhancing the paper. By providing specific guidance on what additional studies to include and how to analyze the results, the comment offers valuable insights that can help the authors improve their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the mode coverage in GAN optimization and suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should conduct additional experiments on these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these datasets in their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include results on specific datasets is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. The reviewer suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. This claim is somewhat verifiable as it provides a logical reasoning for the need to test on more challenging datasets, but it lacks specific examples or references to support the assertion about the difficulty of methods on LSUN and ImageNet. The comment could be strengthened with more detailed reasoning or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. This feedback is valuable as it prompts the authors to consider the generalizability of their findings beyond the datasets they have already tested. However, the comment could be more helpful if it offered specific guidance on how to conduct these additional experiments or what aspects to focus on when analyzing the results. Overall, the comment is somewhat helpful as it identifies an area for improvement and provides a direction for further investigation, but it lacks detailed suggestions for implementation.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should conduct additional experiments on these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these datasets in their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to include results on specific datasets is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these additions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment provides a logical reasoning for the need to test on more challenging datasets, it lacks specific examples or references to support the assertion about the difficulty of methods on LSUN and ImageNet. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the mode coverage in GAN optimization, specifically why GDIM has poor mode coverage while DDGAN has good mode coverage. It suggests that providing results on more challenging high-resolution datasets like LSUN"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"Each attribute of the table feature represents a scene\" in Section 5.1. While it identifies a specific part of the paper that needs clarification, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify this point, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"Each attribute of the table feature represents a scene.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific statement in the paper, \"Each attribute of the table feature represents a scene.\" While it identifies a potential area of confusion or lack of clarity, it does not provide any additional context or suggestions for improvement. The comment lacks depth and actionable guidance, leaving the authors with a basic understanding of what needs clarification but no clear direction on how to address it. Therefore, the comment is barely helpful, as it provides only a starting point for the authors to consider revising the explanation. This aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the lack of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should conduct an ablation study to determine how much better the logsumexp aggregation is compared to direct addition, which would correspond to a basic prototype comparison with reweighted averages on each prototype. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and it highlights the need for a comparison between the logsumexp aggregator and other methods. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is concrete but inferred, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises concerns about the lack of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests conducting an ablation study to determine the superiority of logsumexp aggregation over direct addition, which would correspond to a basic prototype comparison with reweighted averages on each prototype. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and it highlights the need for a comparison between the logsumexp aggregator and other methods. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology or results sections where these comparisons should be discussed. The comment is specific in detailing what needs to be addressed, but it lacks explicit grounding, as it does not directly reference a section or part of the paper. Therefore, this comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It questions the superiority of logsumexp aggregation over direct addition and suggests that the authors should conduct an ablation study to determine this. The comment also questions the compatibility of the token reweighting scheme with existing token-to-token classifiers and highlights the need for a comparison between the logsumexp aggregator and other methods. While the comment provides a logical reasoning for the need for additional studies, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study for the impact of token reweighting versus the logsumexp aggregation scheme. It suggests conducting an ablation study to determine the superiority of logsumexp aggregation over direct addition, which would correspond to a basic prototype comparison with reweighted averages on each prototype. Additionally, the comment questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and it highlights the need for a comparison between the logsumexp aggregator and other methods. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it offered suggestions on how to conduct the ablation study or provided examples of similar studies. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the current datasets used are insufficient to evaluate the effectiveness of ECGs and suggests considering the large-scale datasets mentioned in references [1] and [2]. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their dataset to include these references. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of limited datasets and suggests considering large-scale datasets mentioned in references [1] and [2]. However, it does not specify which part of the paper discusses the datasets or where the authors should include these references. The authors can infer that it relates to the dataset section or experimental setup, but this inference is not direct. The comment is specific in suggesting the use of specific datasets, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current datasets used are insufficient to evaluate the effectiveness of ECGs and suggests considering large-scale datasets mentioned in references [1] and [2]. The comment provides specific references to support the claim, which enhances its verifiability. However, it lacks detailed reasoning or examples on why these datasets are more suitable or how they would improve the evaluation. While the references provide a basis for the claim, the lack of specific justification or detailed explanation makes the comment mostly verifiable. Therefore, the feedback is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the current dataset used to evaluate the effectiveness of ECGs, noting that only five datasets are insufficient. It suggests considering large-scale datasets mentioned in references [1] and [2], which could provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their dataset to include these references, thereby enhancing the robustness and generalizability of their findings. However, the comment could be more helpful if it provided additional context or guidance on how to integrate these datasets into the study. Overall, the comment is mostly helpful, as it offers a specific and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to acknowledge the limitation of analyzing only fully connected ResNets and to include this in the Broader Impact section. This feedback provides a clear and direct action for the authors to take, ensuring that they address the practical relevance of their work. The comment is specific in its request, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the analysis of fully connected ResNets, suggesting that the paper should acknowledge this limitation and include it in the Broader Impact section. However, it does not specify which part of the paper discusses fully connected ResNets, making it weakly grounded. The comment is specific in its suggestion to include the limitation in the Broader Impact section, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is a limitation compared to the typical use of convolutional layers in practice. The reviewer suggests that the paper should acknowledge this limitation and include it in the Broader Impact section. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that convolutional layers are more common in practice. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires additional evidence or examples to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that it only analyzes fully connected ResNets, which is not a typical practice in the field. It suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. By highlighting this limitation, the comment helps the authors understand the scope of their work and its implications, which is valuable for improving the paper. However, the comment could be more helpful if it offered additional guidance on how to address this limitation or suggested ways to incorporate it into the broader context of the paper. Overall, the feedback is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and mentions that standard knowledge distillation (KD) methods have surpassed the reported KD performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or improve their draft based on this comparison. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the performance of a student model trained on the training set, specifically mentioning ResNet18 as the student model. It provides examples of datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. However, it does not specify which part of the paper this information pertains to, such as a specific section or result section. The authors can infer that it relates to the experimental results or discussion, but this inference is not direct. The comment is specific in detailing the performance metrics and references to standard KD methods, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It also mentions that early KD methods have surpassed the reported KD performance. This provides a comprehensive and logical basis for the claim, making it fully verifiable. The reviewer supports the claim with specific examples and references to well-known KD methods, which helps the authors understand the context and relevance of the comparison. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10. It references standard knowledge distillation (KD) methods and mentions that early KD methods have surpassed the reported KD performance. This feedback is valuable as it offers insights into the model\\'s performance and provides a benchmark for comparison. However, the comment could be more helpful if it included specific suggestions on how the authors might improve their model or address the gap between their results and those of standard KD methods. Overall, the comment is somewhat helpful as it provides some context and direction for improvement, but it lacks depth and actionable guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. However, it does not offer any explicit or implicit actions for the authors to take in response to this information. There is no guidance on how the authors should use this comparison to improve their draft or address any potential weaknesses. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the performance of a student model trained on the training set, specifically mentioning ResNet18 as the student model. It provides examples of datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. However, it does not specify which part of the paper this information pertains to, such as a specific section or result section. The authors can infer that it relates to the experimental results or discussion, but this inference is not direct. The comment is specific in detailing the performance metrics and references to standard KD methods, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It also mentions that early KD methods have surpassed the reported KD performance. This provides a comprehensive and logical basis for the claim, making it fully verifiable. The reviewer supports the claim with specific examples and references to well-known KD methods, which helps the authors understand the context and relevance of the comparison. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically asks whether this assumption might be violated by certain GCN variants, such as Geniepath or Gated GNN, where message passing and sub-graph structure are coupled. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and vague, as the authors are left to infer that they need to consider the implications of these GCN variants on their framework. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a specific concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It questions whether this assumption might be violated by certain GCN variants, such as Geniepath or Gated GNN, where message passing and sub-graph structure are coupled. This raises a clear and specific issue that the authors need to address. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing the potential issue with the causal graph assumption. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions GCN variants like Geniepath and Gated GNN, which are known to learn message passing and sub-graph structure in a coupled manner. The reviewer suggests that this coupling could potentially break the causal graph assumption in the proposed framework. While the comment provides a logical reasoning based on existing knowledge of GCN variants, it lacks specific references or detailed examples to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for questioning the assumption but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the assumptions underlying the proposed framework, specifically regarding the causal factors and the direction of influence. It points out that some GCN variants, such as Geniepath and Gated GNN, learn message passing and sub-graph structure in a coupled manner, which could potentially violate the assumed directionality. This feedback is valuable as it challenges the authors to reconsider their assumptions and potentially revise their framework to accommodate these GCN variants. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to incorporate these GCN variants into the framework. Overall, the comment is somewhat helpful as it prompts the authors to consider a significant aspect of their work that may need revision, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions GCN variants like Geniepath and Gated GNN, which are known to learn message passing and sub-graph structure in a coupled manner. The comment implies that the authors should consider whether this coupling could break the causal graph assumption in their proposed framework. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what steps they should take to incorporate these GCN variants into their framework. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a specific concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It mentions GCN variants like Geniepath and Gated GNN, which are known to learn message passing and sub-graph structure in a coupled manner. This raises a clear and specific issue that the authors need to address. However, the comment does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing the potential issue with the causal graph assumption. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions GCN variants like Geniepath and Gated GNN, which are known to learn message passing and sub-graph structure in a coupled manner. The reviewer suggests that this coupling could potentially break the causal graph assumption in the proposed framework. While the comment provides a logical reasoning based on existing knowledge of GCN variants, it lacks specific references or detailed examples to fully"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide a list of the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This feedback is explicit and provides a clear action for the authors to take, which is to include performance data for SOTA algorithms. The suggestion is concrete, as it specifies what information should be added to the draft to enhance its comprehensiveness. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"pre-processing,\" \"message-passing,\" and \"post-processing,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of consideration for pre- and post-processing modules and suggests including the performance of SOTA algorithms in each dataset discussed in Table 1. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the assertion that message-passing layers are the most important part of GNNs, given that different tasks may require different pre- and post-processing modules. The reviewer suggests that listing the performance of state-of-the-art algorithms in each dataset discussed in Table 1 would help clarify the importance of message-passing. While the comment raises a valid point, it lacks specific examples or references to support the claim that message-passing is the most important part of GNNs. The suggestion to include performance data is a logical step, but the initial claim is not fully substantiated. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s analysis, specifically the overemphasis on message-passing layers as the most important part of Graph Neural Networks (GNNs). It points out that different tasks may require different pre- and post-processing modules, which could affect the importance of message-passing. The comment suggests that listing the performance of state-of-the-art algorithms in each dataset discussed in Table 1 would help readers understand the gap between NAS models and human-engineered SOTA architectures. This feedback is clear and actionable, providing a specific suggestion for improving the paper by including performance data. However, it could be more helpful if it offered additional guidance on how to present this information or discussed the implications of the findings. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. While the comment implies that the authors should provide additional evidence or justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more evidence or explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that it would be useful to demonstrate the utility of learning the advantage directly, and it questions the evidence provided in the paper for why this is important compared to other methods. However, it does not specify which part of the paper this concern relates to, making it weakly grounded. The comment is specific in its suggestion to provide more evidence or justification, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to demonstrate the utility of learning the advantage directly and questions the evidence provided in the paper for why this is important compared to other methods. While the comment implies that the authors should provide more evidence, it does not explicitly state a claim or opinion. It is more of a request for clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to demonstrate the utility of learning the advantage directly, as there is little evidence in the paper to support why this is important compared to other methods. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable advice or detailed feedback, the authors may find it challenging to determine how to incorporate this suggestion into their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough detail to be fully actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on, which are used in the appended algorithms. While the comment explicitly states an action\u2014adding explanations\u2014it does not provide specific guidance on which symbols need explanation or how to structure these explanations. The authors are left with a clear direction but without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and so on, which are used in the appended algorithms. However, it does not specify which part of the paper these symbols are used in, making it difficult for the authors to pinpoint the exact sections that need clarification. While the authors might have an idea of where these symbols are used, the comment lacks full grounding. It is specific in suggesting what needs to be addressed, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, etc., which are used in the appended algorithms. However, the comment does not provide any reasoning or evidence to support why these explanations are necessary or how they would improve the paper. Without specific examples or justification, the claim lacks verifiability, making it difficult for the authors to understand the importance of adding these explanations. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, and so on, which are used in the appended algorithms. This feedback is clear and actionable, as it identifies a specific area where the authors can improve the clarity and accessibility of their work. By providing these explanations, the authors can enhance the reader\\'s understanding of the algorithms and their implementation. However, the comment could be more helpful if it specified which symbols are particularly confusing or if it offered examples of how to structure these explanations. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. However, it does not provide specific guidance or suggestions on how the authors could address this issue or improve the innovation of their method. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what specific aspects of the method lack innovation or how the authors could address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to understand and address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation and may represent incremental changes to established methods. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the limited performance gains indicate a lack of innovation and may represent incremental changes to established methods. While it identifies a potential issue with the paper, it lacks specificity and actionable guidance. It does not provide detailed feedback on how the authors could enhance the innovation or suggest ways to differentiate their work from existing methods. This limits the usefulness of the comment for the authors, as it does not offer concrete steps or examples to address the identified concern. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback implies that the authors should conduct a broader comparison to provide a clearer picture of the proposed system\\'s strengths and weaknesses. While the action is explicit, it lacks concrete guidance on how to conduct this comparison or which specific methods or systems to include. The authors are given a clear direction but may need to infer the details of how to implement this suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this suggestion pertains to, such as the results section or the discussion section. This makes it difficult for the authors to pinpoint where this additional analysis should be integrated. While the authors might have an idea of where to incorporate this, the comment lacks full grounding. It is specific in suggesting a direction for improvement but does not provide detailed guidance on how to implement this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, indicating that such an analysis would help clarify the strengths and weaknesses of the proposed system. However, the comment lacks specific examples or references to existing methods or systems that could be compared, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by conducting a broader comparison. By doing so, the authors could better understand the strengths and weaknesses of their proposed system relative to others in the field. However, the comment could be more helpful if it offered examples of specific methods or systems that could be compared or detailed guidance on how to structure this analysis. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides some direction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical usefulness of the method $\\mathrm{PH-GDN}_{\\mathrm{C}}$ due to its theoretical guarantees and the fact that it does not outperform existing methods on the real dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method\\'s practical usefulness. The comment lacks actionable guidance, leaving the authors without a clear path to follow. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"$\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$\" and the real dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ not outperforming existing methods on the real dataset, which is a critical aspect of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment lacks specific examples or references to existing methods that it compares with, making it difficult for the authors to fully understand the basis of the claim. The absence of detailed comparisons or references leaves the claim somewhat verifiable, as it requires more information to be substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ by pointing out that its prediction performance on the real dataset does not outperform existing methods. This is a critical observation that could impact the perceived value and applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method\\'s performance. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a concern regarding the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ due to its theoretical guarantees and the fact that it does not outperform existing methods on the real dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the method\\'s practical usefulness. Without actionable guidance or specific recommendations, the authors are left without a clear path to follow. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"$\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$\" and the real dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ not outperforming existing methods on the real dataset, which is a critical aspect of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment lacks specific examples or references to existing methods that it compares with, making it difficult for the authors to fully understand the basis of the claim. The absence of detailed comparisons or references leaves the claim somewhat verifiable, as it requires more information to be substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the practical usefulness of the method $\\\\mathrm{PH-GDN}_{\\\\mathrm{C}}$ by pointing out that its prediction performance on the real dataset does not outperform existing methods. This is a critical observation that could impact the perceived value and applicability of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the method\\'s performance. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between the proposed algorithm and offline RL algorithms for single agents, noting that the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they might consider to improve the fairness of their comparison. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison between the proposed algorithm and offline RL algorithms for single agents. It points out that the target of those algorithms is not to find an equilibrium, which is a relevant observation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the comparison, but without clear grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because their targets are not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the proposed algorithm and offline RL algorithms for single agents. It points out that the target of those algorithms is not to find an equilibrium, which could affect the fairness of the comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it highlights an important consideration, the feedback lacks actionable advice, making it somewhat helpful. The authors are given insight into a potential weakness but are not directed on how to resolve it, limiting the comment\\'s utility. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should clarify its unique contributions in methodology and purpose, and provide more detailed comparisons to similar works. While the comment implies that the authors should make these clarifications and comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these changes and how to go about it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the overlap of the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014with prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. However, the comment does not specify which part of the paper should be revised or where these comparisons should be made, making it weakly grounded. The comment is specific in suggesting what needs to be clarified and compared, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. The comment provides a logical reasoning by pointing out the overlap with prior work and suggests a need for clarification and detailed comparisons. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the prior works mentioned to fully understand the critique, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential overlap with prior work in the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and suggests that the paper should clarify its unique contributions in methodology and purpose. It provides a specific recommendation to include more detailed comparisons to similar works. This feedback is actionable and provides a clear direction for the authors to enhance the originality and impact of their work. However, the comment could be more helpful if it offered specific examples of similar works or detailed suggestions on how to make these comparisons. Overall, the comment is mostly helpful as it guides the authors toward improving their draft by highlighting areas for clarification and comparison.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks supporting materials. However, it does not provide any explicit guidance or suggestions on what specific supporting materials are needed or how to incorporate them. The action is implicit, as the authors can infer that they need to provide supporting materials, but it lacks concrete details on what those materials should be or how to present them. Therefore, the comment is somewhat actionable, as it identifies an issue but does not provide clear instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of supporting materials for the statement \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"in Section 1, \"human perception is usually invariant to the texture resampling\" lacks support materials.\" However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks supporting materials. This feedback is clear and actionable, as it directs the authors to provide additional evidence or references to support this claim. However, the comment could be more helpful if it offered suggestions on what kind of supporting materials would be appropriate or how to integrate them into the paper. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks, particularly by conducting additional experiments on a broader range of tasks. This feedback provides a clear and explicit action for the authors to take, as it specifies the need for additional experiments to enhance the method\\'s perceived generalizability. The comment is concrete, as it directly instructs the authors on what additional experiments to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the generality of the paper, specifically focusing on the applicability of MiPKD to other CV tasks beyond SR tasks. It suggests that the authors should demonstrate the method\\'s applicability to a broader range of tasks. However, the comment does not explicitly mention which part of the paper discusses MiPKD\\'s performance in SR tasks, making it weakly grounded. The suggestion to show applicability to other CV tasks is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that MiPKD is not specifically designed for the SR task and encourages the authors to demonstrate its applicability to other CV tasks. While the comment provides a logical reasoning that the method\\'s generalizability should be tested on a broader range of tasks, it lacks specific examples or references to support this claim. The suggestion is somewhat verifiable as it highlights a potential limitation but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper\\'s generality, noting that MiPKD is primarily discussed in the context of SR tasks but may not be specifically designed for this task. It suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks, which could enhance the method\\'s perceived generalizability. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and demonstrate the versatility of their method. However, the comment could be more helpful if it offered suggestions on which other CV tasks to consider or how to structure these additional experiments. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This is an explicit suggestion with clear guidance on what the authors should do: they can safely omit these equations. The action is concrete and directly addresses the content of the paper, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by suggesting that these equations may be omitted without affecting the flow of the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This claim is based on the reviewer\\'s belief that these equations are not necessary for understanding the content. However, the comment lacks specific reasoning or evidence to support why these equations are not used or how their omission would impact the flow of the section. Without additional context or justification, the claim remains somewhat verifiable, as it provides a logical suggestion but lacks detailed support. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it provides the authors with a concrete suggestion to simplify their draft by removing unnecessary equations. By addressing this point, the authors can streamline their paper and potentially improve its clarity. However, the comment could be more helpful if it explained why these equations are not used or how their removal would impact the overall understanding of the section. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the optimization module uses a simple iteration strategy to optimize two loss functions and notes that the overall model seems incremental, standing on the shoulders of traditional approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the optimization strategy or address the perceived incremental nature of the model. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the optimization module and its strategy for optimizing two loss functions. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides some insight into the perceived incremental nature of the model, it lacks specificity regarding what aspects of the optimization strategy are problematic or how they could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulders of traditional approaches. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a critique of the optimization module, noting that it applies a simple iteration strategy to optimize two loss functions. It suggests that the overall model is incremental and stands on the shoulders of traditional approaches. While the comment identifies a potential issue with the optimization strategy, it lacks specific suggestions or guidance on how the authors might improve or enhance their approach. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper could be improved and provides a specific suggestion regarding the choice of F(X) for the E(d) case. It asks for more detailed explanation on how to construct F(X) in the main paper and mentions that the authors should elaborate on this in the appendix. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. The suggestion is clear and actionable, giving the authors a specific task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper could be improved, specifically mentioning the choice of F(X) for the E(d) case. It asks for more detailed explanation on how to construct F(X) in the main paper and mentions that the authors should elaborate on this in the appendix. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where F(X) is discussed. The suggestion to elaborate on the construction of F(X) is specific, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing of the paper could be improved, specifically mentioning a concern with the choice of F(X) for the E(d) case. It requests more detailed explanation on how to construct F(X) in the main paper and mentions that the authors should elaborate on this in the appendix. While the comment identifies a potential issue with the writing, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to elaborate on the construction of F(X) provides some guidance, but the overall justification for the claim is somewhat vague. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the writing of the paper, suggesting that the choice of F(X) for the E(d) case is unclear. It provides a clear and actionable suggestion by asking the authors to elaborate on how to construct F(X) in the main paper and to provide more detailed examples in the appendix. This feedback is valuable as it directs the authors to a specific aspect of their writing that needs clarification, offering a concrete way to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance or examples on how to improve the explanation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions they should consider. The action is implicit and vague, as the authors are left to infer that they need to identify and address these assumptions, but without concrete steps or examples, the guidance is lacking. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. However, the comment does not specify which part of the paper discusses these assumptions or where the authors might need to address them. This lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the implicit assumptions the paper adopts for few-shot learning. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implicit assumptions the paper adopts to achieve successful few-shot learning. It suggests that the authors might have made assumptions like the meta-distribution assumption or distribution-closeness assumption. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional assumptions they should consider. While it prompts the authors to think about their assumptions, it lacks actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general direction to explore, but without specific guidance, the comment does not fully support their efforts to improve the draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand their comparison to prior work by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks to facilitate easier comparison. While the comment implies that these actions should be taken, it does not explicitly instruct the authors to do so. The suggestion is concrete, as it specifies what additional comparisons and benchmarks should be included. However, the action is inferred rather than explicitly stated, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks. However, it does not specify which part of the paper this comparison is currently lacking, making it weakly grounded. The comment is specific in suggesting what additional comparisons and benchmarks should be included to enhance the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models, and by providing results for more standard benchmarks. While the comment provides a logical reasoning for why these additions would be beneficial, it lacks specific examples or references to support the claim. The suggestion is based on general reasoning rather than detailed evidence, making it somewhat verifiable. The authors would need to make an effort to understand and address the suggestion, but the lack of concrete examples or references limits the thoroughness of the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models. It also recommends providing results for more standard benchmarks, which would facilitate easier comparison to prior work. This feedback is clear and actionable, offering specific directions for enhancing the paper\\'s comprehensiveness and comparability. By addressing these suggestions, the authors can significantly improve the depth and relevance of their work. However, the comment could be more helpful if it provided examples of specific prior works or benchmarks to consider. Overall, the comment is mostly helpful, as it guides the authors toward meaningful enhancements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution. The comment lacks actionable details, such as recommending specific improvements or alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution need improvement. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts to focus on for improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are lacking or how they could be improved. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the reviewer\\'s assessment. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific suggestions or guidance on how to enhance the contribution. The comment lacks actionable feedback or detailed insights that would help the authors improve their draft. Without concrete advice or examples, the authors are left without a clear path forward. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the clarity of their claims. It lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific benefits claimed in the paper, which allows the authors to identify the relevant sections of the paper. However, it does not explicitly mention which part of the paper these benefits are discussed in, making it weakly grounded. The comment is specific in pointing out that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without references. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three benefits of the paper are difficult to grasp, specifically noting that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements without references. While the comment provides some reasoning by pointing out the lack of detail and references, it lacks specific examples or detailed explanations to fully substantiate the claims. This makes the comment somewhat verifiable, as it provides a general direction for improvement but requires more detailed evidence or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s claims regarding the benefits of understanding the agent\\'s performance post-training. It points out that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without references. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and substantiation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered examples of how to improve the clarity and support for the benefits. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies specific issues with the paper\\'s claims regarding the benefits of understanding the agent\\'s performance post-training. It notes that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without references. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve the clarity of their claims. Without actionable advice or specific steps for the authors to take, the comment lacks actionable value. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific benefits claimed in the paper, allowing the authors to identify the relevant sections of the paper. However, it does not explicitly mention which part of the paper these benefits are discussed in, making it weakly grounded. The comment is specific in pointing out that Benefit 1 is too abstract and lacks contextual detail, and that Benefit 3 includes broad statements without references. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three benefits of understanding the agent\\'s performance post-training are difficult to grasp. It specifically critiques Benefit 1 for being too abstract and lacking contextual detail, and Benefit 3 for including broad statements without references. While the comment provides some reasoning by pointing out the lack of detail and references, it lacks specific examples or detailed explanations to fully substantiate the claims. This makes the comment somewhat verifiable, as it provides a general direction for improvement but requires more detailed evidence or examples to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper\\'s claims regarding the benefits of understanding the agent\\'s performance post-training. It notes that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements without references. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and substantiation. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or offered examples of how to improve the clarity and support for the benefits. Overall, the comment provides some guidance but lacks depth and actionable advice, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_r"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. It also provides a conclusion that the paper presents an interesting, novel approach with sufficient experimental evidence to show effectiveness, but highlights the limited impact of the approach as the only substantial negative. While the comment identifies a gap in the paper\\'s presentation and provides a general assessment of the paper\\'s strengths and weaknesses, it does not offer specific guidance or suggestions on how to address the lack of quantitative results or improve the impact of the approach. The feedback is somewhat actionable as it points out a specific area for improvement but lacks detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. It also provides a conclusion about the paper\\'s novelty and experimental evidence. However, the comment does not specify which part of the paper should include quantitative results or where the qualitative results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being addressed. The comment is specific in questioning the lack of quantitative results and provides a general assessment of the paper\\'s strengths and weaknesses. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. This is a logical claim that highlights a potential gap in the paper\\'s evaluation. However, the comment does not provide specific examples or references to support the claim, nor does it offer suggestions on how to address the lack of quantitative results. The reasoning is somewhat verifiable, as it points out a potential issue but lacks detailed justification or guidance for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. This feedback is somewhat helpful as it highlights an important area for improvement in the paper, prompting the authors to consider including quantitative results to strengthen their evaluation. However, the comment could be more helpful if it provided specific suggestions on how to incorporate quantitative results or what metrics should be used. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. It also provides a conclusion about the paper\\'s novelty and experimental evidence, but does not offer specific guidance or suggestions on how to address the lack of quantitative results or improve the impact of the approach. While the comment identifies a gap in the paper\\'s presentation, it lacks actionable feedback or detailed instructions on how to enhance the draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. It also provides a conclusion about the paper\\'s novelty and experimental evidence, but does not specify which part of the paper should include quantitative results or where the qualitative results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being addressed. The comment is specific in questioning the lack of quantitative results and provides a general assessment of the paper\\'s strengths and weaknesses. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness on a few pictures. This is a logical claim that highlights a potential gap in the paper\\'s evaluation. However, the comment does not provide specific examples or references to support the claim, nor does it offer suggestions on how to address the lack of quantitative results. The reasoning is somewhat verifiable, as it points out a potential issue but lacks detailed justification or guidance for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'help"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the categorization of the paper under Fairness/Accountability/Transparency. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on whether the authors should clarify the categorization, provide additional context, or address any potential gaps in their work. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency section. However, it does not specify which part of the paper is being addressed or what specific aspects of the categorization are unclear. The authors cannot confidently determine which part of the paper the comment pertains to, nor do they have a clear understanding of what needs to be addressed or clarified. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking for clarification about the categorization of the paper under the Fairness/Accountability/Transparency section. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under the Fairness/Accountability/Transparency section. While it identifies a potential area of confusion or misclassification, it does not provide any further context, suggestions, or guidance on how the authors might address this issue. Without additional information or actionable feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a machine learning 2-step baseline to compare their approach with the baselines. This feedback implies that the authors should consider adding a specific type of baseline to their analysis, which would help determine whether the improvements are due to the algorithm itself or the class of algorithms used. While the action is implicit, it is concrete because it specifies the type of baseline that should be included. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the comparison of the proposed approach with baselines, specifically mentioning that all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than the authors\\' assertion that NaviFormer outperforms baselines by tackling the routing and path planning problem jointly. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting a particular type of baseline to include, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with baselines is not sufficient because all approaches appear to be heuristic methods. The reviewer suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than the authors\\' assertion that NaviFormer outperforms baselines. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion of a 2-step baseline. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s evaluation by noting that all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than the authors\\' assertion that NaviFormer outperforms baselines by tackling the routing and path planning problem jointly. This feedback is clear and actionable, as it provides a specific suggestion for improving the robustness of the evaluation. However, it could be more helpful if it offered additional guidance on how to implement the suggested baseline or discussed the potential implications of including it. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment suggests including a machine learning 2-step baseline to compare the proposed approach with the baselines. This feedback implies that the authors should consider adding a specific type of baseline to their analysis to determine whether the improvements are due to the algorithm class or the authors\\' assertion that NaviFormer outperforms baselines by tackling the routing and path planning problem jointly. While the action is implicit, it is concrete because it specifies the type of baseline that should be included. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the comparison of the proposed approach with baselines, specifically mentioning that all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than the authors\\' assertion that NaviFormer outperforms baselines by tackling the routing and path planning problem jointly. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The suggestion to include a specific type of baseline provides some level of specificity, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with baselines is not sufficient because all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than the authors\\' assertion that NaviFormer outperforms baselines by tackling the routing and path planning problem jointly. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion of a 2-step baseline. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s evaluation by noting that all approaches appear to be heuristic methods. It suggests including a machine learning 2-step baseline to determine if the improvements are due to the algorithm class rather than"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors clarify whether the better results are due to a better image generative model or other factors. It provides a specific recommendation to conduct a fair comparison by applying the planning and layering method to the design images generated by other image generative models. This feedback is explicit and provides concrete guidance on how to address the issue, making it highly actionable. The authors know exactly what action to take to improve their draft by conducting a more comprehensive comparison.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the clarity of the results and suggests a specific action to improve them by conducting a fair comparison. It recommends applying the planning and layering method to the design images generated by other image generative models. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improving the comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results are better than other compared methods but questions whether this is due to a better image generative model. The reviewer recommends conducting a fair comparison by applying the planning and layering method to the design images generated by other image generative models. While the suggestion is logical, it lacks specific examples or references to support the claim that the results are solely due to the image generative model. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically questioning whether the better results are due to a better image generative model or other factors. It provides a clear and actionable suggestion by recommending a fair comparison, such as applying the planning and layering method to the design images generated by other image generative models. This feedback is valuable as it guides the authors on how to address the issue and improve the robustness of their results. However, the comment could be more helpful if it included specific examples or references to similar studies that have conducted such comparisons. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparative study with state-of-the-art (SOTA) methods, such as those mentioned by Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), to strengthen their claim about the effectiveness of the proposed method. The comment explicitly states the need for a more comprehensive comparison, which provides a clear action for the authors to take. However, it does not specify how to incorporate these methods or what specific aspects of the comparison would be beneficial. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed method and the need for a comparative study with SOTA methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of SOTA methods like Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019) in the comparative study. This provides clear guidance on how to improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method should include a comparison with SOTA methods to justify the authors\\' claim about the effectiveness of their approach. The reviewer provides a list of specific SOTA methods, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), which supports the claim with examples of relevant work. This provides a clear and specific basis for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the proposed method was only compared with relatively simpler baselines, such as zero padding, but lacked comparison with state-of-the-art (SOTA) methods. This is a crucial observation as it questions the validity of the authors\\' claim about the effectiveness of their method. By suggesting that the comparative study should include SOTA methods like Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), the comment provides a clear and actionable suggestion for improvement. This feedback empowers the authors to strengthen their claims by conducting a more comprehensive comparison, thereby enhancing the rigor and credibility of their work. However, the comment could be more helpful if it offered specific guidance on how to integrate these SOTA methods into the study. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusing aspect in the discussion of the dataset, specifically mentioning lines 329-334. It suggests that the authors should clarify whether the information about \"opinion holder\" and \"opinion targets\" is relevant to the experiments in the paper. If these details are not pertinent, they should be removed. This feedback provides a clear and explicit action for the authors to take, which is to clarify or remove the irrelevant information. The suggestion is concrete, as it specifies what needs to be addressed and how to do so. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 329-334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, noting the confusion regarding the task being plain polarity classification versus the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that if these details are not relevant to the experiments, they should be removed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, particularly regarding the task of plain polarity classification versus the mention of \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these details are not relevant to the experiments, they should be removed. While the comment identifies a potential issue with the clarity of the discussion, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to remove irrelevant information is a logical step, but without further elaboration, the comment remains somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding the dataset, particularly in lines 329-334. It points out a potential confusion in the task description, suggesting that the authors may have inadvertently included irrelevant information about \"opinion holder\" and \"opinion targets.\" The comment provides a clear and actionable suggestion for the authors to clarify whether these details are relevant to the experiments or should be removed. This feedback is valuable as it helps the authors improve the clarity and focus of their discussion, making the comment mostly helpful. However, it could be further improved by providing more context or examples of how these details might impact the discussion. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding the dataset, particularly in lines 329-334. It suggests that the authors should clarify whether the information about \"opinion holder\" and \"opinion targets\" is relevant to the experiments in the paper. If these details are not pertinent, they should be removed. This feedback provides a clear and explicit action for the authors to take, which is to clarify or remove the irrelevant information. The suggestion is concrete, as it specifies what needs to be addressed and how to do so. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 329-334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, noting the confusion regarding the task being plain polarity classification versus the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that if these details are not relevant to the experiments, they should be removed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, particularly regarding the task of plain polarity classification versus the mention of \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these details are not relevant to the experiments, they should be removed. While the comment identifies a potential issue with the clarity of the discussion, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to remove irrelevant information is a logical step, but without further elaboration, the comment remains somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding the dataset,"}
{"generated_text": "{'actionability_rationale': 'The review point continues a previous comment and raises concerns about the unnecessary restriction of capsule networks. It highlights that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, making it difficult to assess the benefits of enforcing equivariance strictly. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their draft. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous discussion, so it is not fully grounded as it does not explicitly mention which part of the paper it addresses. However, it does specify the issue of unnecessary restriction of capsule networks and the lack of information about the number of parameters in the group CapNet, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the unnecessary restriction of capsule networks and the lack of information about the number of parameters in the group CapNet. It suggests that this lack of information makes it difficult to judge the benefits of enforcing equivariance strictly. However, the comment does not provide specific examples or references to support these claims, making it somewhat verifiable. The authors would need to infer the basis of the concern and determine how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment continues a previous discussion, highlighting concerns about the unnecessary restriction of capsule networks and the lack of information about the number of parameters in the group CapNet. It points out that this lack of information makes it difficult to assess the benefits of enforcing equivariance strictly. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it points out a gap in the paper, but it lacks actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. While the comment suggests that the authors might consider these approaches, it does not explicitly instruct them to do so or provide detailed guidance on how to implement these methods. The action is implicit and somewhat vague, as the authors need to infer that they should explore these approaches but are not given specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images and provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. This provides clear guidance on what the authors need to consider or explore in their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. This provides a logical reasoning and specific references to support the claim, making the comment mostly verifiable. However, it could be strengthened by providing more detailed comparisons or examples of how these approaches work, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as discussed on page 4. It provides a valuable suggestion by referencing previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. This feedback is actionable as it directs the authors to consider these existing solutions and potentially adapt them to their work. However, the comment could be more helpful if it provided specific guidance on how to integrate these approaches or what aspects of the existing solutions could be beneficial for the authors. Overall, the comment is mostly helpful as it offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. While the comment suggests that the authors might consider these approaches, it does not explicitly instruct them to do so or provide detailed guidance on how to implement these methods. The action is implicit and somewhat vague, as the authors need to infer that they should explore these approaches but are not given specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images and provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue with more efficient implementations of the Tweedie approach. This provides clear guidance on what the authors need to consider or explore in their work. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an evaluation of inference speed on the hardware. This is an explicit action that the authors can take to improve their draft. However, the comment does not provide specific guidance on how to conduct this evaluation or which hardware should be considered. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an evaluation of inference speed on the hardware, which is a specific suggestion for improvement. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this inference is not direct. The comment is specific in its suggestion, as it clearly identifies what needs to be added to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including an evaluation of inference speed on the hardware would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would impact the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include an evaluation of inference speed on the hardware. This is a clear and actionable suggestion that could enhance the comprehensiveness of the paper by providing additional insights into the practical implications of the work. However, the comment lacks specific guidance on how to conduct this evaluation or which hardware should be considered, which limits its helpfulness. While it points out a potential area for improvement, the authors may need to conduct further research to fully address this suggestion. Therefore, the comment is somewhat helpful, as it identifies a relevant area for enhancement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the modified problem is convex and can be solved via an SDP, but it does not specify where the SDP formulation is located in the paper. While it implies that the authors should include the SDP formulation, it does not provide explicit instructions or concrete guidance on how to locate or present it. The action is implicit and somewhat vague, as the authors need to infer that they should search for the SDP formulation but lack detailed instructions on where to look. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"modified problem\" and the \"SDP formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the absence of the SDP formulation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the modified problem is convex and can be solved via an SDP. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific details or examples that would help the authors understand the basis of the claim or how it relates to their work. Without additional context or explanation, the claim remains unverifiable, making it difficult for the authors to address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, pointing out that the modified problem is convex and can be solved via an SDP, but it lacks the SDP formulation. This feedback is somewhat helpful as it highlights a gap in the paper that needs to be addressed. However, it does not provide detailed guidance or suggestions on how to include the SDP formulation or where it should be placed in the paper. The comment could be more helpful if it offered specific advice or examples on how to present the SDP formulation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: the lack of information on the number of new task combinations used to evaluate compositional generalizability in line 558, and the limited number of composite instructions in Table 7. While the comment identifies these areas as needing clarification, it does not provide explicit instructions on how the authors should address these issues. The authors can infer that they need to provide more details or additional results, but the comment lacks concrete guidance on how to implement these changes. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the lack of information regarding the number of new task combinations used for evaluation and the limited number of composite instructions in Table 7. These statements are descriptive and do not express subjective opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, namely the lack of information on the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending additional experiments or analyses. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, is not well-formatted. However, it does not provide specific guidance on how to improve the layout or what aspects of the formatting are problematic. Without concrete suggestions or examples of what needs to be addressed, the authors are left without a clear understanding of how to enhance the layout of their figures. As a result, the comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the paper, particularly the figures, is not well-formatted. However, it does not specify which figures are being referred to or what specific issues with the layout are problematic. This lack of detail makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is not grounded because it does not provide specific guidance on where to focus improvements. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-formatted. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what constitutes a \"good layout,\" the authors may find it challenging to understand and address the issue. The lack of supporting information makes the claim unverifiable, as it does not provide sufficient justification for the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the figures are not well-formatted. However, it lacks detail and does not provide any guidance on how to improve the layout or what specific aspects of the formatting are problematic. Without actionable feedback or suggestions, the authors are left without a clear path to address the issue. This limits the usefulness of the comment, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s contributions, noting that without clear differentiation from existing works and a detailed comparison with similar techniques, the contributions may be perceived as incremental or lacking substantial novelty. This feedback implies that the authors should address this issue by providing a clearer differentiation and more detailed comparisons. However, the comment does not explicitly instruct the authors on how to achieve this, nor does it provide specific guidance on which existing works to compare with or how to differentiate the contributions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper\\'s contributions, specifically the lack of clear differentiation from existing works and detailed comparison with similar techniques. However, it does not specify which part of the paper should address this issue, making it weakly grounded. The comment is specific in identifying the need for differentiation and comparison, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparison with similar techniques. The comment provides a logical reasoning by suggesting that without such differentiation and comparison, the work may not stand out in the NLP community. However, the comment lacks specific examples or references to existing works for comparison, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s contributions, noting that without clear differentiation from existing works and detailed comparison with similar techniques, the contributions may be perceived as incremental or lacking substantial novelty. This feedback is valuable as it highlights a potential weakness in the paper that could impact its reception and perceived value within the NLP community. However, the comment does not provide specific guidance on how to address this issue, such as suggesting which existing works to compare with or how to differentiate the contributions. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides insight but not comprehensive guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the paper\\'s contributions, noting that without clear differentiation from existing works and detailed comparison with similar techniques, the contributions may be perceived as incremental or lacking substantial novelty. This feedback implies that the authors should address this issue by providing a clearer differentiation and more detailed comparisons. However, the comment does not explicitly instruct the authors on how to achieve this, nor does it provide specific guidance on which existing works to compare with or how to differentiate the contributions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the paper\\'s contributions, noting the lack of clear differentiation from existing works and detailed comparison with similar techniques. However, it does not specify which part of the paper should address this issue, making it weakly grounded. The comment is specific in identifying the need for differentiation and comparison, but without explicit references to sections or elements of the paper, the authors may struggle to pinpoint where to make these improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparison with similar techniques. The comment provides a logical reasoning by suggesting that without such differentiation and comparison, the work may not stand out in the NLP community. However, the comment lacks specific examples or references to existing works for comparison, which would strengthen the claim. This makes the claim somewhat verifiable, as it provides a reasonable basis for the assertion but requires more detailed evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper\\'s contributions, noting that without clear differentiation from existing works and detailed comparison with similar techniques, the contributions may be perceived as incremental or lacking substantial novelty. This feedback is valuable as it highlights a potential weakness in the paper that could impact its reception and perceived value within the N"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests an explanation for the difference between the baseline results in Table 2 and those from Table 3 in [3]. This is a clear and direct action for the authors to take, as it specifies what information needs to be provided to address the reviewer\\'s concern. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is an explanation for the difference between the baseline results in these two tables. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the difference between baseline results in two tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests an explanation for the difference between the baseline results in Table 2 and those from Table 3 in [3]. This is a specific and actionable suggestion that prompts the authors to clarify a potential inconsistency or discrepancy in their results. By addressing this question, the authors can provide a more detailed and accurate explanation, which is beneficial for improving the clarity and credibility of their work. However, the comment could be more helpful if it provided additional context or guidance on how to effectively present this explanation. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of \"execution feedback\" in the title and Figure 2, stating that it is misleading because no execution feedback signal is actually used. The reviewer provides detailed reasoning, explaining that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any perturbation results in a failure. Additionally, the comment points out a potential issue with Equation 1, where the definition of EF is unclear. This feedback is explicit and provides concrete details on how the authors can address the issue by revising the title, figure, and equation to accurately reflect the methodology. The authors are given clear guidance on what needs to be corrected, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the misleading use of \"execution feedback,\" explaining that it is approximated based on structural perturbations in the AST and that the authors assume any perturbation results in a failure. The comment further specifies the potential issue with Equation 1, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the misleading use of \"execution feedback\" in the title and Figure 2, stating that no execution feedback signal is actually used and that execution feedback is approximated based on structural perturbations in the AST. The reviewer provides specific reasoning by referencing lines 233-238 and Equation 1, which support the claim. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claim but lacks some additional evidence or examples to fully substantiate it. This aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of \"execution feedback\" in the title and Figure 2, pointing out that no execution feedback signal is actually used in the work. It explains that execution feedback is approximated based on structural perturbations in the AST and that the authors assume any perturbation results in a failure. The comment also critiques Equation 1, noting that the definition of EF is unclear and that there is no guarantee that perturbations will make the tests fail. This feedback is clear and actionable, as it provides detailed guidance on how the authors can correct the misleading use of terms and improve the clarity of their methodology. By addressing these points, the authors can significantly enhance the accuracy and comprehensiveness of their draft. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail, specifically regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model. It also mentions a lack of detail on how many games are sampled to demonstrate the severity of the bias problem. While the comment identifies these areas as needing clarification, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to provide more information, but they may not be entirely sure of the exact details required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific aspects of the paper, such as the use of \"40 target words\" and \"a sequence of dots,\" and the lack of detail regarding the bias problem. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of information on the use of \"40 target words\" and \"a sequence of dots\" and the need for details on the bias problem, including the number of games sampled. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of information regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, as well as a lack of detail on how many games are sampled to demonstrate the severity of the bias problem. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail, particularly regarding the use of \"40 target words\" and \"a sequence of dots\" to remove bias in the model, as well as the sampling of games to demonstrate the severity of the bias problem. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how similar information has been effectively presented in other works. Overall, the feedback is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, it does not provide any explicit or implicit suggestions for how the authors might address these issues or improve their experimental setup. There is no guidance on whether the authors should consider using more complex datasets or alternative missing data mechanisms. As a result, the comment lacks actionable advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning the use of simple datasets and the unrealistic nature of uniformly random missing data. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues with the experimental setup, but without clear grounding, the authors may struggle to pinpoint where these issues are discussed in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, it does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. While it identifies potential issues with the experimental setup, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their experimental design. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 lacks legends, which makes it difficult to interpret the plots. It provides a clear and specific action for the authors to include what each data point or plot corresponds to. This feedback is direct and provides concrete guidance on how to improve the figure, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of legends for the plots, making it difficult to interpret. The comment provides a clear suggestion for improvement by recommending the inclusion of what each data point or plot corresponds to. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends, making it difficult to interpret the plots. This is a factual observation rather than a subjective claim or suggestion, as it does not require any justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends, which makes the plots difficult to interpret. It provides a clear and actionable suggestion by recommending the inclusion of what each data point or plot corresponds to. This feedback is valuable as it guides the authors on how to enhance the clarity and interpretability of their figures, which is crucial for effective communication of their results. However, the comment could be more helpful if it offered additional guidance on how to choose appropriate labels or what specific information should be included in the legends. Overall, the comment is mostly helpful as it directs the authors toward a specific improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper specifically addresses sequence-to-sequence models and suggests that the quantization-aware training strategy could be applied to other models as well. It also requests clarification on any specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the specific benefits of their approach for sequence-to-sequence models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific focus of the paper on sequence-to-sequence models and suggests that the quantization-aware training strategy could be applicable to other models as well. It also requests clarification on any specific benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. However, the comment does not specify which part of the paper should address these questions, making it weakly grounded. The comment is specific in its request for clarification on the benefits of the proposed scheme for sequence-to-sequence models. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions and requests for clarification regarding the focus of the paper on sequence-to-sequence models and the applicability of the quantization-aware training strategy. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the focus of the paper on sequence-to-sequence models and whether the quantization-aware training strategy is specific to this model type. It also requests clarification on any unique benefits of the proposed robustness-aware quantization scheme for sequence-to-sequence models. While the comment identifies areas for clarification and improvement, it lacks specific suggestions or actionable feedback on how the authors might address these points. The authors are left with a general understanding of what needs to be clarified but without detailed guidance on how to improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. While the comment implies that the authors should conduct additional experiments or analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of lambda on the algorithm\\'s behavior and accuracy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This provides clear guidance on what additional analysis or experiments the authors should conduct. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. However, it does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more ablation on how the algorithm behaves and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This feedback is clear and actionable, as it directs the authors to conduct additional experiments or analyses to better understand the impact of this hyperparameter on the algorithm\\'s performance. However, the comment could be more helpful if it provided specific guidance on how to conduct these ablation studies or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model, asking whether it is trained from scratch or if it has a specific base encoder. This question implies that the authors should clarify this aspect of their model in their draft. However, the comment does not provide explicit instructions or suggestions on how to address this question or what information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide this information but are not given clear guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the base encoder of the proposed model, asking whether it is trained from scratch or has a specific base encoder. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure where this information might be discussed. The authors can infer that it relates to the methodology or model description, but this inference is not direct. The comment is specific in its request for clarification about the base encoder, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the base encoder of the proposed model. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the base encoder of the proposed model, asking whether it is trained from scratch or has a specific base encoder. This question is relevant and could help the authors clarify an important aspect of their methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. While it identifies a potential area for clarification, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Ethical Statement should be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should add this discussion, it does not provide specific guidance on how to address these challenges or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific details of what needs to be added or discussed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests extending the discussion to include challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides clear guidance on what needs to be added or expanded upon in the ethical discussion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Ethical Statement is well-written but suggests it could be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that these challenges are not addressed. The suggestion is somewhat verifiable as it points out a potential gap in the discussion, but it requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the Ethical Statement is well-written but suggests that it could be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their ethical considerations. By identifying a gap in the current discussion, the comment empowers the authors to make a meaningful improvement to their draft. However, it could be more helpful if it offered additional guidance on how to address these challenges or provided examples of how to incorporate them into the discussion. Overall, the comment is mostly helpful, as it effectively directs the authors toward a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transformation of variables from $$\\hat{m}_t$$ and $$g_t$$ in equation (13) to $$x$$ in equation (14). While it highlights a potential issue with clarity, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should clarify the transformation, but it does not specify how to do so or what aspects need to be clarified. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the transformation of variables from $$\\hat{m}_t$$ and $$g_t$$ to $$x$$ in equation (14), which is a clear indication of what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the transformation of variables from $$\\hat{m}_t$$ and $$g_t$$ to $$x$$ in equations (13) and (14). It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which fits the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the transformation of variables from $$\\hat{m}_t$$ and $$g_t$$ to $$x$$ in equations (13) and (14), respectively. While it identifies a potential issue with clarity, it does not provide any suggestions or guidance on how the authors might address this concern or improve the clarity of their presentation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential issue but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the non-integer nature of the mini-batch length, tau_t, and suggests that this should be clarified to avoid potential side effects. It specifically asks what happens if tau_t is much smaller than 1 and questions the validity of the analysis in such cases. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions on how to address the issue or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the non-integer nature of the mini-batch length, tau_t. It raises a concern about potential side effects and asks for clarification on what happens when tau_t is much smaller than 1. This provides some specificity regarding the issue that needs to be addressed. However, the comment does not explicitly mention which part of the paper discusses mini-batch lengths, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the non-integer nature of the mini-batch length, tau_t, and questions the potential side effects, particularly when tau_t is much smaller than 1. The reviewer suggests that the analysis may not be valid in such cases. However, the comment lacks specific examples or references to support the claim about the potential side effects or the validity of the analysis. This makes the claim somewhat verifiable, as the authors would need to further investigate the implications themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the non-integer nature of the mini-batch length, tau_t, and questions the potential side effects that may arise. It highlights a potential issue with the analysis when tau_t is much smaller than 1, suggesting that the authors clarify this aspect to ensure the validity of their results. While the comment identifies a relevant area for clarification, it lacks detailed guidance on how to address the issue or what specific aspects need to be clarified. The feedback is somewhat helpful as it points out a potential weakness in the analysis, but it could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the non-integer nature of the mini-batch length, tau_t, and questions the potential side effects, particularly when tau_t is much smaller than 1. It suggests that the authors clarify this aspect to ensure the validity of their analysis. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to clarify or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the non-integer nature of the mini-batch length, tau_t, and raises a concern about potential side effects, particularly when tau_t is much smaller than 1. It suggests that the authors clarify this aspect to ensure the validity of their analysis. While the comment does not explicitly mention a specific section of the paper, it is clear that it relates to the methodology or experimental setup. The authors can infer that it pertains to these sections, but the comment lacks explicit grounding. It is specific in identifying the issue and suggesting a need for clarification. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the non-integer nature of the mini-batch length, tau_t, and questions the potential side effects, particularly when tau_t is much smaller than 1. The reviewer suggests that the analysis may not be valid in such cases and asks for clarification. While the comment identifies a specific issue, it lacks detailed reasoning or examples to support the claim about the potential side effects or the validity of the analysis. This makes the claim somewhat verifiable, as the authors would need to further investigate the implications themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the non-integer nature of the mini"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. While the comment identifies a relevant aspect that needs attention, it does not provide explicit instructions or concrete steps on how to conduct this examination. The authors are left to infer that they should analyze the computational cost, but without specific guidance on how to do so, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the inference cost of the SCALE model, specifically mentioning the two types of decoding: STM decoding and LLM decoding. This provides some grounding as it refers to specific aspects of the model. However, it does not explicitly mention which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the need to examine the computational cost of inference, but it lacks detailed guidance on how to conduct this examination. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is important to examine the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a critical aspect to consider. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by highlighting the need to examine the computational cost associated with the inference process of the SCALE model. It points out that the model involves two types of decoding: STM decoding and LLM decoding, and suggests that analyzing the computational cost is important. This feedback is clear and actionable, as it directs the authors to consider a critical aspect of their model that could impact its practical application. However, the comment could be more helpful if it provided additional guidance or examples on how to assess and report the computational cost. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, specifically mentioning the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to include performance comparisons and possibly explain or correct the peculiar results. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the 5th row of Table 2,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issues, such as the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, particularly the unsupervised result outperforming the supervised result in the 5th row of Table 2. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the article lacks performance comparisons with state-of-the-art models and presents peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies specific issues, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references to state-of-the-art models makes it difficult for the authors to fully understand and address the concerns. Therefore, the claim is somewhat verifiable, as it provides some basis for the critique but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two significant issues with the paper: the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, specifically mentioning the unsupervised result outperforming the supervised result in the 5th row of Table 2. This feedback is valuable as it highlights areas where the paper could be strengthened, providing the authors with clear directions for improvement. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or explain the peculiar results. Overall, the comment is mostly helpful as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further explained. However, it does not provide any explicit or implicit action for the authors to take. There is no guidance on what specific elaboration is needed or how to address this issue. As a result, the authors are left without any direction on how to improve their draft. Since the comment lacks actionable information, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific phrase, \"lacks inherent semantic meaning,\" but does not specify where in the paper this phrase is used or how it is problematic. Without explicit references to sections, figures, or specific sentences, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity as it does not explain what is meant by \"lacks inherent semantic meaning\" or how this phrase could be clarified or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a factual observation about the use of a phrase without further elaboration. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific issue with the phrase \"lacks inherent semantic meaning,\" noting that it is used but not further explained. However, it does not provide any guidance or suggestions on how the authors might clarify or elaborate on this concept. Without actionable feedback or specific advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential issue but lacks depth and actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out the potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment highlights specific areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left to infer that they need to provide more details and justification, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as the use of a large number of hidden units, an additional elementwise function, and the treatment of unobserved ratings as zeros. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing sufficient details and justification for the choices made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also criticizes the treatment of unobserved ratings as zeros, suggesting that this may introduce bias. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several specific issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out the potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment highlights important areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. Providing specific examples or references to similar studies could enhance the usefulness of the feedback. Overall, the comment is somewhat helpful as it directs the authors to areas needing clarification but could be more beneficial with additional guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the robustness of the motivation claim, noting that MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, but this accuracy can be achieved with 100% accuracy using other tools. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their motivation claim. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on a constructed dataset for complex computations. It points out that while MathGLM achieves a high accuracy of 93.03%, other tools can achieve 100% accuracy. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or paragraph where the motivation is discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the motivation claim but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point challenges the robustness of the motivation claim by pointing out that MathGLM\\'s high accuracy of 93.03% on a constructed dataset for complex computations can be achieved with 100% accuracy using other tools. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison between MathGLM\\'s accuracy and the potential accuracy of other tools. However, the comment lacks specific examples or references to other tools that can achieve 100% accuracy, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the robustness of the motivation claim by pointing out that MathGLM\\'s high accuracy of 93.03% on a constructed dataset for complex computations can be achieved with 100% accuracy using other tools. This feedback identifies a potential weakness in the paper\\'s argument and highlights a gap in the motivation provided for using MathGLM. However, the comment lacks specific suggestions or guidance on how the authors might strengthen their motivation claim or address this issue. While it points out a critical area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on a constructed dataset for complex computations, noting that other tools can achieve 100% accuracy. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. Without specific guidance or suggestions on how to strengthen the motivation claim or improve the paper, the authors are left without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the robustness of the motivation claim regarding MathGLM\\'s accuracy on a constructed dataset for complex computations, noting that other tools can achieve 100% accuracy. However, it does not specify which part of the paper this critique pertains to, such as a specific section or paragraph where the motivation is discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area needing revision. The comment is specific in its critique of the motivation claim but lacks grounding, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the robustness of the motivation claim by pointing out that MathGLM\\'s high accuracy of 93.03% on a constructed dataset for complex computations can be achieved with 100% accuracy using other tools. This claim is somewhat verifiable as it provides a logical reasoning based on the comparison between MathGLM\\'s accuracy and the potential accuracy of other tools. However, the comment lacks specific examples or references to other tools that can achieve 100% accuracy, which would strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the robustness of the motivation claim by pointing out that MathGLM\\'s high accuracy of 93.03% on a constructed dataset for complex computations can be achieved with 100% accuracy using other tools."}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluation does not accurately reflect event-based dense tracking in real-world settings. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on whether the authors should create a dedicated event-based dense tracking dataset, adapt existing datasets, or explore alternative evaluation methods. Without actionable advice or specific steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the reliance on synthetic datasets for evaluating event-based optical flow in real-world settings, which is a significant weakness. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the problem with the evaluation approach, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reliance on synthetic datasets for evaluating event-based optical flow does not accurately reflect real-world event-based dense tracking, which is a significant weakness. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable, leaving the authors without a clear path to address the issue. Therefore, the comment is categorized as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluating event-based optical flow does not accurately reflect real-world event-based dense tracking. This is a critical point that the authors should address to strengthen their work. However, the comment lacks specific suggestions or guidance on how the authors might overcome this limitation or improve their evaluation approach. While it highlights an important issue, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper\\'s motivation and suggests that the experiments are weak due to limited dataset and LLM size. It also points out that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment identifies areas for improvement, it does not provide specific guidance on how to address these issues or improve the motivation. The authors are left to infer that they need to strengthen their motivation and experimental setup, but without concrete steps or suggestions, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper and the experiments conducted, specifically mentioning the limited dataset and LLM size. However, it does not explicitly mention which part of the paper this critique pertains to, such as the introduction or the experimental section. The authors can infer that it relates to the motivation and experimental setup, but this inference is not direct. The comment is specific in detailing the issues with the motivation and experiments, including the lack of justification for opposing common understanding and the unconvincing nature of the results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the paper is unclear and that the experiments are weak due to limited dataset and LLM size. The reviewer supports this claim by referencing existing research on the importance of diversity in instruction-tuning data and suggesting that the paper contradicts this understanding without strong justification. The reviewer also notes that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment provides a logical reasoning and references to existing research, it lacks specific examples or detailed references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration for full clarity.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s motivation, suggesting that it contradicts existing research on the importance of diversity in instruction-tuning data. The reviewer points out that the experiments are weak due to limited dataset and LLM size, which could lead to unconvincing results that might mislead the community. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or strengthen their motivation. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed advice on how to improve it, leaving the authors with a general direction but no actionable steps. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a lack of clarity in the paper\\'s motivation and suggests that the experiments are weak due to limited dataset and LLM size. It also points out that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment identifies areas for improvement, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the motivation. The feedback lacks actionable steps, leaving the authors to infer that they need to strengthen their motivation and experimental setup, but without concrete direction. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper and the experiments conducted, specifically mentioning the limited dataset and LLM size. However, it does not explicitly mention which part of the paper this critique pertains to, such as the introduction or the experimental section. The authors can infer that it relates to the motivation and experimental setup, but this inference is not direct. The comment is specific in detailing the issues with the motivation and experiments, including the lack of justification for opposing common understanding and the unconvincing nature of the results. However, without explicit grounding, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the paper is unclear and that the experiments are weak due to limited dataset and LLM size. The reviewer supports this claim by referencing existing research on the importance of diversity in instruction-tuning data and suggesting that the paper contradicts this understanding without strong justification. The reviewer also notes that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment provides a logical reasoning and references to existing research, it lacks specific examples or detailed references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration for full clarity.',"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks why there are no confidence intervals on the substitution ASR in Table 3. This question implies that the authors should consider adding confidence intervals to provide a measure of uncertainty or variability in the results. While the action is clear, it is not explicitly stated, making the comment mostly actionable. The authors know they need to address the issue but may need to infer the exact steps to take, such as how to calculate and present confidence intervals. Therefore, the comment is rated as mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of confidence intervals on the substitution ASR. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the absence of confidence intervals in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in Table 3, questioning the absence of confidence intervals for the substitution ASR. This feedback is clear and actionable, as it prompts the authors to consider adding confidence intervals to provide a measure of uncertainty or variability in the results. By addressing this point, the authors can enhance the robustness and interpretability of their findings. However, the comment could be more helpful if it suggested how to calculate or present these confidence intervals. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their results that needs attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to estimate the mean element mu_g for different kernel spaces, indicating a lack of clarity in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps to follow to clarify the process. Without specific suggestions or instructions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about estimating the mean element mu_g for different kernel spaces, indicating a lack of clarity in the paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this issue might be addressed, the comment lacks full grounding. It is specific in identifying the need for clarification on estimating mu_g, but without explicit references to sections, it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the clarity of estimating the mean element mu_g for different kernel spaces. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the estimation of the mean element mu_g for different kernel spaces. This feedback highlights a potential gap in the clarity and comprehensibility of the paper, which is important for readers to understand the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it points out a weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. While the comment implies that the authors should include these datasets, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate them into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should consider these datasets and how to integrate them into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental setup or results section. The authors might infer that it relates to the discussion of baselines or the evaluation of datasets, but this inference is not direct. The comment is specific in its suggestion to include larger datasets, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. However, the comment does not provide any specific reasoning or evidence to support why these datasets would be particularly relevant or beneficial. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to enhance the completeness of the story. This feedback is somewhat helpful as it provides a specific direction for expanding the analysis, which could potentially strengthen the paper. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why it would be beneficial. To be more helpful, the comment could include specific examples of how these datasets could be used or what insights they might provide. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of using cosine similarity score instead of the Euclidean distance for computing the Decidability. While it suggests that cosine similarity is more often used in biometric verification, it does not provide explicit guidance or suggestions for the authors to follow. The comment lacks concrete actions or detailed instructions on how to address the question or explore the use of cosine similarity. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of cosine similarity score in biometric verification and its potential superiority over the Euclidean distance for computing Decidability. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment where these metrics are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the suitability of cosine similarity, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the suitability of using cosine similarity score instead of the Euclidean distance for computing Decidability, particularly in the context of biometric verification. However, it does not provide any supporting evidence, reasoning, or references to justify why cosine similarity might be more appropriate or why the Euclidean distance might be less effective. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the suitability of using cosine similarity score instead of the Euclidean distance for computing Decidability, particularly in the context of biometric verification. While it identifies a potential area for improvement or exploration, it does not provide specific guidance or suggestions on how the authors might address this question or why cosine similarity might be more appropriate. The comment lacks actionable feedback, such as recommending specific experiments or analyses to investigate the effectiveness of cosine similarity. As a result, the comment is barely helpful, as it points out an area of potential interest but does not offer concrete steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the experiments are weak, as they only include a toy experiment and an experiment on a real-world dataset. It further emphasizes that the proposed method does not compare with other counterpart methods, and the current experimental results are insufficient to validate the effectiveness of the proposed method. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments or comparisons with other methods. The comment is explicit and provides detailed guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the experimental section of the paper, specifically mentioning the toy experiment and the real-world dataset experiment. It also points out the lack of comparison with other counterpart methods and the insufficient validation of the proposed method. This provides full grounding as the authors can identify the specific parts of the paper being addressed. The comment is also specific, as it clearly outlines what is missing in the experimental section and why the current results are insufficient. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are weak due to the lack of comparison with other counterpart methods and insufficient validation of the proposed method. The comment provides a logical reasoning by stating that the current experimental results are insufficient to validate the effectiveness of the proposed method. However, it lacks specific examples or references to other methods that should be compared, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the experimental section of the paper, noting that the experiments are limited to a toy experiment and an experiment on a real-world dataset. It also points out that the proposed method does not compare with other counterpart methods, which is crucial for validating its effectiveness. This feedback is clear and actionable, as it highlights specific areas where the authors can improve their draft by conducting additional experiments or comparisons. However, the comment could be more helpful if it provided suggestions on how to enhance the experimental design or which specific methods should be compared. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting where these figures should be referenced or how they should be integrated into the analysis sections. The action is implicit and somewhat vague, as the authors need to infer that they should make these references and understand how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This provides full grounding as it explicitly mentions the figures and the sections they should be referenced in. However, the comment does not specify what needs to be addressed in terms of the figures themselves or how they should be integrated into the analysis sections. This lack of specificity makes the comment under-specific. Therefore, the comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a factual statement that does not contain an opinion, judgment, or suggestion. It is a descriptive observation about the paper\\'s structure and organization, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it directs the authors to ensure that all figures are properly integrated into their analysis sections. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate these figures or suggested specific sections where they should be placed. Overall, the comment is mostly helpful as it highlights a critical oversight and offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether perplexity is measured on consistent validation sets across different levels. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what steps to follow to clarify this point. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether perplexity is measured on consistent validation sets across different levels. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the consistency of validation sets, but without explicit references or detailed guidance, the authors may struggle to pinpoint the exact section needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the consistency of validation sets used to measure perplexity across different levels. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the consistency of validation sets used to measure perplexity across different levels. While it identifies a potential issue with the methodology, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern. The comment highlights a gap in the paper but does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is rated as barely helpful, as it provides some insight but lacks the depth and specificity needed to be more beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the setting and algorithm lack originality, suggesting they may seem like incremental combinations of existing methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this perceived lack of originality or suggest ways to enhance the originality of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the originality of the setting and algorithm, suggesting that they may seem like incremental combinations of existing methods. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the setting or algorithm lack originality. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the existing methods are being combined or how the algorithm differs from existing ones. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the setting and algorithm lack originality, suggesting they may seem like incremental combinations of existing methods. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The comment lacks detailed reasoning or evidence to substantiate the claim, rendering it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides an opinion that the setting and algorithm lack originality, suggesting they may seem like incremental combinations of existing methods. However, it does not offer specific examples or detailed feedback on how the authors might enhance the originality of their work. While it highlights a potential issue, the comment lacks actionable guidance or suggestions for improvement, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this approach could harm learning due to the potential use of a suboptimal policy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or alternative approaches to consider. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this approach could harm learning due to the potential use of a suboptimal policy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding how the authors should address this concern or what alternative approaches they might consider. As a result, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this approach could harm learning due to the potential use of a suboptimal policy. However, the comment lacks specific reasoning or evidence to support this claim, such as references to studies or examples of similar issues. Without detailed justification or examples, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about using state-action pairs from the current policy in the target environment as regularization, suggesting that this approach could harm learning due to the potential use of a suboptimal policy. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or alternative approaches to consider. Without actionable feedback or detailed reasoning, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It explicitly suggests that the authors should discuss how this issue could be mitigated to maintain performance on the base classes. While the action is clear, it lacks specific guidance on how to address the potential degradation or what specific mitigation strategies to consider. The authors know they need to discuss this issue, but the comment does not provide detailed steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the feature compactness loss and sharpness-aware minimization, and their potential impact on the model\\'s performance on base classes. It is fully grounded as it explicitly mentions the objective of these techniques and the specific concern about their potential negative impact on performance. The comment is also specific because it clearly specifies what needs to be addressed, namely a discussion on how to mitigate any degradation in performance on the base classes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks specific details or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification for the authors to understand and address the issue.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It raises a valid point about the need to discuss how this issue could be mitigated to maintain performance on the base classes. While the comment highlights an important area for consideration, it lacks detailed guidance or suggestions on how to address the potential degradation. The authors are given a clear direction to consider, but the feedback could be more helpful with additional insights or examples. Therefore, the comment is somewhat helpful, as it provides a valuable perspective but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the insight of the work in developing new methods and how to prevent attention collapse in continual learning (CL). While it raises a valid concern, it does not provide explicit guidance or suggestions on how the authors should address these questions. The comment lacks actionable details, such as recommending specific approaches or providing examples of how to prevent attention collapse. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the insight of the work in developing new methods and how to prevent attention collapse in continual learning (CL). However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the insight and prevention of attention collapse, but without grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the insight of the work and how to prevent attention collapse in continual learning. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the insight of the work in developing new methods and how to prevent attention collapse in continual learning. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The authors are left with a general inquiry rather than concrete suggestions on how to address the issue or where to focus their efforts. Therefore, the comment is somewhat helpful, as it points out an area of potential improvement but does not provide detailed feedback or actionable steps for the authors to take. This aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs and asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. It also inquires about case studies or pilot experiments that illustrate the significance of this influence. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, indicating a direct action for the authors to take. The authors can infer that they need to include more detailed explanations or examples to address these questions. Therefore, the comment is mostly actionable, as it provides concrete guidance on what needs to be added to improve the draft.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CHC model\" and the \"main content,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about how the CHC model affects the capabilities of MLLMs and requests examples or case studies to illustrate this influence. The comment provides detailed guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, asking for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. However, it does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification or additional information, fitting the \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the impact of the CHC model on the capabilities of MLLMs. It raises a critical question about how the CHC model affects the attributes or behaviors of MLLMs, which is a relevant point for the authors to address. The comment also suggests that the paper lacks examples or case studies to illustrate the significance of this influence, providing a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of similar studies. Overall, the feedback is mostly helpful as it highlights a key area for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. It provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This feedback is explicit and provides concrete guidance on how to improve the draft by incorporating more contemporary pretraining models. The authors are given clear instructions on what to do and how to implement the suggested changes, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the pretraining model \"Pre-GNN (Hu et al., 2020)\" and provides a specific suggestion to consider integrating more up-to-date pretraining models. It also provides examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pretraining model, Pre-GNN (Hu et al., 2020), is relatively old in the context of molecular pretraining and suggests that integrating more up-to-date pretraining models would showcase the significance and practical usage of the authors\\' approach. The reviewer supports this claim by referencing recent works in the field, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which provide examples of more contemporary models. This detailed reference to recent works makes the claim mostly verifiable, as it offers a clear rationale and specific examples to substantiate the suggestion. However, the comment could be strengthened by providing more detailed comparisons or analysis of the new models, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the integration of more up-to-date pretraining models. It specifically mentions \"Pre-GNN (Hu et al., 2020)\" as an older model and encourages the authors to consider more recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which are relevant to the field of hierarchical molecular representation learning. This feedback is highly helpful as it not only identifies a potential weakness in the current approach but also offers specific examples of recent works that could enhance the paper. By following this suggestion, the authors can significantly improve the relevance and impact of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential engineering challenge related to the model input, specifically the difficulty in obtaining accurate object segmentation and pose tracking in the real world. It acknowledges that the authors have documented their approach well in Section A.3. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the engineering challenge or suggestions for improvement. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the potential engineering challenge related to the model input, specifically the difficulty in obtaining accurate object segmentation and pose tracking in the real world. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a potential engineering challenge related to the model input, specifically the difficulty in obtaining accurate object segmentation and pose tracking in the real world. It acknowledges that the authors have documented their approach well in Section A.3. However, the comment does not provide specific examples or detailed reasoning to support the claim about the engineering challenge. The mention of Section A.3 provides some context, but it lacks sufficient detail to fully verify the claim. Therefore, the comment is somewhat verifiable, as it provides a general observation but lacks comprehensive evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges a potential engineering challenge related to the model input, specifically the difficulty in obtaining accurate object segmentation and pose tracking in the real world. It notes that the authors have documented their approach well in Section A.3. However, the comment lacks specific suggestions or guidance on how the authors might address this challenge or improve their approach. While it identifies an area of concern, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given some insight into a potential weakness but are left without clear steps to enhance their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, specifically connecting them to real NLG applications. It implies that the authors should demonstrate the advantage of their model, possibly starting with style transfer. While the comment provides a clear direction for improvement, it does not specify which downstream applications to focus on or how to demonstrate the advantage of the model. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more downstream performance of their controllable text generation models and connect them to real NLG applications. The comment further specifies that style transfer could be a good starting point and acknowledges that the authors have addressed previous comments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, connecting them to real NLG applications. It implies that the current discussion about downstream applications is insufficient and lacks demonstration of the model\\'s advantages. The reviewer suggests style transfer as a potential starting point. However, the comment does not provide specific examples or references to support the claim that more downstream performance is necessary or how it would demonstrate the model\\'s advantages. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending that the authors demonstrate the downstream performance of their controllable text generation models. It encourages the authors to connect their proposed models to real NLG applications and highlights style transfer as a potential starting point. This feedback is specific and offers a concrete direction for enhancing the paper, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to effectively demonstrate the model\\'s advantages or specific examples of downstream applications. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the test set performance on the GLUE datasets and questions whether the labels for these sets are not available to the public. While the comment highlights an area of potential concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors might infer that they need to clarify or provide more information about the test set performance, but the comment lacks concrete steps or detailed instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"test set performance on these GLUE datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the availability of labels for these datasets, providing a specific issue for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the availability of labels for the test sets used in the GLUE datasets. It does not express an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which fits the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a concern about the test set performance on the GLUE datasets, specifically questioning whether the labels for these sets are not available to the public. This is a relevant point that could impact the reproducibility and transparency of the study. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their methodology. While it highlights an important area for consideration, it does not offer actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 could be shortened by removing equations that are already well-known in the community, as they are not proposed by the work. This would allow for the inclusion of important details that are currently missing. The action is explicit, as it directly instructs the authors to shorten the section and include missing details. However, while the comment provides a clear direction, it does not specify which equations should be removed or how to identify them. Therefore, the action is mostly actionable, as it provides a clear path but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.2,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that many equations in this section are well-known and not proposed by the work, which could be shortened to include important details. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 could be shortened because many of the equations are well-known and not proposed by the work. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the assertion that these equations are indeed well-known. The comment could be strengthened by providing more detailed examples or references to substantiate the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that Section 3.2 could be shortened by removing equations that are well-known in the community and not proposed by the work. This would allow for the inclusion of important details that are currently missing. The feedback is clear and actionable, as it provides a specific suggestion for improving the paper by streamlining the content and focusing on relevant information. However, the comment could be more helpful if it specified which equations are redundant or unnecessary, providing a more detailed guide for the authors. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the evaluation methods used in Figure 3, Table 3, and Figure 5, specifically asking whether the evaluation is done automatically or by human evaluation. While the comment identifies a specific area of the paper that needs clarification, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify the evaluation methods, but it lacks concrete guidance on how to implement this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures and tables (Figure 3, Table 3, and Figure 5), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the evaluation method used in these figures and tables, whether it is automatic or human evaluation. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the evaluation methods used in specific figures and tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the evaluation methods used in Figures 3, 5, and Table 3, asking whether the evaluation is done automatically or by human evaluation. This is a relevant and precise inquiry that can help the authors clarify their methodology and ensure that their evaluation is clearly presented. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the understanding of the results, specifically regarding the average coverage rate and its relation to the bound by theorem. It asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment implies that the authors should address this misunderstanding, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide clarification or additional assumptions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific time points and values, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the understanding of the results, particularly regarding the average coverage rate and its relation to the bound by theorem. The comment clearly asks for clarification or additional assumptions to achieve the desired coverage rate, providing specific guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification about the results and assumptions underlying the coverage rate. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the understanding of the results, particularly regarding the average coverage rate and its relation to the bound by theorem. It highlights a potential misunderstanding and asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment identifies a specific area of confusion, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their understanding. The feedback is somewhat helpful as it prompts the authors to clarify their results, but it could be more comprehensive with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting the use of multiple translators or providing additional context on the choice of a single translator. Without specific recommendations or steps, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the use of a single translator per language, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, the comment lacks specific reasoning or evidence to support why using a single translator per language is problematic. It does not provide examples or references to similar issues or studies that might validate the claim. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully substantiate the concern.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending the use of multiple translators or providing additional context on the choice of a single translator. Without actionable advice or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the statement \"people wear a hat and play guitar not vice-versa,\" but it does not provide any guidance or suggestions for the authors to address this issue. It lacks explicit or implicit actions for the authors to take, such as clarifying the statement, providing context, or explaining the reasoning behind it. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about a statement regarding people wearing a hat and playing the guitar, but it does not specify which part of the paper this statement is from. This lack of grounding makes it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the logic behind the statement, but without clear grounding, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question about a statement regarding people wearing a hat and playing the guitar, but it does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about a statement regarding people wearing a hat and playing the guitar, but it does not provide any context, explanation, or reasoning for why this question is relevant or important. It lacks actionable feedback or suggestions for the authors to improve their draft. Without specific guidance or insights, the comment does not assist the authors in enhancing their work. Therefore, it is rated as not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as recommending additional data, a different model, or a specific approach to improve learning. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what aspect of the model or learning process is being evaluated. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part needs attention. Additionally, the comment lacks specificity regarding what constitutes \"this transformation\" or how the model's performance is being evaluated. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the assertion and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the dataset size, suggesting that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it lacks specificity and does not provide any guidance on how the authors might address this concern, such as recommending additional data, a different model, or a specific approach to improve learning. Without actionable advice or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between Algorithm 1 and variational inference, asking how the algorithm finds a Gaussian distribution to approximate the target distribution and what the advantages are. While the comment implies that the authors should clarify these aspects, it does not provide explicit instructions or concrete guidance on how to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the algorithm and its advantages. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the differences between Algorithm 1 and variational inference, asking for clarification on how the algorithm finds a Gaussian distribution to approximate the target distribution and what the advantages are. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the differences between Algorithm 1 and variational inference, as well as the advantages of the algorithm. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the differences between Algorithm 1 and variational inference, specifically asking how Algorithm 1 finds a Gaussian distribution to approximate the target distribution and what the advantages are. This feedback is somewhat helpful as it prompts the authors to clarify and explain their method, which could enhance the understanding and clarity of their work. However, the comment lacks specific suggestions or guidance on how the authors might address these questions or improve their explanation. To be more helpful, the comment could include specific areas of the paper where this clarification is needed or provide examples of how to present this information more effectively. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the entailment exercise lacks basic details and recommends either removing it from the paper or providing more empirical and analyzed information. While the comment implies that the authors should take action to improve the entailment exercise, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide more information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the entailment exercise, which suggests that it lacks basic details and provides insufficient information to assess its efficacy. However, it does not specify which part of the paper this exercise is located in, making it weakly grounded. The comment is specific in its suggestion to either remove the exercise or provide more empirical and analyzed information, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details, making it difficult to assess its efficacy. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details and providing a rationale for why this is problematic. It suggests either removing the exercise or providing more empirical and analyzed information to address the issue. While the comment highlights a critical area for improvement, it does not offer detailed guidance or specific suggestions on how to enhance the entailment exercise. This limits the comment\\'s helpfulness, as it provides some insight but lacks comprehensive direction for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific lines (225 and 227) where the mathematical expression of the Gaussian distribution is ambiguous. This provides a clear and explicit action for the authors to take, which is to clarify the mathematical expression in those lines. The comment is specific and actionable, as it directly points out the issue and gives the authors a clear direction on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 225 and line 227,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the ambiguity in the mathematical expression of the Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution in lines 225 and 227 is ambiguous. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is clear and actionable, as it directs the authors to a precise area where the draft needs clarification. By addressing this issue, the authors can improve the clarity and accuracy of their mathematical presentation. However, the comment could be more helpful if it provided suggestions on how to clarify the expression or offered examples of how to improve it. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. While the comment implies that more testing is needed, it does not specify which additional types of responses should be considered or how to incorporate them into the testing process. The action is implicit and somewhat vague, as the authors can infer that more testing is necessary but lack concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, it does not specify which part of the paper this issue is related to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in suggesting the need for additional testing, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, the comment does not provide any specific reasoning or evidence to support why additional types of responses are necessary or how they would improve the testing. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential limitation in the testing approach, suggesting that using only certain tokens may not be sufficient. It implies that additional types of responses should be considered, which could enhance the comprehensiveness of the testing. However, the comment lacks specificity and does not provide guidance on which additional types of responses should be considered or how they might be incorporated into the testing process. While it highlights an area for improvement, the feedback is incomplete and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a concern about the privacy protection capability and points out that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also suggests that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. While the comment highlights specific issues, it does not provide explicit guidance on how to address these concerns or improve the privacy protection capability. The action is implicit and somewhat vague, as the authors can infer that they need to enhance the privacy protection method but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability, specifically mentioning the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in detailing the issue with the privacy protection capability and the limitations of using chatGPT and temperature manipulation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient due to the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, the comment lacks specific examples or references to support the claim that chatGPT does not guarantee the removal of privacy information or that temperature manipulation alone is insufficient for effective text sanitization. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the privacy protection capability of the paper, specifically pointing out that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information in the rewritten text. It also highlights that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. This feedback is clear and actionable, as it directs the authors to consider alternative methods or techniques for enhancing privacy protection. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the privacy protection capability. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a starting point for the authors to address the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach in sentiment analysis using word embeddings to define the weight of each lexicon term is not significant. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their approach or what specific aspects could be improved. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the novelty of the approach in sentiment analysis using word embeddings is not significant enough. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the approach in sentiment analysis using word embeddings to define the weight of each lexicon term is not significant enough. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the approach described in the manuscript, specifically in sentiment analysis using word embeddings to define the weight of each lexicon term. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the novelty or address the perceived lack of significance. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it highlights an area of concern but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This feedback implies that the authors should include such comparisons to provide a clearer understanding of how their proposed method compares to conventional methods and its advantages. While the action is explicit, it lacks concrete details on which non-NeRF methods to consider or how to conduct these comparisons. The authors are given a clear direction but may need to infer the specifics of the comparison, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. However, it does not specify which tasks or methods are being referred to, making it difficult for the authors to identify the exact part of the paper that needs revision. While the authors might have an idea of where this comparison could be relevant, the comment lacks full grounding. It is specific in suggesting a comparison to non-NeRF methods, but without clear guidance on how to implement this suggestion, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This claim is somewhat verifiable as it provides a logical suggestion for improvement by highlighting the potential benefits of such a comparison. However, the comment lacks specific examples or references to non-NeRF methods or tasks, which would strengthen the justification. The authors would need to infer which non-NeRF methods or tasks are relevant, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This feedback is valuable as it provides a clear direction for the authors to enhance the comprehensiveness of their work by placing it in the context of existing conventional methods. By doing so, the authors can better understand the advantages and limitations of their proposed method. However, the comment could be more helpful if it specified which non-NeRF methods or tasks to consider for comparison. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some of the lower-level tasks count as NLU or syntactic tasks, suggesting that the authors clarify this in their paper. However, it does not provide explicit guidance on how to address this issue or what specific tasks should be considered NLU or syntactic. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the classification of tasks in their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether some lower-level tasks count as NLU or syntactic tasks, providing clear guidance on what needs to be clarified. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. However, it does not provide any additional context or reasoning to support why this distinction is important or how it affects the paper. The mention of LINSPECTOR provides some context, but the comment lacks detailed justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. This feedback highlights a potential area of confusion or misinterpretation in the paper, prompting the authors to clarify their terminology and classification. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a particular approach or providing examples of how to distinguish between NLU and syntactic tasks. While it identifies a relevant point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their terminology. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they should clarify the classification of tasks, but without specific instructions, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether some lower-level tasks count as NLU or syntactic tasks, providing clear guidance on what needs to be clarified. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. However, it does not provide detailed reasoning or evidence to support why this distinction is important or how it affects the paper. The mention of LINSPECTOR provides some context, but the comment lacks comprehensive justification or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. This highlights a potential area of confusion or misinterpretation in the paper, prompting the authors to clarify their terminology and classification. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending a particular approach or providing examples of how to distinguish between NLU and syntactic tasks. While it identifies a relevant point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. However, it does not provide explicit guidance or"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the relationship of their idea to traditional attempts in computer vision, specifically mentioning motion segmentation. While the comment implies that this addition would enhance the theoretical and academic value of the approach, it does not explicitly instruct the authors to make this discussion. The action is implicit and somewhat vague, as it lacks specific guidance on how to integrate this discussion into the paper. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of long-term motion trajectories and references a specific paper ([a]) by Keuper et al. This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of temporal motion representations. The comment is also specific because it suggests that the authors should discuss the relationship of their idea to traditional attempts in computer vision, particularly in the context of motion segmentation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of long-term motion trajectories is a traditional idea in computer vision and references a specific paper ([a]) by Keuper et al. to support this claim. The reviewer also proposes that discussing the relationship of the authors\\' idea to these traditional attempts would enhance the theoretical and academic value of their approach. While the reference provides some support, the comment could be strengthened by elaborating on how the discussion would benefit the paper or by offering more detailed reasoning about the relationship between the authors\\' work and the traditional attempts. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that the authors should discuss the relationship of their idea to traditional attempts in computer vision, specifically in the context of motion segmentation. It references a specific paper ([a]) by Keuper et al. as an example of traditional work. This feedback is actionable as it provides a clear direction for the authors to enhance the theoretical and academic value of their approach by connecting it to existing literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate this discussion into the paper or how it would strengthen the authors\\' technical contribution. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the task types addressed on graph data and focuses primarily on formalizing challenges. The comment highlights that the purpose of this section is unclear because it does not convey the author\\'s task objectives. This feedback implies that the authors should revise the section to provide a clearer description of the task types and objectives. While the action is implicit, it is concrete because it specifies what needs to be addressed: a clearer description of task types and objectives. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is the lack of a clear description of the specific task types addressed on graph data. The comment highlights that the purpose of this section is unclear due to its focus on formalizing challenges rather than conveying task objectives. This provides clear guidance on what needs to be addressed to improve the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the problem formalization section lacks clarity in describing the specific task types addressed on graph data, focusing primarily on formalizing challenges. The comment suggests that the purpose of this section is unclear because it does not convey the author\\'s task objectives. This claim is somewhat verifiable as it identifies a specific issue with the clarity and focus of the section. However, it lacks detailed examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data and instead focuses on formalizing challenges. The comment highlights that the purpose of this section is unclear because it fails to convey the author\\'s task objectives, which is inconsistent with the section\\'s intended purpose. This feedback is clear and actionable, as it directs the authors to clarify the task objectives and provide a more focused description of the task types addressed. By addressing this feedback, the authors can improve the clarity and coherence of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of an ablation study on training techniques, specifically mentioning the lack of an analysis on the impact of Informative Prior Initialization (IPI) and v-prediction. It suggests that these techniques could benefit other models and that the absence of an ablation study makes it difficult to assess their specific impact and compare YOSO\\'s performance with other models. While the comment implies that an ablation study should be conducted, it does not provide explicit instructions on how to perform it or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer that an ablation study is needed but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically referring to the introduction of Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014an ablation study on these components\u2014and explains why this is important for assessing their impact and comparing YOSO\\'s performance with other models. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their specific impact and compare YOSO\\'s performance with other models. The comment provides a logical reasoning by highlighting the importance of an ablation study to understand the contribution of these techniques. However, it lacks specific examples or references to similar studies that have successfully employed ablation studies to evaluate training techniques. This makes the claim somewhat verifiable, as it provides a clear rationale but requires additional evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction. It highlights the importance of such an analysis to assess the impact of these techniques and to compare YOSO\\'s performance with other models that could potentially leverage these methods. The comment is clear and actionable, providing the authors with a specific area to address and a rationale for why it is important. However, it could be more helpful by suggesting how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues: the limited content of the paper and redundant descriptions. It explicitly suggests that the authors should address the redundancy by removing the two paragraphs from line 229 to line 272, which already cover the motivation and work approach in the introduction. Additionally, it provides a concrete suggestion for improvement by recommending a small-scale validation experiment using datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This feedback is explicit and provides clear guidance on what actions the authors should take to improve their draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (229 to 272) where the redundant descriptions are located, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of redundancy in describing the motivation and work approach, which are already covered in the introduction. Additionally, it provides a specific suggestion for improvement by recommending a small-scale validation experiment using datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has limited content and redundant descriptions, specifically mentioning the redundancy in the paragraphs from line 229 to line 272. The reviewer suggests that these paragraphs cover information already present in the introduction and recommends presenting a small-scale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. While the comment identifies specific areas of redundancy and provides a suggestion for improvement, it lacks detailed reasoning or examples to fully substantiate the claim of limited content and redundancy. This makes the claim somewhat verifiable, as it provides a direction for improvement but requires more detailed justification or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the limited content and redundant descriptions. It points out that the two paragraphs from line 229 to line 272 redundantly describe the motivation and work approach already covered in the introduction, suggesting that these sections should be removed to improve the paper\\'s clarity. Additionally, the reviewer provides a constructive suggestion by recommending a small-scale validation experiment using datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This feedback is clear, actionable, and provides the authors with specific steps to enhance the quality and depth of their work. Therefore, the comment is highly helpful, as it offers valuable insights and suggestions for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to re-write the section on theoretical contributions to make its connections with the proposed method clearer. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the draft. The feedback is concrete, as it outlines a specific task and the need for clearer connections between the theoretical contributions and the proposed method. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"theoretical contributions\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical contributions, which is their perceived abstractness and lack of connection to the proposed method. The comment suggests re-writing the section to clarify these connections, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclearly connected to the proposed method. The reviewer suggests that the theory does not provide a clear understanding of how it supports the method, particularly regarding the use of segregated feature vectors for backdoored vs. clean data. However, the comment lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact issues and how to address them, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical contributions, noting that they seem too abstract and disconnected from the proposed method. It provides a clear direction for improvement by suggesting that the authors re-write the section to clarify the connections between the theoretical contributions and the proposed method. This feedback is actionable and provides a concrete suggestion for enhancing the clarity and relevance of the theoretical section. However, it could be more helpful if it offered specific examples or guidance on how to make these connections clearer. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, particularly noting that the GCN implementation might be challenging to reproduce without the original code. However, it does not provide explicit guidance or suggestions on how the authors could address this issue. The comment lacks concrete steps or recommendations for the authors to take, such as suggesting ways to improve code accessibility or detailing specific aspects of the GCN implementation that need clarification. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of whether the code will be released, specifically mentioning the GCN implementation. However, it does not specify which part of the paper discusses the code or the GCN implementation, making it weakly grounded. The comment is specific in its concern about the reproducibility of the GCN implementation without the original code, but it lacks detailed guidance on how the authors might address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of whether the code will be released, specifically mentioning the GCN implementation. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the GCN implementation might be hard to reproduce without the original code. The comment lacks specific details or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of whether the code will be released, specifically noting that the GCN implementation might be challenging to reproduce without the original code. While it identifies a potential issue, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. It does not offer actionable steps or examples that could help the authors improve the clarity of their code release or implementation details. As a result, the feedback is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. While it implies that the authors should consider using the differential functions, it does not explicitly instruct them to do so or provide guidance on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should revert to using the differential functions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions instead of differential functions and suggests that the authors should consider using the differential functions themselves. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. However, it does not provide any reasoning or evidence to support why this choice is problematic or why using the differential functions would be more appropriate. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. It questions the rationale behind this choice and suggests that the authors should consider using the differential functions. While the comment highlights a potential area for improvement, it lacks detailed guidance or suggestions on how to implement this change or why it might be beneficial. The feedback is somewhat helpful as it points out a potential weakness but does not provide comprehensive guidance for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. However, the comment does not explicitly instruct the authors to include the missing recall or suggest how to incorporate it into the table. The action is implicit and somewhat vague, as the authors need to infer that they should add the missing recall and understand how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the missing recall on lemmas/forms seen in training for the en-cs BPE to character results. Additionally, the comment provides references to external works, such as [1] to [3], which could guide the authors in addressing the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the en-cs BPE to character results in Table 3 are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. However, the comment does not explicitly explain why this is a significant issue or how it impacts the results. While the references are a step towards verification, the lack of detailed reasoning or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. This feedback is clear and actionable, as it directs the authors to a specific area that needs improvement and offers references to relevant literature. However, the comment could be more helpful if it provided additional guidance on how to incorporate the missing recall or suggested ways to present this information in the table. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. However, the comment does not explicitly instruct the authors to include the missing recall or suggest how to incorporate it into the table. The action is implicit and somewhat vague, as the authors need to infer that they should add the missing recall and understand how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the missing recall on lemmas/forms seen in training for the en-cs BPE to character results. Additionally, the comment provides references to external works, such as [1] to [3], which could guide the authors in addressing the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the en-cs BPE to character results in Table 3 are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. However, the comment does not explicitly explain why this is a significant issue or how it impacts the results. While the references are a step towards verification, the lack of detailed reasoning or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to external works, such as [1] to [3], which could guide the authors in addressing this issue. This feedback is clear and actionable"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the proposed method on the MLSC setup, despite the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation in Section 4. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the proposed method has no impact on the MLSC setup despite the claim about better word-alignment improving many-to-many translation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that better word-alignment improves many-to-many translation, specifically regarding the proposed method\\'s impact on the MLSC setup. It highlights a discrepancy between the claim and the observed results in Table 3, suggesting that the proposed method has no impact on the MLSC setup. The comment implies that the authors should provide an explanation for this discrepancy, but it does not offer specific reasoning or evidence to support the claim. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the consistency between the claim that better word-alignment improves many-to-many translation and the observed results in Table 3. It points out that the proposed method has no impact on the MLSC setup, despite the claim. This is a relevant observation that could help the authors identify and address a potential flaw or gap in their methodology. However, the comment does not provide specific suggestions or guidance on how the authors might resolve this issue or improve their analysis. While it highlights an important area for clarification, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the impact of the proposed method on the MLSC setup, despite the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation in Section 4. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the proposed method has no impact on the MLSC setup despite the claim about better word-alignment improving many-to-many translation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the consistency between the claim that better word-alignment improves many-to-many translation and the observed results in Table 3, specifically regarding the proposed method\\'s impact on the MLSC setup. The comment highlights a discrepancy and suggests that Section 4 should provide an explanation for this observation. However, the comment lacks specific reasoning or evidence to support the claim that the proposed method has no impact on the MLSC setup. The authors would need to infer the reasoning behind the critique, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the consistency between the claim that better word-alignment improves many-to-many translation and the observed results in Table 3. It points out that the proposed method has no impact on the MLSC setup, despite the claim. This observation is important as it could indicate a potential flaw or gap in the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an area of concern,"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. The comment implies that the authors should consider expanding the applicability of their method to online settings. However, it does not provide explicit guidance on how to achieve this or suggest specific steps to address the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should explore online applicability but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the method, namely its restriction to an offline setting. It points out that the method requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This provides a clear and specific critique of the method\\'s applicability. However, the comment does not explicitly mention which part of the paper discusses the offline setting or the method\\'s limitations, making it weakly grounded. Despite this, the comment is specific in detailing the issue with the offline assumption. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting, requiring pre-collected datasets and cannot be applied in an online setting. This claim is somewhat verifiable as it provides a logical reasoning for the limitation, suggesting that the method's applicability is constrained by its reliance on offline datasets. However, the comment lacks specific examples or references to support the claim fully. Providing more detailed evidence or examples of how the offline assumption limits applicability would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting. It points out that the method requires pre-collected datasets and cannot be applied in an online setting where policies interact with the environment. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should consider expanding the applicability of their method to online settings. However, the comment could be more helpful if it provided suggestions on how to address this limitation or explored potential solutions. Overall, the comment is somewhat helpful as it directs the authors to an important area for enhancement but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the method, specifically its restriction to an offline setting, which requires pre-collected datasets and cannot be applied in an online setting. The comment implies that the authors should consider expanding the applicability of their method to online settings, but it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore online applicability but lack detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific limitation of the method, namely its restriction to an offline setting, which requires pre-collected datasets and cannot be applied in an online setting. This provides a clear and specific critique of the method\\'s applicability. However, the comment does not explicitly mention which part of the paper discusses this limitation, making it weakly grounded. Despite this, the comment is specific in detailing the issue with the offline assumption. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting, requiring pre-collected datasets and cannot be applied in an online setting. This claim is somewhat verifiable as it provides a logical reasoning for the limitation, suggesting that the method's applicability is constrained by its reliance on offline datasets. However, the comment lacks specific examples or references to support the claim fully. Providing more detailed evidence or examples of how the offline assumption limits applicability would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting. It points out that the method requires pre-collected datasets and cannot be applied in an online setting where policies interact with the environment. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should consider expanding the applicability of their method to online settings. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this limitation. Overall, the comment is"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation of the learned representation is limited to a linear evaluation setting, suggesting that other downstream tasks could be used for a more comprehensive evaluation. While the comment implies that the authors should consider additional tasks, it does not explicitly instruct them to do so or provide specific guidance on which tasks to include. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include other tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the learned representation, specifically noting that it was only evaluated on the linear evaluation setting. It suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. However, the comment does not specify which part of the paper discusses the evaluation or where these tasks are mentioned, making it weakly grounded. The comment is specific in suggesting additional tasks for evaluation, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it only uses the linear evaluation setting. The reviewer suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. While the comment provides a logical reasoning for the claim, it lacks specific references or examples of how these tasks are typically used in the literature. This makes the claim somewhat verifiable, as the authors would need to further explore the literature to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of the learned representation, specifically noting that it was only evaluated on the linear evaluation setting. It suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. This feedback is clear and actionable, as it provides the authors with specific areas to expand their evaluation, which could significantly enhance the robustness and applicability of their work. However, the comment could be more helpful if it offered additional guidance on how to implement these evaluations or which specific tasks would be most beneficial. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, noting that stage-wise and progressive training have been used extensively in the past. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the novelty of their approach. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance the novelty of their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the work, specifically mentioning the use of stage-wise and progressive training, which have been used extensively in the past. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on how the authors might enhance the novelty of their approach or what aspects of the work could be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the work is very low, as stage-wise and progressive training have been used extensively in the past. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable, as it does not provide sufficient reasoning or examples to substantiate the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the novelty of the work, noting that stage-wise and progressive training have been used extensively in the past. While it identifies a potential issue with the originality of the approach, it lacks specificity and does not provide actionable feedback or suggestions for how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear understanding of how to enhance the novelty of their work. Therefore, the comment is rated as barely helpful, as it highlights a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the generalizability of the analysis to more general cases, specifically regarding the handling of general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. While the comment implies that the authors should consider these generalizations, it does not provide explicit instructions or concrete guidance on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these generalizations but are not given specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the generalizability of the analysis to more general cases, specifically regarding the handling of general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about the generalizability of the analysis, but without explicit references to sections, it is weakly grounded. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the generalizability of the analysis to more general cases, specifically regarding the handling of general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. These questions are not claims but rather inquiries seeking additional information or clarification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis, specifically regarding the handling of general Markov chains and the presence of FFN and nonlinearity on top of the attention layer. These questions prompt the authors to consider the broader applicability of their work, which is a valuable insight for improving the scope and relevance of their analysis. However, the comment does not provide specific guidance or suggestions on how to address these questions or expand the analysis to more general cases. While it identifies areas for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the discussion regarding [19] in section 3.1, specifically questioning whether it uses the same Fine state automaton or if there are any differences. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the use of the Fine state automaton in their discussion. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding whether [19] uses the same Fine state automaton or if there are any differences. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the discussion regarding [19] in section 3.1, specifically questioning whether it uses the same Fine state automaton or if there are any differences. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the discussion regarding [19] in section 3.1, questioning whether it uses the same Fine state automaton or if there are any differences. This feedback is somewhat helpful as it points out a potential area of confusion for the reader, prompting the authors to clarify this aspect in their draft. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as recommending ways to improve clarity or offering examples. To be more helpful, the comment could include suggestions on how to present this information more clearly or provide additional context. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, specifically mentioning that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment does not explicitly instruct the authors to address this issue or suggest specific steps to mitigate the memory requirement. The action is implicit and somewhat vague, as the authors need to infer that they should explore these references or consider alternative approaches to reduce memory usage. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, particularly the requirement for intermediate gradients for each domain, which could lead to high memory usage. The comment further provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which could lead to high memory usage. The comment supports this claim by referencing two external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references provide a starting point, the authors may need to further explore these works to fully understand the implications. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. This feedback is valuable as it highlights a specific area for improvement and directs the authors to relevant literature. However, the comment could be more helpful if it offered more detailed guidance on how to address the memory issue or suggested specific steps to mitigate it. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a potential issue with the auto_weight scheme in Algorithm 1, specifically mentioning that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment does not explicitly instruct the authors to address this issue or suggest specific steps to mitigate the memory requirement. The action is implicit and somewhat vague, as the authors need to infer that they should explore these references or consider alternative approaches to reduce memory usage. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, particularly the requirement for intermediate gradients for each domain, which could lead to high memory usage. The comment further provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which could lead to high memory usage. It supports this claim by referencing two external works, FedGP and FLamby, which might offer insights or solutions to this problem. However, the comment lacks detailed reasoning or specific examples from the referenced works to fully substantiate the claim. While the references provide a starting point, the authors may need to further explore these works to fully understand the implications. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to external works, FedGP and FLamby, which might offer insights or solutions to this problem. This feedback is valuable as it"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the backbone is constrained to a double LSTM, while transformers are not involved, and questions the sufficiency of the limitations discussed in Section 6. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve the paper. The comment lacks actionable details, such as recommending the inclusion of transformers or suggesting ways to enhance the limitations section. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of the double LSTM as the backbone and questions the inclusion of popular transformers, which is a specific aspect of the paper. It also mentions the limitations discussed in Section 6, indicating that the current limitations may not be sufficient. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the backbone and the limitations, but it lacks grounding because it does not specify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of the double LSTM as the backbone, suggesting that popular transformers are not involved. It also raises concerns about the sufficiency of the limitations discussed in Section 6. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that the backbone is constrained to a double LSTM while popular transformers are not involved. It raises a concern about the sufficiency of the limitations discussed in Section 6, suggesting that the application of the method to more extensive model structures remains a potential concern. While the comment highlights an important area for improvement, it lacks actionable suggestions or guidance on how the authors might address these limitations or enhance the discussion in Section 6. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide detailed advice on how to improve the draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation in the paper, specifically that the backbone is constrained to a double LSTM while popular transformers are not involved. It also mentions that the limitations discussed in Section 6 may not be sufficient. However, the comment does not provide explicit guidance or suggestions on how the authors should address these limitations or improve the paper. Without specific actions or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of the double LSTM as the backbone and questions the inclusion of popular transformers, which is a specific aspect of the paper. It also mentions the limitations discussed in Section 6, indicating that the current limitations may not be sufficient. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the backbone and the limitations, but it lacks grounding because it does not specify the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limitations of the paper, specifically noting that the backbone is constrained to a double LSTM while popular transformers are not involved. It also questions the sufficiency of the limitations discussed in Section 6. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that the backbone is constrained to a double LSTM while popular transformers are not involved. It also raises concerns about the sufficiency of the limitations discussed in Section 6, suggesting that the application of the method to more extensive model structures remains a potential concern. While the"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the contribution and novelty of the paper are limited, as it combines existing techniques like structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might enhance the novelty or contribution of their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, stating that the model proposed combines existing techniques. However, it does not specify which sections or parts of the paper this critique is based on, nor does it provide details on how the model's novelty could be improved. Without explicit references to specific sections or detailed feedback, the authors cannot effectively address the critique. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited, as it combines existing techniques like structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, the comment does not provide specific examples or references to these existing techniques, nor does it explain how the combination of these techniques makes the paper's contribution limited. Without detailed justification or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the contribution and novelty of the paper, stating that it combines existing techniques like structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or contribution of their work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting comparison between using MSLR and directly tuning a late-fusion model with separate learning rates for each modality. It implies that the authors should consider this comparison to provide a more comprehensive analysis. However, the comment does not explicitly instruct the authors to perform this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison and determine how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison between MSLR and directly tuning a late-fusion model with separate learning rates for each modality. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare the two approaches, but without grounding, the authors may struggle to identify the exact section where this comparison could be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a comparison between MSLR and directly tuning a late-fusion model with separate learning rates for each modality. It provides a logical reasoning by explaining that MSLR requires knowing the optimal learning rates in advance, which can be resource-intensive. The suggestion to compare these approaches is based on a clear rationale, but it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as it provides a reasonable basis for the suggestion but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an interesting comparison between MSLR and directly tuning a late-fusion model with separate learning rates for each modality. It highlights a potential advantage of the latter approach, which could be explored to provide a more comprehensive analysis. However, the comment does not provide specific guidance or suggestions on how to conduct this comparison or what aspects to focus on. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out an ambiguity in the notation for L_{flow}(X) and suggests that either L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. This feedback provides a clear and explicit action for the authors to take, which is to clarify the notation. The suggestion is concrete, as it specifies the potential alternatives, allowing the authors to directly address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"notation for L_{flow}(X),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the ambiguity of the notation and suggests potential alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the ambiguity of the notation for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. However, the comment does not provide any supporting evidence or reasoning to justify why these alternatives are more appropriate or why the current notation is ambiguous. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the notation for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This feedback is clear and actionable, as it provides the authors with a specific area to clarify in their notation, which could improve the clarity and precision of their work. By addressing this issue, the authors can enhance the readability and understanding of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of using 8-bit representation for input and mentions that 8-bit batch normalization has been proposed before. While it questions the novelty of the work, it does not provide explicit guidance or suggestions for improvement. The authors can infer that they might need to justify the use of 8-bit representation or discuss its novelty further, but the comment lacks concrete steps or detailed advice on how to address this concern. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of using 8-bit representation for input and mentions that 8-bit batch normalization has been proposed before. This provides some context and references to existing literature. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or discussion about input representation. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the novelty of the work but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the work by pointing out that 8-bit batch normalization has been proposed before. It provides a specific reference to a previous work (https://arxiv.org/pdf/1805.11046.pdf), which supports the claim that the proposed method is not entirely novel. This reference offers a clear and specific example of prior work, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent question about the novelty of the work, specifically questioning the necessity of using 8-bit representation for input. It points out that 8-bit batch normalization has been proposed before, which could undermine the originality of the work. This feedback is somewhat helpful as it prompts the authors to reconsider the novelty of their approach and potentially provide a more compelling justification for their choice of using 8-bit representation. However, the comment could be more helpful if it offered suggestions on how to address this concern or provided additional context on why 8-bit representation is crucial for the work. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the necessity of using 8-bit representation for input and mentions that 8-bit batch normalization has been proposed before. While it points out a potential issue with the novelty of the work, it does not provide explicit guidance or suggestions for the authors to address this concern. The comment lacks actionable steps or detailed advice on how the authors might justify the use of 8-bit representation or enhance the novelty of their work. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of using 8-bit representation for input and mentions that 8-bit batch normalization has been proposed before. This provides some context and references to existing literature, which could undermine the novelty of the work. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or discussion about input representation. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the novelty but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the novelty of the work by pointing out that 8-bit batch normalization has been proposed before, referencing a specific paper (https://arxiv.org/pdf/1805.11046.pdf). This provides a clear and specific example of prior work, making the claim mostly verifiable. The reference to a previous study supports the argument that the proposed method may not be entirely novel. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a pertinent question about the novelty of the work, specifically questioning the necessity of using 8-bit"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this concern or improve the practical relevance of their framework. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper discusses the framework or how the dominance of GNNs affects its practical relevance. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the framework's practical relevance could be improved or how the dominance of GNNs could be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how it impacts the practical relevance of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While it identifies a potential issue, the comment lacks specificity and does not provide actionable feedback or suggestions for addressing this concern. It does not offer guidance on how the authors might differentiate their framework or enhance its practical relevance. As a result, the comment is barely helpful, as it points out a potential weakness but does not provide the authors with a clear path to improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this concern or improve the practical relevance of their framework. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, it is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper discusses the framework or how the dominance of GNNs affects its practical relevance. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the framework\\'s practical relevance could be improved or how the dominance of GNNs could be addressed. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment lacks supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how it impacts the practical relevance of their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or enhance the practical relevance of their framework. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. While the comment implies that the authors should conduct an experiment to address this question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add an experiment to demonstrate the necessity of $X$. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific question about the calculation of M_{t} and the necessity of including $X$ in the calculation. It suggests that an experiment should be added to demonstrate the importance of $X$. However, the comment does not explicitly mention which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, namely the necessity of including $X$ in the calculation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. This feedback is clear and actionable, as it provides a direct suggestion for improving the paper by conducting an additional experiment. By addressing this point, the authors can enhance the robustness and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or guidance on how to design and execute the experiment. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point makes a statement about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons, but it does not provide any guidance or suggestions for the authors to address or improve this observation. There is no explicit or implicit action for the authors to take, nor is there any concrete information on how to respond to this observation. As a result, the comment lacks any actionable content, leaving the authors without direction on how to use this feedback to enhance their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment makes a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not specify which part of the paper this observation pertains to, nor does it provide any specific details or suggestions for improvement. The authors cannot confidently determine which part of the paper this comment addresses, nor do they know what aspects need to be addressed or improved. Therefore, the comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a subjective claim about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is true or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment provides a general observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it lacks specificity and does not offer any actionable feedback or suggestions for improvement. Without context or explanation, the authors may find it difficult to understand the significance of this observation or how it relates to their work. As a result, the comment is not helpful, as it does not provide the authors with meaningful guidance on how to address or improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the generalizability of the observations, particularly those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. It provides a specific example of hyperparameters that could be considered, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling. However, the comment does not explicitly instruct the authors to discuss these aspects or provide detailed guidance on how to incorporate this discussion into their paper. The action is implicit and somewhat vague, as the authors need to infer that they should address the generalizability of observations and the influence of hyperparameters. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed explanation of what needs to be addressed, namely the discussion of the generalizability of observations and how various hyperparameters might influence implicit biases in the algorithm. The comment suggests considering factors like optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, which are relevant to the discussion of neural representations, geometric metrics, and learning stages. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the generalizability of observations, such as those in Figure 4, should be discussed, particularly in relation to hyperparameters. It provides a logical reasoning by explaining how various hyperparameters could influence implicit biases in the algorithm, affecting neural representations, geometric metrics, and learning stages. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the specific hyperparameters and their potential impacts, which adds to the complexity of addressing the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss the generalizability of their observations, particularly those presented in Figure 4. It highlights the potential influence of various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, on implicit biases in the algorithm. This feedback is valuable as it prompts the authors to consider the broader implications of their findings and encourages them to explore how different hyperparameters might affect the results. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this discussion into the paper. Overall, the comment is mostly helpful as it identifies a relevant area for further exploration and provides a direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. However, the comment does not provide explicit instructions on how the authors should address this issue, such as recommending the use of the more standard term or suggesting ways to improve the organization of the paper. The action is implicit and vague, as the authors are left to infer that they should make changes but are not given concrete guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of non-standard terminology, particularly the term \"semi-honest\" and suggesting the use of \"honest-but-curious\" instead. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. While the comment provides a specific example of terminology that could be improved, it lacks detailed reasoning or references to support why this terminology is problematic or why \"honest-but-curious\" is more appropriate. The claim is somewhat verifiable, as it highlights a potential issue but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s organization and terminology. It points out the use of non-standard terminology, such as \"semi-honest,\" and suggests that the term \"honest-but-curious\" is more commonly used to describe the server. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the clarity and professionalism of their paper. However, the comment could be more helpful if it offered additional guidance on how to rephrase the terminology or suggested ways to improve the overall organization of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. However, the comment does not provide explicit instructions on how the authors should address this issue, such as recommending the use of the more standard term or suggesting ways to improve the organization of the paper. The action is implicit and lacks concrete guidance, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of non-standard terminology, particularly the term \"semi-honest\" and suggesting the use of \"honest-but-curious\" instead. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review comment claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honest\" in section 4. It suggests that the term \"honest-but-curious\" is more commonly used to describe the server. While the comment provides a specific example of terminology that could be improved, it lacks detailed reasoning or references to support why this terminology is problematic or why \"honest-but-curious\" is more appropriate. The claim is somewhat verifiable, as it highlights a potential issue but requires more detailed justification or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s organization and terminology, pointing out the use of non-standard terminology, such as \"semi-honest,\" and suggesting that the term \"honest-but-curious\" is more commonly used to describe the server. This feedback is clear and actionable, as it provides a specific correction that"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about missing experimental details, specifically asking for clarification on the optimizer, initialization, and PPO-zero. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these gaps. The authors can infer that they need to provide more information about these aspects, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about missing experimental details, specifically asking for clarification on the optimizer, initialization, and PPO-zero. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in its request for clarification on these details, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on specific experimental details, such as the optimizer, initialization, and PPO-zero. These are factual inquiries that do not express an opinion, judgment, or suggestion. Therefore, they are purely descriptive and do not contain claims that require verification. The classification \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail, namely the optimizer, initialization, and PPO-zero. By pointing out these missing details, the comment provides clear guidance for the authors to enhance the transparency and reproducibility of their experimental setup. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of how similar information is typically presented in the literature. Overall, the feedback is somewhat helpful as it highlights important areas for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors need to conduct a detailed efficiency analysis, comparing the proposed method with existing works. It specifies the components to consider, such as total model parameters, FLOPs, and memory, and mentions the need for a detector and LaVIT. This provides clear and concrete guidance on what the authors should do to improve their draft. The explicit nature of the suggestion and the detailed information on what needs to be included make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders and a detector in the decoding process. It suggests that the authors need to conduct a detailed efficiency analysis, comparing their method with existing works. However, the comment does not specify which part of the paper discusses these components, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding efficiency analysis, providing clear guidance on what the authors should include in their analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components (two image encoders and a detector) compared to existing works, which could impact efficiency. The reviewer suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory, is needed. While the comment identifies a potential issue with efficiency, it lacks specific examples or references to existing works for comparison. This makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand the implications of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency and complexity of the proposed method, noting that it requires additional components like LaVIT and Eva-CLIP for encoding and a detector for decoding. It suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory, is needed to justify the necessity of these components. This feedback is clear and actionable, providing the authors with a specific area to address and a clear direction for improvement. By highlighting the need for a detailed efficiency analysis, the comment empowers the authors to enhance their draft with a comprehensive evaluation of their method\\'s efficiency. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}{'actionability_rationale': 'The review comment suggests that the authors need to conduct a detailed efficiency analysis, comparing their proposed method with existing works. It specifies the components to consider, such as total model parameters, FLOPs, and memory, and mentions the need for a detector and LaVIT. This provides clear and concrete guidance on what the authors should include in their analysis to improve the draft. The explicit nature of the suggestion and the detailed information on what needs to be addressed make this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders (LaVIT and Eva-CLIP) and a detector in the decoding process. It suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory, is needed to justify the necessity of these components. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these components are discussed. The comment is specific in detailing what needs to be addressed regarding efficiency analysis, providing clear guidance on how to improve the draft. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components (two image encoders and a detector) compared to existing works, which could impact efficiency. It suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory, is needed to justify the necessity of these components. While the comment identifies a potential issue with efficiency, it lacks specific examples or references to existing works for comparison, making it somewhat verifiable. The authors would need to conduct additional research to fully understand the implications of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the efficiency and complexity of the proposed method, noting that it requires additional components like LaVIT and Eva-CLIP for encoding and a detector for decoding. It suggests that a detailed comparison of efficiency, including model parameters, FLOPs, and memory, is needed to justify"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims extrapolation error is a major issue in MARL but lacks evidence to support this claim. It also notes that the proposed techniques are for bias/variance reduction and do not seem to be directly related to extrapolation error. The reviewer highlights the absence of evidence that the proposed method mitigates extrapolation error, which leads to better performance. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence or clarify the relationship between the proposed techniques and extrapolation error. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about extrapolation error being a major issue in MARL, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of evidence supporting this claim and the apparent disconnect between the proposed techniques and their relation to extrapolation error. The comment is specific in detailing what is missing in the paper, namely evidence and a clear connection between the proposed methods and the issue of extrapolation error. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim about extrapolation error being a major issue in MARL is not supported by evidence. It further states that the proposed techniques are for bias/variance reduction and do not seem to be directly related to extrapolation error. The comment also points out the absence of evidence that the proposed method mitigates extrapolation error, which leads to better performance. While the comment provides logical reasoning and a clear critique of the paper\\'s claims, it lacks specific references or detailed examples to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires additional evidence or examples to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, namely the lack of evidence to support the claim that extrapolation error is a major issue in MARL. It points out that the proposed techniques are for bias/variance reduction and do not seem to be directly related to extrapolation error. The comment also highlights the absence of evidence that the proposed method mitigates extrapolation error, which is crucial for the paper\\'s claims. While the comment effectively identifies a gap in the paper, it could be more helpful by suggesting ways to address this issue or provide evidence. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take, suggesting that they include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. It also emphasizes the need for additional information on benchmark configurations, hardware, and input shapes to ensure fair comparisons. The comment is specific in detailing what needs to be added or improved, providing concrete guidance on how to enhance the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 4 and 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as including detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, it highlights the need for additional information on benchmark configurations, hardware, and input shapes to ensure fair comparisons. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that SCHEME\\'s on-device efficiency is underexplored and suggests that only limited throughput comparisons are presented in Tables 4 and 8. The reviewer argues that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency. Additionally, the comment emphasizes the need for additional information on benchmark configurations, hardware, and input shapes to ensure fair comparisons. While the comment provides a logical argument for the need for more detailed on-device results, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the on-device efficiency of SCHEME, noting that only limited throughput comparisons are presented in Tables 4 and 8. It suggests that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME\\'s efficiency over conventional FFNs. Additionally, the comment emphasizes the need for additional information on benchmark configurations, hardware, and input shapes to ensure fair comparisons. This feedback is clear and actionable, providing the authors with specific directions on how to enhance their draft by expanding the on-device efficiency analysis and ensuring fair comparisons. The comment is highly helpful as it offers detailed guidance that can significantly improve the paper\\'s rigor and comprehensiveness.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. While the comment implies that the authors should change the name, it does not provide specific guidance on how to do so or suggest alternative names. The action is implicit and somewhat vague, as the authors need to infer the need for a name change and how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not specify which part of the paper this name appears in, making it weakly grounded. The suggestion to reconsider the name is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not provide specific reasoning or examples to support why the name is misleading or how it might affect the paper\\'s clarity. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. While the comment identifies a potential issue with the name, it lacks specific suggestions or guidance on how to address this concern or what alternative names might be more appropriate. The feedback is somewhat helpful as it points out a potential confusion but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not provide specific guidance on how to change the name or suggest alternative names. The action is implicit and lacks concrete details, making it somewhat vague. Authors can infer that they need to reconsider the name, but the lack of explicit instructions or examples makes it difficult to implement the suggestion effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not specify which part of the paper this name appears in, making it weakly grounded. The suggestion to reconsider the name is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not provide specific reasoning or examples to support why the name is misleading or how it might affect the paper\\'s clarity. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. While the comment identifies a potential issue with the name, it lacks specific suggestions or guidance on how to address this concern or what alternative names might be more appropriate. The feedback is somewhat helpful as it points out a potential confusion but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its potential association with Long Short Term Memory (LSTM), which could lead to misleading guidance. However, the comment does not provide specific guidance on how to change the name or suggest alternative names. The action is implicit and lacks concrete details, making it somewhat vague. Authors can infer that they"}
{"generated_text": "{'actionability_rationale': 'The review point states that the proposed method is not the best performer in both robustness and fidelity, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their method or address the identified shortcomings. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the \"experiments results\" but does not specify which part of the paper this refers to, making it weakly grounded. It also lacks specificity as it does not detail what specific aspects of the proposed method are not the best performers or what improvements are needed. Without clear guidance on what needs to be addressed, the authors cannot effectively respond to the feedback. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, based on the experiments results. However, the comment does not provide any specific examples, data, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method, noting that it is not the best performer in both robustness and fidelity. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the proposed method is not the best performer in both robustness and fidelity, based on the experiments results. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their method or what specific aspects need attention. Without actionable feedback, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the \"experiments results,\" which suggests that the authors can identify the part of the paper being addressed. However, it lacks specificity as it does not detail what specific aspects of the proposed method are not the best performers or how they can be improved. Without clear guidance on what needs to be addressed or improved, the comment is weakly grounded and not specific. Therefore, it aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, based on the experiments results. However, it lacks specific examples, data, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed method, noting that it is not the best performer in both robustness and fidelity, based on the experiments results. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the proposed method is not the best performer in both robustness and fidelity, based on the experiments results. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve their method. Without specific guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the \"experiments results,\" which suggests that the authors can identify the part of the paper being addressed. However, it lacks specificity as it does not detail what specific aspects of the proposed method are not the best performers or what improvements are needed. Without clear guidance on what needs to be addressed or improved, the authors are left without a clear direction. Therefore, the comment is"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the paper regarding the connections between isometry, OT, and disentanglement. It explicitly instructs the authors to explain these connections more clearly in the revision. The comment provides a specific action\u2014clarifying the connections between the concepts\u2014and offers a clear direction on how to address the issue. This level of detail and specificity makes the comment highly actionable, as it gives the authors a concrete path to follow in improving their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the concepts of isometry, OT, and disentanglement, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the lack of clarity in the connections between these concepts and the authors\\' claim about the connection between isometry and disentanglement. The comment also questions the necessity of OT for isometry and suggests that the authors should explain these connections more clearly. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and logical connections in the paper are unclear, specifically regarding the connections between isometry, OT, and disentanglement. The reviewer provides a logical reasoning by questioning the authors\\' claim that adding geometrical constraints (isometry) can help disentanglement, and suggests that the connection between these concepts is not well explained. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide more detailed explanations or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the paper\\'s motivation and logical connections. It points out that there are three key concepts\u2014isometry, OT, and disentanglement\u2014and that the authors claim a connection between adding geometrical constraints (isometry) and disentanglement. However, the comment notes that this connection is not well explained in the paper, making it difficult for readers to understand the relationship between these concepts. Additionally, the reviewer questions the necessity of OT for isometry and suggests that the authors should clarify these connections more clearly in the revision. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how the authors can enhance the clarity of their paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of the results on regular languages to understanding real-world language models. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear direction on how to enhance their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results on regular languages and questions their relevance to understanding real-world language models. However, it does not specify which part of the paper discusses these results or how they are presented, making it weakly grounded. The comment is specific in questioning the utility of the results for understanding real-world language models, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages to understanding real-world language models. However, it does not provide any supporting evidence, reasoning, or references to justify why these results might not be helpful. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the critique. As a result, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment questions the relevance of the results on regular languages to understanding real-world language models, suggesting that the results may not be helpful in this context. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. The feedback lacks depth and actionable advice, leaving the authors without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment highlights a potential issue regarding novelty, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the differences between their work and the Venom paper, but it lacks concrete details on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the novelty or comparison sections. The question is specific in its inquiry about the differences between the proposed work and the Venom paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the novelty of the paper in relation to the Venom paper [1]. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment identifies a potential area of overlap or novelty, it lacks depth and does not provide specific guidance or suggestions for the authors to address this concern. The feedback is somewhat helpful as it prompts the authors to clarify the differences between their work and the Venom paper, but it does not offer actionable steps or detailed insights to enhance the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the attribution maps, noting that the attended areas of the image do not seem related to the actual task and that there are clusters of attended pixels without clear semantic meaning. However, it acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. The comment implies that the authors should consider improving the qualitative interpretation of the attribution maps, but it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the qualitative understanding of the attribution maps without being given concrete steps to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the attribution maps do not seem to be related to the actual task and that there are clusters of attended pixels without clear semantic meaning. The comment further acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. However, it questions the qualitative value, which is not fully addressed in the comment. Overall, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the qualitative intuition of the attribution maps, specifically noting that the attended areas of the image do not seem related to the actual task and that there are clusters of attended pixels without clear semantic meaning. However, it acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. The comment provides some reasoning and examples to support the critique, but it lacks specific references or detailed explanations to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to be fully convincing. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the attribution maps, noting that the attended areas of the image do not seem related to the actual task, such as in 3D tasks where the 3D worth pixels are not attended. It also points out clusters of attended pixels without clear semantic meaning. While the comment highlights a potential weakness in the qualitative interpretation of the attribution maps, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the qualitative understanding of the maps. The comment acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value, but it does not fully address the qualitative aspect. Therefore, the comment is somewhat helpful, as it provides insight into a potential area for improvement but lacks detailed guidance for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it suggests that the title overclaims the contribution of the paper, as it only presents results on two language models (BERT and RoBERTa) without showing results for large language models (LLMs) like Llama2-70b. The reviewer asks for an empirical justification of the scalability of the proposed method to LLMs. Second, it points out a minor issue with term consistency, specifically the use of \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors can infer that they need to provide empirical justification for scalability and ensure term consistency, but they may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title and the sections related to results and language models, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the overclaim in the title regarding the contribution of the paper, the lack of results for large language models (LLMs), and the inconsistency in term usage. The comment provides clear guidance on what needs to be addressed, including empirical justification for scalability and term consistency. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the title of the paper, suggesting that it overclaims the contribution by only showing results on two language models (BERT and RoBERTa) without including results for large language models (LLMs). The reviewer questions the scalability of the proposed method to LLMs and requests empirical justification. This claim is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim fully. The suggestion to keep term consistency is also a minor point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment addresses two main concerns. First, it points out that the title of the paper overclaims its contribution by only showing results on two language models (BERT and RoBERTa) without including results for large language models (LLMs). This feedback is valuable as it prompts the authors to consider the scalability of their proposed method to LLMs and to provide empirical justification for this claim. Second, the comment highlights a minor issue with term consistency, specifically the use of \"ROBERTA\" in Section 3.3 and \"RoBerta\" in the Introduction. This feedback is actionable and helps the authors ensure consistency in terminology throughout the paper. Overall, the comment provides clear and actionable feedback that can significantly improve the draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should provide a more explicit rationale for their choice, but it does not offer specific guidance on how to address this issue or what kind of motivation should be included. The comment implies that the authors should provide a clearer explanation, but it lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a lack of motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the need for a clearer rationale, but without explicit references to sections or parts of the paper, the authors may struggle to identify the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide a specific motivation for choosing date and country as possible spurious correlating variables with gender. The reviewer supports this claim by referencing a subsequent comment, which implies that the lack of motivation is a concern. However, the initial comment does not provide specific examples or detailed reasoning to substantiate the claim, making it somewhat verifiable. The authors would need to refer to the subsequent comment for a more comprehensive understanding of the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It points out that the paper only speculates about the potential correlations without providing a clear rationale for these choices. This feedback is somewhat helpful as it highlights an area where the authors can improve their draft by offering a more compelling justification for their decisions. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how to provide a stronger motivation. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the incremental nature of the contribution regarding exchanging channels and suggests that the rationale of Theorem 1 is based on a previous work. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, such as recommending specific changes or providing alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific point about the contribution of exchanging channels and its relation to the use of BN. It questions the incremental nature of the contribution and suggests that the rationale of Theorem 1 is based on a previous work. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or theorem. While the authors might infer that it relates to the discussion of exchanging channels or Theorem 1, this inference is not direct. Therefore, the comment is weakly grounded because it does not explicitly mention the part of the paper being addressed, but it is specific in detailing the issue with the contribution and the rationale of Theorem 1. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the incremental nature of the contribution regarding exchanging channels and suggests that the rationale of Theorem 1 is based on a previous work. The reviewer provides a subjective opinion that the contribution is not incremental and that the rationale of Theorem 1 is based on a previous work. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. As a result, the claim is somewhat verifiable, as it provides some insight but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the incremental nature of the contribution regarding exchanging channels and suggests that the rationale of Theorem 1 is based on a previous work. While it identifies a potential issue with the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. The comment highlights a potential weakness but does not provide actionable feedback or constructive advice, leaving the authors without a clear path forward. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it suggests that if the main contribution is a practical method, then more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is an explicit suggestion for additional research, but it lacks concrete guidance on how to conduct these studies or what specific aspects to focus on. Second, it asks for clarification on the meaning of \"K\" in the text, specifically whether it denotes \"NC.\" This is a request for clarification, but it does not provide a direct action for the authors to take. Overall, the comment provides some guidance but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by suggesting that more in-depth studies are needed to establish the method\\'s effectiveness in improving damping in second-order methods. Additionally, it raises a minor question about the meaning of \"K,\" providing specific details that need clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for clarification about the meaning of \"K\" and a suggestion for more in-depth studies to establish the method\\'s effectiveness. The first part is a request for clarification, which does not require verification. The second part suggests that more studies are needed, but it lacks specific reasoning or evidence to support why these studies are necessary. The comment does not provide detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main points. First, it suggests that if the main contribution is a practical method, then more in-depth studies are needed to establish its effectiveness in improving damping in second-order methods. This is a constructive suggestion that encourages the authors to conduct additional research to substantiate their claims. However, the comment lacks specific guidance on how to conduct these studies or what aspects to focus on, which limits its helpfulness. Second, the comment asks for clarification about the meaning of \"K,\" which is a minor issue but still relevant. Overall, the comment provides some actionable feedback but could be more comprehensive, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of k and N on the running time. These suggestions are explicit and provide clear guidance on what the authors should do to improve their draft. Additionally, the comment raises a minor question about a potential mismatch between Figure 2 and the description, which is also actionable. Therefore, the comment is highly actionable, as it provides specific and concrete steps for the authors to take to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study\" and the parameters k and N, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting an in-depth analysis of these parameters and their impact on the running time. The comment is specific in detailing the areas for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of k and N on the running time. These suggestions are logical and provide a clear rationale for why such an analysis would be beneficial. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the importance of these analyses themselves, which limits the comment\\'s verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by suggesting that an in-depth analysis of the parameters k and N in the ablation study would greatly enhance readers\\' understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of k and N on the running time. This guidance is clear and actionable, offering specific areas for the authors to focus on to improve their draft. Additionally, the comment raises a minor point about a potential mismatch between Figure 2 and the corresponding description, which is also helpful. Overall, the comment is mostly helpful as it provides actionable suggestions for enhancing the clarity and depth of the analysis in the paper. However, it could be more comprehensive by offering specific examples or methods for addressing these issues, which would make it highly helpful. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the details in Appendix B regarding the averaging of results over 10 runs without indication of standard deviation. It also inquires about the nature of these 10 runs, whether they involve random hyperparameter configurations for all baselines or the best selected values. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include standard deviation and clarify the nature of the 10 runs. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two distinct questions: why there is no indication of standard deviation and whether the 10 runs involve random hyperparameter configurations for all baselines or the best selected values. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the details provided in Appendix B regarding the averaging of results over 10 runs. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the details provided in Appendix B regarding the averaging of results over 10 runs without indication of standard deviation. It also inquires about the nature of these 10 runs, whether they involve random hyperparameter configurations for all baselines or the best selected values. This feedback is valuable as it prompts the authors to clarify and provide additional information that could enhance the transparency and robustness of their results. However, the comment could be more helpful if it suggested specific ways to address these issues or provided examples of how to present this information. Overall, the comment is mostly helpful as it identifies areas for improvement and encourages the authors to provide additional details, but it could be more comprehensive with further guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include more details about the task generation process in the main text, rather than just in the appendix. This provides a clear and direct action for the authors to take, ensuring that the readers have a better understanding of the experimental setup. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details about the task generation process should be included in the main text, not just in the appendix. This provides a clear and specific suggestion for improvement, indicating that the authors should enhance the main text to provide a better understanding of the experimental setup. However, the comment does not specify which part of the main text should include these details, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text, not just in the appendix. This claim is based on the rationale that providing additional information would enhance the reader\\'s understanding of the experimental setup and improve the paper\\'s presentation. However, the comment does not provide specific examples or references to support why this inclusion would be beneficial or how it would strengthen the paper. Without detailed justification or evidence, the claim remains somewhat verifiable, as it lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending that more details about the task generation process be included in the main text, rather than just in the appendix. This feedback is valuable as it highlights a specific area where the paper could be strengthened, offering a concrete way for the authors to enhance the clarity and comprehensiveness of their presentation. By addressing this suggestion, the authors can provide readers with a better understanding of the experimental setup, which is crucial for evaluating the results and methodology. However, the comment could be more helpful if it offered specific examples or guidance on how to incorporate these details effectively. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the representation of entropy in the paragraphs \"Individual-level entropy\" and \"Group-level entropy\" by indicating that entropy depends on a datapoint, such as $H(p^a|x)$. This feedback provides a clear and concrete action for the authors to take, which is to modify the notation to improve the clarity of the formulas. The suggestion is specific and actionable, giving the authors a direct path to enhance the readability and understanding of their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Individual-level entropy\" and \"Group-level entropy\" paragraphs, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is to clarify the representation of entropy by indicating that it depends on a datapoint, such as $H(p^a|x)$. This provides clear guidance on how to improve the clarity of the formulas. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the representation of entropy in the paragraphs \"Individual-level entropy\" and \"Group-level entropy\" should be clarified to improve the understanding of formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$. The comment provides a specific suggestion for improvement by recommending the use of a more explicit notation, such as $H(p^a|x)$. This feedback is mostly verifiable as it offers a clear suggestion for enhancing clarity, but it could be strengthened by providing additional examples or references to support the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion to improve the clarity of the paper by recommending that the authors clarify the representation of entropy in the paragraphs \"Individual-level entropy\" and \"Group-level entropy.\" It suggests using a more explicit notation, such as $H(p^a|x)$, to make formulas like $\\\\text{argmax}_{x \\\\in U, a \\\\in A} H^a$ more understandable. This feedback is clear and provides a concrete way for the authors to enhance the readability and comprehension of their work. By following this suggestion, the authors can significantly improve the clarity of their draft, making it more accessible to readers. Therefore, the comment is highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point describes a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this method could be improved, applied, or further developed. The comment lacks any actionable information, leaving the authors without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this method is discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of this method are unclear or need improvement. Without clear grounding or detailed feedback, the authors cannot effectively address the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point describes a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement about a method used in the paper, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment describes a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any context, explanation, or suggestions on how this method might be improved or integrated into the paper. Without additional information or guidance, the authors are left without actionable feedback on how to enhance their draft. The comment lacks specificity and does not offer constructive advice, making it not helpful at all. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), noting that the only difference is the use of entropy to capture the difference between distributions. It suggests that the authors provide a more comprehensive illustration of this relationship, including a discussion of the advantages of using entropy over other distance metrics like $f$-divergence, Wasserstein distance, or MMD distance. While the comment implies that the authors should provide a detailed explanation, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know what kind of information is needed to address the comment. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the relationship with Distributionally Robust Optimization (DRO) and the specific difference between the proposed DD risk and DRO risk, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the advantage of using entropy as a distance metric compared to other metrics like $f$-divergence, Wasserstein distance, or MMD distance. The comment suggests that the authors provide a more comprehensive illustration of this relationship, including a discussion of the advantages of entropy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), noting that the only difference is the use of entropy to capture the difference between distributions. It references existing works that use different distance metrics in DRO and asks why entropy leads to better generalization performance. While the comment highlights a potential area for improvement, it does not provide specific examples or references to support the claim that entropy is advantageous. The suggestion to provide a more comprehensive illustration is logical but lacks detailed justification or evidence. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the question but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), noting that the only difference is the use of entropy to capture the difference between distributions. It references existing works that use different distance metrics in DRO and asks why entropy leads to better generalization performance compared to other metrics. The comment suggests that the authors provide a more comprehensive illustration of this relationship, which could include a discussion of the advantages of entropy over other distance metrics. This feedback is clear and actionable, offering a specific direction for the authors to enhance their draft by clarifying the theoretical underpinnings of their approach. However, it could be more helpful if it included specific examples or references to the works mentioned. Overall, the comment is mostly helpful, as it guides the authors toward a more detailed explanation of their method\\'s advantages.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment implies that the authors should consider evaluating their model on annotated datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore evaluating their model on annotated datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment does not explicitly mention a specific part of the paper, the authors can infer that it relates to the dataset or evaluation section. The question is specific in its inquiry about the possibility of evaluating the model on annotated datasets. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the nature of the T-REx dataset and whether it is possible to evaluate the model over an annotated dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment identifies a potential area for improvement by questioning the evaluation methodology, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider alternative evaluation datasets, but it could be more actionable by providing detailed advice or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It suggests that the appendix should be proofread, specifically mentioning \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d P9: \u201csugggest\u201d\" as areas that need attention. Additionally, it recommends expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. These actions are clear and concrete, giving the authors specific tasks to address. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as the use of NeurIPS 2021 style files and the need for a proofread, as well as suggestions for expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the appendix is not using NeurIPS 2021 style files and recommends giving it a proofread. It also mentions specific issues with the text, such as \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d P9: \u201csugggest\u201d,\" and suggests expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. While the comment provides specific examples of issues, it lacks detailed reasoning or references to support the claim that the appendix should be proofread or that the potential negative societal impacts are not adequately discussed. This makes the claim somewhat verifiable, as the authors would need to address the specific issues mentioned but without a clear understanding of the broader context or justification for the suggestions.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It highlights the need for the appendix to use NeurIPS 2021 style files and recommends a proofread, specifically mentioning \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d P9: \u201csugggest\u201d\" as areas that require attention. Additionally, it suggests expanding on the potential negative societal impacts discussed in the limitations and societal impacts section. These specific and actionable points guide the authors on how to improve their draft, making the comment highly helpful. However, the comment could be more helpful if it provided further details or examples on how to address these issues, such as suggesting specific changes or improvements. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should examine the training and validation curves of different losses and determine if the model can bring all three losses down simultaneously. It also asks about any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. The action is somewhat explicit, as the authors can infer that they need to analyze the training and validation curves and consider weighing the losses, but it lacks concrete guidance on how to carry out these analyses. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests looking at training and validation curves of different losses and questions whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors might infer that it relates to the experimental section or results, but this is not explicitly stated. The comment is specific in its request for additional analysis and questions about the model\\'s performance, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should examine the training and validation curves of different losses and questions whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment does not provide any specific reasoning, examples, or references to support the claim that these analyses are necessary or beneficial. The lack of detailed justification or evidence makes it difficult for the authors to understand the importance of these analyses or how they might impact the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should examine the training and validation curves of different losses to determine if the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. While the comment identifies areas for improvement and raises important questions about the model\\'s performance, it lacks specific guidance or actionable steps for the authors to follow. The feedback is somewhat helpful as it points out potential areas for further investigation but does not provide detailed suggestions or examples to guide the authors in making improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should examine the training and validation curves of different losses and determine if the model can bring all three losses down simultaneously. It also asks about any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. The action is somewhat explicit, as the authors can infer that they need to analyze the training and validation curves and consider weighing the losses, but it lacks concrete guidance on how to carry out these analyses. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining the training and validation curves of different losses and questions whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors might infer that it relates to the experimental section or results, but this is not explicitly stated. The comment is specific in its request for additional analysis and questions about the model\\'s performance, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests examining the training and validation curves of different losses and questions whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. However, the comment lacks specific reasoning or evidence to support the claim that these analyses are necessary or beneficial. Without detailed justification or examples, the authors may find it challenging to understand the importance of these analyses or how they might impact the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests examining the training and validation curves of different losses and questions whether the model can bring all three losses down simultaneously. It also inquires about any tricks related to weighing these losses. While the comment identifies areas for further investigation, it lacks specific guidance or actionable steps for the authors to follow. The suggestion to analyze training and validation curves is relevant, but without detailed instructions or examples, the authors may find it"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of rigor in the paper\\'s claim that computing the GOSPA metric is NP-hard. It points out that the paper does not provide a theoretical argument or proof, merely stating that it is NP-hard due to the binary constraint. The reviewer suggests that this claim is not generally true for assignment problems and questions the validity of the assumption that the optimal assignment matrix is accessible. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their argument. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of NP-hardness and references specific equations (4) and (5), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the claim, such as the lack of a rigorous theoretical argument or proof, the assumption of access to the optimal assignment matrix, and the potential reduction of GOSPA to an exact polynomial-time computable assignment problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that computing the GOSPA metric is NP-hard, providing a logical reasoning that questions the validity of this assertion. It points out that the paper does not offer a rigorous theoretical argument or proof, merely stating that it is NP-hard due to the binary constraint. The reviewer suggests that this claim is not generally true for assignment problems and questions the validity of the assumption that the optimal assignment matrix is accessible. This critique is based on logical reasoning and common knowledge about assignment problems, making the claim mostly verifiable. However, it could be strengthened by providing specific references or examples to support the alternative perspective. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim that computing the GOSPA metric is NP-hard. It points out that the paper lacks a rigorous theoretical argument or proof, merely stating that it is NP-hard due to the binary constraint. The reviewer questions the validity of this claim, suggesting that it may not be generally true for assignment problems and that it could be reduced to an exact polynomial-time computable assignment problem. Additionally, the comment highlights the assumption of access to the optimal assignment matrix, which limits the applicability of the claim. While the comment effectively identifies a critical weakness in the paper, it could be more helpful by providing suggestions on how to address these issues or offer a more robust theoretical foundation. Overall, the feedback is mostly helpful as it directs the authors to a significant area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. While it explicitly states the action needed, it does not provide specific guidance on what aspects of the algorithm should be included or how to present it. The lack of detailed instructions makes the action somewhat vague, as the authors know they need to provide an algorithmic writeup but may not be entirely sure of the exact content or format. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for an algorithmic writeup, but without clear grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. However, it does not provide any specific reasoning, examples, or references to support why this would be helpful or how it would improve the paper. Without such details, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that an algorithmic writeup of the solution to the pricing problem would be beneficial. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the algorithm should be included or how it could enhance the paper. Without actionable advice or examples, the authors may find it challenging to determine how to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify or provide additional explanation regarding the mechanism of model averaging in relation to the proposed technique. While the action is implicit, it is somewhat concrete as it points out a specific area for clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the numerical evaluation of the model averaging technique and questions its effectiveness in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in questioning the effectiveness of model averaging and the need for further explanation, but it lacks grounding as it does not explicitly mention the section or figure being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the need for further explanation or clarification. As a result, the claim is somewhat verifiable, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It questions whether the proposed technique achieves this balance through intelligent exploration and gradual updates during initialization, and it suggests that there may be other possible mechanisms or explanations. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or provide additional explanation. The feedback is somewhat helpful as it prompts the authors to clarify their approach and potentially expand their discussion, but it could be more actionable with more detailed suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify or provide additional explanation regarding the mechanism of model averaging in relation to the proposed technique. While the action is implicit, it is somewhat concrete as it points out a specific area for clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in questioning the effectiveness of model averaging and the need for further explanation, but it lacks grounding as it does not explicitly mention the section or figure being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the need for further explanation or clarification. As a result, the claim is somewhat verifiable, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide specific guidance or suggestions for improvement. While the comment identifies a potential weakness in the paper,"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While the action is explicit, it lacks concrete guidance on how to approach this discussion or what specific aspects should be considered. The authors are given a clear direction to address the issue but are left without detailed instructions on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss a different distribution for the size of the batches, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not provide any reasoning, evidence, or references to support why this discussion is necessary or how it would improve the paper. Without such support, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While this is a relevant suggestion that could enhance the paper by exploring alternative scenarios, the comment lacks specificity and does not provide detailed guidance on how to approach this discussion or what specific aspects should be considered. Without actionable advice or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the analysis, specifically that it only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their analysis to include different batch sizes and investigate their impact on the effective initialization scale. However, the comment lacks concrete suggestions or steps on how to conduct this analysis, making the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific limitation in the analysis, noting that it only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. However, it does not specify which part of the paper this analysis is in, making it weakly grounded. The comment is specific in identifying the issue with the analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. This is a factual observation rather than a subjective claim or suggestion. It does not require verification or evidence, as it is a straightforward statement of fact. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. This feedback highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of their results. However, the comment lacks specific suggestions or guidance on how the authors might explore different batch sizes or how to address the issue of effective initialization scale. While it points out a potential weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It asks for an explanation or clarification regarding the observed trend, suggesting that sampling 50% of the data yields better results than sampling 100%. While the comment implies that the authors should provide an explanation or justification for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in the figure, specifically why more data leads to lower results on the ImageNet linear evaluation and asks for an explanation or clarification. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the results shown in Figure 7. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It asks for an explanation or clarification regarding the observed trend, suggesting that sampling 50% of the data yields better results than sampling 100%. While the comment identifies a potential issue and prompts the authors to address it, it lacks specific guidance or suggestions on how to resolve the problem or improve the analysis. The feedback is somewhat helpful as it directs the authors to a specific area for clarification, but it could be more actionable with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. It suggests that including FVD would enhance the paper\\'s credibility and comparability to other video generation methods. While the comment implies that the authors should include FVD in their evaluation, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors know they need to include FVD but may not be entirely sure of the exact steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of comprehensive evaluation, specifically referring to the absence of quantitative results on mainstream metrics like FVD. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of FVD to enhance the paper\\'s credibility and comparability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of quantitative results on mainstream metrics like FVD. The reviewer suggests that including FVD would enhance the paper\\'s credibility and comparability. While the comment provides a logical reasoning for the inclusion of FVD, it lacks specific references or detailed examples to fully substantiate the claim. The suggestion is mostly verifiable, as it highlights a potential area for improvement but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation, specifically the lack of quantitative results on mainstream metrics like FVD, which are widely recognized and robust for evaluating temporal video prediction. By suggesting the inclusion of FVD, the comment provides a clear and actionable way to enhance the paper\\'s credibility and comparability to other video generation methods. Additionally, the comment highlights the limited novelty and insufficient methodological depth, which are valid concerns that the authors should address. However, the comment could be more helpful if it offered specific suggestions on how to incorporate FVD or other metrics into the evaluation. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment states that the technical details in section 2.2 are difficult to follow. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as by clarifying the technical details or providing additional explanations. Without specific guidance or actionable steps, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"2.2,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the technical details are difficult to follow or suggest how they might be clarified. Without specific guidance or examples, the authors may struggle to understand and address the issue. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are difficult to follow. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the technical details in section 2.2, noting that they are difficult to follow. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve the technical details. Without actionable feedback or specific examples, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it highlights a problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the improvements offered by EVA over backbone models like OT-Flow, particularly in the context of the RFDiffusion benchmark. It suggests that the main contribution of the work is the addition of geometry information and motif-interpolation, and it asks whether these design choices provide benefits over prior backbones. While the comment implies that the authors should clarify the improvements and benefits of their work, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"in-silico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the improvements offered by EVA over backbone models like OT-Flow and whether the design choices provide benefits over prior backbones. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the improvements offered by EVA over backbone models like OT-Flow, particularly in the context of the RFDiffusion benchmark. It highlights that in most experiments, backbone models perform better in terms of designability and success rates. The reviewer suggests that the main contribution of the work is the addition of geometry information and motif-interpolation, and asks whether these design choices provide benefits over prior backbones. While the comment raises valid questions, it lacks specific examples or references to support the claim about the superiority of backbone models. This makes the claim somewhat verifiable, as it provides a logical basis for questioning but requires more detailed evidence or examples to fully substantiate the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the improvements offered by the work over existing backbone models, such as OT-Flow, in the context of the RFDiffusion benchmark. It highlights that in most experiments, these backbone models perform better in terms of designability and success rates. The comment also questions whether the main contribution of the work is the addition of geometry information and motif-interpolation, and whether these design choices provide benefits over prior backbones. This feedback is mostly helpful as it prompts the authors to clarify the unique contributions of their work and to provide a more detailed analysis of the improvements offered over existing models. However, it could be more helpful if it suggested specific areas for improvement or provided examples of how to address these questions. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion. While it identifies a specific issue with the draft, it does not provide explicit guidance on how to address it. The authors are left to infer that they should revise or eliminate the redundant sentences, but the comment lacks concrete instructions on which sentences to target or how to rephrase them. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the draft, namely the presence of too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not specify which sentences are identical or provide guidance on how to address this issue. The authors can infer that the comment pertains to these sections, but the lack of specificity makes it difficult to pinpoint the exact sentences that need revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand which sentences are redundant or how to address the issue. Without detailed evidence or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion. While this feedback highlights a potential problem with redundancy, it lacks depth and does not provide actionable guidance on how to address the issue. The authors are left to infer that they should revise or eliminate the redundant sentences, but the comment does not specify which sentences are problematic or how to rephrase them to improve the draft. As a result, the comment is somewhat helpful, as it points out a potential issue but does not offer detailed suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the reward function used in the ablation studies, specifically questioning whether it is sEH. This direct request for information provides a clear and explicit action for the authors to take, which is to specify the reward function used in their study. The comment is actionable because it directly instructs the authors on what information is needed to improve their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Reward Function\" and the \"ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification about the reward function used in the ablation studies, particularly whether it is sEH. This provides clear guidance on what information is needed to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the reward function used in the ablation studies, specifically questioning whether it is sEH. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for clarification regarding the reward function used in the ablation studies, specifically questioning whether it is sEH. While it identifies a specific area that needs clarification, it does not provide any additional context or suggestions for improvement. The comment is somewhat helpful as it prompts the authors to clarify a technical detail, but it lacks depth and actionable guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. However, it does not provide explicit guidance on how the authors should address this issue or improve the fairness of their comparison. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the comparison, but without clear grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code instead of a placeholder is not a fair comparison due to the sampling process. However, it does not provide specific reasoning or evidence to support why this is the case. The comment lacks detailed explanation or references to substantiate the claim, making it difficult for the authors to understand and address the issue. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. It highlights a specific concern that the authors should address, which is important for ensuring the validity of their results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their comparison. While it points out a critical area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that sections 3 and 4, which are currently squeezed into a single page, should be expanded to better present the main contributions of the paper. It specifically mentions the lack of precise mathematical definitions of quantum states in Eq (4), which makes it difficult to follow. This feedback provides a clear and concrete action for the authors to take, namely to expand these sections and include the necessary mathematical definitions. The comment is explicit and provides specific guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the issue of these sections being squeezed into a single page and highlights the missing precise mathematical definitions of quantum states in Eq (4), which makes it difficult to follow. This provides clear guidance on what needs to be addressed in terms of content and presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that sections 3 and 4 should be expanded to better present the main contributions of the paper, as they are currently squeezed into a single page. The reviewer provides a specific example by mentioning the lack of precise mathematical definitions of quantum states in Eq (4), which makes it difficult to follow. This claim is supported by logical reasoning and a specific example, making it mostly verifiable. However, the comment could be strengthened by providing additional examples or references to similar papers that effectively present complex mathematical concepts. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that sections 3 and 4, which are crucial for presenting the main contributions, are squeezed into a single page. It highlights a particular example, the lack of precise mathematical definitions of quantum states in Eq (4), which makes it difficult for readers to follow. This feedback is clear and actionable, as it directs the authors to expand these sections and include the necessary mathematical details. However, the comment could be more helpful if it provided suggestions on how to present these definitions or examples to enhance clarity. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting specific analyses or methodologies to investigate fairness. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic could be addressed, the comment lacks full grounding. It is specific in its concern about fairness and discrimination, but without explicit references to sections, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. This is a critical issue that the authors should address to ensure the ethical and unbiased nature of their work. However, the comment lacks specific guidance or suggestions on how to investigate or mitigate this potential bias. While it highlights a significant concern, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific and actionable feedback, suggesting that the authors should address the length of the paragraph describing Co-variance in Section 1, which is affecting the legibility of the paper. It also recommends adding more details to the experiments on long-tailed datasets, which are crucial for affirming the paper\\'s contribution. Additionally, it suggests that the authors could use more pages to present the tables and figures, as the experiments on long-tailed datasets are more important for the paper. Each of these suggestions is explicit and provides concrete guidance on how to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and \"Co-variance,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be improved: the length of the paragraph describing Co-variance, the need for more details on the experiments with long-tailed datasets, and the suggestion to use more pages for tables and figures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of observations and suggestions for improvement, such as the length of a paragraph and the need for more details on experiments. These are factual statements that do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It identifies that the paragraph describing Co-variance in Section 1 is too long, suggesting that the authors should shorten it to improve legibility. Additionally, it points out that the experiments on long-tailed datasets are crucial for affirming the paper\\'s contribution and recommends adding more details to these sections. The comment also suggests that the authors could use more pages for the tables and figures, as the experiments on long-tailed datasets are more important for the paper. This feedback is clear and constructive, offering the authors concrete steps to enhance the clarity and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes needed to make EC-Diffusers work on real-world data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific changes are needed or how to implement them. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, nor does it provide any specific details or suggestions on what those changes might be. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper this question addresses. Additionally, the comment lacks specificity in terms of what changes are needed or how to implement them. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the necessary changes to make EC-Diffusers work on real-world data. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The authors are left without clear direction on what specific changes are needed or how to address the issue. The comment is vague and does not provide enough detail to be helpful, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. While the comment implies that the authors should consider conducting a human study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for a human study to assess the evaluation protocol, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reliability of the evaluation and the inclusion of a human study to gauge the efficacy of the evaluation protocol. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reliability of the evaluation process, specifically inquiring whether there is a human study to gauge the efficacy of the evaluation protocol. This feedback is valuable as it prompts the authors to consider the human element in their evaluation, which could enhance the robustness and credibility of their work. However, the comment lacks specific guidance or suggestions on how to incorporate a human study or what aspects of the evaluation protocol could be improved. While it identifies an area for enhancement, it does not provide detailed, actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. However, it does not provide explicit guidance or suggestions on how to conduct such a study or what aspects of the evaluation protocol should be assessed. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they should consider a human study, but the comment does not provide specific steps or examples for implementation. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for a human study to assess the evaluation protocol, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the reliability of the evaluation and the inclusion of a human study to gauge the efficacy of the evaluation protocol. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the reliability of the evaluation process, specifically inquiring whether there is a human study to gauge the efficacy of the evaluation protocol. This feedback is valuable as it prompts the authors to consider the human element in their evaluation, which could enhance the robustness and credibility of their work. However, the comment lacks specific guidance or suggestions on how to incorporate a human study or what aspects of the evaluation protocol should be assessed. While it identifies an area for improvement, it does not provide detailed, actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the reliability of the evaluation and suggests the inclusion of a human study to gauge the efficacy of the evaluation protocol. However, it does not provide explicit guidance or instructions on how the authors should conduct such a study or what specific aspects should be evaluated. The action is implicit and lacks concrete details, making it somewhat actionable. The authors can infer that they should consider a human study, but the comment does not provide a clear path for implementation. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the reliability of the evaluation"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, noting that it seems somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty of their work or differentiate it from existing contributions. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, it is rated as a 1 on the actionability scale.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not specify which part of the paper this comparison is based on, nor does it provide details on how the work is incremental or lacks novelty. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, the comment does not provide specific examples or detailed reasoning to support this claim. Without explicit references or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the novelty of the work, suggesting that it appears somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). While it identifies a potential issue with the paper\\'s contribution, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the performance of PromptMix, which is dependent on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment implies that such an analysis should be conducted, it does not explicitly instruct the authors to perform these tasks. The action is implicit but concrete, as the authors can infer the need for an analysis and understand the specific aspects to consider. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the performance of PromptMix and its dependence on the quality of questions/answers generated by the LLM. It suggests an analysis to determine which open-source LLMs would work with this approach and identifies a potential parameter count cutoff (e.g., 7B) below which performance might degrade. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the performance of PromptMix is discussed. The comment is specific in detailing what needs to be addressed, providing clear guidance on potential analyses to conduct. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by the LLM. It implies that using a high-quality model is essential for success, but it does not provide specific evidence or examples to support this claim. The suggestion to analyze which open-source LLMs would work with this approach or find a parameter count cutoff is a logical extension of the comment, but it lacks detailed justification or references. Therefore, the claim is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive support or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the paper, namely the dependence of PromptMix\\'s performance on the quality of questions/answers generated by the LLM. It suggests that using a high-quality model is essential for the success of the task and provides a specific direction for improvement by recommending an analysis of which open-source LLMs would work with this approach. Additionally, it suggests finding a parameter count cutoff (e.g., 7B) below which performance might degrade. This feedback is clear and actionable, offering the authors a concrete path to enhance their work by exploring the compatibility of different LLMs and determining performance thresholds. However, the comment could be more helpful if it included specific examples or references to existing LLMs or studies that could be used for comparison. Overall, the comment is mostly helpful as it provides valuable insights and actionable steps for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment highlights a potential issue with the performance of PromptMix, which is dependent on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance might degrade would be beneficial. While the comment implies that such an analysis should be conducted, it does not explicitly instruct the authors to perform these tasks. The action is implicit but concrete, as the authors can infer the need for an analysis and understand the specific aspects to consider. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the performance of PromptMix and its dependence on the quality of questions/answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance might degrade would be beneficial. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the performance of PromptMix is discussed. The comment is specific in detailing what needs to be addressed, providing clear guidance on potential analyses to conduct. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential issue with the performance of PromptMix, which is dependent on the quality of questions/answers generated by the LLM. It suggests that using a high-quality model is essential for the success of the task and provides a logical suggestion for further analysis, such as determining which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance might degrade. While the comment provides a reasonable suggestion, it lacks specific"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment implies that the authors should provide more information on the scalability and runtimes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the scalability and runtimes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and references the SATURATE algorithm from Krause et al., 2008, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the approach and suggesting that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. The reviewer suggests that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the scalability. The suggestion to comment on feasibility is logical, but without additional evidence or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. This feedback is clear and actionable, as it directs the authors to provide more detailed information on the scalability and performance of their approach. However, the comment could be more helpful if it included specific suggestions on how to analyze and present the runtimes or offered additional context on why this scalability is a concern. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment implies that the authors should provide more information on the scalability and runtimes, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the scalability and runtimes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"submodularity approach subroutine\" and references the SATURATE algorithm from Krause et al., 2008, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the approach and suggesting that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the submodularity approach subroutine, which uses the SATURATE algorithm and is said to scale with N^5. It suggests that the authors comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim about the scalability. The suggestion to comment on feasibility is logical, but without additional evidence or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Ver"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the explanation of inference at test time could be improved by providing more details. While it implies that the authors should add more information, it does not specify what aspects need further elaboration or how to structure this additional detail. The action is implicit and somewhat vague, as the authors know they need to provide more details but may not be entirely sure of the exact content or format. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to a specific line number, \"594,\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. However, the comment lacks specificity as it does not detail what specific aspects of the inference at test time explanation need more details or clarification. Without additional context or suggestions, the authors may find it challenging to determine exactly what needs to be addressed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the explanation of inference at test time is brief and could benefit from more details. However, it does not provide any specific reasoning, examples, or references to support why this explanation is insufficient or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved by providing more details about inference at test time. While it highlights a potential weakness, it does not offer specific suggestions or guidance on what additional details should be included or how they could be presented. This limits the usefulness of the feedback, as the authors are left with a general idea of what needs to be addressed but without actionable steps to take. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comments are more of an observation or critique rather than actionable feedback, leaving the authors without clear steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several specific issues related to the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors may find it challenging to understand and address the issues without additional context or evidence. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the points.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas of concern regarding the evaluation of programs generated by CodeChain. It questions the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their evaluation. While it highlights important areas for consideration, it does not provide actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but does not offer detailed guidance for implementation.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review point raises several concerns about the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their evaluation. The comment lacks actionable steps or concrete advice, leaving the authors without clear direction on how to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several concerns about the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns, but without clear references to sections or figures, the authors may struggle to pinpoint where these issues are addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the evaluation of programs generated by CodeChain, including the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the points.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas of concern regarding the evaluation of programs generated by CodeChain. It questions the alignment of modality and reusability with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the argument presented in lines 306-307 regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. The reviewer suggests that this could imply a less even distribution of error rates across subgroups, which would indicate a lack of fairness. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit and vague, as the authors are left to infer that they should explore the implications of this argument and potentially provide a more nuanced discussion on fairness. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 306-307, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the argument presented in those lines, suggesting that it implies a less even distribution of error rates across subgroups, which would indicate a lack of fairness. The comment provides a clear direction for the authors to consider and potentially address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the argument presented in lines 306-307 regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. The reviewer suggests that this could imply a less even distribution of error rates across subgroups, which would indicate a lack of fairness. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the argument presented in lines 306-307, questioning the implications of the claim regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. The reviewer suggests that this could imply a less even distribution of error rates across subgroups, which would indicate a lack of fairness. This feedback is valuable as it prompts the authors to reconsider their argument and potentially provide a more nuanced discussion on fairness. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue or further explore the implications of the claim. Overall, the comment is somewhat helpful as it identifies a potential weakness in the argument and encourages further exploration, but it lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report the improvement on object classification directly, in addition to the overall scene graph results. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to strengthen their paper. The feedback is specific and actionable, offering a concrete step for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that the relational embedding module improves object classification, noting that no results are provided to support this claim. The comment suggests a specific action\u2014reporting the improvement on object classification directly in addition to the overall scene graph results\u2014to strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s assertion about the relational embedding module\\'s improvement in object classification is not supported by any results. This claim is somewhat verifiable as it highlights a gap in the evidence provided for the claim. However, it lacks specific examples or references to substantiate the claim further. The authors would need to provide additional information or data to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module\\'s improvement in object classification is not supported by any results. It provides a clear and actionable suggestion for the authors to report the improvement on object classification directly, in addition to the overall scene graph results. This feedback is valuable as it guides the authors on how to strengthen their paper by providing concrete evidence for their claims. However, the comment could be more helpful if it offered additional guidance on how to present these results or what specific metrics should be used. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a critique of the paper\\'s scope, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small, as it primarily adds self-supervised learning on top of existing work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the scope of the paper, specifically mentioning the combination of self-supervised learning with multimodal representation learning based on hypergraph. It references a previous CVPR 2020 paper, which provides a specific point of comparison. However, the comment does not explicitly mention which part of the paper this critique pertains to, such as a specific section or figure. While the authors might infer that it relates to the methodology or related work sections, this inference is not direct. The comment is specific in identifying the novelty as relatively small compared to existing work, but it lacks full grounding due to the absence of explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the scope of the paper is narrow, as it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer supports this claim by referencing the CVPR 2020 paper, providing a specific example of existing work. However, the comment could be strengthened by elaborating on how the novelty of the manuscript is limited to the addition of self-supervised learning on top of existing multimodal learning approaches. While the reference to the CVPR 2020 paper provides some support, the claim could be more robust with additional details or comparisons. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a critique of the paper\\'s scope, noting that the combination of self-supervised learning with multimodal representation learning based on hypergraph is not novel, as it has been explored in a previous CVPR 2020 paper. The reviewer suggests that the only novel aspect of the manuscript is the addition of self-supervised learning on top of existing work, which is considered relatively small. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should include more examples, clarify the examples provided, or address any specific issues related to the examples in Figure 4. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difficulty of finding intuitive attention examples, providing a clear direction for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The authors are left without clear direction on how to address the issue or what specific aspects of the examples could be improved. The comment is somewhat helpful as it prompts the authors to consider the clarity and intuitiveness of their attention examples, but it does not provide detailed feedback or suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difference between 01 and 10 in Figure 1. While it does not explicitly instruct the authors to make a change, the question implies that the authors should clarify this difference in their draft. The action is implicit but concrete, as the authors know exactly what information needs to be clarified. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the difference between 01 and 10 in the figure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the difference between 01 and 10 in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difference between 01 and 10 in Figure 1. While it identifies a specific area that needs clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their figure. The comment lacks depth and actionable feedback, leaving the authors with a general question but no clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to separate the \"Related Work\" section from the \"Introduction\" section, suggesting that the current structure is confusing. It provides a specific suggestion to move the three bullet points about traditional, deep neural, and pre-training AES to the \"Related Work\" section. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what changes to make to improve the organization of their paper.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Introduction\" section and the \"Related Work\" section, providing full grounding as the authors can accurately identify the parts of the paper being addressed. It specifies the issue by suggesting that the current structure is confusing, with the introduction and related work sections mixed together. The comment also provides a specific suggestion to move the three bullet points about traditional, deep neural, and pre-training AES to the \"Related Work\" section. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current structure of the paper is confusing, with the \"Introduction\" section containing both an introduction and related work sections. The reviewer proposes moving the three bullet points about traditional, deep neural, and pre-training AES to the \"Related Work\" section. While the comment provides a logical suggestion for improving the paper\\'s organization, it lacks specific examples or references to support the claim that the current structure is confusing. This makes the comment somewhat verifiable, as it provides a reasonable suggestion but lacks detailed justification or evidence to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the organization of the paper by separating the \"Related Work\" section from the \"Introduction\" section. It identifies a specific issue with the current structure, where the introduction and related work sections are mixed, making it confusing for the reader. The reviewer offers a specific solution by recommending the relocation of the three bullet points about traditional, deep neural, and pre-training AES to the \"Related Work\" section. This feedback is clear and constructive, as it helps the authors enhance the clarity and flow of their paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could present the overall process and rationale for construction more clearly. While it implies that the authors should improve the clarity of this section, it does not provide specific guidance on how to achieve this clarity. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of rules and data augmentation methods used in constructing the benchmark, indicating that the overall process and rationale could be presented more clearly. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the process and rationale should be presented more clearly, but without explicit grounding, it remains challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could present the overall process and rationale for construction more clearly. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks explicit evidence or references to justify why the current presentation is unclear or how it could be improved. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient detail to fully substantiate the suggestion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the description of rules and data augmentation methods used in constructing the benchmark could be presented more clearly. While it highlights a potential weakness in the paper, it does not provide detailed guidance or suggestions on how to improve the clarity of this section. The feedback is somewhat helpful as it points out a specific area for enhancement, but it lacks depth and actionable advice, leaving the authors with a general direction to improve without specific steps to follow. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several areas where the paper lacks content, specifically mentioning the absence of a literature review on recent advances in active learning communities, particularly in Bayesian learning. It highlights the relevance of Bayesian Coreset to the work and suggests that the authors should discuss how their current setup is more advanced than related studies. While the comment provides explicit actions, such as conducting a literature review and discussing the advancement of the current setup, it does not offer detailed guidance on how to implement these actions. The authors are given a clear direction but may need to infer specific steps to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content in the literature review, specifically highlighting the absence of recent advances in active learning communities related to Bayesian learning. It provides a specific example of Bayesian Coreset being relevant to the work and suggests that the authors should discuss how their current setup is more advanced than related studies. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks content, specifically mentioning the absence of a literature review on recent advances in active learning communities related to Bayesian learning. The comment provides a specific example of Bayesian Coreset being relevant to the work but ignored in the literature review. It also references external works that discuss similar directions, suggesting that the current setup may not be as advanced as claimed. While the comment provides some reasoning and references, it lacks detailed examples or specific comparisons to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper, specifically the lack of a comprehensive literature review on recent advances in active learning communities, particularly in Bayesian learning. It highlights the relevance of Bayesian Coreset to the work and suggests that the authors should include it in their literature review. Additionally, the comment points out that there are multiple works discussing similar directions, such as combining uncertainty with Coreset, and suggests that the authors should discuss how their current setup is more advanced than related studies. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it offered additional guidance on how to incorporate these suggestions into the paper. Overall, the comment is mostly helpful, as it effectively directs the authors toward enhancing the content and depth of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, it does not provide any explicit or implicit suggestions on how the authors might address these issues. There is no guidance on whether the authors should simplify the plot, clarify the trends, or remove the noise. Without actionable advice or specific steps to improve the figure, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the \"one-to-many relationship\" and the presence of noise in the plots, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Fig 2, noting that the \"one-to-many relationship\" makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This feedback is somewhat helpful as it highlights a potential weakness in the visual representation of data, which could impact the clarity and effectiveness of the paper. However, the comment lacks detailed guidance or suggestions on how the authors might address these issues, such as recommending ways to simplify the plot or clarify the trends. Without actionable advice, the authors may find it challenging to improve the draft based on this feedback alone. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of the comparison with existing algorithms like Performer and Reformer, which are often not deeply optimized. It also questions whether DFSSATTEN supports training from scratch, suggesting that this aspect should be studied. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to consider the fairness of their comparisons and investigate DFSSATTEN\\'s support for training from scratch, but the guidance is not as concrete as it could be. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison of DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that the comparison might be unfair due to the lack of deep optimization in these algorithms. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. However, the comment does not specify which part of the paper discusses these comparisons or the training process, making it weakly grounded. The comment is specific in detailing the issues with the comparison and the importance of training from scratch, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the fairness of the comparison between DFSSATTEN and existing algorithms like Performer and Reformer, noting that these algorithms are often not deeply optimized. The reviewer suggests that directly comparing DFSSATTEN with them might be unfair. Additionally, the comment questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. While the comment provides logical reasoning and highlights potential issues, it lacks specific references or examples to fully substantiate the claims. This makes the comment mostly verifiable, as it provides a reasonable basis for the claims but requires further elaboration to be fully convincing.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises important concerns about the fairness of the comparison between DFSSATTEN and existing algorithms like Performer and Reformer, noting that these algorithms are often not deeply optimized. It suggests that directly comparing DFSSATTEN with them might be unfair. Additionally, the comment questions whether DFSSATTEN supports training from scratch, which is a significant direction given the popularity of pretraining. The reviewer provides a clear and actionable suggestion for future work, recommending that DFSSATTEN should be studied for its ability to accelerate training from scratch. This feedback is valuable as it prompts the authors to consider a critical aspect of their method that may not have been adequately addressed. However, the comment could be more helpful if it offered specific guidance on how to investigate these aspects or provided examples of how to approach the comparison. Overall, the comment is mostly helpful, as it identifies a significant area for improvement and provides a clear direction for further exploration.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on whether the authors should address this concern, clarify the evaluation process, or provide additional details. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, the comment lacks specificity and does not provide any guidance or suggestions for the authors to address this issue. Without additional context or actionable feedback, the authors are left without a clear understanding of how to improve their work. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on whether the authors should address this concern, clarify the evaluation process, or provide additional details. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what needs to be addressed or improved in this context. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, the comment lacks supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not provide any specific guidance or suggestions for the authors to address this issue. Without actionable feedback or detailed explanation, the authors are left without a clear understanding of how to improve their work. The comment lacks depth and specificity, making it unhelpful for the authors. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, questioning whether it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take in response"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved and refers the authors to the questions section for details. However, it does not provide specific guidance or examples of what aspects of the method\\'s description need clarification or how to improve it. The action is implicit, as the authors need to infer that they should address the clarity of the method\\'s description, and it is vague because it lacks concrete details on how to achieve this improvement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this description is located in. The authors might infer that it relates to the methodology section, but this inference is not direct. Additionally, the comment does not provide specific details on what aspects of the method\\'s description are unclear or how they could be improved. Without explicit references or detailed guidance, the authors cannot effectively address the feedback. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide any specific examples or detailed reasoning to support this claim. The comment refers to the \"questions section\" for details, but without those details, the authors are left without guidance on how to address the issue. This lack of specific evidence or justification makes the claim unverifiable, as it does not provide sufficient information for the authors to understand and improve upon the issue.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide specific details or examples of what aspects of the description are unclear or how they could be clarified. This lack of specificity and actionable guidance limits the usefulness of the feedback for the authors. Without detailed suggestions or examples, the authors may struggle to understand and address the issue effectively. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not offer sufficient guidance for the authors to make meaningful changes.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in a GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and asks whether this is observed in empirical evaluations or if the authors can explain why such correlations are not considered. While the comment implies that the authors should investigate this issue, it does not provide explicit instructions or concrete steps on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore this correlation further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of pruning strategies across different layers in a GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and asks whether this is observed in empirical evaluations or if the authors can explain why such correlations are not considered. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where pruning strategies are discussed. The comment is specific in questioning the independence of pruning strategies across layers and suggesting an empirical evaluation or explanation. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in a GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and asks whether this is observed in empirical evaluations or if the authors can explain why such correlations are not considered. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a request for clarification or further explanation, fitting the classification of \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the independence of pruning strategies across different layers in a GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and asks whether this is observed in empirical evaluations or if the authors can explain why such correlations are not considered. This feedback is somewhat helpful as it prompts the authors to consider the interdependencies of pruning strategies across layers, which could be an important aspect of their methodology. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or where in the paper this observation should be considered. To be more helpful, the comment could provide additional context or suggest ways to explore this correlation empirically. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide explicit guidance on how the authors should address this concern or suggest specific steps to consider other in-distribution datasets. The action is implicit and vague, as the authors are left to infer that they should broaden their experimental validation but without clear instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does provide some level of specificity by questioning whether the conclusions would generalize to other in-distribution datasets and suggesting that some datasets might need to be nuanced. However, it lacks detailed guidance on how to address this concern or what specific datasets should be considered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the concern. The mention of \"NB: If this is customary\" suggests that the reviewer is questioning the validity of the experimental setup rather than identifying a specific flaw in the work. Therefore, the claim is somewhat verifiable, as it provides a logical basis for the concern but lacks detailed evidence or references to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. This feedback highlights an important aspect of the experimental setup that the authors should consider, as it impacts the generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this concern, such as recommending additional datasets to consider or how to evaluate generalizability. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific steps to take to evaluate generalizability. The action is implicit and lacks concrete details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. It raises a concern about whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment provides some level of specificity by questioning the generalizability of the conclusions and suggesting that some datasets might need to be nuanced, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand the basis of the concern. The mention of \"NB: If this is customary\" suggests that the reviewer is questioning the validity of the experimental setup rather than identifying a specific flaw in the work. Therefore, the claim is somewhat verifiable, as it provides a logical basis for the concern but lacks detailed evidence or references to fully substantiate it.', 'verifi"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks concrete guidance on how to implement this suggestion, such as specifying which parts of the paper should include this information or how to present the gradient conflicts ratio. The authors are given a clear direction but without detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This provides clear guidance on what needs to be addressed in the table, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that AlphaNets trained with alpha-divergence do not benefit from the method described in the paper. It implies that showing the gradient conflicts ratio for these AlphaNets could provide insights. However, the comment lacks specific evidence or reasoning to support this claim, such as comparisons with other methods or detailed analysis of the results. This makes the claim somewhat verifiable, as the authors would need to further investigate and provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alpha-divergence do not seem to benefit from the method described in the paper. It suggests that showing the gradient conflicts ratio for these AlphaNets could provide insights. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify or provide additional information. However, it lacks detailed guidance on how to present the gradient conflicts ratio or what insights it might reveal. To be more helpful, the comment could include suggestions on how to present this information or what specific insights the gradient conflicts ratio might offer. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks concrete guidance on how to implement this suggestion, such as specifying which parts of the paper should include this information or how to present the gradient conflicts ratio. The authors are given a clear direction but without detailed instructions on execution, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This provides clear guidance on what needs to be addressed in the table, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that AlphaNets trained with alpha-divergence do not benefit from the method described in the paper, and it implies that showing the gradient conflicts ratio for these AlphaNets could provide insights. However, the comment lacks specific evidence or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to further investigate and provide additional context to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alpha-divergence do not seem to benefit from the method described in the paper. It suggests that showing the gradient conflicts ratio for these AlphaNets could provide insights. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify or provide additional information. However, the comment lacks detailed guidance on how to present the gradient conflicts ratio or what insights it might reveal. To be more helpful, the comment could include suggestions on how to present this information or what specific insights the gradient conflicts ratio might offer. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the explicit SDF supervision and suggests that it could be simplified by applying the loss on the 3D location without occlusion reasoning. It also implies that a good reason or ablation study for the current setup is missing. While the comment identifies a potential issue and suggests a simpler approach, it does not explicitly instruct the authors to make these changes or conduct an ablation study. The action is implicit and somewhat vague, as the authors need to infer the need for simplification and the potential benefits of an ablation study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.2,\" \"L. 165,\" and \"L. 173,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the current setup of explicit SDF supervision, questioning the necessity of occlusion handling and view-awareness. The comment suggests a simpler approach and requests a good reason or ablation study for the current setup. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of the explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach. The reviewer provides a logical reasoning by questioning the complexity of the current setup and suggesting a more straightforward method. However, the comment lacks specific examples or references to support the claim that the current setup is unnecessary or inefficient. This makes the claim somewhat verifiable, as it provides a basis for questioning the current approach but requires more detailed justification or evidence to fully substantiate the critique.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the paper regarding the explicit SDF supervision, specifically questioning the necessity of occlusion handling and view-awareness. It suggests a simpler approach by proposing to apply the loss on the 3D location without occlusion reasoning, which seems more straightforward. The comment also points out the absence of a good reason or ablation study for the current setup, indicating that a more thorough justification or comparison is missing. This feedback is clear and actionable, as it provides a specific suggestion for simplifying the approach and highlights the need for additional justification or analysis. However, it could be more helpful if it included specific examples or guidance on how to conduct the suggested ablation study. Overall, the comment is mostly helpful, as it effectively directs the authors to improve the clarity and robustness of their methodology.', 'helpfulness_label': '4'}"}
